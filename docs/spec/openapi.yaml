openapi: 3.0.0
info:
  title: OpenAI API
  description: The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference
    for more details.
  termsOfService: https://openai.com/policies/terms-of-use
  contact:
    name: OpenAI Support
    url: https://help.openai.com/
  license:
    name: MIT
    url: https://github.com/openai/openai-openapi/blob/master/LICENSE
  version: 2.3.0
servers:
- url: https://api.openai.com/v1
security:
- ApiKeyAuth: []
tags:
- name: Assistants
  description: Build Assistants that can call models and use tools.
- name: Audio
  description: Turn audio into text or text into audio.
- name: Chat
  description: "Given a list of messages comprising a conversation, the model will\
    \ return a response."
- name: Completions
  description: "Given a prompt, the model will return one or more predicted completions,\
    \ and can also return the probabilities of alternative tokens at each position."
- name: Embeddings
  description: Get a vector representation of a given input that can be easily consumed
    by machine learning models and algorithms.
- name: Evals
  description: Manage and run evals in the OpenAI platform.
- name: Fine-tuning
  description: Manage fine-tuning jobs to tailor a model to your specific training
    data.
- name: Batch
  description: Create large batches of API requests to run asynchronously.
- name: Files
  description: Files are used to upload documents that can be used with features like
    Assistants and Fine-tuning.
- name: Uploads
  description: Use Uploads to upload large files in multiple parts.
- name: Images
  description: "Given a prompt and/or an input image, the model will generate a new\
    \ image."
- name: Models
  description: List and describe the various models available in the API.
- name: Moderations
  description: "Given text and/or image inputs, classifies if those inputs are potentially\
    \ harmful."
- name: Audit Logs
  description: List user actions and configuration changes within this organization.
paths:
  /assistants:
    get:
      tags:
      - Assistants
      summary: Returns a list of assistants.
      operationId: listAssistants
      parameters:
      - name: limit
        in: query
        description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20
        required: false
        style: form
        explode: true
        schema:
          type: integer
          default: 20
      - name: order
        in: query
        description: |
          Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order
        required: false
        style: form
        explode: true
        schema:
          type: string
          default: desc
          enum:
          - asc
          - desc
      - name: after
        in: query
        description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list
        required: false
        style: form
        explode: true
        schema:
          type: string
      - name: before
        in: query
        description: |
          A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list
        required: false
        style: form
        explode: true
        schema:
          type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListAssistantsResponse'
      x-oaiMeta:
        name: List assistants
        group: assistants
        beta: true
        returns: "A list of [assistant](/docs/api-reference/assistants/object) objects."
        examples:
          request:
            curl: |
              curl "https://api.openai.com/v1/assistants?order=desc&limit=20" \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              my_assistants = client.beta.assistants.list(
                  order="desc",
                  limit="20",
              )
              print(my_assistants.data)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const myAssistants = await openai.beta.assistants.list({
                  order: "desc",
                  limit: "20",
                });

                console.log(myAssistants.data);
              }

              main();
          response: |
            {
              "object": "list",
              "data": [
                {
                  "id": "asst_abc123",
                  "object": "assistant",
                  "created_at": 1698982736,
                  "name": "Coding Tutor",
                  "description": null,
                  "model": "gpt-4o",
                  "instructions": "You are a helpful assistant designed to make me better at coding!",
                  "tools": [],
                  "tool_resources": {},
                  "metadata": {},
                  "top_p": 1.0,
                  "temperature": 1.0,
                  "response_format": "auto"
                },
                {
                  "id": "asst_abc456",
                  "object": "assistant",
                  "created_at": 1698982718,
                  "name": "My Assistant",
                  "description": null,
                  "model": "gpt-4o",
                  "instructions": "You are a helpful assistant designed to make me better at coding!",
                  "tools": [],
                  "tool_resources": {},
                  "metadata": {},
                  "top_p": 1.0,
                  "temperature": 1.0,
                  "response_format": "auto"
                },
                {
                  "id": "asst_abc789",
                  "object": "assistant",
                  "created_at": 1698982643,
                  "name": null,
                  "description": null,
                  "model": "gpt-4o",
                  "instructions": null,
                  "tools": [],
                  "tool_resources": {},
                  "metadata": {},
                  "top_p": 1.0,
                  "temperature": 1.0,
                  "response_format": "auto"
                }
              ],
              "first_id": "asst_abc123",
              "last_id": "asst_abc789",
              "has_more": false
            }
    post:
      tags:
      - Assistants
      summary: Create an assistant with a model and instructions.
      operationId: createAssistant
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateAssistantRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/AssistantObject'
      x-oaiMeta:
        name: Create assistant
        group: assistants
        beta: true
        returns: "An [assistant](/docs/api-reference/assistants/object) object."
        examples:
        - title: Code Interpreter
          request:
            curl: |
              curl "https://api.openai.com/v1/assistants" \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                  "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
                  "name": "Math Tutor",
                  "tools": [{"type": "code_interpreter"}],
                  "model": "gpt-4o"
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              my_assistant = client.beta.assistants.create(
                  instructions="You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
                  name="Math Tutor",
                  tools=[{"type": "code_interpreter"}],
                  model="gpt-4o",
              )
              print(my_assistant)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const myAssistant = await openai.beta.assistants.create({
                  instructions:
                    "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
                  name: "Math Tutor",
                  tools: [{ type: "code_interpreter" }],
                  model: "gpt-4o",
                });

                console.log(myAssistant);
              }

              main();
          response: |
            {
              "id": "asst_abc123",
              "object": "assistant",
              "created_at": 1698984975,
              "name": "Math Tutor",
              "description": null,
              "model": "gpt-4o",
              "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
              "tools": [
                {
                  "type": "code_interpreter"
                }
              ],
              "metadata": {},
              "top_p": 1.0,
              "temperature": 1.0,
              "response_format": "auto"
            }
        - title: Files
          request:
            curl: |
              curl https://api.openai.com/v1/assistants \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                  "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies.",
                  "tools": [{"type": "file_search"}],
                  "tool_resources": {"file_search": {"vector_store_ids": ["vs_123"]}},
                  "model": "gpt-4o"
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              my_assistant = client.beta.assistants.create(
                  instructions="You are an HR bot, and you have access to files to answer employee questions about company policies.",
                  name="HR Helper",
                  tools=[{"type": "file_search"}],
                  tool_resources={"file_search": {"vector_store_ids": ["vs_123"]}},
                  model="gpt-4o"
              )
              print(my_assistant)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const myAssistant = await openai.beta.assistants.create({
                  instructions:
                    "You are an HR bot, and you have access to files to answer employee questions about company policies.",
                  name: "HR Helper",
                  tools: [{ type: "file_search" }],
                  tool_resources: {
                    file_search: {
                      vector_store_ids: ["vs_123"]
                    }
                  },
                  model: "gpt-4o"
                });

                console.log(myAssistant);
              }

              main();
          response: |
            {
              "id": "asst_abc123",
              "object": "assistant",
              "created_at": 1699009403,
              "name": "HR Helper",
              "description": null,
              "model": "gpt-4o",
              "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies.",
              "tools": [
                {
                  "type": "file_search"
                }
              ],
              "tool_resources": {
                "file_search": {
                  "vector_store_ids": ["vs_123"]
                }
              },
              "metadata": {},
              "top_p": 1.0,
              "temperature": 1.0,
              "response_format": "auto"
            }
  /assistants/{assistantId}:
    get:
      tags:
      - Assistants
      summary: Retrieves an assistant.
      operationId: getAssistant
      parameters:
      - name: assistantId
        in: path
        description: The ID of the assistant to retrieve
        required: true
        style: simple
        explode: false
        schema:
          type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/AssistantObject'
      x-oaiMeta:
        name: Retrieve assistant
        group: assistants
        beta: true
        returns: "The [assistant](/docs/api-reference/assistants/object) object matching\
          \ the specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/assistants/asst_abc123 \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              my_assistant = client.beta.assistants.retrieve("asst_abc123")
              print(my_assistant)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const myAssistant = await openai.beta.assistants.retrieve(
                  "asst_abc123"
                );

                console.log(myAssistant);
              }

              main();
          response: |
            {
              "id": "asst_abc123",
              "object": "assistant",
              "created_at": 1699009709,
              "name": "HR Helper",
              "description": null,
              "model": "gpt-4o",
              "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies.",
              "tools": [
                {
                  "type": "file_search"
                }
              ],
              "metadata": {},
              "top_p": 1.0,
              "temperature": 1.0,
              "response_format": "auto"
            }
    post:
      tags:
      - Assistants
      summary: Modifies an assistant.
      operationId: modifyAssistant
      parameters:
      - name: assistantId
        in: path
        description: The ID of the assistant to modify
        required: true
        style: simple
        explode: false
        schema:
          type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ModifyAssistantRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/AssistantObject'
      x-oaiMeta:
        name: Modify assistant
        group: assistants
        beta: true
        returns: "The modified [assistant](/docs/api-reference/assistants/object)\
          \ object."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/assistants/asst_abc123 \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                    "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
                    "tools": [{"type": "file_search"}],
                    "model": "gpt-4o"
                  }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              my_updated_assistant = client.beta.assistants.update(
                "asst_abc123",
                instructions="You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
                name="HR Helper",
                tools=[{"type": "file_search"}],
                model="gpt-4o"
              )

              print(my_updated_assistant)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const myUpdatedAssistant = await openai.beta.assistants.update(
                  "asst_abc123",
                  {
                    instructions:
                      "You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
                    name: "HR Helper",
                    tools: [{ type: "file_search" }],
                    model: "gpt-4o"
                  }
                );

                console.log(myUpdatedAssistant);
              }

              main();
          response: |
            {
              "id": "asst_123",
              "object": "assistant",
              "created_at": 1699009709,
              "name": "HR Helper",
              "description": null,
              "model": "gpt-4o",
              "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
              "tools": [
                {
                  "type": "file_search"
                }
              ],
              "tool_resources": {
                "file_search": {
                  "vector_store_ids": []
                }
              },
              "metadata": {},
              "top_p": 1.0,
              "temperature": 1.0,
              "response_format": "auto"
            }
    delete:
      tags:
      - Assistants
      summary: Delete an assistant.
      operationId: deleteAssistant
      parameters:
      - name: assistantId
        in: path
        description: The ID of the assistant to delete
        required: true
        style: simple
        explode: false
        schema:
          type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DeleteAssistantResponse'
      x-oaiMeta:
        name: Delete assistant
        group: assistants
        beta: true
        returns: Deletion status
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/assistants/asst_abc123 \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2" \
                -X DELETE
            python: |
              from openai import OpenAI
              client = OpenAI()

              response = client.beta.assistants.delete("asst_abc123")
              print(response)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const response = await openai.beta.assistants.del("asst_abc123");

                console.log(response);
              }
              main();
          response: |
            {
              "id": "asst_abc123",
              "object": "assistant.deleted",
              "deleted": true
            }
  /audio/speech:
    post:
      tags:
      - Audio
      summary: Generates audio from the input text.
      operationId: createSpeech
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateSpeechRequest'
        required: true
      responses:
        "200":
          description: OK
          headers:
            Transfer-Encoding:
              description: chunked
              style: simple
              explode: false
              schema:
                type: string
          content:
            application/octet-stream:
              schema:
                type: string
                format: binary
      x-oaiMeta:
        name: Create speech
        group: audio
        returns: The audio file content.
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/audio/speech \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -d '{
                  "model": "gpt-4o-mini-tts",
                  "input": "The quick brown fox jumped over the lazy dog.",
                  "voice": "alloy"
                }' \
                --output speech.mp3
            python: |
              from pathlib import Path
              import openai

              speech_file_path = Path(__file__).parent / "speech.mp3"
              with openai.audio.speech.with_streaming_response.create(
                model="gpt-4o-mini-tts",
                voice="alloy",
                input="The quick brown fox jumped over the lazy dog."
              ) as response:
                response.stream_to_file(speech_file_path)
            javascript: |
              import fs from "fs";
              import path from "path";
              import OpenAI from "openai";

              const openai = new OpenAI();

              const speechFile = path.resolve("./speech.mp3");

              async function main() {
                const mp3 = await openai.audio.speech.create({
                  model: "gpt-4o-mini-tts",
                  voice: "alloy",
                  input: "Today is a wonderful day to build something people love!",
                });
                console.log(speechFile);
                const buffer = Buffer.from(await mp3.arrayBuffer());
                await fs.promises.writeFile(speechFile, buffer);
              }
              main();
            csharp: |
              using System;
              using System.IO;

              using OpenAI.Audio;

              AudioClient client = new(
                  model: "gpt-4o-mini-tts",
                  apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
              );

              BinaryData speech = client.GenerateSpeech(
                  text: "The quick brown fox jumped over the lazy dog.",
                  voice: GeneratedSpeechVoice.Alloy
              );

              using FileStream stream = File.OpenWrite("speech.mp3");
              speech.ToStream().CopyTo(stream);
  /audio/transcriptions:
    post:
      tags:
      - Audio
      summary: Transcribes audio into the input language.
      operationId: createTranscription
      requestBody:
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/CreateTranscriptionRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/InlineResponse200'
            text/event-stream:
              schema:
                $ref: '#/components/schemas/CreateTranscriptionResponseStreamEvent'
      x-oaiMeta:
        name: Create transcription
        group: audio
        returns: "The [transcription object](/docs/api-reference/audio/json-object),\
          \ a [verbose transcription object](/docs/api-reference/audio/verbose-json-object)\
          \ or a [stream of transcript events](/docs/api-reference/audio/transcript-text-delta-event)."
        examples:
        - title: Default
          request:
            curl: |
              curl https://api.openai.com/v1/audio/transcriptions \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: multipart/form-data" \
                -F file="@/path/to/file/audio.mp3" \
                -F model="gpt-4o-transcribe"
            python: |
              from openai import OpenAI
              client = OpenAI()

              audio_file = open("speech.mp3", "rb")
              transcript = client.audio.transcriptions.create(
                model="gpt-4o-transcribe",
                file=audio_file
              )
            javascript: |
              import fs from "fs";
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const transcription = await openai.audio.transcriptions.create({
                  file: fs.createReadStream("audio.mp3"),
                  model: "gpt-4o-transcribe",
                });

                console.log(transcription.text);
              }
              main();
            csharp: |
              using System;

              using OpenAI.Audio;
              string audioFilePath = "audio.mp3";

              AudioClient client = new(
                  model: "gpt-4o-transcribe",
                  apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
              );

              AudioTranscription transcription = client.TranscribeAudio(audioFilePath);

              Console.WriteLine($"{transcription.Text}");
          response: |
            {
              "text": "Imagine the wildest idea that you've ever had, and you're curious about how it might scale to something that's a 100, a 1,000 times bigger. This is a place where you can get to do that."
            }
        - title: Streaming
          request:
            curl: |
              curl https://api.openai.com/v1/audio/transcriptions \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: multipart/form-data" \
                -F file="@/path/to/file/audio.mp3" \
                -F model="gpt-4o-mini-transcribe" \
                -F stream=true
            python: |
              from openai import OpenAI
              client = OpenAI()

              audio_file = open("speech.mp3", "rb")
              stream = client.audio.transcriptions.create(
                file=audio_file,
                model="gpt-4o-mini-transcribe",
                stream=True
              )

              for event in stream:
                print(event)
            javascript: |
              import fs from "fs";
              import OpenAI from "openai";

              const openai = new OpenAI();

              const stream = await openai.audio.transcriptions.create({
                file: fs.createReadStream("audio.mp3"),
                model: "gpt-4o-mini-transcribe",
                stream: true,
              });

              for await (const event of stream) {
                console.log(event);
              }
          response: |
            data: {"type":"transcript.text.delta","delta":"I","logprobs":[{"token":"I","logprob":-0.00007588794,"bytes":[73]}]}

            data: {"type":"transcript.text.delta","delta":" see","logprobs":[{"token":" see","logprob":-3.1281633e-7,"bytes":[32,115,101,101]}]}

            data: {"type":"transcript.text.delta","delta":" skies","logprobs":[{"token":" skies","logprob":-2.3392786e-6,"bytes":[32,115,107,105,101,115]}]}

            data: {"type":"transcript.text.delta","delta":" of","logprobs":[{"token":" of","logprob":-3.1281633e-7,"bytes":[32,111,102]}]}

            data: {"type":"transcript.text.delta","delta":" blue","logprobs":[{"token":" blue","logprob":-1.0280384e-6,"bytes":[32,98,108,117,101]}]}

            data: {"type":"transcript.text.delta","delta":" and","logprobs":[{"token":" and","logprob":-0.0005108566,"bytes":[32,97,110,100]}]}

            data: {"type":"transcript.text.delta","delta":" clouds","logprobs":[{"token":" clouds","logprob":-1.9361265e-7,"bytes":[32,99,108,111,117,100,115]}]}

            data: {"type":"transcript.text.delta","delta":" of","logprobs":[{"token":" of","logprob":-1.9361265e-7,"bytes":[32,111,102]}]}

            data: {"type":"transcript.text.delta","delta":" white","logprobs":[{"token":" white","logprob":-7.89631e-7,"bytes":[32,119,104,105,116,101]}]}

            data: {"type":"transcript.text.delta","delta":",","logprobs":[{"token":",","logprob":-0.0014890312,"bytes":[44]}]}

            data: {"type":"transcript.text.delta","delta":" the","logprobs":[{"token":" the","logprob":-0.0110956915,"bytes":[32,116,104,101]}]}

            data: {"type":"transcript.text.delta","delta":" bright","logprobs":[{"token":" bright","logprob":0.0,"bytes":[32,98,114,105,103,104,116]}]}

            data: {"type":"transcript.text.delta","delta":" blessed","logprobs":[{"token":" blessed","logprob":-0.000045848617,"bytes":[32,98,108,101,115,115,101,100]}]}

            data: {"type":"transcript.text.delta","delta":" days","logprobs":[{"token":" days","logprob":-0.000010802739,"bytes":[32,100,97,121,115]}]}

            data: {"type":"transcript.text.delta","delta":",","logprobs":[{"token":",","logprob":-0.00001700133,"bytes":[44]}]}

            data: {"type":"transcript.text.delta","delta":" the","logprobs":[{"token":" the","logprob":-0.0000118755715,"bytes":[32,116,104,101]}]}

            data: {"type":"transcript.text.delta","delta":" dark","logprobs":[{"token":" dark","logprob":-5.5122365e-7,"bytes":[32,100,97,114,107]}]}

            data: {"type":"transcript.text.delta","delta":" sacred","logprobs":[{"token":" sacred","logprob":-5.4385737e-6,"bytes":[32,115,97,99,114,101,100]}]}

            data: {"type":"transcript.text.delta","delta":" nights","logprobs":[{"token":" nights","logprob":-4.00813e-6,"bytes":[32,110,105,103,104,116,115]}]}

            data: {"type":"transcript.text.delta","delta":",","logprobs":[{"token":",","logprob":-0.0036910512,"bytes":[44]}]}

            data: {"type":"transcript.text.delta","delta":" and","logprobs":[{"token":" and","logprob":-0.0031903093,"bytes":[32,97,110,100]}]}

            data: {"type":"transcript.text.delta","delta":" I","logprobs":[{"token":" I","logprob":-1.504853e-6,"bytes":[32,73]}]}

            data: {"type":"transcript.text.delta","delta":" think","logprobs":[{"token":" think","logprob":-4.3202e-7,"bytes":[32,116,104,105,110,107]}]}

            data: {"type":"transcript.text.delta","delta":" to","logprobs":[{"token":" to","logprob":-1.9361265e-7,"bytes":[32,116,111]}]}

            data: {"type":"transcript.text.delta","delta":" myself","logprobs":[{"token":" myself","logprob":-1.7432603e-6,"bytes":[32,109,121,115,101,108,102]}]}

            data: {"type":"transcript.text.delta","delta":",","logprobs":[{"token":",","logprob":-0.29254505,"bytes":[44]}]}

            data: {"type":"transcript.text.delta","delta":" what","logprobs":[{"token":" what","logprob":-0.016815351,"bytes":[32,119,104,97,116]}]}

            data: {"type":"transcript.text.delta","delta":" a","logprobs":[{"token":" a","logprob":-3.1281633e-7,"bytes":[32,97]}]}

            data: {"type":"transcript.text.delta","delta":" wonderful","logprobs":[{"token":" wonderful","logprob":-2.1008714e-6,"bytes":[32,119,111,110,100,101,114,102,117,108]}]}

            data: {"type":"transcript.text.delta","delta":" world","logprobs":[{"token":" world","logprob":-8.180258e-6,"bytes":[32,119,111,114,108,100]}]}

            data: {"type":"transcript.text.delta","delta":".","logprobs":[{"token":".","logprob":-0.014231676,"bytes":[46]}]}

            data: {"type":"transcript.text.done","text":"I see skies of blue and clouds of white, the bright blessed days, the dark sacred nights, and I think to myself, what a wonderful world.","logprobs":[{"token":"I","logprob":-0.00007588794,"bytes":[73]},{"token":" see","logprob":-3.1281633e-7,"bytes":[32,115,101,101]},{"token":" skies","logprob":-2.3392786e-6,"bytes":[32,115,107,105,101,115]},{"token":" of","logprob":-3.1281633e-7,"bytes":[32,111,102]},{"token":" blue","logprob":-1.0280384e-6,"bytes":[32,98,108,117,101]},{"token":" and","logprob":-0.0005108566,"bytes":[32,97,110,100]},{"token":" clouds","logprob":-1.9361265e-7,"bytes":[32,99,108,111,117,100,115]},{"token":" of","logprob":-1.9361265e-7,"bytes":[32,111,102]},{"token":" white","logprob":-7.89631e-7,"bytes":[32,119,104,105,116,101]},{"token":",","logprob":-0.0014890312,"bytes":[44]},{"token":" the","logprob":-0.0110956915,"bytes":[32,116,104,101]},{"token":" bright","logprob":0.0,"bytes":[32,98,114,105,103,104,116]},{"token":" blessed","logprob":-0.000045848617,"bytes":[32,98,108,101,115,115,101,100]},{"token":" days","logprob":-0.000010802739,"bytes":[32,100,97,121,115]},{"token":",","logprob":-0.00001700133,"bytes":[44]},{"token":" the","logprob":-0.0000118755715,"bytes":[32,116,104,101]},{"token":" dark","logprob":-5.5122365e-7,"bytes":[32,100,97,114,107]},{"token":" sacred","logprob":-5.4385737e-6,"bytes":[32,115,97,99,114,101,100]},{"token":" nights","logprob":-4.00813e-6,"bytes":[32,110,105,103,104,116,115]},{"token":",","logprob":-0.0036910512,"bytes":[44]},{"token":" and","logprob":-0.0031903093,"bytes":[32,97,110,100]},{"token":" I","logprob":-1.504853e-6,"bytes":[32,73]},{"token":" think","logprob":-4.3202e-7,"bytes":[32,116,104,105,110,107]},{"token":" to","logprob":-1.9361265e-7,"bytes":[32,116,111]},{"token":" myself","logprob":-1.7432603e-6,"bytes":[32,109,121,115,101,108,102]},{"token":",","logprob":-0.29254505,"bytes":[44]},{"token":" what","logprob":-0.016815351,"bytes":[32,119,104,97,116]},{"token":" a","logprob":-3.1281633e-7,"bytes":[32,97]},{"token":" wonderful","logprob":-2.1008714e-6,"bytes":[32,119,111,110,100,101,114,102,117,108]},{"token":" world","logprob":-8.180258e-6,"bytes":[32,119,111,114,108,100]},{"token":".","logprob":-0.014231676,"bytes":[46]}]}
        - title: Logprobs
          request:
            curl: |
              curl https://api.openai.com/v1/audio/transcriptions \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: multipart/form-data" \
                -F file="@/path/to/file/audio.mp3" \
                -F "include[]=logprobs" \
                -F model="gpt-4o-transcribe" \
                -F response_format="json"
            python: |
              from openai import OpenAI
              client = OpenAI()

              audio_file = open("speech.mp3", "rb")
              transcript = client.audio.transcriptions.create(
                file=audio_file,
                model="gpt-4o-transcribe",
                response_format="json",
                include=["logprobs"]
              )

              print(transcript)
            javascript: |
              import fs from "fs";
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const transcription = await openai.audio.transcriptions.create({
                  file: fs.createReadStream("audio.mp3"),
                  model: "gpt-4o-transcribe",
                  response_format: "json",
                  include: ["logprobs"]
                });

                console.log(transcription);
              }
              main();
          response: |
            {
              "text": "Hey, my knee is hurting and I want to see the doctor tomorrow ideally.",
              "logprobs": [
                { "token": "Hey", "logprob": -1.0415299, "bytes": [72, 101, 121] },
                { "token": ",", "logprob": -9.805982e-5, "bytes": [44] },
                { "token": " my", "logprob": -0.00229799, "bytes": [32, 109, 121] },
                {
                  "token": " knee",
                  "logprob": -4.7159858e-5,
                  "bytes": [32, 107, 110, 101, 101]
                },
                { "token": " is", "logprob": -0.043909557, "bytes": [32, 105, 115] },
                {
                  "token": " hurting",
                  "logprob": -1.1041146e-5,
                  "bytes": [32, 104, 117, 114, 116, 105, 110, 103]
                },
                { "token": " and", "logprob": -0.011076359, "bytes": [32, 97, 110, 100] },
                { "token": " I", "logprob": -5.3193703e-6, "bytes": [32, 73] },
                {
                  "token": " want",
                  "logprob": -0.0017156356,
                  "bytes": [32, 119, 97, 110, 116]
                },
                { "token": " to", "logprob": -7.89631e-7, "bytes": [32, 116, 111] },
                { "token": " see", "logprob": -5.5122365e-7, "bytes": [32, 115, 101, 101] },
                { "token": " the", "logprob": -0.0040786397, "bytes": [32, 116, 104, 101] },
                {
                  "token": " doctor",
                  "logprob": -2.3392786e-6,
                  "bytes": [32, 100, 111, 99, 116, 111, 114]
                },
                {
                  "token": " tomorrow",
                  "logprob": -7.89631e-7,
                  "bytes": [32, 116, 111, 109, 111, 114, 114, 111, 119]
                },
                {
                  "token": " ideally",
                  "logprob": -0.5800861,
                  "bytes": [32, 105, 100, 101, 97, 108, 108, 121]
                },
                { "token": ".", "logprob": -0.00011093382, "bytes": [46] }
              ]
            }
        - title: Word timestamps
          request:
            curl: |
              curl https://api.openai.com/v1/audio/transcriptions \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: multipart/form-data" \
                -F file="@/path/to/file/audio.mp3" \
                -F "timestamp_granularities[]=word" \
                -F model="whisper-1" \
                -F response_format="verbose_json"
            python: |
              from openai import OpenAI
              client = OpenAI()

              audio_file = open("speech.mp3", "rb")
              transcript = client.audio.transcriptions.create(
                file=audio_file,
                model="whisper-1",
                response_format="verbose_json",
                timestamp_granularities=["word"]
              )

              print(transcript.words)
            javascript: |
              import fs from "fs";
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const transcription = await openai.audio.transcriptions.create({
                  file: fs.createReadStream("audio.mp3"),
                  model: "whisper-1",
                  response_format: "verbose_json",
                  timestamp_granularities: ["word"]
                });

                console.log(transcription.text);
              }
              main();
            csharp: |
              using System;

              using OpenAI.Audio;

              string audioFilePath = "audio.mp3";

              AudioClient client = new(
                  model: "whisper-1",
                  apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
              );

              AudioTranscriptionOptions options = new()
              {
                  ResponseFormat = AudioTranscriptionFormat.Verbose,
                  TimestampGranularities = AudioTimestampGranularities.Word,
              };

              AudioTranscription transcription = client.TranscribeAudio(audioFilePath, options);

              Console.WriteLine($"{transcription.Text}");
          response: |
            {
              "task": "transcribe",
              "language": "english",
              "duration": 8.470000267028809,
              "text": "The beach was a popular spot on a hot summer day. People were swimming in the ocean, building sandcastles, and playing beach volleyball.",
              "words": [
                {
                  "word": "The",
                  "start": 0.0,
                  "end": 0.23999999463558197
                },
                ...
                {
                  "word": "volleyball",
                  "start": 7.400000095367432,
                  "end": 7.900000095367432
                }
              ]
            }
        - title: Segment timestamps
          request:
            curl: |
              curl https://api.openai.com/v1/audio/transcriptions \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: multipart/form-data" \
                -F file="@/path/to/file/audio.mp3" \
                -F "timestamp_granularities[]=segment" \
                -F model="whisper-1" \
                -F response_format="verbose_json"
            python: |
              from openai import OpenAI
              client = OpenAI()

              audio_file = open("speech.mp3", "rb")
              transcript = client.audio.transcriptions.create(
                file=audio_file,
                model="whisper-1",
                response_format="verbose_json",
                timestamp_granularities=["segment"]
              )

              print(transcript.words)
            javascript: |
              import fs from "fs";
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const transcription = await openai.audio.transcriptions.create({
                  file: fs.createReadStream("audio.mp3"),
                  model: "whisper-1",
                  response_format: "verbose_json",
                  timestamp_granularities: ["segment"]
                });

                console.log(transcription.text);
              }
              main();
            csharp: |
              using System;

              using OpenAI.Audio;

              string audioFilePath = "audio.mp3";

              AudioClient client = new(
                  model: "whisper-1",
                  apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
              );

              AudioTranscriptionOptions options = new()
              {
                  ResponseFormat = AudioTranscriptionFormat.Verbose,
                  TimestampGranularities = AudioTimestampGranularities.Segment,
              };

              AudioTranscription transcription = client.TranscribeAudio(audioFilePath, options);

              Console.WriteLine($"{transcription.Text}");
          response: |
            {
              "task": "transcribe",
              "language": "english",
              "duration": 8.470000267028809,
              "text": "The beach was a popular spot on a hot summer day. People were swimming in the ocean, building sandcastles, and playing beach volleyball.",
              "segments": [
                {
                  "id": 0,
                  "seek": 0,
                  "start": 0.0,
                  "end": 3.319999933242798,
                  "text": " The beach was a popular spot on a hot summer day.",
                  "tokens": [
                    50364, 440, 7534, 390, 257, 3743, 4008, 322, 257, 2368, 4266, 786, 13, 50530
                  ],
                  "temperature": 0.0,
                  "avg_logprob": -0.2860786020755768,
                  "compression_ratio": 1.2363636493682861,
                  "no_speech_prob": 0.00985979475080967
                },
                ...
              ]
            }
  /audio/translations:
    post:
      tags:
      - Audio
      summary: Translates audio into English.
      operationId: createTranslation
      requestBody:
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/CreateTranslationRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/InlineResponse2001'
      x-oaiMeta:
        name: Create translation
        group: audio
        returns: The translated text.
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/audio/translations \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: multipart/form-data" \
                -F file="@/path/to/file/german.m4a" \
                -F model="whisper-1"
            python: |
              from openai import OpenAI
              client = OpenAI()

              audio_file = open("speech.mp3", "rb")
              transcript = client.audio.translations.create(
                model="whisper-1",
                file=audio_file
              )
            javascript: |
              import fs from "fs";
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                  const translation = await openai.audio.translations.create({
                      file: fs.createReadStream("speech.mp3"),
                      model: "whisper-1",
                  });

                  console.log(translation.text);
              }
              main();
            csharp: |
              using System;

              using OpenAI.Audio;

              string audioFilePath = "audio.mp3";

              AudioClient client = new(
                  model: "whisper-1",
                  apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
              );

              AudioTranscription transcription = client.TranscribeAudio(audioFilePath);

              Console.WriteLine($"{transcription.Text}");
          response: |
            {
              "text": "Hello, my name is Wolfgang and I come from Germany. Where are you heading today?"
            }
  /batches:
    get:
      tags:
      - Batch
      summary: List your organization's batches.
      operationId: listBatches
      parameters:
      - name: after
        in: query
        description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list
        required: false
        style: form
        explode: true
        schema:
          type: string
      - name: limit
        in: query
        description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20
        required: false
        style: form
        explode: true
        schema:
          type: integer
          default: 20
      responses:
        "200":
          description: Batch listed successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListBatchesResponse'
      x-oaiMeta:
        name: List batch
        group: batch
        returns: "A list of paginated [Batch](/docs/api-reference/batch/object) objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/batches?limit=2 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json"
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.batches.list()
            node: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const list = await openai.batches.list();

                for await (const batch of list) {
                  console.log(batch);
                }
              }

              main();
          response: |
            {
              "object": "list",
              "data": [
                {
                  "id": "batch_abc123",
                  "object": "batch",
                  "endpoint": "/v1/chat/completions",
                  "errors": null,
                  "input_file_id": "file-abc123",
                  "completion_window": "24h",
                  "status": "completed",
                  "output_file_id": "file-cvaTdG",
                  "error_file_id": "file-HOWS94",
                  "created_at": 1711471533,
                  "in_progress_at": 1711471538,
                  "expires_at": 1711557933,
                  "finalizing_at": 1711493133,
                  "completed_at": 1711493163,
                  "failed_at": null,
                  "expired_at": null,
                  "cancelling_at": null,
                  "cancelled_at": null,
                  "request_counts": {
                    "total": 100,
                    "completed": 95,
                    "failed": 5
                  },
                  "metadata": {
                    "customer_id": "user_123456789",
                    "batch_description": "Nightly job",
                  }
                },
                { ... },
              ],
              "first_id": "batch_abc123",
              "last_id": "batch_abc456",
              "has_more": true
            }
    post:
      tags:
      - Batch
      summary: Creates and executes a batch from an uploaded file of requests
      operationId: createBatch
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/BatchesBody'
        required: true
      responses:
        "200":
          description: Batch created successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Batch'
      x-oaiMeta:
        name: Create batch
        group: batch
        returns: "The created [Batch](/docs/api-reference/batch/object) object."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/batches \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -d '{
                  "input_file_id": "file-abc123",
                  "endpoint": "/v1/chat/completions",
                  "completion_window": "24h"
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.batches.create(
                input_file_id="file-abc123",
                endpoint="/v1/chat/completions",
                completion_window="24h"
              )
            node: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const batch = await openai.batches.create({
                  input_file_id: "file-abc123",
                  endpoint: "/v1/chat/completions",
                  completion_window: "24h"
                });

                console.log(batch);
              }

              main();
          response: |
            {
              "id": "batch_abc123",
              "object": "batch",
              "endpoint": "/v1/chat/completions",
              "errors": null,
              "input_file_id": "file-abc123",
              "completion_window": "24h",
              "status": "validating",
              "output_file_id": null,
              "error_file_id": null,
              "created_at": 1711471533,
              "in_progress_at": null,
              "expires_at": null,
              "finalizing_at": null,
              "completed_at": null,
              "failed_at": null,
              "expired_at": null,
              "cancelling_at": null,
              "cancelled_at": null,
              "request_counts": {
                "total": 0,
                "completed": 0,
                "failed": 0
              },
              "metadata": {
                "customer_id": "user_123456789",
                "batch_description": "Nightly eval job",
              }
            }
  /batches/{batchId}:
    get:
      tags:
      - Batch
      summary: Retrieves a batch.
      operationId: retrieveBatch
      parameters:
      - name: batchId
        in: path
        description: The ID of the batch to retrieve
        required: true
        style: simple
        explode: false
        schema:
          type: string
      responses:
        "200":
          description: Batch retrieved successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Batch'
      x-oaiMeta:
        name: Retrieve batch
        group: batch
        returns: "The [Batch](/docs/api-reference/batch/object) object matching the\
          \ specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/batches/batch_abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.batches.retrieve("batch_abc123")
            node: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const batch = await openai.batches.retrieve("batch_abc123");

                console.log(batch);
              }

              main();
          response: |
            {
              "id": "batch_abc123",
              "object": "batch",
              "endpoint": "/v1/completions",
              "errors": null,
              "input_file_id": "file-abc123",
              "completion_window": "24h",
              "status": "completed",
              "output_file_id": "file-cvaTdG",
              "error_file_id": "file-HOWS94",
              "created_at": 1711471533,
              "in_progress_at": 1711471538,
              "expires_at": 1711557933,
              "finalizing_at": 1711493133,
              "completed_at": 1711493163,
              "failed_at": null,
              "expired_at": null,
              "cancelling_at": null,
              "cancelled_at": null,
              "request_counts": {
                "total": 100,
                "completed": 95,
                "failed": 5
              },
              "metadata": {
                "customer_id": "user_123456789",
                "batch_description": "Nightly eval job",
              }
            }
  /batches/{batchId}/cancel:
    post:
      tags:
      - Batch
      summary: "Cancels an in-progress batch. The batch will be in status `cancelling`\
        \ for up to 10 minutes, before changing to `cancelled`, where it will have\
        \ partial results (if any) available in the output file."
      operationId: cancelBatch
      parameters:
      - name: batchId
        in: path
        description: The ID of the batch to cancel
        required: true
        style: simple
        explode: false
        schema:
          type: string
      responses:
        "200":
          description: Batch is cancelling. Returns the cancelling batch's details
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Batch'
      x-oaiMeta:
        name: Cancel batch
        group: batch
        returns: "The [Batch](/docs/api-reference/batch/object) object matching the\
          \ specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/batches/batch_abc123/cancel \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -X POST
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.batches.cancel("batch_abc123")
            node: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const batch = await openai.batches.cancel("batch_abc123");

                console.log(batch);
              }

              main();
          response: |
            {
              "id": "batch_abc123",
              "object": "batch",
              "endpoint": "/v1/chat/completions",
              "errors": null,
              "input_file_id": "file-abc123",
              "completion_window": "24h",
              "status": "cancelling",
              "output_file_id": null,
              "error_file_id": null,
              "created_at": 1711471533,
              "in_progress_at": 1711471538,
              "expires_at": 1711557933,
              "finalizing_at": null,
              "completed_at": null,
              "failed_at": null,
              "expired_at": null,
              "cancelling_at": 1711475133,
              "cancelled_at": null,
              "request_counts": {
                "total": 100,
                "completed": 23,
                "failed": 1
              },
              "metadata": {
                "customer_id": "user_123456789",
                "batch_description": "Nightly eval job",
              }
            }
  /chat/completions:
    get:
      tags:
      - Chat
      summary: |
        List stored Chat Completions. Only Chat Completions that have been stored
        with the `store` parameter set to `true` will be returned.
      operationId: listChatCompletions
      parameters:
      - name: model
        in: query
        description: The model used to generate the Chat Completions
        required: false
        style: form
        explode: true
        schema:
          type: string
      - name: metadata
        in: query
        description: |
          A list of metadata keys to filter the Chat Completions by. Example:

          `metadata[key1]=value1&metadata[key2]=value2`
        required: false
        style: form
        explode: true
        schema:
          $ref: '#/components/schemas/Metadata'
      - name: after
        in: query
        description: Identifier for the last chat completion from the previous pagination
          request
        required: false
        style: form
        explode: true
        schema:
          type: string
      - name: limit
        in: query
        description: Number of Chat Completions to retrieve
        required: false
        style: form
        explode: true
        schema:
          type: integer
          default: 20
      - name: order
        in: query
        description: Sort order for Chat Completions by timestamp. Use `asc` for ascending
          order or `desc` for descending order. Defaults to `asc`
        required: false
        style: form
        explode: true
        schema:
          type: string
          default: asc
          enum:
          - asc
          - desc
      responses:
        "200":
          description: A list of Chat Completions
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ChatCompletionList'
      x-oaiMeta:
        name: List Chat Completions
        group: chat
        returns: "A list of [Chat Completions](/docs/api-reference/chat/list-object)\
          \ matching the specified filters."
        path: list
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/chat/completions \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json"
            python: |
              from openai import OpenAI
              client = OpenAI()

              completions = client.chat.completions.list()
              print(completions)
          response: |
            {
              "object": "list",
              "data": [
                {
                  "object": "chat.completion",
                  "id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2",
                  "model": "gpt-4.1-2025-04-14",
                  "created": 1738960610,
                  "request_id": "req_ded8ab984ec4bf840f37566c1011c417",
                  "tool_choice": null,
                  "usage": {
                    "total_tokens": 31,
                    "completion_tokens": 18,
                    "prompt_tokens": 13
                  },
                  "seed": 4944116822809979520,
                  "top_p": 1.0,
                  "temperature": 1.0,
                  "presence_penalty": 0.0,
                  "frequency_penalty": 0.0,
                  "system_fingerprint": "fp_50cad350e4",
                  "input_user": null,
                  "service_tier": "default",
                  "tools": null,
                  "metadata": {},
                  "choices": [
                    {
                      "index": 0,
                      "message": {
                        "content": "Mind of circuits hum,  \nLearning patterns in silence  \nFuture's quiet spark.",
                        "role": "assistant",
                        "tool_calls": null,
                        "function_call": null
                      },
                      "finish_reason": "stop",
                      "logprobs": null
                    }
                  ],
                  "response_format": null
                }
              ],
              "first_id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2",
              "last_id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2",
              "has_more": false
            }
    post:
      tags:
      - Chat
      summary: "**Starting a new project?** We recommend trying [Responses](/docs/api-reference/responses)\
        \ \nto take advantage of the latest OpenAI platform features. Compare\n[Chat\
        \ Completions with Responses](/docs/guides/responses-vs-chat-completions?api-mode=responses).\n\
        \n---\n\nCreates a model response for the given chat conversation. Learn more\
        \ in the\n[text generation](/docs/guides/text-generation), [vision](/docs/guides/vision),\n\
        and [audio](/docs/guides/audio) guides.\n\nParameter support can differ depending\
        \ on the model used to generate the\nresponse, particularly for newer reasoning\
        \ models. Parameters that are only\nsupported for reasoning models are noted\
        \ below. For the current state of \nunsupported parameters in reasoning models,\
        \ \n[refer to the reasoning guide](/docs/guides/reasoning).\n"
      operationId: createChatCompletion
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateChatCompletionRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CreateChatCompletionResponse'
            text/event-stream:
              schema:
                $ref: '#/components/schemas/CreateChatCompletionStreamResponse'
      x-oaiMeta:
        name: Create chat completion
        group: chat
        returns: |
          Returns a [chat completion](/docs/api-reference/chat/object) object, or a streamed sequence of [chat completion chunk](/docs/api-reference/chat/streaming) objects if the request is streamed.
        path: create
        examples:
        - title: Default
          request:
            curl: |
              curl https://api.openai.com/v1/chat/completions \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "VAR_chat_model_id",
                  "messages": [
                    {
                      "role": "developer",
                      "content": "You are a helpful assistant."
                    },
                    {
                      "role": "user",
                      "content": "Hello!"
                    }
                  ]
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              completion = client.chat.completions.create(
                model="VAR_chat_model_id",
                messages=[
                  {"role": "developer", "content": "You are a helpful assistant."},
                  {"role": "user", "content": "Hello!"}
                ]
              )

              print(completion.choices[0].message)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const completion = await openai.chat.completions.create({
                  messages: [{ role: "developer", content: "You are a helpful assistant." }],
                  model: "VAR_chat_model_id",
                  store: true,
                });

                console.log(completion.choices[0]);
              }

              main();
            csharp: |
              using System;
              using System.Collections.Generic;

              using OpenAI.Chat;

              ChatClient client = new(
                  model: "gpt-4.1",
                  apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
              );

              List<ChatMessage> messages =
              [
                  new SystemChatMessage("You are a helpful assistant."),
                  new UserChatMessage("Hello!")
              ];

              ChatCompletion completion = client.CompleteChat(messages);

              Console.WriteLine(completion.Content[0].Text);
          response: |
            {
              "id": "chatcmpl-B9MBs8CjcvOU2jLn4n570S5qMJKcT",
              "object": "chat.completion",
              "created": 1741569952,
              "model": "gpt-4.1-2025-04-14",
              "choices": [
                {
                  "index": 0,
                  "message": {
                    "role": "assistant",
                    "content": "Hello! How can I assist you today?",
                    "refusal": null,
                    "annotations": []
                  },
                  "logprobs": null,
                  "finish_reason": "stop"
                }
              ],
              "usage": {
                "prompt_tokens": 19,
                "completion_tokens": 10,
                "total_tokens": 29,
                "prompt_tokens_details": {
                  "cached_tokens": 0,
                  "audio_tokens": 0
                },
                "completion_tokens_details": {
                  "reasoning_tokens": 0,
                  "audio_tokens": 0,
                  "accepted_prediction_tokens": 0,
                  "rejected_prediction_tokens": 0
                }
              },
              "service_tier": "default"
            }
        - title: Image input
          request:
            curl: |
              curl https://api.openai.com/v1/chat/completions \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "gpt-4.1",
                  "messages": [
                    {
                      "role": "user",
                      "content": [
                        {
                          "type": "text",
                          "text": "What is in this image?"
                        },
                        {
                          "type": "image_url",
                          "image_url": {
                            "url": "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg"
                          }
                        }
                      ]
                    }
                  ],
                  "max_tokens": 300
                }'
            python: |
              from openai import OpenAI

              client = OpenAI()

              response = client.chat.completions.create(
                  model="gpt-4.1",
                  messages=[
                      {
                          "role": "user",
                          "content": [
                              {"type": "text", "text": "What's in this image?"},
                              {
                                  "type": "image_url",
                                  "image_url": {
                                      "url": "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg",
                                  }
                              },
                          ],
                      }
                  ],
                  max_tokens=300,
              )

              print(response.choices[0])
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const response = await openai.chat.completions.create({
                  model: "gpt-4.1",
                  messages: [
                    {
                      role: "user",
                      content: [
                        { type: "text", text: "What's in this image?" },
                        {
                          type: "image_url",
                          image_url: {
                            "url": "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg",
                          },
                        }
                      ],
                    },
                  ],
                });
                console.log(response.choices[0]);
              }
              main();
            csharp: |
              using System;
              using System.Collections.Generic;

              using OpenAI.Chat;

              ChatClient client = new(
                  model: "gpt-4.1",
                  apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
              );

              List<ChatMessage> messages =
              [
                  new UserChatMessage(
                  [
                      ChatMessageContentPart.CreateTextPart("What's in this image?"),
                      ChatMessageContentPart.CreateImagePart(new Uri("https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg"))
                  ])
              ];

              ChatCompletion completion = client.CompleteChat(messages);

              Console.WriteLine(completion.Content[0].Text);
          response: |
            {
              "id": "chatcmpl-B9MHDbslfkBeAs8l4bebGdFOJ6PeG",
              "object": "chat.completion",
              "created": 1741570283,
              "model": "gpt-4.1-2025-04-14",
              "choices": [
                {
                  "index": 0,
                  "message": {
                    "role": "assistant",
                    "content": "The image shows a wooden boardwalk path running through a lush green field or meadow. The sky is bright blue with some scattered clouds, giving the scene a serene and peaceful atmosphere. Trees and shrubs are visible in the background.",
                    "refusal": null,
                    "annotations": []
                  },
                  "logprobs": null,
                  "finish_reason": "stop"
                }
              ],
              "usage": {
                "prompt_tokens": 1117,
                "completion_tokens": 46,
                "total_tokens": 1163,
                "prompt_tokens_details": {
                  "cached_tokens": 0,
                  "audio_tokens": 0
                },
                "completion_tokens_details": {
                  "reasoning_tokens": 0,
                  "audio_tokens": 0,
                  "accepted_prediction_tokens": 0,
                  "rejected_prediction_tokens": 0
                }
              },
              "service_tier": "default"
            }
        - title: Streaming
          request:
            curl: |
              curl https://api.openai.com/v1/chat/completions \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "VAR_chat_model_id",
                  "messages": [
                    {
                      "role": "developer",
                      "content": "You are a helpful assistant."
                    },
                    {
                      "role": "user",
                      "content": "Hello!"
                    }
                  ],
                  "stream": true
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              completion = client.chat.completions.create(
                model="VAR_chat_model_id",
                messages=[
                  {"role": "developer", "content": "You are a helpful assistant."},
                  {"role": "user", "content": "Hello!"}
                ],
                stream=True
              )

              for chunk in completion:
                print(chunk.choices[0].delta)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const completion = await openai.chat.completions.create({
                  model: "VAR_chat_model_id",
                  messages: [
                    {"role": "developer", "content": "You are a helpful assistant."},
                    {"role": "user", "content": "Hello!"}
                  ],
                  stream: true,
                });

                for await (const chunk of completion) {
                  console.log(chunk.choices[0].delta.content);
                }
              }

              main();
            csharp: |
              using System;
              using System.ClientModel;
              using System.Collections.Generic;
              using System.Threading.Tasks;

              using OpenAI.Chat;

              ChatClient client = new(
                  model: "gpt-4.1",
                  apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
              );

              List<ChatMessage> messages =
              [
                  new SystemChatMessage("You are a helpful assistant."),
                  new UserChatMessage("Hello!")
              ];

              AsyncCollectionResult<StreamingChatCompletionUpdate> completionUpdates = client.CompleteChatStreamingAsync(messages);

              await foreach (StreamingChatCompletionUpdate completionUpdate in completionUpdates)
              {
                  if (completionUpdate.ContentUpdate.Count > 0)
                  {
                      Console.Write(completionUpdate.ContentUpdate[0].Text);
                  }
              }
          response: |
            {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"role":"assistant","content":""},"logprobs":null,"finish_reason":null}]}

            {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"content":"Hello"},"logprobs":null,"finish_reason":null}]}

            ....

            {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}]}
        - title: Functions
          request:
            curl: |
              curl https://api.openai.com/v1/chat/completions \
              -H "Content-Type: application/json" \
              -H "Authorization: Bearer $OPENAI_API_KEY" \
              -d '{
                "model": "gpt-4.1",
                "messages": [
                  {
                    "role": "user",
                    "content": "What is the weather like in Boston today?"
                  }
                ],
                "tools": [
                  {
                    "type": "function",
                    "function": {
                      "name": "get_current_weather",
                      "description": "Get the current weather in a given location",
                      "parameters": {
                        "type": "object",
                        "properties": {
                          "location": {
                            "type": "string",
                            "description": "The city and state, e.g. San Francisco, CA"
                          },
                          "unit": {
                            "type": "string",
                            "enum": ["celsius", "fahrenheit"]
                          }
                        },
                        "required": ["location"]
                      }
                    }
                  }
                ],
                "tool_choice": "auto"
              }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              tools = [
                {
                  "type": "function",
                  "function": {
                    "name": "get_current_weather",
                    "description": "Get the current weather in a given location",
                    "parameters": {
                      "type": "object",
                      "properties": {
                        "location": {
                          "type": "string",
                          "description": "The city and state, e.g. San Francisco, CA",
                        },
                        "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
                      },
                      "required": ["location"],
                    },
                  }
                }
              ]
              messages = [{"role": "user", "content": "What's the weather like in Boston today?"}]
              completion = client.chat.completions.create(
                model="VAR_chat_model_id",
                messages=messages,
                tools=tools,
                tool_choice="auto"
              )

              print(completion)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const messages = [{"role": "user", "content": "What's the weather like in Boston today?"}];
                const tools = [
                    {
                      "type": "function",
                      "function": {
                        "name": "get_current_weather",
                        "description": "Get the current weather in a given location",
                        "parameters": {
                          "type": "object",
                          "properties": {
                            "location": {
                              "type": "string",
                              "description": "The city and state, e.g. San Francisco, CA",
                            },
                            "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
                          },
                          "required": ["location"],
                        },
                      }
                    }
                ];

                const response = await openai.chat.completions.create({
                  model: "gpt-4.1",
                  messages: messages,
                  tools: tools,
                  tool_choice: "auto",
                });

                console.log(response);
              }

              main();
            csharp: |
              using System;
              using System.Collections.Generic;

              using OpenAI.Chat;

              ChatClient client = new(
                  model: "gpt-4.1",
                  apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
              );

              ChatTool getCurrentWeatherTool = ChatTool.CreateFunctionTool(
                  functionName: "get_current_weather",
                  functionDescription: "Get the current weather in a given location",
                  functionParameters: BinaryData.FromString("""
                      {
                          "type": "object",
                          "properties": {
                              "location": {
                                  "type": "string",
                                  "description": "The city and state, e.g. San Francisco, CA"
                              },
                              "unit": {
                                  "type": "string",
                                  "enum": [ "celsius", "fahrenheit" ]
                              }
                          },
                          "required": [ "location" ]
                      }
                  """)
              );

              List<ChatMessage> messages =
              [
                  new UserChatMessage("What's the weather like in Boston today?"),
              ];

              ChatCompletionOptions options = new()
              {
                  Tools =
                  {
                      getCurrentWeatherTool
                  },
                  ToolChoice = ChatToolChoice.CreateAutoChoice(),
              };

              ChatCompletion completion = client.CompleteChat(messages, options);
          response: |
            {
              "id": "chatcmpl-abc123",
              "object": "chat.completion",
              "created": 1699896916,
              "model": "gpt-4o-mini",
              "choices": [
                {
                  "index": 0,
                  "message": {
                    "role": "assistant",
                    "content": null,
                    "tool_calls": [
                      {
                        "id": "call_abc123",
                        "type": "function",
                        "function": {
                          "name": "get_current_weather",
                          "arguments": "{\n\"location\": \"Boston, MA\"\n}"
                        }
                      }
                    ]
                  },
                  "logprobs": null,
                  "finish_reason": "tool_calls"
                }
              ],
              "usage": {
                "prompt_tokens": 82,
                "completion_tokens": 17,
                "total_tokens": 99,
                "completion_tokens_details": {
                  "reasoning_tokens": 0,
                  "accepted_prediction_tokens": 0,
                  "rejected_prediction_tokens": 0
                }
              }
            }
        - title: Logprobs
          request:
            curl: |
              curl https://api.openai.com/v1/chat/completions \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "VAR_chat_model_id",
                  "messages": [
                    {
                      "role": "user",
                      "content": "Hello!"
                    }
                  ],
                  "logprobs": true,
                  "top_logprobs": 2
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              completion = client.chat.completions.create(
                model="VAR_chat_model_id",
                messages=[
                  {"role": "user", "content": "Hello!"}
                ],
                logprobs=True,
                top_logprobs=2
              )

              print(completion.choices[0].message)
              print(completion.choices[0].logprobs)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const completion = await openai.chat.completions.create({
                  messages: [{ role: "user", content: "Hello!" }],
                  model: "VAR_chat_model_id",
                  logprobs: true,
                  top_logprobs: 2,
                });

                console.log(completion.choices[0]);
              }

              main();
            csharp: |
              using System;
              using System.Collections.Generic;

              using OpenAI.Chat;

              ChatClient client = new(
                  model: "gpt-4.1",
                  apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
              );

              List<ChatMessage> messages =
              [
                  new UserChatMessage("Hello!")
              ];

              ChatCompletionOptions options = new()
              {
                  IncludeLogProbabilities = true,
                  TopLogProbabilityCount = 2
              };

              ChatCompletion completion = client.CompleteChat(messages, options);

              Console.WriteLine(completion.Content[0].Text);
          response: |
            {
              "id": "chatcmpl-123",
              "object": "chat.completion",
              "created": 1702685778,
              "model": "gpt-4o-mini",
              "choices": [
                {
                  "index": 0,
                  "message": {
                    "role": "assistant",
                    "content": "Hello! How can I assist you today?"
                  },
                  "logprobs": {
                    "content": [
                      {
                        "token": "Hello",
                        "logprob": -0.31725305,
                        "bytes": [72, 101, 108, 108, 111],
                        "top_logprobs": [
                          {
                            "token": "Hello",
                            "logprob": -0.31725305,
                            "bytes": [72, 101, 108, 108, 111]
                          },
                          {
                            "token": "Hi",
                            "logprob": -1.3190403,
                            "bytes": [72, 105]
                          }
                        ]
                      },
                      {
                        "token": "!",
                        "logprob": -0.02380986,
                        "bytes": [
                          33
                        ],
                        "top_logprobs": [
                          {
                            "token": "!",
                            "logprob": -0.02380986,
                            "bytes": [33]
                          },
                          {
                            "token": " there",
                            "logprob": -3.787621,
                            "bytes": [32, 116, 104, 101, 114, 101]
                          }
                        ]
                      },
                      {
                        "token": " How",
                        "logprob": -0.000054669687,
                        "bytes": [32, 72, 111, 119],
                        "top_logprobs": [
                          {
                            "token": " How",
                            "logprob": -0.000054669687,
                            "bytes": [32, 72, 111, 119]
                          },
                          {
                            "token": "<|end|>",
                            "logprob": -10.953937,
                            "bytes": null
                          }
                        ]
                      },
                      {
                        "token": " can",
                        "logprob": -0.015801601,
                        "bytes": [32, 99, 97, 110],
                        "top_logprobs": [
                          {
                            "token": " can",
                            "logprob": -0.015801601,
                            "bytes": [32, 99, 97, 110]
                          },
                          {
                            "token": " may",
                            "logprob": -4.161023,
                            "bytes": [32, 109, 97, 121]
                          }
                        ]
                      },
                      {
                        "token": " I",
                        "logprob": -3.7697225e-6,
                        "bytes": [
                          32,
                          73
                        ],
                        "top_logprobs": [
                          {
                            "token": " I",
                            "logprob": -3.7697225e-6,
                            "bytes": [32, 73]
                          },
                          {
                            "token": " assist",
                            "logprob": -13.596657,
                            "bytes": [32, 97, 115, 115, 105, 115, 116]
                          }
                        ]
                      },
                      {
                        "token": " assist",
                        "logprob": -0.04571125,
                        "bytes": [32, 97, 115, 115, 105, 115, 116],
                        "top_logprobs": [
                          {
                            "token": " assist",
                            "logprob": -0.04571125,
                            "bytes": [32, 97, 115, 115, 105, 115, 116]
                          },
                          {
                            "token": " help",
                            "logprob": -3.1089056,
                            "bytes": [32, 104, 101, 108, 112]
                          }
                        ]
                      },
                      {
                        "token": " you",
                        "logprob": -5.4385737e-6,
                        "bytes": [32, 121, 111, 117],
                        "top_logprobs": [
                          {
                            "token": " you",
                            "logprob": -5.4385737e-6,
                            "bytes": [32, 121, 111, 117]
                          },
                          {
                            "token": " today",
                            "logprob": -12.807695,
                            "bytes": [32, 116, 111, 100, 97, 121]
                          }
                        ]
                      },
                      {
                        "token": " today",
                        "logprob": -0.0040071653,
                        "bytes": [32, 116, 111, 100, 97, 121],
                        "top_logprobs": [
                          {
                            "token": " today",
                            "logprob": -0.0040071653,
                            "bytes": [32, 116, 111, 100, 97, 121]
                          },
                          {
                            "token": "?",
                            "logprob": -5.5247097,
                            "bytes": [63]
                          }
                        ]
                      },
                      {
                        "token": "?",
                        "logprob": -0.0008108172,
                        "bytes": [63],
                        "top_logprobs": [
                          {
                            "token": "?",
                            "logprob": -0.0008108172,
                            "bytes": [63]
                          },
                          {
                            "token": "?\n",
                            "logprob": -7.184561,
                            "bytes": [63, 10]
                          }
                        ]
                      }
                    ]
                  },
                  "finish_reason": "stop"
                }
              ],
              "usage": {
                "prompt_tokens": 9,
                "completion_tokens": 9,
                "total_tokens": 18,
                "completion_tokens_details": {
                  "reasoning_tokens": 0,
                  "accepted_prediction_tokens": 0,
                  "rejected_prediction_tokens": 0
                }
              },
              "system_fingerprint": null
            }
  /chat/completions/{completionId}:
    get:
      tags:
      - Chat
      summary: |
        Get a stored chat completion. Only Chat Completions that have been created
        with the `store` parameter set to `true` will be returned.
      operationId: getChatCompletion
      parameters:
      - name: completionId
        in: path
        description: The ID of the chat completion to retrieve
        required: true
        style: simple
        explode: false
        schema:
          type: string
      responses:
        "200":
          description: A chat completion
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CreateChatCompletionResponse'
      x-oaiMeta:
        name: Get chat completion
        group: chat
        returns: "The [ChatCompletion](/docs/api-reference/chat/object) object matching\
          \ the specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/chat/completions/chatcmpl-abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json"
            python: |
              from openai import OpenAI
              client = OpenAI()

              completions = client.chat.completions.list()
              first_id = completions[0].id
              first_completion = client.chat.completions.retrieve(completion_id=first_id)
              print(first_completion)
          response: |
            {
              "object": "chat.completion",
              "id": "chatcmpl-abc123",
              "model": "gpt-4o-2024-08-06",
              "created": 1738960610,
              "request_id": "req_ded8ab984ec4bf840f37566c1011c417",
              "tool_choice": null,
              "usage": {
                "total_tokens": 31,
                "completion_tokens": 18,
                "prompt_tokens": 13
              },
              "seed": 4944116822809979520,
              "top_p": 1.0,
              "temperature": 1.0,
              "presence_penalty": 0.0,
              "frequency_penalty": 0.0,
              "system_fingerprint": "fp_50cad350e4",
              "input_user": null,
              "service_tier": "default",
              "tools": null,
              "metadata": {},
              "choices": [
                {
                  "index": 0,
                  "message": {
                    "content": "Mind of circuits hum,  \nLearning patterns in silence  \nFuture's quiet spark.",
                    "role": "assistant",
                    "tool_calls": null,
                    "function_call": null
                  },
                  "finish_reason": "stop",
                  "logprobs": null
                }
              ],
              "response_format": null
            }
    post:
      tags:
      - Chat
      summary: |
        Modify a stored chat completion. Only Chat Completions that have been
        created with the `store` parameter set to `true` can be modified. Currently,
        the only supported modification is to update the `metadata` field.
      operationId: updateChatCompletion
      parameters:
      - name: completionId
        in: path
        description: The ID of the chat completion to update
        required: true
        style: simple
        explode: false
        schema:
          type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CompletionscompletionIdBody'
        required: true
      responses:
        "200":
          description: A chat completion
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CreateChatCompletionResponse'
      x-oaiMeta:
        name: Update chat completion
        group: chat
        returns: "The [ChatCompletion](/docs/api-reference/chat/object) object matching\
          \ the specified ID."
        examples:
          request:
            curl: |
              curl -X POST https://api.openai.com/v1/chat/completions/chat_abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -d '{"metadata": {"foo": "bar"}}'
            python: |
              from openai import OpenAI
              client = OpenAI()

              completions = client.chat.completions.list()
              first_id = completions[0].id
              updated_completion = client.chat.completions.update(completion_id=first_id, request_body={"metadata": {"foo": "bar"}})
              print(updated_completion)
          response: |
            {
              "object": "chat.completion",
              "id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2",
              "model": "gpt-4o-2024-08-06",
              "created": 1738960610,
              "request_id": "req_ded8ab984ec4bf840f37566c1011c417",
              "tool_choice": null,
              "usage": {
                "total_tokens": 31,
                "completion_tokens": 18,
                "prompt_tokens": 13
              },
              "seed": 4944116822809979520,
              "top_p": 1.0,
              "temperature": 1.0,
              "presence_penalty": 0.0,
              "frequency_penalty": 0.0,
              "system_fingerprint": "fp_50cad350e4",
              "input_user": null,
              "service_tier": "default",
              "tools": null,
              "metadata": {
                "foo": "bar"
              },
              "choices": [
                {
                  "index": 0,
                  "message": {
                    "content": "Mind of circuits hum,  \nLearning patterns in silence  \nFuture's quiet spark.",
                    "role": "assistant",
                    "tool_calls": null,
                    "function_call": null
                  },
                  "finish_reason": "stop",
                  "logprobs": null
                }
              ],
              "response_format": null
            }
    delete:
      tags:
      - Chat
      summary: |
        Delete a stored chat completion. Only Chat Completions that have been
        created with the `store` parameter set to `true` can be deleted.
      operationId: deleteChatCompletion
      parameters:
      - name: completionId
        in: path
        description: The ID of the chat completion to delete
        required: true
        style: simple
        explode: false
        schema:
          type: string
      responses:
        "200":
          description: The chat completion was deleted successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ChatCompletionDeleted'
      x-oaiMeta:
        name: Delete chat completion
        group: chat
        returns: A deletion confirmation object.
        examples:
          request:
            curl: |
              curl -X DELETE https://api.openai.com/v1/chat/completions/chat_abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json"
            python: |
              from openai import OpenAI
              client = OpenAI()

              completions = client.chat.completions.list()
              first_id = completions[0].id
              delete_response = client.chat.completions.delete(completion_id=first_id)
              print(delete_response)
          response: |
            {
              "object": "chat.completion.deleted",
              "id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2",
              "deleted": true
            }
  /chat/completions/{completionId}/messages:
    get:
      tags:
      - Chat
      summary: |
        Get the messages in a stored chat completion. Only Chat Completions that
        have been created with the `store` parameter set to `true` will be
        returned.
      operationId: getChatCompletionMessages
      parameters:
      - name: completionId
        in: path
        description: The ID of the chat completion to retrieve messages from
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: after
        in: query
        description: Identifier for the last message from the previous pagination
          request
        required: false
        style: form
        explode: true
        schema:
          type: string
      - name: limit
        in: query
        description: Number of messages to retrieve
        required: false
        style: form
        explode: true
        schema:
          type: integer
          default: 20
      - name: order
        in: query
        description: Sort order for messages by timestamp. Use `asc` for ascending
          order or `desc` for descending order. Defaults to `asc`
        required: false
        style: form
        explode: true
        schema:
          type: string
          default: asc
          enum:
          - asc
          - desc
      responses:
        "200":
          description: A list of messages
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ChatCompletionMessageList'
      x-oaiMeta:
        name: Get chat messages
        group: chat
        returns: "A list of [messages](/docs/api-reference/chat/message-list) for\
          \ the specified chat completion."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/chat/completions/chat_abc123/messages \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json"
            python: |
              from openai import OpenAI
              client = OpenAI()

              completions = client.chat.completions.list()
              first_id = completions[0].id
              first_completion = client.chat.completions.retrieve(completion_id=first_id)
              messages = client.chat.completions.messages.list(completion_id=first_id)
              print(messages)
          response: |
            {
              "object": "list",
              "data": [
                {
                  "id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2-0",
                  "role": "user",
                  "content": "write a haiku about ai",
                  "name": null,
                  "content_parts": null
                }
              ],
              "first_id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2-0",
              "last_id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2-0",
              "has_more": false
            }
  /completions:
    post:
      tags:
      - Completions
      summary: Creates a completion for the provided prompt and parameters.
      operationId: createCompletion
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateCompletionRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CreateCompletionResponse'
      x-oaiMeta:
        name: Create completion
        group: completions
        returns: |
          Returns a [completion](/docs/api-reference/completions/object) object, or a sequence of completion objects if the request is streamed.
        legacy: true
        examples:
        - title: No streaming
          request:
            curl: |
              curl https://api.openai.com/v1/completions \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "VAR_completion_model_id",
                  "prompt": "Say this is a test",
                  "max_tokens": 7,
                  "temperature": 0
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.completions.create(
                model="VAR_completion_model_id",
                prompt="Say this is a test",
                max_tokens=7,
                temperature=0
              )
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const completion = await openai.completions.create({
                  model: "VAR_completion_model_id",
                  prompt: "Say this is a test.",
                  max_tokens: 7,
                  temperature: 0,
                });

                console.log(completion);
              }
              main();
          response: |
            {
              "id": "cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7",
              "object": "text_completion",
              "created": 1589478378,
              "model": "VAR_completion_model_id",
              "system_fingerprint": "fp_44709d6fcb",
              "choices": [
                {
                  "text": "\n\nThis is indeed a test",
                  "index": 0,
                  "logprobs": null,
                  "finish_reason": "length"
                }
              ],
              "usage": {
                "prompt_tokens": 5,
                "completion_tokens": 7,
                "total_tokens": 12
              }
            }
        - title: Streaming
          request:
            curl: |
              curl https://api.openai.com/v1/completions \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "VAR_completion_model_id",
                  "prompt": "Say this is a test",
                  "max_tokens": 7,
                  "temperature": 0,
                  "stream": true
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              for chunk in client.completions.create(
                model="VAR_completion_model_id",
                prompt="Say this is a test",
                max_tokens=7,
                temperature=0,
                stream=True
              ):
                print(chunk.choices[0].text)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const stream = await openai.completions.create({
                  model: "VAR_completion_model_id",
                  prompt: "Say this is a test.",
                  stream: true,
                });

                for await (const chunk of stream) {
                  console.log(chunk.choices[0].text)
                }
              }
              main();
          response: |
            {
              "id": "cmpl-7iA7iJjj8V2zOkCGvWF2hAkDWBQZe",
              "object": "text_completion",
              "created": 1690759702,
              "choices": [
                {
                  "text": "This",
                  "index": 0,
                  "logprobs": null,
                  "finish_reason": null
                }
              ],
              "model": "gpt-3.5-turbo-instruct"
              "system_fingerprint": "fp_44709d6fcb",
            }
  /embeddings:
    post:
      tags:
      - Embeddings
      summary: Creates an embedding vector representing the input text.
      operationId: createEmbedding
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateEmbeddingRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CreateEmbeddingResponse'
      x-oaiMeta:
        name: Create embeddings
        group: embeddings
        returns: "A list of [embedding](/docs/api-reference/embeddings/object) objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/embeddings \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -d '{
                  "input": "The food was delicious and the waiter...",
                  "model": "text-embedding-ada-002",
                  "encoding_format": "float"
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.embeddings.create(
                model="text-embedding-ada-002",
                input="The food was delicious and the waiter...",
                encoding_format="float"
              )
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const embedding = await openai.embeddings.create({
                  model: "text-embedding-ada-002",
                  input: "The quick brown fox jumped over the lazy dog",
                  encoding_format: "float",
                });

                console.log(embedding);
              }

              main();
            csharp: |
              using System;

              using OpenAI.Embeddings;

              EmbeddingClient client = new(
                  model: "text-embedding-3-small",
                  apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
              );

              OpenAIEmbedding embedding = client.GenerateEmbedding(input: "The quick brown fox jumped over the lazy dog");
              ReadOnlyMemory<float> vector = embedding.ToFloats();

              for (int i = 0; i < vector.Length; i++)
              {
                  Console.WriteLine($"  [{i,4}] = {vector.Span[i]}");
              }
          response: |
            {
              "object": "list",
              "data": [
                {
                  "object": "embedding",
                  "embedding": [
                    0.0023064255,
                    -0.009327292,
                    .... (1536 floats total for ada-002)
                    -0.0028842222,
                  ],
                  "index": 0
                }
              ],
              "model": "text-embedding-ada-002",
              "usage": {
                "prompt_tokens": 8,
                "total_tokens": 8
              }
            }
  /evals:
    get:
      tags:
      - Evals
      summary: |
        List evaluations for a project.
      operationId: listEvals
      parameters:
      - name: after
        in: query
        description: Identifier for the last eval from the previous pagination request
        required: false
        style: form
        explode: true
        schema:
          type: string
      - name: limit
        in: query
        description: Number of evals to retrieve
        required: false
        style: form
        explode: true
        schema:
          type: integer
          default: 20
      - name: order
        in: query
        description: Sort order for evals by timestamp. Use `asc` for ascending order
          or `desc` for descending order
        required: false
        style: form
        explode: true
        schema:
          type: string
          default: asc
          enum:
          - asc
          - desc
      - name: order_by
        in: query
        description: |
          Evals can be ordered by creation time or last updated time. Use
          `created_at` for creation time or `updated_at` for last updated time
        required: false
        style: form
        explode: true
        schema:
          type: string
          default: created_at
          enum:
          - created_at
          - updated_at
        x-ballerina-name: orderBy
      responses:
        "200":
          description: A list of evals
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/EvalList'
      x-oaiMeta:
        name: List evals
        group: evals
        returns: "A list of [evals](/docs/api-reference/evals/object) matching the\
          \ specified filters."
        path: list
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/evals?limit=1 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json"
          response: |
            {
              "object": "list",
              "data": [
                {
                  "id": "eval_67abd54d9b0081909a86353f6fb9317a",
                  "object": "eval",
                  "data_source_config": {
                    "type": "stored_completions",
                    "metadata": {
                      "usecase": "push_notifications_summarizer"
                    },
                    "schema": {
                      "type": "object",
                      "properties": {
                        "item": {
                          "type": "object"
                        },
                        "sample": {
                          "type": "object"
                        }
                      },
                      "required": [
                        "item",
                        "sample"
                      ]
                    }
                  },
                  "testing_criteria": [
                    {
                      "name": "Push Notification Summary Grader",
                      "id": "Push Notification Summary Grader-9b876f24-4762-4be9-aff4-db7a9b31c673",
                      "type": "label_model",
                      "model": "o3-mini",
                      "input": [
                        {
                          "type": "message",
                          "role": "developer",
                          "content": {
                            "type": "input_text",
                            "text": "\nLabel the following push notification summary as either correct or incorrect.\nThe push notification and the summary will be provided below.\nA good push notificiation summary is concise and snappy.\nIf it is good, then label it as correct, if not, then incorrect.\n"
                          }
                        },
                        {
                          "type": "message",
                          "role": "user",
                          "content": {
                            "type": "input_text",
                            "text": "\nPush notifications: {{item.input}}\nSummary: {{sample.output_text}}\n"
                          }
                        }
                      ],
                      "passing_labels": [
                        "correct"
                      ],
                      "labels": [
                        "correct",
                        "incorrect"
                      ],
                      "sampling_params": null
                    }
                  ],
                  "name": "Push Notification Summary Grader",
                  "created_at": 1739314509,
                  "metadata": {
                    "description": "A stored completions eval for push notification summaries"
                  }
                }
              ],
              "first_id": "eval_67abd54d9b0081909a86353f6fb9317a",
              "last_id": "eval_67aa884cf6688190b58f657d4441c8b7",
              "has_more": true
            }
    post:
      tags:
      - Evals
      summary: |
        Create the structure of an evaluation that can be used to test a model's performance.
        An evaluation is a set of testing criteria and a datasource. After creating an evaluation, you can run it on different models and model parameters. We support several types of graders and datasources.
        For more information, see the [Evals guide](/docs/guides/evals).
      operationId: createEval
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateEvalRequest'
        required: true
      responses:
        "201":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Eval'
      x-oaiMeta:
        name: Create eval
        group: evals
        returns: "The created [Eval](/docs/api-reference/evals/object) object."
        path: post
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/evals \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -d '{
                      "name": "Sentiment",
                      "data_source_config": {
                        "type": "stored_completions",
                        "metadata": {
                            "usecase": "chatbot"
                        }
                      },
                      "testing_criteria": [
                        {
                          "type": "label_model",
                          "model": "o3-mini",
                          "input": [
                            {
                              "role": "developer",
                              "content": "Classify the sentiment of the following statement as one of 'positive', 'neutral', or 'negative'"
                            },
                            {
                              "role": "user",
                              "content": "Statement: {{item.input}}"
                            }
                          ],
                          "passing_labels": [
                            "positive"
                          ],
                          "labels": [
                            "positive",
                            "neutral",
                            "negative"
                          ],
                          "name": "Example label grader"
                        }
                      ]
                    }'
          response: |
            {
              "object": "eval",
              "id": "eval_67b7fa9a81a88190ab4aa417e397ea21",
              "data_source_config": {
                "type": "stored_completions",
                "metadata": {
                  "usecase": "chatbot"
                },
                "schema": {
                  "type": "object",
                  "properties": {
                    "item": {
                      "type": "object"
                    },
                    "sample": {
                      "type": "object"
                    }
                  },
                  "required": [
                    "item",
                    "sample"
                  ]
              },
              "testing_criteria": [
                {
                  "name": "Example label grader",
                  "type": "label_model",
                  "model": "o3-mini",
                  "input": [
                    {
                      "type": "message",
                      "role": "developer",
                      "content": {
                        "type": "input_text",
                        "text": "Classify the sentiment of the following statement as one of positive, neutral, or negative"
                      }
                    },
                    {
                      "type": "message",
                      "role": "user",
                      "content": {
                        "type": "input_text",
                        "text": "Statement: {{item.input}}"
                      }
                    }
                  ],
                  "passing_labels": [
                    "positive"
                  ],
                  "labels": [
                    "positive",
                    "neutral",
                    "negative"
                  ]
                }
              ],
              "name": "Sentiment",
              "created_at": 1740110490,
              "metadata": {
                "description": "An eval for sentiment analysis"
              }
            }
  /evals/{evalId}:
    get:
      tags:
      - Evals
      summary: |
        Get an evaluation by ID.
      operationId: getEval
      parameters:
      - name: evalId
        in: path
        description: The ID of the evaluation to retrieve
        required: true
        style: simple
        explode: false
        schema:
          type: string
      responses:
        "200":
          description: The evaluation
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Eval'
      x-oaiMeta:
        name: Get an eval
        group: evals
        returns: "The [Eval](/docs/api-reference/evals/object) object matching the\
          \ specified ID."
        path: get
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/evals/eval_67abd54d9b0081909a86353f6fb9317a \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json"
          response: |
            {
              "object": "eval",
              "id": "eval_67abd54d9b0081909a86353f6fb9317a",
              "data_source_config": {
                "type": "custom",
                "schema": {
                  "type": "object",
                  "properties": {
                    "item": {
                      "type": "object",
                      "properties": {
                        "input": {
                          "type": "string"
                        },
                        "ground_truth": {
                          "type": "string"
                        }
                      },
                      "required": [
                        "input",
                        "ground_truth"
                      ]
                    }
                  },
                  "required": [
                    "item"
                  ]
                }
              },
              "testing_criteria": [
                {
                  "name": "String check",
                  "id": "String check-2eaf2d8d-d649-4335-8148-9535a7ca73c2",
                  "type": "string_check",
                  "input": "{{item.input}}",
                  "reference": "{{item.ground_truth}}",
                  "operation": "eq"
                }
              ],
              "name": "External Data Eval",
              "created_at": 1739314509,
              "metadata": {},
            }
    post:
      tags:
      - Evals
      summary: |
        Update certain properties of an evaluation.
      operationId: updateEval
      parameters:
      - name: evalId
        in: path
        description: The ID of the evaluation to update
        required: true
        style: simple
        explode: false
        schema:
          type: string
      requestBody:
        description: Request to update an evaluation
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/EvalsevalIdBody'
        required: true
      responses:
        "200":
          description: The updated evaluation
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Eval'
      x-oaiMeta:
        name: Update an eval
        group: evals
        returns: "The [Eval](/docs/api-reference/evals/object) object matching the\
          \ updated version."
        path: update
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/evals/eval_67abd54d9b0081909a86353f6fb9317a \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -d '{"name": "Updated Eval", "metadata": {"description": "Updated description"}}'
          response: |
            {
              "object": "eval",
              "id": "eval_67abd54d9b0081909a86353f6fb9317a",
              "data_source_config": {
                "type": "custom",
                "schema": {
                  "type": "object",
                  "properties": {
                    "item": {
                      "type": "object",
                      "properties": {
                        "input": {
                          "type": "string"
                        },
                        "ground_truth": {
                          "type": "string"
                        }
                      },
                      "required": [
                        "input",
                        "ground_truth"
                      ]
                    }
                  },
                  "required": [
                    "item"
                  ]
                }
              },
              "testing_criteria": [
                {
                  "name": "String check",
                  "id": "String check-2eaf2d8d-d649-4335-8148-9535a7ca73c2",
                  "type": "string_check",
                  "input": "{{item.input}}",
                  "reference": "{{item.ground_truth}}",
                  "operation": "eq"
                }
              ],
              "name": "Updated Eval",
              "created_at": 1739314509,
              "metadata": {"description": "Updated description"},
            }
    delete:
      tags:
      - Evals
      summary: |
        Delete an evaluation.
      operationId: deleteEval
      parameters:
      - name: evalId
        in: path
        description: The ID of the evaluation to delete
        required: true
        style: simple
        explode: false
        schema:
          type: string
      responses:
        "200":
          description: Successfully deleted the evaluation
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/InlineResponse2002'
        "404":
          description: Evaluation not found.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Error'
      x-oaiMeta:
        name: Delete an eval
        group: evals
        returns: A deletion confirmation object.
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/evals/eval_abc123 \
                -X DELETE \
                -H "Authorization: Bearer $OPENAI_API_KEY"
          response: |
            {
              "object": "eval.deleted",
              "deleted": true,
              "eval_id": "eval_abc123"
            }
  /evals/{evalId}/runs:
    get:
      tags:
      - Evals
      summary: |
        Get a list of runs for an evaluation.
      operationId: getEvalRuns
      parameters:
      - name: evalId
        in: path
        description: The ID of the evaluation to retrieve runs for
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: after
        in: query
        description: Identifier for the last run from the previous pagination request
        required: false
        style: form
        explode: true
        schema:
          type: string
      - name: limit
        in: query
        description: Number of runs to retrieve
        required: false
        style: form
        explode: true
        schema:
          type: integer
          default: 20
      - name: order
        in: query
        description: Sort order for runs by timestamp. Use `asc` for ascending order
          or `desc` for descending order. Defaults to `asc`
        required: false
        style: form
        explode: true
        schema:
          type: string
          default: asc
          enum:
          - asc
          - desc
      - name: status
        in: query
        description: Filter runs by status. One of `queued` | `in_progress` | `failed`
          | `completed` | `canceled`
        required: false
        style: form
        explode: true
        schema:
          type: string
          enum:
          - queued
          - in_progress
          - completed
          - canceled
          - failed
      responses:
        "200":
          description: A list of runs for the evaluation
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/EvalRunList'
      x-oaiMeta:
        name: Get eval runs
        group: evals
        returns: "A list of [EvalRun](/docs/api-reference/evals/run-object) objects\
          \ matching the specified ID."
        path: get-runs
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/evals/egroup_67abd54d9b0081909a86353f6fb9317a/runs \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json"
          response: |
            {
              "object": "list",
              "data": [
                {
                  "object": "eval.run",
                  "id": "evalrun_67e0c7d31560819090d60c0780591042",
                  "eval_id": "eval_67e0c726d560819083f19a957c4c640b",
                  "report_url": "https://platform.openai.com/evaluations/eval_67e0c726d560819083f19a957c4c640b",
                  "status": "completed",
                  "model": "o3-mini",
                  "name": "bulk_with_negative_examples_o3-mini",
                  "created_at": 1742784467,
                  "result_counts": {
                    "total": 1,
                    "errored": 0,
                    "failed": 0,
                    "passed": 1
                  },
                  "per_model_usage": [
                    {
                      "model_name": "o3-mini",
                      "invocation_count": 1,
                      "prompt_tokens": 563,
                      "completion_tokens": 874,
                      "total_tokens": 1437,
                      "cached_tokens": 0
                    }
                  ],
                  "per_testing_criteria_results": [
                    {
                      "testing_criteria": "Push Notification Summary Grader-1808cd0b-eeec-4e0b-a519-337e79f4f5d1",
                      "passed": 1,
                      "failed": 0
                    }
                  ],
                  "data_source": {
                    "type": "completions",
                    "source": {
                      "type": "file_content",
                      "content": [
                        {
                          "item": {
                            "notifications": "\n- New message from Sarah: \"Can you call me later?\"\n- Your package has been delivered!\n- Flash sale: 20% off electronics for the next 2 hours!\n"
                          }
                        }
                      ]
                    },
                    "input_messages": {
                      "type": "template",
                      "template": [
                        {
                          "type": "message",
                          "role": "developer",
                          "content": {
                            "type": "input_text",
                            "text": "\n\n\n\nYou are a helpful assistant that takes in an array of push notifications and returns a collapsed summary of them.\nThe push notification will be provided as follows:\n<push_notifications>\n...notificationlist...\n</push_notifications>\n\nYou should return just the summary and nothing else.\n\n\nYou should return a summary that is concise and snappy.\n\n\nHere is an example of a good summary:\n<push_notifications>\n- Traffic alert: Accident reported on Main Street.- Package out for delivery: Expected by 5 PM.- New friend suggestion: Connect with Emma.\n</push_notifications>\n<summary>\nTraffic alert, package expected by 5pm, suggestion for new friend (Emily).\n</summary>\n\n\nHere is an example of a bad summary:\n<push_notifications>\n- Traffic alert: Accident reported on Main Street.- Package out for delivery: Expected by 5 PM.- New friend suggestion: Connect with Emma.\n</push_notifications>\n<summary>\nTraffic alert reported on main street. You have a package that will arrive by 5pm, Emily is a new friend suggested for you.\n</summary>\n"
                          }
                        },
                        {
                          "type": "message",
                          "role": "user",
                          "content": {
                            "type": "input_text",
                            "text": "<push_notifications>{{item.notifications}}</push_notifications>"
                          }
                        }
                      ]
                    },
                    "model": "o3-mini",
                    "sampling_params": null
                  },
                  "error": null,
                  "metadata": {}
                }
              ],
              "first_id": "evalrun_67e0c7d31560819090d60c0780591042",
              "last_id": "evalrun_67e0c7d31560819090d60c0780591042",
              "has_more": true
            }
    post:
      tags:
      - Evals
      summary: |
        Create a new evaluation run. This is the endpoint that will kick off grading.
      operationId: createEvalRun
      parameters:
      - name: evalId
        in: path
        description: The ID of the evaluation to create a run for
        required: true
        style: simple
        explode: false
        schema:
          type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateEvalRunRequest'
        required: true
      responses:
        "201":
          description: Successfully created a run for the evaluation
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/EvalRun'
        "400":
          description: "Bad request (for example, missing eval object)"
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Error'
      x-oaiMeta:
        name: Create eval run
        group: evals
        returns: "The [EvalRun](/docs/api-reference/evals/run-object) object matching\
          \ the specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/evals/eval_67e579652b548190aaa83ada4b125f47/runs \
                -X POST \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -d '{"name":"gpt-4o-mini","data_source":{"type":"completions","input_messages":{"type":"template","template":[{"role":"developer","content":"Categorize a given news headline into one of the following topics: Technology, Markets, World, Business, or Sports.\n\n# Steps\n\n1. Analyze the content of the news headline to understand its primary focus.\n2. Extract the subject matter, identifying any key indicators or keywords.\n3. Use the identified indicators to determine the most suitable category out of the five options: Technology, Markets, World, Business, or Sports.\n4. Ensure only one category is selected per headline.\n\n# Output Format\n\nRespond with the chosen category as a single word. For instance: \"Technology\", \"Markets\", \"World\", \"Business\", or \"Sports\".\n\n# Examples\n\n**Input**: \"Apple Unveils New iPhone Model, Featuring Advanced AI Features\"  \n**Output**: \"Technology\"\n\n**Input**: \"Global Stocks Mixed as Investors Await Central Bank Decisions\"  \n**Output**: \"Markets\"\n\n**Input**: \"War in Ukraine: Latest Updates on Negotiation Status\"  \n**Output**: \"World\"\n\n**Input**: \"Microsoft in Talks to Acquire Gaming Company for $2 Billion\"  \n**Output**: \"Business\"\n\n**Input**: \"Manchester United Secures Win in Premier League Football Match\"  \n**Output**: \"Sports\" \n\n# Notes\n\n- If the headline appears to fit into more than one category, choose the most dominant theme.\n- Keywords or phrases such as \"stocks\", \"company acquisition\", \"match\", or technological brands can be good indicators for classification.\n"} , {"role":"user","content":"{{item.input}}"}]},"sampling_params":{"temperature":1,"max_completions_tokens":2048,"top_p":1,"seed":42},"model":"gpt-4o-mini","source":{"type":"file_content","content":[{"item":{"input":"Tech Company Launches Advanced Artificial Intelligence Platform","ground_truth":"Technology"}}]}}'
          response: |
            {
              "object": "eval.run",
              "id": "evalrun_67e57965b480819094274e3a32235e4c",
              "eval_id": "eval_67e579652b548190aaa83ada4b125f47",
              "report_url": "https://platform.openai.com/evaluations/eval_67e579652b548190aaa83ada4b125f47&run_id=evalrun_67e57965b480819094274e3a32235e4c",
              "status": "queued",
              "model": "gpt-4o-mini",
              "name": "gpt-4o-mini",
              "created_at": 1743092069,
              "result_counts": {
                "total": 0,
                "errored": 0,
                "failed": 0,
                "passed": 0
              },
              "per_model_usage": null,
              "per_testing_criteria_results": null,
              "data_source": {
                "type": "completions",
                "source": {
                  "type": "file_content",
                  "content": [
                    {
                      "item": {
                        "input": "Tech Company Launches Advanced Artificial Intelligence Platform",
                        "ground_truth": "Technology"
                      }
                    }
                  ]
                },
                "input_messages": {
                  "type": "template",
                  "template": [
                    {
                      "type": "message",
                      "role": "developer",
                      "content": {
                        "type": "input_text",
                        "text": "Categorize a given news headline into one of the following topics: Technology, Markets, World, Business, or Sports.\n\n# Steps\n\n1. Analyze the content of the news headline to understand its primary focus.\n2. Extract the subject matter, identifying any key indicators or keywords.\n3. Use the identified indicators to determine the most suitable category out of the five options: Technology, Markets, World, Business, or Sports.\n4. Ensure only one category is selected per headline.\n\n# Output Format\n\nRespond with the chosen category as a single word. For instance: \"Technology\", \"Markets\", \"World\", \"Business\", or \"Sports\".\n\n# Examples\n\n**Input**: \"Apple Unveils New iPhone Model, Featuring Advanced AI Features\"  \n**Output**: \"Technology\"\n\n**Input**: \"Global Stocks Mixed as Investors Await Central Bank Decisions\"  \n**Output**: \"Markets\"\n\n**Input**: \"War in Ukraine: Latest Updates on Negotiation Status\"  \n**Output**: \"World\"\n\n**Input**: \"Microsoft in Talks to Acquire Gaming Company for $2 Billion\"  \n**Output**: \"Business\"\n\n**Input**: \"Manchester United Secures Win in Premier League Football Match\"  \n**Output**: \"Sports\" \n\n# Notes\n\n- If the headline appears to fit into more than one category, choose the most dominant theme.\n- Keywords or phrases such as \"stocks\", \"company acquisition\", \"match\", or technological brands can be good indicators for classification.\n"
                      }
                    },
                    {
                      "type": "message",
                      "role": "user",
                      "content": {
                        "type": "input_text",
                        "text": "{{item.input}}"
                      }
                    }
                  ]
                },
                "model": "gpt-4o-mini",
                "sampling_params": {
                  "seed": 42,
                  "temperature": 1.0,
                  "top_p": 1.0,
                  "max_completions_tokens": 2048
                }
              },
              "error": null,
              "metadata": {}
            }
  /evals/{evalId}/runs/{runId}:
    get:
      tags:
      - Evals
      summary: |
        Get an evaluation run by ID.
      operationId: getEvalRun
      parameters:
      - name: evalId
        in: path
        description: The ID of the evaluation to retrieve runs for
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: runId
        in: path
        description: The ID of the run to retrieve
        required: true
        style: simple
        explode: false
        schema:
          type: string
      responses:
        "200":
          description: The evaluation run
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/EvalRun'
      x-oaiMeta:
        name: Get an eval run
        group: evals
        returns: "The [EvalRun](/docs/api-reference/evals/run-object) object matching\
          \ the specified ID."
        path: get
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/evals/eval_67abd54d9b0081909a86353f6fb9317a/runs/evalrun_67abd54d60ec8190832b46859da808f7 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json"
          response: |
            {
              "object": "eval.run",
              "id": "evalrun_67abd54d60ec8190832b46859da808f7",
              "eval_id": "eval_67abd54d9b0081909a86353f6fb9317a",
              "report_url": "https://platform.openai.com/evaluations/eval_67abd54d9b0081909a86353f6fb9317a?run_id=evalrun_67abd54d60ec8190832b46859da808f7",
              "status": "queued",
              "model": "gpt-4o-mini",
              "name": "gpt-4o-mini",
              "created_at": 1743092069,
              "result_counts": {
                "total": 0,
                "errored": 0,
                "failed": 0,
                "passed": 0
              },
              "per_model_usage": null,
              "per_testing_criteria_results": null,
              "data_source": {
                "type": "completions",
                "source": {
                  "type": "file_content",
                  "content": [
                    {
                      "item": {
                        "input": "Tech Company Launches Advanced Artificial Intelligence Platform",
                        "ground_truth": "Technology"
                      }
                    },
                    {
                      "item": {
                        "input": "Central Bank Increases Interest Rates Amid Inflation Concerns",
                        "ground_truth": "Markets"
                      }
                    },
                    {
                      "item": {
                        "input": "International Summit Addresses Climate Change Strategies",
                        "ground_truth": "World"
                      }
                    },
                    {
                      "item": {
                        "input": "Major Retailer Reports Record-Breaking Holiday Sales",
                        "ground_truth": "Business"
                      }
                    },
                    {
                      "item": {
                        "input": "National Team Qualifies for World Championship Finals",
                        "ground_truth": "Sports"
                      }
                    },
                    {
                      "item": {
                        "input": "Stock Markets Rally After Positive Economic Data Released",
                        "ground_truth": "Markets"
                      }
                    },
                    {
                      "item": {
                        "input": "Global Manufacturer Announces Merger with Competitor",
                        "ground_truth": "Business"
                      }
                    },
                    {
                      "item": {
                        "input": "Breakthrough in Renewable Energy Technology Unveiled",
                        "ground_truth": "Technology"
                      }
                    },
                    {
                      "item": {
                        "input": "World Leaders Sign Historic Climate Agreement",
                        "ground_truth": "World"
                      }
                    },
                    {
                      "item": {
                        "input": "Professional Athlete Sets New Record in Championship Event",
                        "ground_truth": "Sports"
                      }
                    },
                    {
                      "item": {
                        "input": "Financial Institutions Adapt to New Regulatory Requirements",
                        "ground_truth": "Business"
                      }
                    },
                    {
                      "item": {
                        "input": "Tech Conference Showcases Advances in Artificial Intelligence",
                        "ground_truth": "Technology"
                      }
                    },
                    {
                      "item": {
                        "input": "Global Markets Respond to Oil Price Fluctuations",
                        "ground_truth": "Markets"
                      }
                    },
                    {
                      "item": {
                        "input": "International Cooperation Strengthened Through New Treaty",
                        "ground_truth": "World"
                      }
                    },
                    {
                      "item": {
                        "input": "Sports League Announces Revised Schedule for Upcoming Season",
                        "ground_truth": "Sports"
                      }
                    }
                  ]
                },
                "input_messages": {
                  "type": "template",
                  "template": [
                    {
                      "type": "message",
                      "role": "developer",
                      "content": {
                        "type": "input_text",
                        "text": "Categorize a given news headline into one of the following topics: Technology, Markets, World, Business, or Sports.\n\n# Steps\n\n1. Analyze the content of the news headline to understand its primary focus.\n2. Extract the subject matter, identifying any key indicators or keywords.\n3. Use the identified indicators to determine the most suitable category out of the five options: Technology, Markets, World, Business, or Sports.\n4. Ensure only one category is selected per headline.\n\n# Output Format\n\nRespond with the chosen category as a single word. For instance: \"Technology\", \"Markets\", \"World\", \"Business\", or \"Sports\".\n\n# Examples\n\n**Input**: \"Apple Unveils New iPhone Model, Featuring Advanced AI Features\"  \n**Output**: \"Technology\"\n\n**Input**: \"Global Stocks Mixed as Investors Await Central Bank Decisions\"  \n**Output**: \"Markets\"\n\n**Input**: \"War in Ukraine: Latest Updates on Negotiation Status\"  \n**Output**: \"World\"\n\n**Input**: \"Microsoft in Talks to Acquire Gaming Company for $2 Billion\"  \n**Output**: \"Business\"\n\n**Input**: \"Manchester United Secures Win in Premier League Football Match\"  \n**Output**: \"Sports\" \n\n# Notes\n\n- If the headline appears to fit into more than one category, choose the most dominant theme.\n- Keywords or phrases such as \"stocks\", \"company acquisition\", \"match\", or technological brands can be good indicators for classification.\n"
                      }
                    },
                    {
                      "type": "message",
                      "role": "user",
                      "content": {
                        "type": "input_text",
                        "text": "{{item.input}}"
                      }
                    }
                  ]
                },
                "model": "gpt-4o-mini",
                "sampling_params": {
                  "seed": 42,
                  "temperature": 1.0,
                  "top_p": 1.0,
                  "max_completions_tokens": 2048
                }
              },
              "error": null,
              "metadata": {}
            }
    post:
      tags:
      - Evals
      summary: |
        Cancel an ongoing evaluation run.
      operationId: cancelEvalRun
      parameters:
      - name: evalId
        in: path
        description: The ID of the evaluation whose run you want to cancel
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: runId
        in: path
        description: The ID of the run to cancel
        required: true
        style: simple
        explode: false
        schema:
          type: string
      responses:
        "200":
          description: The canceled eval run object
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/EvalRun'
      x-oaiMeta:
        name: Cancel eval run
        group: evals
        returns: "The updated [EvalRun](/docs/api-reference/evals/run-object) object\
          \ reflecting that the run is canceled."
        path: post
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/evals/eval_67abd54d9b0081909a86353f6fb9317a/runs/evalrun_67abd54d60ec8190832b46859da808f7/cancel \
                -X POST \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json"
          response: |
            {
              "object": "eval.run",
              "id": "evalrun_67abd54d60ec8190832b46859da808f7",
              "eval_id": "eval_67abd54d9b0081909a86353f6fb9317a",
              "report_url": "https://platform.openai.com/evaluations/eval_67abd54d9b0081909a86353f6fb9317a?run_id=evalrun_67abd54d60ec8190832b46859da808f7",
              "status": "canceled",
              "model": "gpt-4o-mini",
              "name": "gpt-4o-mini",
              "created_at": 1743092069,
              "result_counts": {
                "total": 0,
                "errored": 0,
                "failed": 0,
                "passed": 0
              },
              "per_model_usage": null,
              "per_testing_criteria_results": null,
              "data_source": {
                "type": "completions",
                "source": {
                  "type": "file_content",
                  "content": [
                    {
                      "item": {
                        "input": "Tech Company Launches Advanced Artificial Intelligence Platform",
                        "ground_truth": "Technology"
                      }
                    },
                    {
                      "item": {
                        "input": "Central Bank Increases Interest Rates Amid Inflation Concerns",
                        "ground_truth": "Markets"
                      }
                    },
                    {
                      "item": {
                        "input": "International Summit Addresses Climate Change Strategies",
                        "ground_truth": "World"
                      }
                    },
                    {
                      "item": {
                        "input": "Major Retailer Reports Record-Breaking Holiday Sales",
                        "ground_truth": "Business"
                      }
                    },
                    {
                      "item": {
                        "input": "National Team Qualifies for World Championship Finals",
                        "ground_truth": "Sports"
                      }
                    },
                    {
                      "item": {
                        "input": "Stock Markets Rally After Positive Economic Data Released",
                        "ground_truth": "Markets"
                      }
                    },
                    {
                      "item": {
                        "input": "Global Manufacturer Announces Merger with Competitor",
                        "ground_truth": "Business"
                      }
                    },
                    {
                      "item": {
                        "input": "Breakthrough in Renewable Energy Technology Unveiled",
                        "ground_truth": "Technology"
                      }
                    },
                    {
                      "item": {
                        "input": "World Leaders Sign Historic Climate Agreement",
                        "ground_truth": "World"
                      }
                    },
                    {
                      "item": {
                        "input": "Professional Athlete Sets New Record in Championship Event",
                        "ground_truth": "Sports"
                      }
                    },
                    {
                      "item": {
                        "input": "Financial Institutions Adapt to New Regulatory Requirements",
                        "ground_truth": "Business"
                      }
                    },
                    {
                      "item": {
                        "input": "Tech Conference Showcases Advances in Artificial Intelligence",
                        "ground_truth": "Technology"
                      }
                    },
                    {
                      "item": {
                        "input": "Global Markets Respond to Oil Price Fluctuations",
                        "ground_truth": "Markets"
                      }
                    },
                    {
                      "item": {
                        "input": "International Cooperation Strengthened Through New Treaty",
                        "ground_truth": "World"
                      }
                    },
                    {
                      "item": {
                        "input": "Sports League Announces Revised Schedule for Upcoming Season",
                        "ground_truth": "Sports"
                      }
                    }
                  ]
                },
                "input_messages": {
                  "type": "template",
                  "template": [
                    {
                      "type": "message",
                      "role": "developer",
                      "content": {
                        "type": "input_text",
                        "text": "Categorize a given news headline into one of the following topics: Technology, Markets, World, Business, or Sports.\n\n# Steps\n\n1. Analyze the content of the news headline to understand its primary focus.\n2. Extract the subject matter, identifying any key indicators or keywords.\n3. Use the identified indicators to determine the most suitable category out of the five options: Technology, Markets, World, Business, or Sports.\n4. Ensure only one category is selected per headline.\n\n# Output Format\n\nRespond with the chosen category as a single word. For instance: \"Technology\", \"Markets\", \"World\", \"Business\", or \"Sports\".\n\n# Examples\n\n**Input**: \"Apple Unveils New iPhone Model, Featuring Advanced AI Features\"  \n**Output**: \"Technology\"\n\n**Input**: \"Global Stocks Mixed as Investors Await Central Bank Decisions\"  \n**Output**: \"Markets\"\n\n**Input**: \"War in Ukraine: Latest Updates on Negotiation Status\"  \n**Output**: \"World\"\n\n**Input**: \"Microsoft in Talks to Acquire Gaming Company for $2 Billion\"  \n**Output**: \"Business\"\n\n**Input**: \"Manchester United Secures Win in Premier League Football Match\"  \n**Output**: \"Sports\" \n\n# Notes\n\n- If the headline appears to fit into more than one category, choose the most dominant theme.\n- Keywords or phrases such as \"stocks\", \"company acquisition\", \"match\", or technological brands can be good indicators for classification.\n"
                      }
                    },
                    {
                      "type": "message",
                      "role": "user",
                      "content": {
                        "type": "input_text",
                        "text": "{{item.input}}"
                      }
                    }
                  ]
                },
                "model": "gpt-4o-mini",
                "sampling_params": {
                  "seed": 42,
                  "temperature": 1.0,
                  "top_p": 1.0,
                  "max_completions_tokens": 2048
                }
              },
              "error": null,
              "metadata": {}
            }
    delete:
      tags:
      - Evals
      summary: |
        Delete an eval run.
      operationId: deleteEvalRun
      parameters:
      - name: evalId
        in: path
        description: The ID of the evaluation to delete the run from
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: runId
        in: path
        description: The ID of the run to delete
        required: true
        style: simple
        explode: false
        schema:
          type: string
      responses:
        "200":
          description: Successfully deleted the eval run
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/InlineResponse2003'
        "404":
          description: Run not found
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Error'
      x-oaiMeta:
        name: Delete eval run
        group: evals
        returns: An object containing the status of the delete operation.
        path: delete
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/evals/eval_123abc/runs/evalrun_abc456 \
                -X DELETE \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json"
          response: |
            {
              "object": "eval.run.deleted",
              "deleted": true,
              "run_id": "evalrun_abc456"
            }
  /evals/{evalId}/runs/{runId}/output_items:
    get:
      tags:
      - Evals
      summary: |
        Get a list of output items for an evaluation run.
      operationId: getEvalRunOutputItems
      parameters:
      - name: evalId
        in: path
        description: The ID of the evaluation to retrieve runs for
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: runId
        in: path
        description: The ID of the run to retrieve output items for
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: after
        in: query
        description: Identifier for the last output item from the previous pagination
          request
        required: false
        style: form
        explode: true
        schema:
          type: string
      - name: limit
        in: query
        description: Number of output items to retrieve
        required: false
        style: form
        explode: true
        schema:
          type: integer
          default: 20
      - name: status
        in: query
        description: |
          Filter output items by status. Use `failed` to filter by failed output
          items or `pass` to filter by passed output items
        required: false
        style: form
        explode: true
        schema:
          type: string
          enum:
          - fail
          - pass
      - name: order
        in: query
        description: Sort order for output items by timestamp. Use `asc` for ascending
          order or `desc` for descending order. Defaults to `asc`
        required: false
        style: form
        explode: true
        schema:
          type: string
          default: asc
          enum:
          - asc
          - desc
      responses:
        "200":
          description: A list of output items for the evaluation run
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/EvalRunOutputItemList'
      x-oaiMeta:
        name: Get eval run output items
        group: evals
        returns: "A list of [EvalRunOutputItem](/docs/api-reference/evals/run-output-item-object)\
          \ objects matching the specified ID."
        path: get
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/evals/egroup_67abd54d9b0081909a86353f6fb9317a/runs/erun_67abd54d60ec8190832b46859da808f7/output_items \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json"
          response: |
            {
              "object": "list",
              "data": [
                {
                  "object": "eval.run.output_item",
                  "id": "outputitem_67e5796c28e081909917bf79f6e6214d",
                  "created_at": 1743092076,
                  "run_id": "evalrun_67abd54d60ec8190832b46859da808f7",
                  "eval_id": "eval_67abd54d9b0081909a86353f6fb9317a",
                  "status": "pass",
                  "datasource_item_id": 5,
                  "datasource_item": {
                    "input": "Stock Markets Rally After Positive Economic Data Released",
                    "ground_truth": "Markets"
                  },
                  "results": [
                    {
                      "name": "String check-a2486074-d803-4445-b431-ad2262e85d47",
                      "sample": null,
                      "passed": true,
                      "score": 1.0
                    }
                  ],
                  "sample": {
                    "input": [
                      {
                        "role": "developer",
                        "content": "Categorize a given news headline into one of the following topics: Technology, Markets, World, Business, or Sports.\n\n# Steps\n\n1. Analyze the content of the news headline to understand its primary focus.\n2. Extract the subject matter, identifying any key indicators or keywords.\n3. Use the identified indicators to determine the most suitable category out of the five options: Technology, Markets, World, Business, or Sports.\n4. Ensure only one category is selected per headline.\n\n# Output Format\n\nRespond with the chosen category as a single word. For instance: \"Technology\", \"Markets\", \"World\", \"Business\", or \"Sports\".\n\n# Examples\n\n**Input**: \"Apple Unveils New iPhone Model, Featuring Advanced AI Features\"  \n**Output**: \"Technology\"\n\n**Input**: \"Global Stocks Mixed as Investors Await Central Bank Decisions\"  \n**Output**: \"Markets\"\n\n**Input**: \"War in Ukraine: Latest Updates on Negotiation Status\"  \n**Output**: \"World\"\n\n**Input**: \"Microsoft in Talks to Acquire Gaming Company for $2 Billion\"  \n**Output**: \"Business\"\n\n**Input**: \"Manchester United Secures Win in Premier League Football Match\"  \n**Output**: \"Sports\" \n\n# Notes\n\n- If the headline appears to fit into more than one category, choose the most dominant theme.\n- Keywords or phrases such as \"stocks\", \"company acquisition\", \"match\", or technological brands can be good indicators for classification.\n",
                        "tool_call_id": null,
                        "tool_calls": null,
                        "function_call": null
                      },
                      {
                        "role": "user",
                        "content": "Stock Markets Rally After Positive Economic Data Released",
                        "tool_call_id": null,
                        "tool_calls": null,
                        "function_call": null
                      }
                    ],
                    "output": [
                      {
                        "role": "assistant",
                        "content": "Markets",
                        "tool_call_id": null,
                        "tool_calls": null,
                        "function_call": null
                      }
                    ],
                    "finish_reason": "stop",
                    "model": "gpt-4o-mini-2024-07-18",
                    "usage": {
                      "total_tokens": 325,
                      "completion_tokens": 2,
                      "prompt_tokens": 323,
                      "cached_tokens": 0
                    },
                    "error": null,
                    "temperature": 1.0,
                    "max_completion_tokens": 2048,
                    "top_p": 1.0,
                    "seed": 42
                  }
                }
              ],
              "first_id": "outputitem_67e5796c28e081909917bf79f6e6214d",
              "last_id": "outputitem_67e5796c28e081909917bf79f6e6214d",
              "has_more": true
            }
  /evals/{evalId}/runs/{runId}/output_items/{outputItemId}:
    get:
      tags:
      - Evals
      summary: |
        Get an evaluation run output item by ID.
      operationId: getEvalRunOutputItem
      parameters:
      - name: evalId
        in: path
        description: The ID of the evaluation to retrieve runs for
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: runId
        in: path
        description: The ID of the run to retrieve
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: outputItemId
        in: path
        description: The ID of the output item to retrieve
        required: true
        style: simple
        explode: false
        schema:
          type: string
      responses:
        "200":
          description: The evaluation run output item
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/EvalRunOutputItem'
      x-oaiMeta:
        name: Get an output item of an eval run
        group: evals
        returns: "The [EvalRunOutputItem](/docs/api-reference/evals/run-output-item-object)\
          \ object matching the specified ID."
        path: get
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/evals/eval_67abd54d9b0081909a86353f6fb9317a/runs/evalrun_67abd54d60ec8190832b46859da808f7/output_items/outputitem_67abd55eb6548190bb580745d5644a33 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json"
          response: |
            {
              "object": "eval.run.output_item",
              "id": "outputitem_67e5796c28e081909917bf79f6e6214d",
              "created_at": 1743092076,
              "run_id": "evalrun_67abd54d60ec8190832b46859da808f7",
              "eval_id": "eval_67abd54d9b0081909a86353f6fb9317a",
              "status": "pass",
              "datasource_item_id": 5,
              "datasource_item": {
                "input": "Stock Markets Rally After Positive Economic Data Released",
                "ground_truth": "Markets"
              },
              "results": [
                {
                  "name": "String check-a2486074-d803-4445-b431-ad2262e85d47",
                  "sample": null,
                  "passed": true,
                  "score": 1.0
                }
              ],
              "sample": {
                "input": [
                  {
                    "role": "developer",
                    "content": "Categorize a given news headline into one of the following topics: Technology, Markets, World, Business, or Sports.\n\n# Steps\n\n1. Analyze the content of the news headline to understand its primary focus.\n2. Extract the subject matter, identifying any key indicators or keywords.\n3. Use the identified indicators to determine the most suitable category out of the five options: Technology, Markets, World, Business, or Sports.\n4. Ensure only one category is selected per headline.\n\n# Output Format\n\nRespond with the chosen category as a single word. For instance: \"Technology\", \"Markets\", \"World\", \"Business\", or \"Sports\".\n\n# Examples\n\n**Input**: \"Apple Unveils New iPhone Model, Featuring Advanced AI Features\"  \n**Output**: \"Technology\"\n\n**Input**: \"Global Stocks Mixed as Investors Await Central Bank Decisions\"  \n**Output**: \"Markets\"\n\n**Input**: \"War in Ukraine: Latest Updates on Negotiation Status\"  \n**Output**: \"World\"\n\n**Input**: \"Microsoft in Talks to Acquire Gaming Company for $2 Billion\"  \n**Output**: \"Business\"\n\n**Input**: \"Manchester United Secures Win in Premier League Football Match\"  \n**Output**: \"Sports\" \n\n# Notes\n\n- If the headline appears to fit into more than one category, choose the most dominant theme.\n- Keywords or phrases such as \"stocks\", \"company acquisition\", \"match\", or technological brands can be good indicators for classification.\n",
                    "tool_call_id": null,
                    "tool_calls": null,
                    "function_call": null
                  },
                  {
                    "role": "user",
                    "content": "Stock Markets Rally After Positive Economic Data Released",
                    "tool_call_id": null,
                    "tool_calls": null,
                    "function_call": null
                  }
                ],
                "output": [
                  {
                    "role": "assistant",
                    "content": "Markets",
                    "tool_call_id": null,
                    "tool_calls": null,
                    "function_call": null
                  }
                ],
                "finish_reason": "stop",
                "model": "gpt-4o-mini-2024-07-18",
                "usage": {
                  "total_tokens": 325,
                  "completion_tokens": 2,
                  "prompt_tokens": 323,
                  "cached_tokens": 0
                },
                "error": null,
                "temperature": 1.0,
                "max_completion_tokens": 2048,
                "top_p": 1.0,
                "seed": 42
              }
            }
  /files:
    get:
      tags:
      - Files
      summary: Returns a list of files.
      operationId: listFiles
      parameters:
      - name: purpose
        in: query
        description: Only return files with the given purpose
        required: false
        style: form
        explode: true
        schema:
          type: string
      - name: limit
        in: query
        description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 10,000, and the default is 10,000
        required: false
        style: form
        explode: true
        schema:
          type: integer
          default: 10000
      - name: order
        in: query
        description: |
          Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order
        required: false
        style: form
        explode: true
        schema:
          type: string
          default: desc
          enum:
          - asc
          - desc
      - name: after
        in: query
        description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list
        required: false
        style: form
        explode: true
        schema:
          type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListFilesResponse'
      x-oaiMeta:
        name: List files
        group: files
        returns: "A list of [File](/docs/api-reference/files/object) objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/files \
                -H "Authorization: Bearer $OPENAI_API_KEY"
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.files.list()
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const list = await openai.files.list();

                for await (const file of list) {
                  console.log(file);
                }
              }

              main();
          response: |
            {
              "data": [
                {
                  "id": "file-abc123",
                  "object": "file",
                  "bytes": 175,
                  "created_at": 1613677385,
                  "filename": "salesOverview.pdf",
                  "purpose": "assistants",
                },
                {
                  "id": "file-abc123",
                  "object": "file",
                  "bytes": 140,
                  "created_at": 1613779121,
                  "filename": "puppy.jsonl",
                  "purpose": "fine-tune",
                }
              ],
              "object": "list"
            }
    post:
      tags:
      - Files
      summary: |
        Upload a file that can be used across various endpoints. Individual files can be up to 512 MB, and the size of all files uploaded by one organization can be up to 100 GB.

        The Assistants API supports files up to 2 million tokens and of specific file types. See the [Assistants Tools guide](/docs/assistants/tools) for details.

        The Fine-tuning API only supports `.jsonl` files. The input also has certain required formats for fine-tuning [chat](/docs/api-reference/fine-tuning/chat-input) or [completions](/docs/api-reference/fine-tuning/completions-input) models.

        The Batch API only supports `.jsonl` files up to 200 MB in size. The input also has a specific required [format](/docs/api-reference/batch/request-input).

        Please [contact us](https://help.openai.com/) if you need to increase these storage limits.
      operationId: createFile
      requestBody:
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/CreateFileRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/OpenAIFile'
      x-oaiMeta:
        name: Upload file
        group: files
        returns: "The uploaded [File](/docs/api-reference/files/object) object."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/files \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -F purpose="fine-tune" \
                -F file="@mydata.jsonl"
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.files.create(
                file=open("mydata.jsonl", "rb"),
                purpose="fine-tune"
              )
            node.js: |-
              import fs from "fs";
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const file = await openai.files.create({
                  file: fs.createReadStream("mydata.jsonl"),
                  purpose: "fine-tune",
                });

                console.log(file);
              }

              main();
          response: |
            {
              "id": "file-abc123",
              "object": "file",
              "bytes": 120000,
              "created_at": 1677610602,
              "filename": "mydata.jsonl",
              "purpose": "fine-tune",
            }
  /files/{fileId}:
    get:
      tags:
      - Files
      summary: Returns information about a specific file.
      operationId: retrieveFile
      parameters:
      - name: fileId
        in: path
        description: The ID of the file to use for this request
        required: true
        style: simple
        explode: false
        schema:
          type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/OpenAIFile'
      x-oaiMeta:
        name: Retrieve file
        group: files
        returns: "The [File](/docs/api-reference/files/object) object matching the\
          \ specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/files/file-abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY"
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.files.retrieve("file-abc123")
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const file = await openai.files.retrieve("file-abc123");

                console.log(file);
              }

              main();
          response: |
            {
              "id": "file-abc123",
              "object": "file",
              "bytes": 120000,
              "created_at": 1677610602,
              "filename": "mydata.jsonl",
              "purpose": "fine-tune",
            }
    delete:
      tags:
      - Files
      summary: Delete a file.
      operationId: deleteFile
      parameters:
      - name: fileId
        in: path
        description: The ID of the file to use for this request
        required: true
        style: simple
        explode: false
        schema:
          type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DeleteFileResponse'
      x-oaiMeta:
        name: Delete file
        group: files
        returns: Deletion status.
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/files/file-abc123 \
                -X DELETE \
                -H "Authorization: Bearer $OPENAI_API_KEY"
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.files.delete("file-abc123")
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const file = await openai.files.del("file-abc123");

                console.log(file);
              }

              main();
          response: |
            {
              "id": "file-abc123",
              "object": "file",
              "deleted": true
            }
  /files/{fileId}/content:
    get:
      tags:
      - Files
      summary: Returns the contents of the specified file.
      operationId: downloadFile
      parameters:
      - name: fileId
        in: path
        description: The ID of the file to use for this request
        required: true
        style: simple
        explode: false
        schema:
          type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                type: string
      x-oaiMeta:
        name: Retrieve file content
        group: files
        returns: The file content.
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/files/file-abc123/content \
                -H "Authorization: Bearer $OPENAI_API_KEY" > file.jsonl
            python: |
              from openai import OpenAI
              client = OpenAI()

              content = client.files.content("file-abc123")
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const file = await openai.files.content("file-abc123");

                console.log(file);
              }

              main();
  /fine_tuning/checkpoints/{fineTunedModelCheckpoint}/permissions:
    get:
      tags:
      - Fine-tuning
      summary: |
        **NOTE:** This endpoint requires an [admin API key](../admin-api-keys).

        Organization owners can use this endpoint to view all permissions for a fine-tuned model checkpoint.
      operationId: listFineTuningCheckpointPermissions
      parameters:
      - name: fineTunedModelCheckpoint
        in: path
        description: |
          The ID of the fine-tuned model checkpoint to get permissions for
        required: true
        style: simple
        explode: false
        schema:
          type: string
          example: ft-AF1WoRqd3aJAHsqc9NY7iL8F
      - name: project_id
        in: query
        description: The ID of the project to get permissions for
        required: false
        style: form
        explode: true
        schema:
          type: string
        x-ballerina-name: projectId
      - name: after
        in: query
        description: Identifier for the last permission ID from the previous pagination
          request
        required: false
        style: form
        explode: true
        schema:
          type: string
      - name: limit
        in: query
        description: Number of permissions to retrieve
        required: false
        style: form
        explode: true
        schema:
          type: integer
          default: 10
      - name: order
        in: query
        description: The order in which to retrieve permissions
        required: false
        style: form
        explode: true
        schema:
          type: string
          default: descending
          enum:
          - ascending
          - descending
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListFineTuningCheckpointPermissionResponse'
      x-oaiMeta:
        name: List checkpoint permissions
        group: fine-tuning
        returns: "A list of fine-tuned model checkpoint [permission objects](/docs/api-reference/fine-tuning/permission-object)\
          \ for a fine-tuned model checkpoint."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/fine_tuning/checkpoints/ft:gpt-4o-mini-2024-07-18:org:weather:B7R9VjQd/permissions \
                -H "Authorization: Bearer $OPENAI_API_KEY"
          response: |
            {
              "object": "list",
              "data": [
                {
                  "object": "checkpoint.permission",
                  "id": "cp_zc4Q7MP6XxulcVzj4MZdwsAB",
                  "created_at": 1721764867,
                  "project_id": "proj_abGMw1llN8IrBb6SvvY5A1iH"
                },
                {
                  "object": "checkpoint.permission",
                  "id": "cp_enQCFmOTGj3syEpYVhBRLTSy",
                  "created_at": 1721764800,
                  "project_id": "proj_iqGMw1llN8IrBb6SvvY5A1oF"
                },
              ],
              "first_id": "cp_zc4Q7MP6XxulcVzj4MZdwsAB",
              "last_id": "cp_enQCFmOTGj3syEpYVhBRLTSy",
              "has_more": false
            }
    post:
      tags:
      - Fine-tuning
      summary: |
        **NOTE:** Calling this endpoint requires an [admin API key](../admin-api-keys).

        This enables organization owners to share fine-tuned models with other projects in their organization.
      operationId: createFineTuningCheckpointPermission
      parameters:
      - name: fineTunedModelCheckpoint
        in: path
        description: |
          The ID of the fine-tuned model checkpoint to create a permission for
        required: true
        style: simple
        explode: false
        schema:
          type: string
          example: ft:gpt-4o-mini-2024-07-18:org:weather:B7R9VjQd
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateFineTuningCheckpointPermissionRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListFineTuningCheckpointPermissionResponse'
      x-oaiMeta:
        name: Create checkpoint permissions
        group: fine-tuning
        returns: "A list of fine-tuned model checkpoint [permission objects](/docs/api-reference/fine-tuning/permission-object)\
          \ for a fine-tuned model checkpoint."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/fine_tuning/checkpoints/ft:gpt-4o-mini-2024-07-18:org:weather:B7R9VjQd/permissions \
                -H "Authorization: Bearer $OPENAI_API_KEY"
                -d '{"project_ids": ["proj_abGMw1llN8IrBb6SvvY5A1iH"]}'
          response: |
            {
              "object": "list",
              "data": [
                {
                  "object": "checkpoint.permission",
                  "id": "cp_zc4Q7MP6XxulcVzj4MZdwsAB",
                  "created_at": 1721764867,
                  "project_id": "proj_abGMw1llN8IrBb6SvvY5A1iH"
                }
              ],
              "first_id": "cp_zc4Q7MP6XxulcVzj4MZdwsAB",
              "last_id": "cp_zc4Q7MP6XxulcVzj4MZdwsAB",
              "has_more": false
            }
  /fine_tuning/checkpoints/{fineTunedModelCheckpoint}/permissions/{permissionId}:
    delete:
      tags:
      - Fine-tuning
      summary: |
        **NOTE:** This endpoint requires an [admin API key](../admin-api-keys).

        Organization owners can use this endpoint to delete a permission for a fine-tuned model checkpoint.
      operationId: deleteFineTuningCheckpointPermission
      parameters:
      - name: fineTunedModelCheckpoint
        in: path
        description: |
          The ID of the fine-tuned model checkpoint to delete a permission for
        required: true
        style: simple
        explode: false
        schema:
          type: string
          example: ft:gpt-4o-mini-2024-07-18:org:weather:B7R9VjQd
      - name: permissionId
        in: path
        description: |
          The ID of the fine-tuned model checkpoint permission to delete
        required: true
        style: simple
        explode: false
        schema:
          type: string
          example: cp_zc4Q7MP6XxulcVzj4MZdwsAB
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DeleteFineTuningCheckpointPermissionResponse'
      x-oaiMeta:
        name: Delete checkpoint permission
        group: fine-tuning
        returns: "The deletion status of the fine-tuned model checkpoint [permission\
          \ object](/docs/api-reference/fine-tuning/permission-object)."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/fine_tuning/checkpoints/ft:gpt-4o-mini-2024-07-18:org:weather:B7R9VjQd/permissions/cp_zc4Q7MP6XxulcVzj4MZdwsAB \
                -H "Authorization: Bearer $OPENAI_API_KEY"
          response: |
            {
              "object": "checkpoint.permission",
              "id": "cp_zc4Q7MP6XxulcVzj4MZdwsAB",
              "deleted": true
            }
  /fine_tuning/jobs:
    get:
      tags:
      - Fine-tuning
      summary: |
        List your organization's fine-tuning jobs
      operationId: listPaginatedFineTuningJobs
      parameters:
      - name: after
        in: query
        description: Identifier for the last job from the previous pagination request
        required: false
        style: form
        explode: true
        schema:
          type: string
      - name: limit
        in: query
        description: Number of fine-tuning jobs to retrieve
        required: false
        style: form
        explode: true
        schema:
          type: integer
          default: 20
      - name: metadata
        in: query
        description: |
          Optional metadata filter. To filter, use the syntax `metadata[k]=v`. Alternatively, set `metadata=null` to indicate no metadata
        required: false
        style: deepObject
        explode: true
        schema:
          type: object
          additionalProperties:
            type: string
          nullable: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListPaginatedFineTuningJobsResponse'
      x-oaiMeta:
        name: List fine-tuning jobs
        group: fine-tuning
        returns: "A list of paginated [fine-tuning job](/docs/api-reference/fine-tuning/object)\
          \ objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/fine_tuning/jobs?limit=2&metadata[key]=value \
                -H "Authorization: Bearer $OPENAI_API_KEY"
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.fine_tuning.jobs.list()
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const list = await openai.fineTuning.jobs.list();

                for await (const fineTune of list) {
                  console.log(fineTune);
                }
              }

              main();
          response: |
            {
              "object": "list",
              "data": [
                {
                  "object": "fine_tuning.job",
                  "id": "ftjob-abc123",
                  "model": "gpt-4o-mini-2024-07-18",
                  "created_at": 1721764800,
                  "fine_tuned_model": null,
                  "organization_id": "org-123",
                  "result_files": [],
                  "status": "queued",
                  "validation_file": null,
                  "training_file": "file-abc123",
                  "metadata": {
                    "key": "value"
                  }
                },
                { ... },
                { ... }
              ], "has_more": true
            }
    post:
      tags:
      - Fine-tuning
      summary: |
        Creates a fine-tuning job which begins the process of creating a new model from a given dataset.

        Response includes details of the enqueued job including job status and the name of the fine-tuned models once complete.

        [Learn more about fine-tuning](/docs/guides/fine-tuning)
      operationId: createFineTuningJob
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateFineTuningJobRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FineTuningJob'
      x-oaiMeta:
        name: Create fine-tuning job
        group: fine-tuning
        returns: "A [fine-tuning.job](/docs/api-reference/fine-tuning/object) object."
        examples:
        - title: Default
          request:
            curl: |
              curl https://api.openai.com/v1/fine_tuning/jobs \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "training_file": "file-BK7bzQj3FfZFXr7DbL6xJwfo",
                  "model": "gpt-4o-mini"
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.fine_tuning.jobs.create(
                training_file="file-abc123",
                model="gpt-4o-mini"
              )
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const fineTune = await openai.fineTuning.jobs.create({
                  training_file: "file-abc123"
                });

                console.log(fineTune);
              }

              main();
          response: |
            {
              "object": "fine_tuning.job",
              "id": "ftjob-abc123",
              "model": "gpt-4o-mini-2024-07-18",
              "created_at": 1721764800,
              "fine_tuned_model": null,
              "organization_id": "org-123",
              "result_files": [],
              "status": "queued",
              "validation_file": null,
              "training_file": "file-abc123",
              "method": {
                "type": "supervised",
                "supervised": {
                  "hyperparameters": {
                    "batch_size": "auto",
                    "learning_rate_multiplier": "auto",
                    "n_epochs": "auto",
                  }
                }
              },
              "metadata": null
            }
        - title: Epochs
          request:
            curl: |
              curl https://api.openai.com/v1/fine_tuning/jobs \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "training_file": "file-abc123",
                  "model": "gpt-4o-mini",
                  "method": {
                    "type": "supervised",
                    "supervised": {
                      "hyperparameters": {
                        "n_epochs": 2
                      }
                    }
                  }
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.fine_tuning.jobs.create(
                training_file="file-abc123",
                model="gpt-4o-mini",
                method={
                  "type": "supervised",
                  "supervised": {
                    "hyperparameters": {
                      "n_epochs": 2
                    }
                  }
                }
              )
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const fineTune = await openai.fineTuning.jobs.create({
                  training_file: "file-abc123",
                  model: "gpt-4o-mini",
                  method: {
                    type: "supervised",
                    supervised: {
                      hyperparameters: {
                        n_epochs: 2
                      }
                    }
                  }
                });

                console.log(fineTune);
              }

              main();
          response: |
            {
              "object": "fine_tuning.job",
              "id": "ftjob-abc123",
              "model": "gpt-4o-mini-2024-07-18",
              "created_at": 1721764800,
              "fine_tuned_model": null,
              "organization_id": "org-123",
              "result_files": [],
              "status": "queued",
              "validation_file": null,
              "training_file": "file-abc123",
              "hyperparameters": {"n_epochs": 2},
              "method": {
                "type": "supervised",
                "supervised": {
                  "hyperparameters": {
                    "batch_size": "auto",
                    "learning_rate_multiplier": "auto",
                    "n_epochs": 2,
                  }
                }
              },
              "metadata": null
            }
        - title: Validation file
          request:
            curl: |
              curl https://api.openai.com/v1/fine_tuning/jobs \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "training_file": "file-abc123",
                  "validation_file": "file-abc123",
                  "model": "gpt-4o-mini"
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.fine_tuning.jobs.create(
                training_file="file-abc123",
                validation_file="file-def456",
                model="gpt-4o-mini"
              )
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const fineTune = await openai.fineTuning.jobs.create({
                  training_file: "file-abc123",
                  validation_file: "file-abc123"
                });

                console.log(fineTune);
              }

              main();
          response: |
            {
              "object": "fine_tuning.job",
              "id": "ftjob-abc123",
              "model": "gpt-4o-mini-2024-07-18",
              "created_at": 1721764800,
              "fine_tuned_model": null,
              "organization_id": "org-123",
              "result_files": [],
              "status": "queued",
              "validation_file": "file-abc123",
              "training_file": "file-abc123",
              "method": {
                "type": "supervised",
                "supervised": {
                  "hyperparameters": {
                    "batch_size": "auto",
                    "learning_rate_multiplier": "auto",
                    "n_epochs": "auto",
                  }
                }
              },
              "metadata": null
            }
        - title: DPO
          request:
            curl: |
              curl https://api.openai.com/v1/fine_tuning/jobs \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "training_file": "file-abc123",
                  "validation_file": "file-abc123",
                  "model": "gpt-4o-mini",
                  "method": {
                    "type": "dpo",
                    "dpo": {
                      "hyperparameters": {
                        "beta": 0.1,
                      }
                    }
                  }
                }'
          response: |
            {
              "object": "fine_tuning.job",
              "id": "ftjob-abc123",
              "model": "gpt-4o-mini-2024-07-18",
              "created_at": 1721764800,
              "fine_tuned_model": null,
              "organization_id": "org-123",
              "result_files": [],
              "status": "queued",
              "validation_file": "file-abc123",
              "training_file": "file-abc123",
              "method": {
                "type": "dpo",
                "dpo": {
                  "hyperparameters": {
                    "beta": 0.1,
                    "batch_size": "auto",
                    "learning_rate_multiplier": "auto",
                    "n_epochs": "auto",
                  }
                }
              },
              "metadata": null
            }
        - title: W&B Integration
          request:
            curl: |
              curl https://api.openai.com/v1/fine_tuning/jobs \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "training_file": "file-abc123",
                  "validation_file": "file-abc123",
                  "model": "gpt-4o-mini",
                  "integrations": [
                    {
                      "type": "wandb",
                      "wandb": {
                        "project": "my-wandb-project",
                        "name": "ft-run-display-name"
                        "tags": [
                          "first-experiment", "v2"
                        ]
                      }
                    }
                  ]
                }'
          response: |
            {
              "object": "fine_tuning.job",
              "id": "ftjob-abc123",
              "model": "gpt-4o-mini-2024-07-18",
              "created_at": 1721764800,
              "fine_tuned_model": null,
              "organization_id": "org-123",
              "result_files": [],
              "status": "queued",
              "validation_file": "file-abc123",
              "training_file": "file-abc123",
              "integrations": [
                {
                  "type": "wandb",
                  "wandb": {
                    "project": "my-wandb-project",
                    "entity": None,
                    "run_id": "ftjob-abc123"
                  }
                }
              ],
              "method": {
                "type": "supervised",
                "supervised": {
                  "hyperparameters": {
                    "batch_size": "auto",
                    "learning_rate_multiplier": "auto",
                    "n_epochs": "auto",
                  }
                }
              },
              "metadata": null
            }
  /fine_tuning/jobs/{fineTuningJobId}:
    get:
      tags:
      - Fine-tuning
      summary: |
        Get info about a fine-tuning job.

        [Learn more about fine-tuning](/docs/guides/fine-tuning)
      operationId: retrieveFineTuningJob
      parameters:
      - name: fineTuningJobId
        in: path
        description: |
          The ID of the fine-tuning job
        required: true
        style: simple
        explode: false
        schema:
          type: string
          example: ft-AF1WoRqd3aJAHsqc9NY7iL8F
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FineTuningJob'
      x-oaiMeta:
        name: Retrieve fine-tuning job
        group: fine-tuning
        returns: "The [fine-tuning](/docs/api-reference/fine-tuning/object) object\
          \ with the given ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/fine_tuning/jobs/ft-AF1WoRqd3aJAHsqc9NY7iL8F \
                -H "Authorization: Bearer $OPENAI_API_KEY"
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.fine_tuning.jobs.retrieve("ftjob-abc123")
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const fineTune = await openai.fineTuning.jobs.retrieve("ftjob-abc123");

                console.log(fineTune);
              }

              main();
          response: |
            {
              "object": "fine_tuning.job",
              "id": "ftjob-abc123",
              "model": "davinci-002",
              "created_at": 1692661014,
              "finished_at": 1692661190,
              "fine_tuned_model": "ft:davinci-002:my-org:custom_suffix:7q8mpxmy",
              "organization_id": "org-123",
              "result_files": [
                  "file-abc123"
              ],
              "status": "succeeded",
              "validation_file": null,
              "training_file": "file-abc123",
              "hyperparameters": {
                  "n_epochs": 4,
                  "batch_size": 1,
                  "learning_rate_multiplier": 1.0
              },
              "trained_tokens": 5768,
              "integrations": [],
              "seed": 0,
              "estimated_finish": 0,
              "method": {
                "type": "supervised",
                "supervised": {
                  "hyperparameters": {
                    "n_epochs": 4,
                    "batch_size": 1,
                    "learning_rate_multiplier": 1.0
                  }
                }
              }
            }
  /fine_tuning/jobs/{fineTuningJobId}/cancel:
    post:
      tags:
      - Fine-tuning
      summary: |
        Immediately cancel a fine-tune job.
      operationId: cancelFineTuningJob
      parameters:
      - name: fineTuningJobId
        in: path
        description: |
          The ID of the fine-tuning job to cancel
        required: true
        style: simple
        explode: false
        schema:
          type: string
          example: ft-AF1WoRqd3aJAHsqc9NY7iL8F
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FineTuningJob'
      x-oaiMeta:
        name: Cancel fine-tuning
        group: fine-tuning
        returns: "The cancelled [fine-tuning](/docs/api-reference/fine-tuning/object)\
          \ object."
        examples:
          request:
            curl: |
              curl -X POST https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/cancel \
                -H "Authorization: Bearer $OPENAI_API_KEY"
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.fine_tuning.jobs.cancel("ftjob-abc123")
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const fineTune = await openai.fineTuning.jobs.cancel("ftjob-abc123");

                console.log(fineTune);
              }
              main();
          response: |
            {
              "object": "fine_tuning.job",
              "id": "ftjob-abc123",
              "model": "gpt-4o-mini-2024-07-18",
              "created_at": 1721764800,
              "fine_tuned_model": null,
              "organization_id": "org-123",
              "result_files": [],
              "status": "cancelled",
              "validation_file": "file-abc123",
              "training_file": "file-abc123"
            }
  /fine_tuning/jobs/{fineTuningJobId}/checkpoints:
    get:
      tags:
      - Fine-tuning
      summary: |
        List checkpoints for a fine-tuning job.
      operationId: listFineTuningJobCheckpoints
      parameters:
      - name: fineTuningJobId
        in: path
        description: |
          The ID of the fine-tuning job to get checkpoints for
        required: true
        style: simple
        explode: false
        schema:
          type: string
          example: ft-AF1WoRqd3aJAHsqc9NY7iL8F
      - name: after
        in: query
        description: Identifier for the last checkpoint ID from the previous pagination
          request
        required: false
        style: form
        explode: true
        schema:
          type: string
      - name: limit
        in: query
        description: Number of checkpoints to retrieve
        required: false
        style: form
        explode: true
        schema:
          type: integer
          default: 10
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListFineTuningJobCheckpointsResponse'
      x-oaiMeta:
        name: List fine-tuning checkpoints
        group: fine-tuning
        returns: "A list of fine-tuning [checkpoint objects](/docs/api-reference/fine-tuning/checkpoint-object)\
          \ for a fine-tuning job."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/checkpoints \
                -H "Authorization: Bearer $OPENAI_API_KEY"
          response: |
            {
              "object": "list"
              "data": [
                {
                  "object": "fine_tuning.job.checkpoint",
                  "id": "ftckpt_zc4Q7MP6XxulcVzj4MZdwsAB",
                  "created_at": 1721764867,
                  "fine_tuned_model_checkpoint": "ft:gpt-4o-mini-2024-07-18:my-org:custom-suffix:96olL566:ckpt-step-2000",
                  "metrics": {
                    "full_valid_loss": 0.134,
                    "full_valid_mean_token_accuracy": 0.874
                  },
                  "fine_tuning_job_id": "ftjob-abc123",
                  "step_number": 2000,
                },
                {
                  "object": "fine_tuning.job.checkpoint",
                  "id": "ftckpt_enQCFmOTGj3syEpYVhBRLTSy",
                  "created_at": 1721764800,
                  "fine_tuned_model_checkpoint": "ft:gpt-4o-mini-2024-07-18:my-org:custom-suffix:7q8mpxmy:ckpt-step-1000",
                  "metrics": {
                    "full_valid_loss": 0.167,
                    "full_valid_mean_token_accuracy": 0.781
                  },
                  "fine_tuning_job_id": "ftjob-abc123",
                  "step_number": 1000,
                },
              ],
              "first_id": "ftckpt_zc4Q7MP6XxulcVzj4MZdwsAB",
              "last_id": "ftckpt_enQCFmOTGj3syEpYVhBRLTSy",
              "has_more": true
            }
  /fine_tuning/jobs/{fineTuningJobId}/events:
    get:
      tags:
      - Fine-tuning
      summary: |
        Get status updates for a fine-tuning job.
      operationId: listFineTuningEvents
      parameters:
      - name: fineTuningJobId
        in: path
        description: |
          The ID of the fine-tuning job to get events for
        required: true
        style: simple
        explode: false
        schema:
          type: string
          example: ft-AF1WoRqd3aJAHsqc9NY7iL8F
      - name: after
        in: query
        description: Identifier for the last event from the previous pagination request
        required: false
        style: form
        explode: true
        schema:
          type: string
      - name: limit
        in: query
        description: Number of events to retrieve
        required: false
        style: form
        explode: true
        schema:
          type: integer
          default: 20
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListFineTuningJobEventsResponse'
      x-oaiMeta:
        name: List fine-tuning events
        group: fine-tuning
        returns: A list of fine-tuning event objects.
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/events \
                -H "Authorization: Bearer $OPENAI_API_KEY"
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.fine_tuning.jobs.list_events(
                fine_tuning_job_id="ftjob-abc123",
                limit=2
              )
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const list = await openai.fineTuning.list_events(id="ftjob-abc123", limit=2);

                for await (const fineTune of list) {
                  console.log(fineTune);
                }
              }

              main();
          response: |
            {
              "object": "list",
              "data": [
                {
                  "object": "fine_tuning.job.event",
                  "id": "ft-event-ddTJfwuMVpfLXseO0Am0Gqjm",
                  "created_at": 1721764800,
                  "level": "info",
                  "message": "Fine tuning job successfully completed",
                  "data": null,
                  "type": "message"
                },
                {
                  "object": "fine_tuning.job.event",
                  "id": "ft-event-tyiGuB72evQncpH87xe505Sv",
                  "created_at": 1721764800,
                  "level": "info",
                  "message": "New fine-tuned model created: ft:gpt-4o-mini:openai::7p4lURel",
                  "data": null,
                  "type": "message"
                }
              ],
              "has_more": true
            }
  /images/edits:
    post:
      tags:
      - Images
      summary: Creates an edited or extended image given one or more source images
        and a prompt. This endpoint only supports `gpt-image-1` and `dall-e-2`.
      operationId: createImageEdit
      requestBody:
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/CreateImageEditRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ImagesResponse'
      x-oaiMeta:
        name: Create image edit
        group: images
        returns: "Returns a list of [image](/docs/api-reference/images/object) objects."
        examples:
          request:
            curl: |
              curl -s -D >(grep -i x-request-id >&2) \
                -o >(jq -r '.data[0].b64_json' | base64 --decode > gift-basket.png) \
                -X POST "https://api.openai.com/v1/images/edits" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -F "model=gpt-image-1" \
                -F "image[]=@body-lotion.png" \
                -F "image[]=@bath-bomb.png" \
                -F "image[]=@incense-kit.png" \
                -F "image[]=@soap.png" \
                -F 'prompt=Create a lovely gift basket with these four items in it'
            python: "import base64\nfrom openai import OpenAI\nclient = OpenAI()\n\
              \nprompt = \"\"\"\nGenerate a photorealistic image of a gift basket\
              \ on a white background \nlabeled 'Relax & Unwind' with a ribbon and\
              \ handwriting-like font, \ncontaining all the items in the reference\
              \ pictures.\n\"\"\"\n\nresult = client.images.edit(\n    model=\"gpt-image-1\"\
              ,\n    image=[\n        open(\"body-lotion.png\", \"rb\"),\n       \
              \ open(\"bath-bomb.png\", \"rb\"),\n        open(\"incense-kit.png\"\
              , \"rb\"),\n        open(\"soap.png\", \"rb\"),\n    ],\n    prompt=prompt\n\
              )\n\nimage_base64 = result.data[0].b64_json\nimage_bytes = base64.b64decode(image_base64)\n\
              \n# Save the image to a file\nwith open(\"gift-basket.png\", \"wb\"\
              ) as f:\n    f.write(image_bytes)\n"
            node.js: |
              import fs from "fs";
              import OpenAI, { toFile } from "openai";

              const client = new OpenAI();

              const imageFiles = [
                  "bath-bomb.png",
                  "body-lotion.png",
                  "incense-kit.png",
                  "soap.png",
              ];

              const images = await Promise.all(
                  imageFiles.map(async (file) =>
                      await toFile(fs.createReadStream(file), null, {
                          type: "image/png",
                      })
                  ),
              );

              const rsp = await client.images.edit({
                  model: "gpt-image-1",
                  image: images,
                  prompt: "Create a lovely gift basket with these four items in it",
              });

              // Save the image to a file
              const image_base64 = rsp.data[0].b64_json;
              const image_bytes = Buffer.from(image_base64, "base64");
              fs.writeFileSync("basket.png", image_bytes);
          response: |
            {
              "created": 1713833628,
              "data": [
                {
                  "b64_json": "..."
                }
              ],
              "usage": {
                "total_tokens": 100,
                "input_tokens": 50,
                "output_tokens": 50,
                "input_tokens_details": {
                  "text_tokens": 10,
                  "image_tokens": 40
                }
              }
            }
  /images/generations:
    post:
      tags:
      - Images
      summary: |
        Creates an image given a prompt. [Learn more](/docs/guides/images).
      operationId: createImage
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateImageRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ImagesResponse'
      x-oaiMeta:
        name: Create image
        group: images
        returns: "Returns a list of [image](/docs/api-reference/images/object) objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/images/generations \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "gpt-image-1",
                  "prompt": "A cute baby sea otter",
                  "n": 1,
                  "size": "1024x1024"
                }'
            python: |
              import base64
              from openai import OpenAI
              client = OpenAI()

              img = client.images.generate(
                  model="gpt-image-1",
                  prompt="A cute baby sea otter",
                  n=1,
                  size="1024x1024"
              )

              image_bytes = base64.b64decode(img.data[0].b64_json)
              with open("output.png", "wb") as f:
                  f.write(image_bytes)
            node.js: |
              import OpenAI from "openai";
              import { writeFile } from "fs/promises";

              const client = new OpenAI();

              const img = await client.images.generate({
                model: "gpt-image-1",
                prompt: "A cute baby sea otter",
                n: 1,
                size: "1024x1024"
              });

              const imageBuffer = Buffer.from(img.data[0].b64_json, "base64");
              await writeFile("output.png", imageBuffer);
          response: |
            {
              "created": 1713833628,
              "data": [
                {
                  "b64_json": "..."
                }
              ],
              "usage": {
                "total_tokens": 100,
                "input_tokens": 50,
                "output_tokens": 50,
                "input_tokens_details": {
                  "text_tokens": 10,
                  "image_tokens": 40
                }
              }
            }
  /images/variations:
    post:
      tags:
      - Images
      summary: Creates a variation of a given image. This endpoint only supports `dall-e-2`.
      operationId: createImageVariation
      requestBody:
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/CreateImageVariationRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ImagesResponse'
      x-oaiMeta:
        name: Create image variation
        group: images
        returns: "Returns a list of [image](/docs/api-reference/images/object) objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/images/variations \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -F image="@otter.png" \
                -F n=2 \
                -F size="1024x1024"
            python: |
              from openai import OpenAI
              client = OpenAI()

              response = client.images.create_variation(
                image=open("image_edit_original.png", "rb"),
                n=2,
                size="1024x1024"
              )
            node.js: |-
              import fs from "fs";
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const image = await openai.images.createVariation({
                  image: fs.createReadStream("otter.png"),
                });

                console.log(image.data);
              }
              main();
            csharp: |
              using System;

              using OpenAI.Images;

              ImageClient client = new(
                  model: "dall-e-2",
                  apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
              );

              GeneratedImage image = client.GenerateImageVariation(imageFilePath: "otter.png");

              Console.WriteLine(image.ImageUri);
          response: |
            {
              "created": 1589478378,
              "data": [
                {
                  "url": "https://..."
                },
                {
                  "url": "https://..."
                }
              ]
            }
  /models:
    get:
      tags:
      - Models
      summary: "Lists the currently available models, and provides basic information\
        \ about each one such as the owner and availability."
      operationId: listModels
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListModelsResponse'
      x-oaiMeta:
        name: List models
        group: models
        returns: "A list of [model](/docs/api-reference/models/object) objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/models \
                -H "Authorization: Bearer $OPENAI_API_KEY"
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.models.list()
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const list = await openai.models.list();

                for await (const model of list) {
                  console.log(model);
                }
              }
              main();
            csharp: |
              using System;

              using OpenAI.Models;

              OpenAIModelClient client = new(
                  apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
              );

              foreach (var model in client.GetModels().Value)
              {
                  Console.WriteLine(model.Id);
              }
          response: |
            {
              "object": "list",
              "data": [
                {
                  "id": "model-id-0",
                  "object": "model",
                  "created": 1686935002,
                  "owned_by": "organization-owner"
                },
                {
                  "id": "model-id-1",
                  "object": "model",
                  "created": 1686935002,
                  "owned_by": "organization-owner",
                },
                {
                  "id": "model-id-2",
                  "object": "model",
                  "created": 1686935002,
                  "owned_by": "openai"
                },
              ],
              "object": "list"
            }
  /models/{model}:
    get:
      tags:
      - Models
      summary: "Retrieves a model instance, providing basic information about the\
        \ model such as the owner and permissioning."
      operationId: retrieveModel
      parameters:
      - name: model
        in: path
        description: The ID of the model to use for this request
        required: true
        style: simple
        explode: false
        schema:
          type: string
          example: gpt-4o-mini
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Model'
      x-oaiMeta:
        name: Retrieve model
        group: models
        returns: "The [model](/docs/api-reference/models/object) object matching the\
          \ specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/models/VAR_chat_model_id \
                -H "Authorization: Bearer $OPENAI_API_KEY"
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.models.retrieve("VAR_chat_model_id")
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const model = await openai.models.retrieve("VAR_chat_model_id");

                console.log(model);
              }

              main();
            csharp: |
              using System;
              using System.ClientModel;

              using OpenAI.Models;

                OpenAIModelClient client = new(
                  apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
              );

              ClientResult<OpenAIModel> model = client.GetModel("babbage-002");
              Console.WriteLine(model.Value.Id);
          response: |
            {
              "id": "VAR_chat_model_id",
              "object": "model",
              "created": 1686935002,
              "owned_by": "openai"
            }
    delete:
      tags:
      - Models
      summary: Delete a fine-tuned model. You must have the Owner role in your organization
        to delete a model.
      operationId: deleteModel
      parameters:
      - name: model
        in: path
        description: The model to delete
        required: true
        style: simple
        explode: false
        schema:
          type: string
          example: ft:gpt-4o-mini:acemeco:suffix:abc123
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DeleteModelResponse'
      x-oaiMeta:
        name: Delete a fine-tuned model
        group: models
        returns: Deletion status.
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/models/ft:gpt-4o-mini:acemeco:suffix:abc123 \
                -X DELETE \
                -H "Authorization: Bearer $OPENAI_API_KEY"
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.models.delete("ft:gpt-4o-mini:acemeco:suffix:abc123")
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const model = await openai.models.del("ft:gpt-4o-mini:acemeco:suffix:abc123");

                console.log(model);
              }
              main();
            csharp: |
              using System;
              using System.ClientModel;

              using OpenAI.Models;

              OpenAIModelClient client = new(
                  apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
              );

              ClientResult success = client.DeleteModel("ft:gpt-4o-mini:acemeco:suffix:abc123");
              Console.WriteLine(success);
          response: |
            {
              "id": "ft:gpt-4o-mini:acemeco:suffix:abc123",
              "object": "model",
              "deleted": true
            }
  /moderations:
    post:
      tags:
      - Moderations
      summary: |
        Classifies if text and/or image inputs are potentially harmful. Learn
        more in the [moderation guide](/docs/guides/moderation).
      operationId: createModeration
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateModerationRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CreateModerationResponse'
      x-oaiMeta:
        name: Create moderation
        group: moderations
        returns: "A [moderation](/docs/api-reference/moderations/object) object."
        examples:
        - title: Single string
          request:
            curl: |
              curl https://api.openai.com/v1/moderations \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "input": "I want to kill them."
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              moderation = client.moderations.create(input="I want to kill them.")
              print(moderation)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const moderation = await openai.moderations.create({ input: "I want to kill them." });

                console.log(moderation);
              }
              main();
            csharp: |
              using System;
              using System.ClientModel;

              using OpenAI.Moderations;

              ModerationClient client = new(
                  model: "omni-moderation-latest",
                  apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
              );

              ClientResult<ModerationResult> moderation = client.ClassifyText("I want to kill them.");
          response: |
            {
              "id": "modr-AB8CjOTu2jiq12hp1AQPfeqFWaORR",
              "model": "text-moderation-007",
              "results": [
                {
                  "flagged": true,
                  "categories": {
                    "sexual": false,
                    "hate": false,
                    "harassment": true,
                    "self-harm": false,
                    "sexual/minors": false,
                    "hate/threatening": false,
                    "violence/graphic": false,
                    "self-harm/intent": false,
                    "self-harm/instructions": false,
                    "harassment/threatening": true,
                    "violence": true
                  },
                  "category_scores": {
                    "sexual": 0.000011726012417057063,
                    "hate": 0.22706663608551025,
                    "harassment": 0.5215635299682617,
                    "self-harm": 2.227119921371923e-6,
                    "sexual/minors": 7.107352217872176e-8,
                    "hate/threatening": 0.023547329008579254,
                    "violence/graphic": 0.00003391829886822961,
                    "self-harm/intent": 1.646940972932498e-6,
                    "self-harm/instructions": 1.1198755256458526e-9,
                    "harassment/threatening": 0.5694745779037476,
                    "violence": 0.9971134662628174
                  }
                }
              ]
            }
        - title: Image and text
          request:
            curl: |
              curl https://api.openai.com/v1/moderations \
                -X POST \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "omni-moderation-latest",
                  "input": [
                    { "type": "text", "text": "...text to classify goes here..." },
                    {
                      "type": "image_url",
                      "image_url": {
                        "url": "https://example.com/image.png"
                      }
                    }
                  ]
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              response = client.moderations.create(
                  model="omni-moderation-latest",
                  input=[
                      {"type": "text", "text": "...text to classify goes here..."},
                      {
                          "type": "image_url",
                          "image_url": {
                              "url": "https://example.com/image.png",
                              # can also use base64 encoded image URLs
                              # "url": "data:image/jpeg;base64,abcdefg..."
                          }
                      },
                  ],
              )

              print(response)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              const moderation = await openai.moderations.create({
                  model: "omni-moderation-latest",
                  input: [
                      { type: "text", text: "...text to classify goes here..." },
                      {
                          type: "image_url",
                          image_url: {
                              url: "https://example.com/image.png"
                              // can also use base64 encoded image URLs
                              // url: "data:image/jpeg;base64,abcdefg..."
                          }
                      }
                  ],
              });

              console.log(moderation);
          response: |
            {
              "id": "modr-0d9740456c391e43c445bf0f010940c7",
              "model": "omni-moderation-latest",
              "results": [
                {
                  "flagged": true,
                  "categories": {
                    "harassment": true,
                    "harassment/threatening": true,
                    "sexual": false,
                    "hate": false,
                    "hate/threatening": false,
                    "illicit": false,
                    "illicit/violent": false,
                    "self-harm/intent": false,
                    "self-harm/instructions": false,
                    "self-harm": false,
                    "sexual/minors": false,
                    "violence": true,
                    "violence/graphic": true
                  },
                  "category_scores": {
                    "harassment": 0.8189693396524255,
                    "harassment/threatening": 0.804985420696006,
                    "sexual": 1.573112165348997e-6,
                    "hate": 0.007562942636942845,
                    "hate/threatening": 0.004208854591835476,
                    "illicit": 0.030535955153511665,
                    "illicit/violent": 0.008925306722380033,
                    "self-harm/intent": 0.00023023930975076432,
                    "self-harm/instructions": 0.0002293869201073356,
                    "self-harm": 0.012598046106750154,
                    "sexual/minors": 2.212566909570261e-8,
                    "violence": 0.9999992735124786,
                    "violence/graphic": 0.843064871157054
                  },
                  "category_applied_input_types": {
                    "harassment": [
                      "text"
                    ],
                    "harassment/threatening": [
                      "text"
                    ],
                    "sexual": [
                      "text",
                      "image"
                    ],
                    "hate": [
                      "text"
                    ],
                    "hate/threatening": [
                      "text"
                    ],
                    "illicit": [
                      "text"
                    ],
                    "illicit/violent": [
                      "text"
                    ],
                    "self-harm/intent": [
                      "text",
                      "image"
                    ],
                    "self-harm/instructions": [
                      "text",
                      "image"
                    ],
                    "self-harm": [
                      "text",
                      "image"
                    ],
                    "sexual/minors": [
                      "text"
                    ],
                    "violence": [
                      "text",
                      "image"
                    ],
                    "violence/graphic": [
                      "text",
                      "image"
                    ]
                  }
                }
              ]
            }
  /organization/admin_api_keys:
    get:
      summary: List organization API keys
      description: Retrieve a paginated list of organization admin API keys.
      operationId: admin-api-keys-list
      parameters:
      - name: after
        in: query
        required: false
        style: form
        explode: true
        schema:
          type: string
          description: Return keys with IDs that come after this ID in the pagination
            order.
          nullable: true
      - name: order
        in: query
        required: false
        style: form
        explode: true
        schema:
          type: string
          description: "Order results by creation time, ascending or descending."
          default: asc
          enum:
          - asc
          - desc
      - name: limit
        in: query
        required: false
        style: form
        explode: true
        schema:
          type: integer
          description: Maximum number of keys to return.
          default: 20
      responses:
        "200":
          description: A list of organization API keys
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ApiKeyList'
      x-oaiMeta:
        name: List all organization and project API keys.
        group: administration
        returns: A list of admin and project API key objects.
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/organization/admin_api_keys?after=key_abc&limit=20 \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response: |
            {
              "object": "list",
              "data": [
                {
                  "object": "organization.admin_api_key",
                  "id": "key_abc",
                  "name": "Main Admin Key",
                  "redacted_value": "sk-admin...def",
                  "created_at": 1711471533,
                  "last_used_at": 1711471534,
                  "owner": {
                    "type": "service_account",
                    "object": "organization.service_account",
                    "id": "sa_456",
                    "name": "My Service Account",
                    "created_at": 1711471533,
                    "role": "member"
                  }
                }
              ],
              "first_id": "key_abc",
              "last_id": "key_abc",
              "has_more": false
            }
    post:
      summary: Create an organization admin API key
      description: Create a new admin-level API key for the organization.
      operationId: admin-api-keys-create
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/OrganizationAdminApiKeysBody'
        required: true
      responses:
        "200":
          description: The newly created admin API key
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/AdminApiKey'
      x-oaiMeta:
        name: Create admin API key
        group: administration
        returns: "The created [AdminApiKey](/docs/api-reference/admin-api-keys/object)\
          \ object."
        examples:
          request:
            curl: |
              curl -X POST https://api.openai.com/v1/organization/admin_api_keys \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json" \
                -d '{
                    "name": "New Admin Key"
                }'
          response: |
            {
              "object": "organization.admin_api_key",
              "id": "key_xyz",
              "name": "New Admin Key",
              "redacted_value": "sk-admin...xyz",
              "created_at": 1711471533,
              "last_used_at": 1711471534,
              "owner": {
                "type": "user",
                "object": "organization.user",
                "id": "user_123",
                "name": "John Doe",
                "created_at": 1711471533,
                "role": "owner"
              },
              "value": "sk-admin-1234abcd"
            }
  /organization/admin_api_keys/{keyId}:
    get:
      summary: Retrieve a single organization API key
      description: Get details for a specific organization API key by its ID.
      operationId: admin-api-keys-get
      parameters:
      - name: keyId
        in: path
        required: true
        style: simple
        explode: false
        schema:
          type: string
          description: The ID of the API key.
      responses:
        "200":
          description: Details of the requested API key
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/AdminApiKey'
      x-oaiMeta:
        name: Retrieve admin API key
        group: administration
        returns: "The requested [AdminApiKey](/docs/api-reference/admin-api-keys/object)\
          \ object."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/organization/admin_api_keys/key_abc \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response: |
            {
              "object": "organization.admin_api_key",
              "id": "key_abc",
              "name": "Main Admin Key",
              "redacted_value": "sk-admin...xyz",
              "created_at": 1711471533,
              "last_used_at": 1711471534,
              "owner": {
                "type": "user",
                "object": "organization.user",
                "id": "user_123",
                "name": "John Doe",
                "created_at": 1711471533,
                "role": "owner"
              }
            }
    delete:
      summary: Delete an organization admin API key
      description: Delete the specified admin API key.
      operationId: admin-api-keys-delete
      parameters:
      - name: keyId
        in: path
        required: true
        style: simple
        explode: false
        schema:
          type: string
          description: The ID of the API key to be deleted.
      responses:
        "200":
          description: Confirmation that the API key was deleted
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/InlineResponse2004'
      x-oaiMeta:
        name: Delete admin API key
        group: administration
        returns: A confirmation object indicating the key was deleted.
        examples:
          request:
            curl: |
              curl -X DELETE https://api.openai.com/v1/organization/admin_api_keys/key_abc \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response: |
            {
              "id": "key_abc",
              "object": "organization.admin_api_key.deleted",
              "deleted": true
            }
  /organization/audit_logs:
    get:
      tags:
      - Audit Logs
      summary: List user actions and configuration changes within this organization.
      operationId: list-audit-logs
      parameters:
      - name: effective_at
        in: query
        description: Return only events whose `effective_at` (Unix seconds) is in
          this range
        required: false
        style: form
        explode: true
        schema:
          $ref: '#/components/schemas/EffectiveAt'
        x-ballerina-name: effectiveAt
      - name: "project_ids[]"
        in: query
        description: Return only events for these projects
        required: false
        style: form
        explode: true
        schema:
          type: array
          items:
            type: string
        x-ballerina-name: projectIds
      - name: "event_types[]"
        in: query
        description: "Return only events with a `type` in one of these values. For\
          \ example, `project.created`. For all options, see the documentation for\
          \ the [audit log object](/docs/api-reference/audit-logs/object)"
        required: false
        style: form
        explode: true
        schema:
          type: array
          items:
            $ref: '#/components/schemas/AuditLogEventType'
        x-ballerina-name: eventTypes
      - name: "actor_ids[]"
        in: query
        description: "Return only events performed by these actors. Can be a user\
          \ ID, a service account ID, or an api key tracking ID"
        required: false
        style: form
        explode: true
        schema:
          type: array
          items:
            type: string
        x-ballerina-name: actorIds
      - name: "actor_emails[]"
        in: query
        description: Return only events performed by users with these emails
        required: false
        style: form
        explode: true
        schema:
          type: array
          items:
            type: string
        x-ballerina-name: actorEmails
      - name: "resource_ids[]"
        in: query
        description: "Return only events performed on these targets. For example,\
          \ a project ID updated"
        required: false
        style: form
        explode: true
        schema:
          type: array
          items:
            type: string
        x-ballerina-name: resourceIds
      - name: limit
        in: query
        description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20
        required: false
        style: form
        explode: true
        schema:
          type: integer
          default: 20
      - name: after
        in: query
        description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list
        required: false
        style: form
        explode: true
        schema:
          type: string
      - name: before
        in: query
        description: |
          A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list
        required: false
        style: form
        explode: true
        schema:
          type: string
      responses:
        "200":
          description: Audit logs listed successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListAuditLogsResponse'
      x-oaiMeta:
        name: List audit logs
        group: audit-logs
        returns: "A list of paginated [Audit Log](/docs/api-reference/audit-logs/object)\
          \ objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/organization/audit_logs \
              -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
              -H "Content-Type: application/json"
          response: |
            {
                "object": "list",
                "data": [
                    {
                        "id": "audit_log-xxx_yyyymmdd",
                        "type": "project.archived",
                        "effective_at": 1722461446,
                        "actor": {
                            "type": "api_key",
                            "api_key": {
                                "type": "user",
                                "user": {
                                    "id": "user-xxx",
                                    "email": "user@example.com"
                                }
                            }
                        },
                        "project.archived": {
                            "id": "proj_abc"
                        },
                    },
                    {
                        "id": "audit_log-yyy__20240101",
                        "type": "api_key.updated",
                        "effective_at": 1720804190,
                        "actor": {
                            "type": "session",
                            "session": {
                                "user": {
                                    "id": "user-xxx",
                                    "email": "user@example.com"
                                },
                                "ip_address": "127.0.0.1",
                                "user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
                                "ja3": "a497151ce4338a12c4418c44d375173e",
                                "ja4": "q13d0313h3_55b375c5d22e_c7319ce65786",
                                "ip_address_details": {
                                  "country": "US",
                                  "city": "San Francisco",
                                  "region": "California",
                                  "region_code": "CA",
                                  "asn": "1234",
                                  "latitude": "37.77490",
                                  "longitude": "-122.41940"
                                }
                            }
                        },
                        "api_key.updated": {
                            "id": "key_xxxx",
                            "data": {
                                "scopes": ["resource_2.operation_2"]
                            }
                        },
                    }
                ],
                "first_id": "audit_log-xxx__20240101",
                "last_id": "audit_log_yyy__20240101",
                "has_more": true
            }
  /organization/certificates:
    get:
      tags:
      - Certificates
      summary: List uploaded certificates for this organization.
      operationId: listOrganizationCertificates
      parameters:
      - name: limit
        in: query
        description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20
        required: false
        style: form
        explode: true
        schema:
          type: integer
          default: 20
      - name: after
        in: query
        description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list
        required: false
        style: form
        explode: true
        schema:
          type: string
      - name: order
        in: query
        description: |
          Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order
        required: false
        style: form
        explode: true
        schema:
          type: string
          default: desc
          enum:
          - asc
          - desc
      responses:
        "200":
          description: Certificates listed successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListCertificatesResponse'
      x-oaiMeta:
        name: List organization certificates
        group: administration
        returns: "A list of [Certificate](/docs/api-reference/certificates/object)\
          \ objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/organization/certificates \
              -H "Authorization: Bearer $OPENAI_ADMIN_KEY"
          response: |
            {
              "object": "list",
              "data": [
                {
                  "object": "organization.certificate",
                  "id": "cert_abc",
                  "name": "My Example Certificate",
                  "active": true,
                  "created_at": 1234567,
                  "certificate_details": {
                    "valid_at": 12345667,
                    "expires_at": 12345678
                  }
                },
              ],
              "first_id": "cert_abc",
              "last_id": "cert_abc",
              "has_more": false
            }
    post:
      tags:
      - Certificates
      summary: |
        Upload a certificate to the organization. This does **not** automatically activate the certificate.

        Organizations can upload up to 50 certificates.
      operationId: uploadCertificate
      requestBody:
        description: The certificate upload payload
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/UploadCertificateRequest'
        required: true
      responses:
        "200":
          description: Certificate uploaded successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Certificate'
      x-oaiMeta:
        name: Upload certificate
        group: administration
        returns: "A single [Certificate](/docs/api-reference/certificates/object)\
          \ object."
        examples:
          request:
            curl: |
              curl -X POST https://api.openai.com/v1/organization/certificates \
              -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
              -H "Content-Type: application/json" \
              -d '{
                "name": "My Example Certificate",
                "certificate": "-----BEGIN CERTIFICATE-----\\nMIIDeT...\\n-----END CERTIFICATE-----"
              }'
          response: |
            {
              "object": "certificate",
              "id": "cert_abc",
              "name": "My Example Certificate",
              "created_at": 1234567,
              "certificate_details": {
                "valid_at": 12345667,
                "expires_at": 12345678
              }
            }
  /organization/certificates/activate:
    post:
      tags:
      - Certificates
      summary: |
        Activate certificates at the organization level.

        You can atomically and idempotently activate up to 10 certificates at a time.
      operationId: activateOrganizationCertificates
      requestBody:
        description: The certificate activation payload
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ToggleCertificatesRequest'
        required: true
      responses:
        "200":
          description: Certificates activated successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListCertificatesResponse'
      x-oaiMeta:
        name: Activate certificates for organization
        group: administration
        returns: "A list of [Certificate](/docs/api-reference/certificates/object)\
          \ objects that were activated."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/organization/certificates/activate \
              -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
              -H "Content-Type: application/json" \
              -d '{
                "data": ["cert_abc", "cert_def"]
              }'
          response: |
            {
              "object": "organization.certificate.activation",
              "data": [
                {
                  "object": "organization.certificate",
                  "id": "cert_abc",
                  "name": "My Example Certificate",
                  "active": true,
                  "created_at": 1234567,
                  "certificate_details": {
                    "valid_at": 12345667,
                    "expires_at": 12345678
                  }
                },
                {
                  "object": "organization.certificate",
                  "id": "cert_def",
                  "name": "My Example Certificate 2",
                  "active": true,
                  "created_at": 1234567,
                  "certificate_details": {
                    "valid_at": 12345667,
                    "expires_at": 12345678
                  }
                },
              ],
            }
  /organization/certificates/deactivate:
    post:
      tags:
      - Certificates
      summary: |
        Deactivate certificates at the organization level.

        You can atomically and idempotently deactivate up to 10 certificates at a time.
      operationId: deactivateOrganizationCertificates
      requestBody:
        description: The certificate deactivation payload
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ToggleCertificatesRequest'
        required: true
      responses:
        "200":
          description: Certificates deactivated successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListCertificatesResponse'
      x-oaiMeta:
        name: Deactivate certificates for organization
        group: administration
        returns: "A list of [Certificate](/docs/api-reference/certificates/object)\
          \ objects that were deactivated."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/organization/certificates/deactivate \
              -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
              -H "Content-Type: application/json" \
              -d '{
                "data": ["cert_abc", "cert_def"]
              }'
          response: |
            {
              "object": "organization.certificate.deactivation",
              "data": [
                {
                  "object": "organization.certificate",
                  "id": "cert_abc",
                  "name": "My Example Certificate",
                  "active": false,
                  "created_at": 1234567,
                  "certificate_details": {
                    "valid_at": 12345667,
                    "expires_at": 12345678
                  }
                },
                {
                  "object": "organization.certificate",
                  "id": "cert_def",
                  "name": "My Example Certificate 2",
                  "active": false,
                  "created_at": 1234567,
                  "certificate_details": {
                    "valid_at": 12345667,
                    "expires_at": 12345678
                  }
                },
              ],
            }
  /organization/certificates/{certificateId}:
    get:
      tags:
      - Certificates
      summary: |
        Get a certificate that has been uploaded to the organization.

        You can get a certificate regardless of whether it is active or not.
      operationId: getCertificate
      parameters:
      - name: certificateId
        in: path
        description: Unique ID of the certificate to retrieve
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: include
        in: query
        description: A list of additional fields to include in the response. Currently
          the only supported value is `content` to fetch the PEM content of the certificate
        required: false
        style: form
        explode: true
        schema:
          type: array
          items:
            type: string
            enum:
            - content
      responses:
        "200":
          description: Certificate retrieved successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Certificate'
      x-oaiMeta:
        name: Get certificate
        group: administration
        returns: "A single [Certificate](/docs/api-reference/certificates/object)\
          \ object."
        examples:
          request:
            curl: |
              curl "https://api.openai.com/v1/organization/certificates/cert_abc?include[]=content" \
              -H "Authorization: Bearer $OPENAI_ADMIN_KEY"
          response: |
            {
              "object": "certificate",
              "id": "cert_abc",
              "name": "My Example Certificate",
              "created_at": 1234567,
              "certificate_details": {
                "valid_at": 1234567,
                "expires_at": 12345678,
                "content": "-----BEGIN CERTIFICATE-----MIIDeT...-----END CERTIFICATE-----"
              }
            }
    post:
      tags:
      - Certificates
      summary: |
        Modify a certificate. Note that only the name can be modified.
      operationId: modifyCertificate
      requestBody:
        description: The certificate modification payload
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ModifyCertificateRequest'
        required: true
      responses:
        "200":
          description: Certificate modified successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Certificate'
      x-oaiMeta:
        name: Modify certificate
        group: administration
        returns: "The updated [Certificate](/docs/api-reference/certificates/object)\
          \ object."
        examples:
          request:
            curl: |
              curl -X POST https://api.openai.com/v1/organization/certificates/cert_abc \
              -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
              -H "Content-Type: application/json" \
              -d '{
                "name": "Renamed Certificate"
              }'
          response: |
            {
              "object": "certificate",
              "id": "cert_abc",
              "name": "Renamed Certificate",
              "created_at": 1234567,
              "certificate_details": {
                "valid_at": 12345667,
                "expires_at": 12345678
              }
            }
    delete:
      tags:
      - Certificates
      summary: |
        Delete a certificate from the organization.

        The certificate must be inactive for the organization and all projects.
      operationId: deleteCertificate
      responses:
        "200":
          description: Certificate deleted successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DeleteCertificateResponse'
      x-oaiMeta:
        name: Delete certificate
        group: administration
        returns: A confirmation object indicating the certificate was deleted.
        examples:
          request:
            curl: |
              curl -X DELETE https://api.openai.com/v1/organization/certificates/cert_abc \
              -H "Authorization: Bearer $OPENAI_ADMIN_KEY"
          response: |
            {
              "object": "certificate.deleted",
              "id": "cert_abc"
            }
    parameters:
    - name: certificateId
      in: path
      required: true
      style: simple
      explode: false
      schema:
        type: string
  /organization/costs:
    get:
      tags:
      - Usage
      summary: Get costs details for the organization.
      operationId: usage-costs
      parameters:
      - name: start_time
        in: query
        description: "Start time (Unix seconds) of the query time range, inclusive"
        required: true
        style: form
        explode: true
        schema:
          type: integer
        x-ballerina-name: startTime
      - name: end_time
        in: query
        description: "End time (Unix seconds) of the query time range, exclusive"
        required: false
        style: form
        explode: true
        schema:
          type: integer
        x-ballerina-name: endTime
      - name: bucket_width
        in: query
        description: "Width of each time bucket in response. Currently only `1d` is\
          \ supported, default to `1d`"
        required: false
        style: form
        explode: true
        schema:
          type: string
          default: 1d
          enum:
          - 1d
        x-ballerina-name: bucketWidth
      - name: project_ids
        in: query
        description: Return only costs for these projects
        required: false
        style: form
        explode: true
        schema:
          type: array
          items:
            type: string
        x-ballerina-name: projectIds
      - name: group_by
        in: query
        description: "Group the costs by the specified fields. Support fields include\
          \ `project_id`, `line_item` and any combination of them"
        required: false
        style: form
        explode: true
        schema:
          type: array
          items:
            type: string
            enum:
            - project_id
            - line_item
        x-ballerina-name: groupBy
      - name: limit
        in: query
        description: |
          A limit on the number of buckets to be returned. Limit can range between 1 and 180, and the default is 7
        required: false
        style: form
        explode: true
        schema:
          type: integer
          default: 7
      - name: page
        in: query
        description: A cursor for use in pagination. Corresponding to the `next_page`
          field from the previous response
        required: false
        style: form
        explode: true
        schema:
          type: string
      responses:
        "200":
          description: Costs data retrieved successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/UsageResponse'
      x-oaiMeta:
        name: Costs
        group: usage-costs
        returns: "A list of paginated, time bucketed [Costs](/docs/api-reference/usage/costs_object)\
          \ objects."
        examples:
          request:
            curl: |
              curl "https://api.openai.com/v1/organization/costs?start_time=1730419200&limit=1" \
              -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
              -H "Content-Type: application/json"
          response: |
            {
                "object": "page",
                "data": [
                    {
                        "object": "bucket",
                        "start_time": 1730419200,
                        "end_time": 1730505600,
                        "results": [
                            {
                                "object": "organization.costs.result",
                                "amount": {
                                    "value": 0.06,
                                    "currency": "usd"
                                },
                                "line_item": null,
                                "project_id": null
                            }
                        ]
                    }
                ],
                "has_more": false,
                "next_page": null
            }
  /organization/invites:
    get:
      tags:
      - Invites
      summary: Returns a list of invites in the organization.
      operationId: list-invites
      parameters:
      - name: limit
        in: query
        description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20
        required: false
        style: form
        explode: true
        schema:
          type: integer
          default: 20
      - name: after
        in: query
        description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list
        required: false
        style: form
        explode: true
        schema:
          type: string
      responses:
        "200":
          description: Invites listed successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/InviteListResponse'
      x-oaiMeta:
        name: List invites
        group: administration
        returns: "A list of [Invite](/docs/api-reference/invite/object) objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/organization/invites?after=invite-abc&limit=20 \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response: |
            {
              "object": "list",
              "data": [
                {
                  "object": "organization.invite",
                  "id": "invite-abc",
                  "email": "user@example.com",
                  "role": "owner",
                  "status": "accepted",
                  "invited_at": 1711471533,
                  "expires_at": 1711471533,
                  "accepted_at": 1711471533
                }
              ],
              "first_id": "invite-abc",
              "last_id": "invite-abc",
              "has_more": false
            }
    post:
      tags:
      - Invites
      summary: Create an invite for a user to the organization. The invite must be
        accepted by the user before they have access to the organization.
      operationId: inviteUser
      requestBody:
        description: The invite request payload
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/InviteRequest'
        required: true
      responses:
        "200":
          description: User invited successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Invite'
      x-oaiMeta:
        name: Create invite
        group: administration
        returns: "The created [Invite](/docs/api-reference/invite/object) object."
        examples:
          request:
            curl: |
              curl -X POST https://api.openai.com/v1/organization/invites \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json" \
                -d '{
                    "email": "anotheruser@example.com",
                    "role": "reader",
                    "projects": [
                      {
                        "id": "project-xyz",
                        "role": "member"
                      },
                      {
                        "id": "project-abc",
                        "role": "owner"
                      }
                    ]
                }'
          response: |
            {
              "object": "organization.invite",
              "id": "invite-def",
              "email": "anotheruser@example.com",
              "role": "reader",
              "status": "pending",
              "invited_at": 1711471533,
              "expires_at": 1711471533,
              "accepted_at": null,
              "projects": [
                {
                  "id": "project-xyz",
                  "role": "member"
                },
                {
                  "id": "project-abc",
                  "role": "owner"
                }
              ]
            }
  /organization/invites/{inviteId}:
    get:
      tags:
      - Invites
      summary: Retrieves an invite.
      operationId: retrieve-invite
      parameters:
      - name: inviteId
        in: path
        description: The ID of the invite to retrieve
        required: true
        style: simple
        explode: false
        schema:
          type: string
      responses:
        "200":
          description: Invite retrieved successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Invite'
      x-oaiMeta:
        name: Retrieve invite
        group: administration
        returns: "The [Invite](/docs/api-reference/invite/object) object matching\
          \ the specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/organization/invites/invite-abc \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response: |
            {
                "object": "organization.invite",
                "id": "invite-abc",
                "email": "user@example.com",
                "role": "owner",
                "status": "accepted",
                "invited_at": 1711471533,
                "expires_at": 1711471533,
                "accepted_at": 1711471533
            }
    delete:
      tags:
      - Invites
      summary: "Delete an invite. If the invite has already been accepted, it cannot\
        \ be deleted."
      operationId: delete-invite
      parameters:
      - name: inviteId
        in: path
        description: The ID of the invite to delete
        required: true
        style: simple
        explode: false
        schema:
          type: string
      responses:
        "200":
          description: Invite deleted successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/InviteDeleteResponse'
      x-oaiMeta:
        name: Delete invite
        group: administration
        returns: Confirmation that the invite has been deleted
        examples:
          request:
            curl: |
              curl -X DELETE https://api.openai.com/v1/organization/invites/invite-abc \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response: |
            {
                "object": "organization.invite.deleted",
                "id": "invite-abc",
                "deleted": true
            }
  /organization/projects:
    get:
      tags:
      - Projects
      summary: Returns a list of projects.
      operationId: list-projects
      parameters:
      - name: limit
        in: query
        description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20
        required: false
        style: form
        explode: true
        schema:
          type: integer
          default: 20
      - name: after
        in: query
        description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list
        required: false
        style: form
        explode: true
        schema:
          type: string
      - name: include_archived
        in: query
        description: If `true` returns all projects including those that have been
          `archived`. Archived projects are not included by default
        required: false
        style: form
        explode: true
        schema:
          type: boolean
          default: false
        x-ballerina-name: includeArchived
      responses:
        "200":
          description: Projects listed successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProjectListResponse'
      x-oaiMeta:
        name: List projects
        group: administration
        returns: "A list of [Project](/docs/api-reference/projects/object) objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/organization/projects?after=proj_abc&limit=20&include_archived=false \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response: |
            {
                "object": "list",
                "data": [
                    {
                        "id": "proj_abc",
                        "object": "organization.project",
                        "name": "Project example",
                        "created_at": 1711471533,
                        "archived_at": null,
                        "status": "active"
                    }
                ],
                "first_id": "proj-abc",
                "last_id": "proj-xyz",
                "has_more": false
            }
    post:
      tags:
      - Projects
      summary: "Create a new project in the organization. Projects can be created\
        \ and archived, but cannot be deleted."
      operationId: create-project
      requestBody:
        description: The project create request payload
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ProjectCreateRequest'
        required: true
      responses:
        "200":
          description: Project created successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Project'
      x-oaiMeta:
        name: Create project
        group: administration
        returns: "The created [Project](/docs/api-reference/projects/object) object."
        examples:
          request:
            curl: |
              curl -X POST https://api.openai.com/v1/organization/projects \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json" \
                -d '{
                    "name": "Project ABC"
                }'
          response: |
            {
                "id": "proj_abc",
                "object": "organization.project",
                "name": "Project ABC",
                "created_at": 1711471533,
                "archived_at": null,
                "status": "active"
            }
  /organization/projects/{projectId}:
    get:
      tags:
      - Projects
      summary: Retrieves a project.
      operationId: retrieve-project
      parameters:
      - name: projectId
        in: path
        description: The ID of the project
        required: true
        style: simple
        explode: false
        schema:
          type: string
      responses:
        "200":
          description: Project retrieved successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Project'
      x-oaiMeta:
        name: Retrieve project
        group: administration
        description: Retrieve a project.
        returns: "The [Project](/docs/api-reference/projects/object) object matching\
          \ the specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/organization/projects/proj_abc \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response: |
            {
                "id": "proj_abc",
                "object": "organization.project",
                "name": "Project example",
                "created_at": 1711471533,
                "archived_at": null,
                "status": "active"
            }
    post:
      tags:
      - Projects
      summary: Modifies a project in the organization.
      operationId: modify-project
      parameters:
      - name: projectId
        in: path
        description: The ID of the project
        required: true
        style: simple
        explode: false
        schema:
          type: string
      requestBody:
        description: The project update request payload
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ProjectUpdateRequest'
        required: true
      responses:
        "200":
          description: Project updated successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Project'
        "400":
          description: Error response when updating the default project.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
      x-oaiMeta:
        name: Modify project
        group: administration
        returns: "The updated [Project](/docs/api-reference/projects/object) object."
        examples:
          request:
            curl: |
              curl -X POST https://api.openai.com/v1/organization/projects/proj_abc \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json" \
                -d '{
                    "name": "Project DEF"
                }'
  /organization/projects/{projectId}/api_keys:
    get:
      tags:
      - Projects
      summary: Returns a list of API keys in the project.
      operationId: list-project-api-keys
      parameters:
      - name: projectId
        in: path
        description: The ID of the project
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: limit
        in: query
        description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20
        required: false
        style: form
        explode: true
        schema:
          type: integer
          default: 20
      - name: after
        in: query
        description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list
        required: false
        style: form
        explode: true
        schema:
          type: string
      responses:
        "200":
          description: Project API keys listed successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProjectApiKeyListResponse'
      x-oaiMeta:
        name: List project API keys
        group: administration
        returns: "A list of [ProjectApiKey](/docs/api-reference/project-api-keys/object)\
          \ objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/organization/projects/proj_abc/api_keys?after=key_abc&limit=20 \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response: |
            {
                "object": "list",
                "data": [
                    {
                        "object": "organization.project.api_key",
                        "redacted_value": "sk-abc...def",
                        "name": "My API Key",
                        "created_at": 1711471533,
                        "last_used_at": 1711471534,
                        "id": "key_abc",
                        "owner": {
                            "type": "user",
                            "user": {
                                "object": "organization.project.user",
                                "id": "user_abc",
                                "name": "First Last",
                                "email": "user@example.com",
                                "role": "owner",
                                "added_at": 1711471533
                            }
                        }
                    }
                ],
                "first_id": "key_abc",
                "last_id": "key_xyz",
                "has_more": false
            }
  /organization/projects/{projectId}/api_keys/{keyId}:
    get:
      tags:
      - Projects
      summary: Retrieves an API key in the project.
      operationId: retrieve-project-api-key
      parameters:
      - name: projectId
        in: path
        description: The ID of the project
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: keyId
        in: path
        description: The ID of the API key
        required: true
        style: simple
        explode: false
        schema:
          type: string
      responses:
        "200":
          description: Project API key retrieved successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProjectApiKey'
      x-oaiMeta:
        name: Retrieve project API key
        group: administration
        returns: "The [ProjectApiKey](/docs/api-reference/project-api-keys/object)\
          \ object matching the specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/organization/projects/proj_abc/api_keys/key_abc \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response: |
            {
                "object": "organization.project.api_key",
                "redacted_value": "sk-abc...def",
                "name": "My API Key",
                "created_at": 1711471533,
                "last_used_at": 1711471534,
                "id": "key_abc",
                "owner": {
                    "type": "user",
                    "user": {
                        "object": "organization.project.user",
                        "id": "user_abc",
                        "name": "First Last",
                        "email": "user@example.com",
                        "role": "owner",
                        "added_at": 1711471533
                    }
                }
            }
    delete:
      tags:
      - Projects
      summary: Deletes an API key from the project.
      operationId: delete-project-api-key
      parameters:
      - name: projectId
        in: path
        description: The ID of the project
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: keyId
        in: path
        description: The ID of the API key
        required: true
        style: simple
        explode: false
        schema:
          type: string
      responses:
        "200":
          description: Project API key deleted successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProjectApiKeyDeleteResponse'
        "400":
          description: Error response for various conditions.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
      x-oaiMeta:
        name: Delete project API key
        group: administration
        returns: Confirmation of the key's deletion or an error if the key belonged
          to a service account
        examples:
          request:
            curl: |
              curl -X DELETE https://api.openai.com/v1/organization/projects/proj_abc/api_keys/key_abc \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response: |
            {
                "object": "organization.project.api_key.deleted",
                "id": "key_abc",
                "deleted": true
            }
  /organization/projects/{projectId}/archive:
    post:
      tags:
      - Projects
      summary: Archives a project in the organization. Archived projects cannot be
        used or updated.
      operationId: archive-project
      parameters:
      - name: projectId
        in: path
        description: The ID of the project
        required: true
        style: simple
        explode: false
        schema:
          type: string
      responses:
        "200":
          description: Project archived successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Project'
      x-oaiMeta:
        name: Archive project
        group: administration
        returns: "The archived [Project](/docs/api-reference/projects/object) object."
        examples:
          request:
            curl: |
              curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/archive \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response: |
            {
                "id": "proj_abc",
                "object": "organization.project",
                "name": "Project DEF",
                "created_at": 1711471533,
                "archived_at": 1711471533,
                "status": "archived"
            }
  /organization/projects/{projectId}/certificates:
    get:
      tags:
      - Certificates
      summary: List certificates for this project.
      operationId: listProjectCertificates
      parameters:
      - name: limit
        in: query
        description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20
        required: false
        style: form
        explode: true
        schema:
          type: integer
          default: 20
      - name: after
        in: query
        description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list
        required: false
        style: form
        explode: true
        schema:
          type: string
      - name: order
        in: query
        description: |
          Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order
        required: false
        style: form
        explode: true
        schema:
          type: string
          default: desc
          enum:
          - asc
          - desc
      responses:
        "200":
          description: Certificates listed successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListCertificatesResponse'
      x-oaiMeta:
        name: List project certificates
        group: administration
        returns: "A list of [Certificate](/docs/api-reference/certificates/object)\
          \ objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/organization/projects/proj_abc/certificates \
              -H "Authorization: Bearer $OPENAI_ADMIN_KEY"
          response: |
            {
              "object": "list",
              "data": [
                {
                  "object": "organization.project.certificate",
                  "id": "cert_abc",
                  "name": "My Example Certificate",
                  "active": true,
                  "created_at": 1234567,
                  "certificate_details": {
                    "valid_at": 12345667,
                    "expires_at": 12345678
                  }
                },
              ],
              "first_id": "cert_abc",
              "last_id": "cert_abc",
              "has_more": false
            }
    parameters:
    - name: projectId
      in: path
      required: true
      style: simple
      explode: false
      schema:
        type: string
  /organization/projects/{projectId}/certificates/activate:
    post:
      tags:
      - Certificates
      summary: |
        Activate certificates at the project level.

        You can atomically and idempotently activate up to 10 certificates at a time.
      operationId: activateProjectCertificates
      requestBody:
        description: The certificate activation payload
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ToggleCertificatesRequest'
        required: true
      responses:
        "200":
          description: Certificates activated successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListCertificatesResponse'
      x-oaiMeta:
        name: Activate certificates for project
        group: administration
        returns: "A list of [Certificate](/docs/api-reference/certificates/object)\
          \ objects that were activated."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/organization/projects/proj_abc/certificates/activate \
              -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
              -H "Content-Type: application/json" \
              -d '{
                "data": ["cert_abc", "cert_def"]
              }'
          response: |
            {
              "object": "organization.project.certificate.activation",
              "data": [
                {
                  "object": "organization.project.certificate",
                  "id": "cert_abc",
                  "name": "My Example Certificate",
                  "active": true,
                  "created_at": 1234567,
                  "certificate_details": {
                    "valid_at": 12345667,
                    "expires_at": 12345678
                  }
                },
                {
                  "object": "organization.project.certificate",
                  "id": "cert_def",
                  "name": "My Example Certificate 2",
                  "active": true,
                  "created_at": 1234567,
                  "certificate_details": {
                    "valid_at": 12345667,
                    "expires_at": 12345678
                  }
                },
              ],
            }
    parameters:
    - name: projectId
      in: path
      required: true
      style: simple
      explode: false
      schema:
        type: string
  /organization/projects/{projectId}/certificates/deactivate:
    post:
      tags:
      - Certificates
      summary: |
        Deactivate certificates at the project level.

        You can atomically and idempotently deactivate up to 10 certificates at a time.
      operationId: deactivateProjectCertificates
      requestBody:
        description: The certificate deactivation payload
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ToggleCertificatesRequest'
        required: true
      responses:
        "200":
          description: Certificates deactivated successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListCertificatesResponse'
      x-oaiMeta:
        name: Deactivate certificates for project
        group: administration
        returns: "A list of [Certificate](/docs/api-reference/certificates/object)\
          \ objects that were deactivated."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/organization/projects/proj_abc/certificates/deactivate \
              -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
              -H "Content-Type: application/json" \
              -d '{
                "data": ["cert_abc", "cert_def"]
              }'
          response: |
            {
              "object": "organization.project.certificate.deactivation",
              "data": [
                {
                  "object": "organization.project.certificate",
                  "id": "cert_abc",
                  "name": "My Example Certificate",
                  "active": false,
                  "created_at": 1234567,
                  "certificate_details": {
                    "valid_at": 12345667,
                    "expires_at": 12345678
                  }
                },
                {
                  "object": "organization.project.certificate",
                  "id": "cert_def",
                  "name": "My Example Certificate 2",
                  "active": false,
                  "created_at": 1234567,
                  "certificate_details": {
                    "valid_at": 12345667,
                    "expires_at": 12345678
                  }
                },
              ],
            }
    parameters:
    - name: projectId
      in: path
      required: true
      style: simple
      explode: false
      schema:
        type: string
  /organization/projects/{projectId}/rate_limits:
    get:
      tags:
      - Projects
      summary: Returns the rate limits per model for a project.
      operationId: list-project-rate-limits
      parameters:
      - name: projectId
        in: path
        description: The ID of the project
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: limit
        in: query
        description: |
          A limit on the number of objects to be returned. The default is 100
        required: false
        style: form
        explode: true
        schema:
          type: integer
          default: 100
      - name: after
        in: query
        description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list
        required: false
        style: form
        explode: true
        schema:
          type: string
      - name: before
        in: query
        description: |
          A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, beginning with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list
        required: false
        style: form
        explode: true
        schema:
          type: string
      responses:
        "200":
          description: Project rate limits listed successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProjectRateLimitListResponse'
      x-oaiMeta:
        name: List project rate limits
        group: administration
        returns: "A list of [ProjectRateLimit](/docs/api-reference/project-rate-limits/object)\
          \ objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/organization/projects/proj_abc/rate_limits?after=rl_xxx&limit=20 \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response: |
            {
                "object": "list",
                "data": [
                    {
                      "object": "project.rate_limit",
                      "id": "rl-ada",
                      "model": "ada",
                      "max_requests_per_1_minute": 600,
                      "max_tokens_per_1_minute": 150000,
                      "max_images_per_1_minute": 10
                    }
                ],
                "first_id": "rl-ada",
                "last_id": "rl-ada",
                "has_more": false
            }
          error_response: |
            {
                "code": 404,
                "message": "The project {project_id} was not found"
            }
  /organization/projects/{projectId}/rate_limits/{rateLimitId}:
    post:
      tags:
      - Projects
      summary: Updates a project rate limit.
      operationId: update-project-rate-limits
      parameters:
      - name: projectId
        in: path
        description: The ID of the project
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: rateLimitId
        in: path
        description: The ID of the rate limit
        required: true
        style: simple
        explode: false
        schema:
          type: string
      requestBody:
        description: The project rate limit update request payload
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ProjectRateLimitUpdateRequest'
        required: true
      responses:
        "200":
          description: Project rate limit updated successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProjectRateLimit'
        "400":
          description: Error response for various conditions.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
      x-oaiMeta:
        name: Modify project rate limit
        group: administration
        returns: "The updated [ProjectRateLimit](/docs/api-reference/project-rate-limits/object)\
          \ object."
        examples:
          request:
            curl: |
              curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/rate_limits/rl_xxx \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json" \
                -d '{
                    "max_requests_per_1_minute": 500
                }'
          response: |
            {
                "object": "project.rate_limit",
                "id": "rl-ada",
                "model": "ada",
                "max_requests_per_1_minute": 600,
                "max_tokens_per_1_minute": 150000,
                "max_images_per_1_minute": 10
              }
          error_response: |
            {
                "code": 404,
                "message": "The project {project_id} was not found"
            }
  /organization/projects/{projectId}/service_accounts:
    get:
      tags:
      - Projects
      summary: Returns a list of service accounts in the project.
      operationId: list-project-service-accounts
      parameters:
      - name: projectId
        in: path
        description: The ID of the project
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: limit
        in: query
        description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20
        required: false
        style: form
        explode: true
        schema:
          type: integer
          default: 20
      - name: after
        in: query
        description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list
        required: false
        style: form
        explode: true
        schema:
          type: string
      responses:
        "200":
          description: Project service accounts listed successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProjectServiceAccountListResponse'
        "400":
          description: Error response when project is archived.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
      x-oaiMeta:
        name: List project service accounts
        group: administration
        returns: "A list of [ProjectServiceAccount](/docs/api-reference/project-service-accounts/object)\
          \ objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/organization/projects/proj_abc/service_accounts?after=custom_id&limit=20 \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response: |
            {
                "object": "list",
                "data": [
                    {
                        "object": "organization.project.service_account",
                        "id": "svc_acct_abc",
                        "name": "Service Account",
                        "role": "owner",
                        "created_at": 1711471533
                    }
                ],
                "first_id": "svc_acct_abc",
                "last_id": "svc_acct_xyz",
                "has_more": false
            }
    post:
      tags:
      - Projects
      summary: Creates a new service account in the project. This also returns an
        unredacted API key for the service account.
      operationId: create-project-service-account
      parameters:
      - name: projectId
        in: path
        description: The ID of the project
        required: true
        style: simple
        explode: false
        schema:
          type: string
      requestBody:
        description: The project service account create request payload
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ProjectServiceAccountCreateRequest'
        required: true
      responses:
        "200":
          description: Project service account created successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProjectServiceAccountCreateResponse'
        "400":
          description: Error response when project is archived.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
      x-oaiMeta:
        name: Create project service account
        group: administration
        returns: "The created [ProjectServiceAccount](/docs/api-reference/project-service-accounts/object)\
          \ object."
        examples:
          request:
            curl: |
              curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/service_accounts \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json" \
                -d '{
                    "name": "Production App"
                }'
          response: |
            {
                "object": "organization.project.service_account",
                "id": "svc_acct_abc",
                "name": "Production App",
                "role": "member",
                "created_at": 1711471533,
                "api_key": {
                    "object": "organization.project.service_account.api_key",
                    "value": "sk-abcdefghijklmnop123",
                    "name": "Secret Key",
                    "created_at": 1711471533,
                    "id": "key_abc"
                }
            }
  /organization/projects/{projectId}/service_accounts/{serviceAccountId}:
    get:
      tags:
      - Projects
      summary: Retrieves a service account in the project.
      operationId: retrieve-project-service-account
      parameters:
      - name: projectId
        in: path
        description: The ID of the project
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: serviceAccountId
        in: path
        description: The ID of the service account
        required: true
        style: simple
        explode: false
        schema:
          type: string
      responses:
        "200":
          description: Project service account retrieved successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProjectServiceAccount'
      x-oaiMeta:
        name: Retrieve project service account
        group: administration
        returns: "The [ProjectServiceAccount](/docs/api-reference/project-service-accounts/object)\
          \ object matching the specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/organization/projects/proj_abc/service_accounts/svc_acct_abc \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response: |
            {
                "object": "organization.project.service_account",
                "id": "svc_acct_abc",
                "name": "Service Account",
                "role": "owner",
                "created_at": 1711471533
            }
    delete:
      tags:
      - Projects
      summary: Deletes a service account from the project.
      operationId: delete-project-service-account
      parameters:
      - name: projectId
        in: path
        description: The ID of the project
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: serviceAccountId
        in: path
        description: The ID of the service account
        required: true
        style: simple
        explode: false
        schema:
          type: string
      responses:
        "200":
          description: Project service account deleted successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProjectServiceAccountDeleteResponse'
      x-oaiMeta:
        name: Delete project service account
        group: administration
        returns: "Confirmation of service account being deleted, or an error in case\
          \ of an archived project, which has no service accounts"
        examples:
          request:
            curl: |
              curl -X DELETE https://api.openai.com/v1/organization/projects/proj_abc/service_accounts/svc_acct_abc \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response: |
            {
                "object": "organization.project.service_account.deleted",
                "id": "svc_acct_abc",
                "deleted": true
            }
  /organization/projects/{projectId}/users:
    get:
      tags:
      - Projects
      summary: Returns a list of users in the project.
      operationId: list-project-users
      parameters:
      - name: projectId
        in: path
        description: The ID of the project
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: limit
        in: query
        description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20
        required: false
        style: form
        explode: true
        schema:
          type: integer
          default: 20
      - name: after
        in: query
        description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list
        required: false
        style: form
        explode: true
        schema:
          type: string
      responses:
        "200":
          description: Project users listed successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProjectUserListResponse'
        "400":
          description: Error response when project is archived.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
      x-oaiMeta:
        name: List project users
        group: administration
        returns: "A list of [ProjectUser](/docs/api-reference/project-users/object)\
          \ objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/organization/projects/proj_abc/users?after=user_abc&limit=20 \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response: |
            {
                "object": "list",
                "data": [
                    {
                        "object": "organization.project.user",
                        "id": "user_abc",
                        "name": "First Last",
                        "email": "user@example.com",
                        "role": "owner",
                        "added_at": 1711471533
                    }
                ],
                "first_id": "user-abc",
                "last_id": "user-xyz",
                "has_more": false
            }
    post:
      tags:
      - Projects
      summary: Adds a user to the project. Users must already be members of the organization
        to be added to a project.
      operationId: create-project-user
      parameters:
      - name: projectId
        in: path
        description: The ID of the project
        required: true
        style: simple
        explode: false
        schema:
          type: string
      requestBody:
        description: The project user create request payload
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ProjectUserCreateRequest'
        required: true
      responses:
        "200":
          description: User added to project successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProjectUser'
        "400":
          description: Error response for various conditions.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
      x-oaiMeta:
        name: Create project user
        group: administration
        returns: "The created [ProjectUser](/docs/api-reference/project-users/object)\
          \ object."
        examples:
          request:
            curl: |
              curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/users \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json" \
                -d '{
                    "user_id": "user_abc",
                    "role": "member"
                }'
          response: |
            {
                "object": "organization.project.user",
                "id": "user_abc",
                "email": "user@example.com",
                "role": "owner",
                "added_at": 1711471533
            }
  /organization/projects/{projectId}/users/{userId}:
    get:
      tags:
      - Projects
      summary: Retrieves a user in the project.
      operationId: retrieve-project-user
      parameters:
      - name: projectId
        in: path
        description: The ID of the project
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: userId
        in: path
        description: The ID of the user
        required: true
        style: simple
        explode: false
        schema:
          type: string
      responses:
        "200":
          description: Project user retrieved successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProjectUser'
      x-oaiMeta:
        name: Retrieve project user
        group: administration
        returns: "The [ProjectUser](/docs/api-reference/project-users/object) object\
          \ matching the specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/organization/projects/proj_abc/users/user_abc \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response: |
            {
                "object": "organization.project.user",
                "id": "user_abc",
                "name": "First Last",
                "email": "user@example.com",
                "role": "owner",
                "added_at": 1711471533
            }
    post:
      tags:
      - Projects
      summary: Modifies a user's role in the project.
      operationId: modify-project-user
      parameters:
      - name: projectId
        in: path
        description: The ID of the project
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: userId
        in: path
        description: The ID of the user
        required: true
        style: simple
        explode: false
        schema:
          type: string
      requestBody:
        description: The project user update request payload
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ProjectUserUpdateRequest'
        required: true
      responses:
        "200":
          description: Project user's role updated successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProjectUser'
        "400":
          description: Error response for various conditions.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
      x-oaiMeta:
        name: Modify project user
        group: administration
        returns: "The updated [ProjectUser](/docs/api-reference/project-users/object)\
          \ object."
        examples:
          request:
            curl: |
              curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/users/user_abc \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json" \
                -d '{
                    "role": "owner"
                }'
          response: |
            {
                "object": "organization.project.user",
                "id": "user_abc",
                "name": "First Last",
                "email": "user@example.com",
                "role": "owner",
                "added_at": 1711471533
            }
    delete:
      tags:
      - Projects
      summary: Deletes a user from the project.
      operationId: delete-project-user
      parameters:
      - name: projectId
        in: path
        description: The ID of the project
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: userId
        in: path
        description: The ID of the user
        required: true
        style: simple
        explode: false
        schema:
          type: string
      responses:
        "200":
          description: Project user deleted successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProjectUserDeleteResponse'
        "400":
          description: Error response for various conditions.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
      x-oaiMeta:
        name: Delete project user
        group: administration
        returns: "Confirmation that project has been deleted or an error in case of\
          \ an archived project, which has no users"
        examples:
          request:
            curl: |
              curl -X DELETE https://api.openai.com/v1/organization/projects/proj_abc/users/user_abc \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response: |
            {
                "object": "organization.project.user.deleted",
                "id": "user_abc",
                "deleted": true
            }
  /organization/usage/audio_speeches:
    get:
      tags:
      - Usage
      summary: Get audio speeches usage details for the organization.
      operationId: usage-audio-speeches
      parameters:
      - name: start_time
        in: query
        description: "Start time (Unix seconds) of the query time range, inclusive"
        required: true
        style: form
        explode: true
        schema:
          type: integer
        x-ballerina-name: startTime
      - name: end_time
        in: query
        description: "End time (Unix seconds) of the query time range, exclusive"
        required: false
        style: form
        explode: true
        schema:
          type: integer
        x-ballerina-name: endTime
      - name: bucket_width
        in: query
        description: "Width of each time bucket in response. Currently `1m`, `1h`\
          \ and `1d` are supported, default to `1d`"
        required: false
        style: form
        explode: true
        schema:
          type: string
          default: 1d
          enum:
          - 1m
          - 1h
          - 1d
        x-ballerina-name: bucketWidth
      - name: project_ids
        in: query
        description: Return only usage for these projects
        required: false
        style: form
        explode: true
        schema:
          type: array
          items:
            type: string
        x-ballerina-name: projectIds
      - name: user_ids
        in: query
        description: Return only usage for these users
        required: false
        style: form
        explode: true
        schema:
          type: array
          items:
            type: string
        x-ballerina-name: userIds
      - name: api_key_ids
        in: query
        description: Return only usage for these API keys
        required: false
        style: form
        explode: true
        schema:
          type: array
          items:
            type: string
        x-ballerina-name: apiKeyIds
      - name: models
        in: query
        description: Return only usage for these models
        required: false
        style: form
        explode: true
        schema:
          type: array
          items:
            type: string
      - name: group_by
        in: query
        description: "Group the usage data by the specified fields. Support fields\
          \ include `project_id`, `user_id`, `api_key_id`, `model` or any combination\
          \ of them"
        required: false
        style: form
        explode: true
        schema:
          type: array
          items:
            type: string
            enum:
            - project_id
            - user_id
            - api_key_id
            - model
        x-ballerina-name: groupBy
      - name: limit
        in: query
        description: |
          Specifies the number of buckets to return.
          - `bucket_width=1d`: default: 7, max: 31
          - `bucket_width=1h`: default: 24, max: 168
          - `bucket_width=1m`: default: 60, max: 1440
        required: false
        style: form
        explode: true
        schema:
          type: integer
      - name: page
        in: query
        description: A cursor for use in pagination. Corresponding to the `next_page`
          field from the previous response
        required: false
        style: form
        explode: true
        schema:
          type: string
      responses:
        "200":
          description: Usage data retrieved successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/UsageResponse'
      x-oaiMeta:
        name: Audio speeches
        group: usage-audio-speeches
        returns: "A list of paginated, time bucketed [Audio speeches usage](/docs/api-reference/usage/audio_speeches_object)\
          \ objects."
        examples:
          request:
            curl: |
              curl "https://api.openai.com/v1/organization/usage/audio_speeches?start_time=1730419200&limit=1" \
              -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
              -H "Content-Type: application/json"
          response: |
            {
                "object": "page",
                "data": [
                    {
                        "object": "bucket",
                        "start_time": 1730419200,
                        "end_time": 1730505600,
                        "results": [
                            {
                                "object": "organization.usage.audio_speeches.result",
                                "characters": 45,
                                "num_model_requests": 1,
                                "project_id": null,
                                "user_id": null,
                                "api_key_id": null,
                                "model": null
                            }
                        ]
                    }
                ],
                "has_more": false,
                "next_page": null
            }
  /organization/usage/audio_transcriptions:
    get:
      tags:
      - Usage
      summary: Get audio transcriptions usage details for the organization.
      operationId: usage-audio-transcriptions
      parameters:
      - name: start_time
        in: query
        description: "Start time (Unix seconds) of the query time range, inclusive"
        required: true
        style: form
        explode: true
        schema:
          type: integer
        x-ballerina-name: startTime
      - name: end_time
        in: query
        description: "End time (Unix seconds) of the query time range, exclusive"
        required: false
        style: form
        explode: true
        schema:
          type: integer
        x-ballerina-name: endTime
      - name: bucket_width
        in: query
        description: "Width of each time bucket in response. Currently `1m`, `1h`\
          \ and `1d` are supported, default to `1d`"
        required: false
        style: form
        explode: true
        schema:
          type: string
          default: 1d
          enum:
          - 1m
          - 1h
          - 1d
        x-ballerina-name: bucketWidth
      - name: project_ids
        in: query
        description: Return only usage for these projects
        required: false
        style: form
        explode: true
        schema:
          type: array
          items:
            type: string
        x-ballerina-name: projectIds
      - name: user_ids
        in: query
        description: Return only usage for these users
        required: false
        style: form
        explode: true
        schema:
          type: array
          items:
            type: string
        x-ballerina-name: userIds
      - name: api_key_ids
        in: query
        description: Return only usage for these API keys
        required: false
        style: form
        explode: true
        schema:
          type: array
          items:
            type: string
        x-ballerina-name: apiKeyIds
      - name: models
        in: query
        description: Return only usage for these models
        required: false
        style: form
        explode: true
        schema:
          type: array
          items:
            type: string
      - name: group_by
        in: query
        description: "Group the usage data by the specified fields. Support fields\
          \ include `project_id`, `user_id`, `api_key_id`, `model` or any combination\
          \ of them"
        required: false
        style: form
        explode: true
        schema:
          type: array
          items:
            type: string
            enum:
            - project_id
            - user_id
            - api_key_id
            - model
        x-ballerina-name: groupBy
      - name: limit
        in: query
        description: |
          Specifies the number of buckets to return.
          - `bucket_width=1d`: default: 7, max: 31
          - `bucket_width=1h`: default: 24, max: 168
          - `bucket_width=1m`: default: 60, max: 1440
        required: false
        style: form
        explode: true
        schema:
          type: integer
      - name: page
        in: query
        description: A cursor for use in pagination. Corresponding to the `next_page`
          field from the previous response
        required: false
        style: form
        explode: true
        schema:
          type: string
      responses:
        "200":
          description: Usage data retrieved successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/UsageResponse'
      x-oaiMeta:
        name: Audio transcriptions
        group: usage-audio-transcriptions
        returns: "A list of paginated, time bucketed [Audio transcriptions usage](/docs/api-reference/usage/audio_transcriptions_object)\
          \ objects."
        examples:
          request:
            curl: |
              curl "https://api.openai.com/v1/organization/usage/audio_transcriptions?start_time=1730419200&limit=1" \
              -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
              -H "Content-Type: application/json"
          response: |
            {
                "object": "page",
                "data": [
                    {
                        "object": "bucket",
                        "start_time": 1730419200,
                        "end_time": 1730505600,
                        "results": [
                            {
                                "object": "organization.usage.audio_transcriptions.result",
                                "seconds": 20,
                                "num_model_requests": 1,
                                "project_id": null,
                                "user_id": null,
                                "api_key_id": null,
                                "model": null
                            }
                        ]
                    }
                ],
                "has_more": false,
                "next_page": null
            }
  /organization/usage/code_interpreter_sessions:
    get:
      tags:
      - Usage
      summary: Get code interpreter sessions usage details for the organization.
      operationId: usage-code-interpreter-sessions
      parameters:
      - name: start_time
        in: query
        description: "Start time (Unix seconds) of the query time range, inclusive"
        required: true
        style: form
        explode: true
        schema:
          type: integer
        x-ballerina-name: startTime
      - name: end_time
        in: query
        description: "End time (Unix seconds) of the query time range, exclusive"
        required: false
        style: form
        explode: true
        schema:
          type: integer
        x-ballerina-name: endTime
      - name: bucket_width
        in: query
        description: "Width of each time bucket in response. Currently `1m`, `1h`\
          \ and `1d` are supported, default to `1d`"
        required: false
        style: form
        explode: true
        schema:
          type: string
          default: 1d
          enum:
          - 1m
          - 1h
          - 1d
        x-ballerina-name: bucketWidth
      - name: project_ids
        in: query
        description: Return only usage for these projects
        required: false
        style: form
        explode: true
        schema:
          type: array
          items:
            type: string
        x-ballerina-name: projectIds
      - name: group_by
        in: query
        description: Group the usage data by the specified fields. Support fields
          include `project_id`
        required: false
        style: form
        explode: true
        schema:
          type: array
          items:
            type: string
            enum:
            - project_id
        x-ballerina-name: groupBy
      - name: limit
        in: query
        description: |
          Specifies the number of buckets to return.
          - `bucket_width=1d`: default: 7, max: 31
          - `bucket_width=1h`: default: 24, max: 168
          - `bucket_width=1m`: default: 60, max: 1440
        required: false
        style: form
        explode: true
        schema:
          type: integer
      - name: page
        in: query
        description: A cursor for use in pagination. Corresponding to the `next_page`
          field from the previous response
        required: false
        style: form
        explode: true
        schema:
          type: string
      responses:
        "200":
          description: Usage data retrieved successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/UsageResponse'
      x-oaiMeta:
        name: Code interpreter sessions
        group: usage-code-interpreter-sessions
        returns: "A list of paginated, time bucketed [Code interpreter sessions usage](/docs/api-reference/usage/code_interpreter_sessions_object)\
          \ objects."
        examples:
          request:
            curl: |
              curl "https://api.openai.com/v1/organization/usage/code_interpreter_sessions?start_time=1730419200&limit=1" \
              -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
              -H "Content-Type: application/json"
          response: |
            {
                "object": "page",
                "data": [
                    {
                        "object": "bucket",
                        "start_time": 1730419200,
                        "end_time": 1730505600,
                        "results": [
                            {
                                "object": "organization.usage.code_interpreter_sessions.result",
                                "num_sessions": 1,
                                "project_id": null
                            }
                        ]
                    }
                ],
                "has_more": false,
                "next_page": null
            }
  /organization/usage/completions:
    get:
      tags:
      - Usage
      summary: Get completions usage details for the organization.
      operationId: usage-completions
      parameters:
      - name: start_time
        in: query
        description: "Start time (Unix seconds) of the query time range, inclusive"
        required: true
        style: form
        explode: true
        schema:
          type: integer
        x-ballerina-name: startTime
      - name: end_time
        in: query
        description: "End time (Unix seconds) of the query time range, exclusive"
        required: false
        style: form
        explode: true
        schema:
          type: integer
        x-ballerina-name: endTime
      - name: bucket_width
        in: query
        description: "Width of each time bucket in response. Currently `1m`, `1h`\
          \ and `1d` are supported, default to `1d`"
        required: false
        style: form
        explode: true
        schema:
          type: string
          default: 1d
          enum:
          - 1m
          - 1h
          - 1d
        x-ballerina-name: bucketWidth
      - name: project_ids
        in: query
        description: Return only usage for these projects
        required: false
        style: form
        explode: true
        schema:
          type: array
          items:
            type: string
        x-ballerina-name: projectIds
      - name: user_ids
        in: query
        description: Return only usage for these users
        required: false
        style: form
        explode: true
        schema:
          type: array
          items:
            type: string
        x-ballerina-name: userIds
      - name: api_key_ids
        in: query
        description: Return only usage for these API keys
        required: false
        style: form
        explode: true
        schema:
          type: array
          items:
            type: string
        x-ballerina-name: apiKeyIds
      - name: models
        in: query
        description: Return only usage for these models
        required: false
        style: form
        explode: true
        schema:
          type: array
          items:
            type: string
      - name: batch
        in: query
        description: |
          If `true`, return batch jobs only. If `false`, return non-batch jobs only. By default, return both
        required: false
        style: form
        explode: true
        schema:
          type: boolean
      - name: group_by
        in: query
        description: "Group the usage data by the specified fields. Support fields\
          \ include `project_id`, `user_id`, `api_key_id`, `model`, `batch` or any\
          \ combination of them"
        required: false
        style: form
        explode: true
        schema:
          type: array
          items:
            type: string
            enum:
            - project_id
            - user_id
            - api_key_id
            - model
            - batch
        x-ballerina-name: groupBy
      - name: limit
        in: query
        description: |
          Specifies the number of buckets to return.
          - `bucket_width=1d`: default: 7, max: 31
          - `bucket_width=1h`: default: 24, max: 168
          - `bucket_width=1m`: default: 60, max: 1440
        required: false
        style: form
        explode: true
        schema:
          type: integer
      - name: page
        in: query
        description: A cursor for use in pagination. Corresponding to the `next_page`
          field from the previous response
        required: false
        style: form
        explode: true
        schema:
          type: string
      responses:
        "200":
          description: Usage data retrieved successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/UsageResponse'
      x-oaiMeta:
        name: Completions
        group: usage-completions
        returns: "A list of paginated, time bucketed [Completions usage](/docs/api-reference/usage/completions_object)\
          \ objects."
        examples:
          request:
            curl: |
              curl "https://api.openai.com/v1/organization/usage/completions?start_time=1730419200&limit=1" \
              -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
              -H "Content-Type: application/json"
          response: |
            {
                "object": "page",
                "data": [
                    {
                        "object": "bucket",
                        "start_time": 1730419200,
                        "end_time": 1730505600,
                        "results": [
                            {
                                "object": "organization.usage.completions.result",
                                "input_tokens": 1000,
                                "output_tokens": 500,
                                "input_cached_tokens": 800,
                                "input_audio_tokens": 0,
                                "output_audio_tokens": 0,
                                "num_model_requests": 5,
                                "project_id": null,
                                "user_id": null,
                                "api_key_id": null,
                                "model": null,
                                "batch": null
                            }
                        ]
                    }
                ],
                "has_more": true,
                "next_page": "page_AAAAAGdGxdEiJdKOAAAAAGcqsYA="
            }
  /organization/usage/embeddings:
    get:
      tags:
      - Usage
      summary: Get embeddings usage details for the organization.
      operationId: usage-embeddings
      parameters:
      - name: start_time
        in: query
        description: "Start time (Unix seconds) of the query time range, inclusive"
        required: true
        style: form
        explode: true
        schema:
          type: integer
        x-ballerina-name: startTime
      - name: end_time
        in: query
        description: "End time (Unix seconds) of the query time range, exclusive"
        required: false
        style: form
        explode: true
        schema:
          type: integer
        x-ballerina-name: endTime
      - name: bucket_width
        in: query
        description: "Width of each time bucket in response. Currently `1m`, `1h`\
          \ and `1d` are supported, default to `1d`"
        required: false
        style: form
        explode: true
        schema:
          type: string
          default: 1d
          enum:
          - 1m
          - 1h
          - 1d
        x-ballerina-name: bucketWidth
      - name: project_ids
        in: query
        description: Return only usage for these projects
        required: false
        style: form
        explode: true
        schema:
          type: array
          items:
            type: string
        x-ballerina-name: projectIds
      - name: user_ids
        in: query
        description: Return only usage for these users
        required: false
        style: form
        explode: true
        schema:
          type: array
          items:
            type: string
        x-ballerina-name: userIds
      - name: api_key_ids
        in: query
        description: Return only usage for these API keys
        required: false
        style: form
        explode: true
        schema:
          type: array
          items:
            type: string
        x-ballerina-name: apiKeyIds
      - name: models
        in: query
        description: Return only usage for these models
        required: false
        style: form
        explode: true
        schema:
          type: array
          items:
            type: string
      - name: group_by
        in: query
        description: "Group the usage data by the specified fields. Support fields\
          \ include `project_id`, `user_id`, `api_key_id`, `model` or any combination\
          \ of them"
        required: false
        style: form
        explode: true
        schema:
          type: array
          items:
            type: string
            enum:
            - project_id
            - user_id
            - api_key_id
            - model
        x-ballerina-name: groupBy
      - name: limit
        in: query
        description: |
          Specifies the number of buckets to return.
          - `bucket_width=1d`: default: 7, max: 31
          - `bucket_width=1h`: default: 24, max: 168
          - `bucket_width=1m`: default: 60, max: 1440
        required: false
        style: form
        explode: true
        schema:
          type: integer
      - name: page
        in: query
        description: A cursor for use in pagination. Corresponding to the `next_page`
          field from the previous response
        required: false
        style: form
        explode: true
        schema:
          type: string
      responses:
        "200":
          description: Usage data retrieved successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/UsageResponse'
      x-oaiMeta:
        name: Embeddings
        group: usage-embeddings
        returns: "A list of paginated, time bucketed [Embeddings usage](/docs/api-reference/usage/embeddings_object)\
          \ objects."
        examples:
          request:
            curl: |
              curl "https://api.openai.com/v1/organization/usage/embeddings?start_time=1730419200&limit=1" \
              -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
              -H "Content-Type: application/json"
          response: |
            {
                "object": "page",
                "data": [
                    {
                        "object": "bucket",
                        "start_time": 1730419200,
                        "end_time": 1730505600,
                        "results": [
                            {
                                "object": "organization.usage.embeddings.result",
                                "input_tokens": 16,
                                "num_model_requests": 2,
                                "project_id": null,
                                "user_id": null,
                                "api_key_id": null,
                                "model": null
                            }
                        ]
                    }
                ],
                "has_more": false,
                "next_page": null
            }
  /organization/usage/images:
    get:
      tags:
      - Usage
      summary: Get images usage details for the organization.
      operationId: usage-images
      parameters:
      - name: start_time
        in: query
        description: "Start time (Unix seconds) of the query time range, inclusive"
        required: true
        style: form
        explode: true
        schema:
          type: integer
        x-ballerina-name: startTime
      - name: end_time
        in: query
        description: "End time (Unix seconds) of the query time range, exclusive"
        required: false
        style: form
        explode: true
        schema:
          type: integer
        x-ballerina-name: endTime
      - name: bucket_width
        in: query
        description: "Width of each time bucket in response. Currently `1m`, `1h`\
          \ and `1d` are supported, default to `1d`"
        required: false
        style: form
        explode: true
        schema:
          type: string
          default: 1d
          enum:
          - 1m
          - 1h
          - 1d
        x-ballerina-name: bucketWidth
      - name: sources
        in: query
        description: "Return only usages for these sources. Possible values are `image.generation`,\
          \ `image.edit`, `image.variation` or any combination of them"
        required: false
        style: form
        explode: true
        schema:
          type: array
          items:
            type: string
            enum:
            - image.generation
            - image.edit
            - image.variation
      - name: sizes
        in: query
        description: "Return only usages for these image sizes. Possible values are\
          \ `256x256`, `512x512`, `1024x1024`, `1792x1792`, `1024x1792` or any combination\
          \ of them"
        required: false
        style: form
        explode: true
        schema:
          type: array
          items:
            type: string
            enum:
            - 256x256
            - 512x512
            - 1024x1024
            - 1792x1792
            - 1024x1792
      - name: project_ids
        in: query
        description: Return only usage for these projects
        required: false
        style: form
        explode: true
        schema:
          type: array
          items:
            type: string
        x-ballerina-name: projectIds
      - name: user_ids
        in: query
        description: Return only usage for these users
        required: false
        style: form
        explode: true
        schema:
          type: array
          items:
            type: string
        x-ballerina-name: userIds
      - name: api_key_ids
        in: query
        description: Return only usage for these API keys
        required: false
        style: form
        explode: true
        schema:
          type: array
          items:
            type: string
        x-ballerina-name: apiKeyIds
      - name: models
        in: query
        description: Return only usage for these models
        required: false
        style: form
        explode: true
        schema:
          type: array
          items:
            type: string
      - name: group_by
        in: query
        description: "Group the usage data by the specified fields. Support fields\
          \ include `project_id`, `user_id`, `api_key_id`, `model`, `size`, `source`\
          \ or any combination of them"
        required: false
        style: form
        explode: true
        schema:
          type: array
          items:
            type: string
            enum:
            - project_id
            - user_id
            - api_key_id
            - model
            - size
            - source
        x-ballerina-name: groupBy
      - name: limit
        in: query
        description: |
          Specifies the number of buckets to return.
          - `bucket_width=1d`: default: 7, max: 31
          - `bucket_width=1h`: default: 24, max: 168
          - `bucket_width=1m`: default: 60, max: 1440
        required: false
        style: form
        explode: true
        schema:
          type: integer
      - name: page
        in: query
        description: A cursor for use in pagination. Corresponding to the `next_page`
          field from the previous response
        required: false
        style: form
        explode: true
        schema:
          type: string
      responses:
        "200":
          description: Usage data retrieved successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/UsageResponse'
      x-oaiMeta:
        name: Images
        group: usage-images
        returns: "A list of paginated, time bucketed [Images usage](/docs/api-reference/usage/images_object)\
          \ objects."
        examples:
          request:
            curl: |
              curl "https://api.openai.com/v1/organization/usage/images?start_time=1730419200&limit=1" \
              -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
              -H "Content-Type: application/json"
          response: |
            {
                "object": "page",
                "data": [
                    {
                        "object": "bucket",
                        "start_time": 1730419200,
                        "end_time": 1730505600,
                        "results": [
                            {
                                "object": "organization.usage.images.result",
                                "images": 2,
                                "num_model_requests": 2,
                                "size": null,
                                "source": null,
                                "project_id": null,
                                "user_id": null,
                                "api_key_id": null,
                                "model": null
                            }
                        ]
                    }
                ],
                "has_more": false,
                "next_page": null
            }
  /organization/usage/moderations:
    get:
      tags:
      - Usage
      summary: Get moderations usage details for the organization.
      operationId: usage-moderations
      parameters:
      - name: start_time
        in: query
        description: "Start time (Unix seconds) of the query time range, inclusive"
        required: true
        style: form
        explode: true
        schema:
          type: integer
        x-ballerina-name: startTime
      - name: end_time
        in: query
        description: "End time (Unix seconds) of the query time range, exclusive"
        required: false
        style: form
        explode: true
        schema:
          type: integer
        x-ballerina-name: endTime
      - name: bucket_width
        in: query
        description: "Width of each time bucket in response. Currently `1m`, `1h`\
          \ and `1d` are supported, default to `1d`"
        required: false
        style: form
        explode: true
        schema:
          type: string
          default: 1d
          enum:
          - 1m
          - 1h
          - 1d
        x-ballerina-name: bucketWidth
      - name: project_ids
        in: query
        description: Return only usage for these projects
        required: false
        style: form
        explode: true
        schema:
          type: array
          items:
            type: string
        x-ballerina-name: projectIds
      - name: user_ids
        in: query
        description: Return only usage for these users
        required: false
        style: form
        explode: true
        schema:
          type: array
          items:
            type: string
        x-ballerina-name: userIds
      - name: api_key_ids
        in: query
        description: Return only usage for these API keys
        required: false
        style: form
        explode: true
        schema:
          type: array
          items:
            type: string
        x-ballerina-name: apiKeyIds
      - name: models
        in: query
        description: Return only usage for these models
        required: false
        style: form
        explode: true
        schema:
          type: array
          items:
            type: string
      - name: group_by
        in: query
        description: "Group the usage data by the specified fields. Support fields\
          \ include `project_id`, `user_id`, `api_key_id`, `model` or any combination\
          \ of them"
        required: false
        style: form
        explode: true
        schema:
          type: array
          items:
            type: string
            enum:
            - project_id
            - user_id
            - api_key_id
            - model
        x-ballerina-name: groupBy
      - name: limit
        in: query
        description: |
          Specifies the number of buckets to return.
          - `bucket_width=1d`: default: 7, max: 31
          - `bucket_width=1h`: default: 24, max: 168
          - `bucket_width=1m`: default: 60, max: 1440
        required: false
        style: form
        explode: true
        schema:
          type: integer
      - name: page
        in: query
        description: A cursor for use in pagination. Corresponding to the `next_page`
          field from the previous response
        required: false
        style: form
        explode: true
        schema:
          type: string
      responses:
        "200":
          description: Usage data retrieved successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/UsageResponse'
      x-oaiMeta:
        name: Moderations
        group: usage-moderations
        returns: "A list of paginated, time bucketed [Moderations usage](/docs/api-reference/usage/moderations_object)\
          \ objects."
        examples:
          request:
            curl: |
              curl "https://api.openai.com/v1/organization/usage/moderations?start_time=1730419200&limit=1" \
              -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
              -H "Content-Type: application/json"
          response: |
            {
                "object": "page",
                "data": [
                    {
                        "object": "bucket",
                        "start_time": 1730419200,
                        "end_time": 1730505600,
                        "results": [
                            {
                                "object": "organization.usage.moderations.result",
                                "input_tokens": 16,
                                "num_model_requests": 2,
                                "project_id": null,
                                "user_id": null,
                                "api_key_id": null,
                                "model": null
                            }
                        ]
                    }
                ],
                "has_more": false,
                "next_page": null
            }
  /organization/usage/vector_stores:
    get:
      tags:
      - Usage
      summary: Get vector stores usage details for the organization.
      operationId: usage-vector-stores
      parameters:
      - name: start_time
        in: query
        description: "Start time (Unix seconds) of the query time range, inclusive"
        required: true
        style: form
        explode: true
        schema:
          type: integer
        x-ballerina-name: startTime
      - name: end_time
        in: query
        description: "End time (Unix seconds) of the query time range, exclusive"
        required: false
        style: form
        explode: true
        schema:
          type: integer
        x-ballerina-name: endTime
      - name: bucket_width
        in: query
        description: "Width of each time bucket in response. Currently `1m`, `1h`\
          \ and `1d` are supported, default to `1d`"
        required: false
        style: form
        explode: true
        schema:
          type: string
          default: 1d
          enum:
          - 1m
          - 1h
          - 1d
        x-ballerina-name: bucketWidth
      - name: project_ids
        in: query
        description: Return only usage for these projects
        required: false
        style: form
        explode: true
        schema:
          type: array
          items:
            type: string
        x-ballerina-name: projectIds
      - name: group_by
        in: query
        description: Group the usage data by the specified fields. Support fields
          include `project_id`
        required: false
        style: form
        explode: true
        schema:
          type: array
          items:
            type: string
            enum:
            - project_id
        x-ballerina-name: groupBy
      - name: limit
        in: query
        description: |
          Specifies the number of buckets to return.
          - `bucket_width=1d`: default: 7, max: 31
          - `bucket_width=1h`: default: 24, max: 168
          - `bucket_width=1m`: default: 60, max: 1440
        required: false
        style: form
        explode: true
        schema:
          type: integer
      - name: page
        in: query
        description: A cursor for use in pagination. Corresponding to the `next_page`
          field from the previous response
        required: false
        style: form
        explode: true
        schema:
          type: string
      responses:
        "200":
          description: Usage data retrieved successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/UsageResponse'
      x-oaiMeta:
        name: Vector stores
        group: usage-vector-stores
        returns: "A list of paginated, time bucketed [Vector stores usage](/docs/api-reference/usage/vector_stores_object)\
          \ objects."
        examples:
          request:
            curl: |
              curl "https://api.openai.com/v1/organization/usage/vector_stores?start_time=1730419200&limit=1" \
              -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
              -H "Content-Type: application/json"
          response: |
            {
                "object": "page",
                "data": [
                    {
                        "object": "bucket",
                        "start_time": 1730419200,
                        "end_time": 1730505600,
                        "results": [
                            {
                                "object": "organization.usage.vector_stores.result",
                                "usage_bytes": 1024,
                                "project_id": null
                            }
                        ]
                    }
                ],
                "has_more": false,
                "next_page": null
            }
  /organization/users:
    get:
      tags:
      - Users
      summary: Lists all of the users in the organization.
      operationId: list-users
      parameters:
      - name: limit
        in: query
        description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20
        required: false
        style: form
        explode: true
        schema:
          type: integer
          default: 20
      - name: after
        in: query
        description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list
        required: false
        style: form
        explode: true
        schema:
          type: string
      - name: emails
        in: query
        description: Filter by the email address of users
        required: false
        style: form
        explode: true
        schema:
          type: array
          items:
            type: string
      responses:
        "200":
          description: Users listed successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/UserListResponse'
      x-oaiMeta:
        name: List users
        group: administration
        returns: "A list of [User](/docs/api-reference/users/object) objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/organization/users?after=user_abc&limit=20 \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response: |
            {
                "object": "list",
                "data": [
                    {
                        "object": "organization.user",
                        "id": "user_abc",
                        "name": "First Last",
                        "email": "user@example.com",
                        "role": "owner",
                        "added_at": 1711471533
                    }
                ],
                "first_id": "user-abc",
                "last_id": "user-xyz",
                "has_more": false
            }
  /organization/users/{userId}:
    get:
      tags:
      - Users
      summary: Retrieves a user by their identifier.
      operationId: retrieve-user
      parameters:
      - name: userId
        in: path
        description: The ID of the user
        required: true
        style: simple
        explode: false
        schema:
          type: string
      responses:
        "200":
          description: User retrieved successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/User'
      x-oaiMeta:
        name: Retrieve user
        group: administration
        returns: "The [User](/docs/api-reference/users/object) object matching the\
          \ specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/organization/users/user_abc \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response: |
            {
                "object": "organization.user",
                "id": "user_abc",
                "name": "First Last",
                "email": "user@example.com",
                "role": "owner",
                "added_at": 1711471533
            }
    post:
      tags:
      - Users
      summary: Modifies a user's role in the organization.
      operationId: modify-user
      parameters:
      - name: userId
        in: path
        description: The ID of the user
        required: true
        style: simple
        explode: false
        schema:
          type: string
      requestBody:
        description: The new user role to modify. This must be one of `owner` or `member`
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/UserRoleUpdateRequest'
        required: true
      responses:
        "200":
          description: User role updated successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/User'
      x-oaiMeta:
        name: Modify user
        group: administration
        returns: "The updated [User](/docs/api-reference/users/object) object."
        examples:
          request:
            curl: |
              curl -X POST https://api.openai.com/v1/organization/users/user_abc \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json" \
                -d '{
                    "role": "owner"
                }'
          response: |
            {
                "object": "organization.user",
                "id": "user_abc",
                "name": "First Last",
                "email": "user@example.com",
                "role": "owner",
                "added_at": 1711471533
            }
    delete:
      tags:
      - Users
      summary: Deletes a user from the organization.
      operationId: delete-user
      parameters:
      - name: userId
        in: path
        description: The ID of the user
        required: true
        style: simple
        explode: false
        schema:
          type: string
      responses:
        "200":
          description: User deleted successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/UserDeleteResponse'
      x-oaiMeta:
        name: Delete user
        group: administration
        returns: Confirmation of the deleted user
        examples:
          request:
            curl: |
              curl -X DELETE https://api.openai.com/v1/organization/users/user_abc \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response: |
            {
                "object": "organization.user.deleted",
                "id": "user_abc",
                "deleted": true
            }
  /realtime/sessions:
    post:
      tags:
      - Realtime
      summary: |
        Create an ephemeral API token for use in client-side applications with the
        Realtime API. Can be configured with the same session parameters as the
        `session.update` client event.

        It responds with a session object, plus a `client_secret` key which contains
        a usable ephemeral API token that can be used to authenticate browser clients
        for the Realtime API.
      operationId: create-realtime-session
      requestBody:
        description: Create an ephemeral API key with the given session configuration
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/RealtimeSessionCreateRequest'
        required: true
      responses:
        "200":
          description: Session created successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RealtimeSessionCreateResponse'
      x-oaiMeta:
        name: Create session
        group: realtime
        returns: "The created Realtime session object, plus an ephemeral key"
        examples:
          request:
            curl: |
              curl -X POST https://api.openai.com/v1/realtime/sessions \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -d '{
                  "model": "gpt-4o-realtime-preview",
                  "modalities": ["audio", "text"],
                  "instructions": "You are a friendly assistant."
                }'
          response: "{\n  \"id\": \"sess_001\",\n  \"object\": \"realtime.session\"\
            ,\n  \"model\": \"gpt-4o-realtime-preview\",\n  \"modalities\": [\"audio\"\
            , \"text\"],\n  \"instructions\": \"You are a friendly assistant.\",\n\
            \  \"voice\": \"alloy\",\n  \"input_audio_format\": \"pcm16\",\n  \"output_audio_format\"\
            : \"pcm16\",\n  \"input_audio_transcription\": {\n      \"model\": \"\
            whisper-1\"\n  },\n  \"turn_detection\": null,\n  \"tools\": [],\n  \"\
            tool_choice\": \"none\",\n  \"temperature\": 0.7,\n  \"max_response_output_tokens\"\
            : 200,\n  \"client_secret\": {\n    \"value\": \"ek_abc123\", \n    \"\
            expires_at\": 1234567890\n  }\n}\n"
  /realtime/transcription_sessions:
    post:
      tags:
      - Realtime
      summary: "Create an ephemeral API token for use in client-side applications\
        \ with the\nRealtime API specifically for realtime transcriptions. \nCan be\
        \ configured with the same session parameters as the `transcription_session.update`\
        \ client event.\n\nIt responds with a session object, plus a `client_secret`\
        \ key which contains\na usable ephemeral API token that can be used to authenticate\
        \ browser clients\nfor the Realtime API.\n"
      operationId: create-realtime-transcription-session
      requestBody:
        description: Create an ephemeral API key with the given session configuration
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/RealtimeTranscriptionSessionCreateRequest'
        required: true
      responses:
        "200":
          description: Session created successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RealtimeTranscriptionSessionCreateResponse'
      x-oaiMeta:
        name: Create transcription session
        group: realtime
        returns: "The created [Realtime transcription session object](/docs/api-reference/realtime-sessions/transcription_session_object),\
          \ plus an ephemeral key"
        examples:
          request:
            curl: |
              curl -X POST https://api.openai.com/v1/realtime/transcription_sessions \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -d '{}'
          response: |
            {
              "id": "sess_BBwZc7cFV3XizEyKGDCGL",
              "object": "realtime.transcription_session",
              "modalities": ["audio", "text"],
              "turn_detection": {
                "type": "server_vad",
                "threshold": 0.5,
                "prefix_padding_ms": 300,
                "silence_duration_ms": 200
              },
              "input_audio_format": "pcm16",
              "input_audio_transcription": {
                "model": "gpt-4o-transcribe",
                "language": null,
                "prompt": ""
              },
              "client_secret": null
            }
  /responses:
    post:
      tags:
      - Responses
      summary: |
        Creates a model response. Provide [text](/docs/guides/text) or
        [image](/docs/guides/images) inputs to generate [text](/docs/guides/text)
        or [JSON](/docs/guides/structured-outputs) outputs. Have the model call
        your own [custom code](/docs/guides/function-calling) or use built-in
        [tools](/docs/guides/tools) like [web search](/docs/guides/tools-web-search)
        or [file search](/docs/guides/tools-file-search) to use your own data
        as input for the model's response.
      operationId: createResponse
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateResponse'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Response'
            text/event-stream:
              schema:
                $ref: '#/components/schemas/ResponseStreamEvent'
      x-oaiMeta:
        name: Create a model response
        group: responses
        returns: |
          Returns a [Response](/docs/api-reference/responses/object) object.
        path: create
        examples:
        - title: Text input
          request:
            curl: |
              curl https://api.openai.com/v1/responses \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "gpt-4.1",
                  "input": "Tell me a three sentence bedtime story about a unicorn."
                }'
            javascript: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              const response = await openai.responses.create({
                  model: "gpt-4.1",
                  input: "Tell me a three sentence bedtime story about a unicorn."
              });

              console.log(response);
            python: |
              from openai import OpenAI

              client = OpenAI()

              response = client.responses.create(
                model="gpt-4.1",
                input="Tell me a three sentence bedtime story about a unicorn."
              )

              print(response)
            csharp: |
              using System;
              using OpenAI.Responses;

              OpenAIResponseClient client = new(
                  model: "gpt-4.1",
                  apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
              );

              OpenAIResponse response = client.CreateResponse("Tell me a three sentence bedtime story about a unicorn.");

              Console.WriteLine(response.GetOutputText());
          response: |
            {
              "id": "resp_67ccd2bed1ec8190b14f964abc0542670bb6a6b452d3795b",
              "object": "response",
              "created_at": 1741476542,
              "status": "completed",
              "error": null,
              "incomplete_details": null,
              "instructions": null,
              "max_output_tokens": null,
              "model": "gpt-4.1-2025-04-14",
              "output": [
                {
                  "type": "message",
                  "id": "msg_67ccd2bf17f0819081ff3bb2cf6508e60bb6a6b452d3795b",
                  "status": "completed",
                  "role": "assistant",
                  "content": [
                    {
                      "type": "output_text",
                      "text": "In a peaceful grove beneath a silver moon, a unicorn named Lumina discovered a hidden pool that reflected the stars. As she dipped her horn into the water, the pool began to shimmer, revealing a pathway to a magical realm of endless night skies. Filled with wonder, Lumina whispered a wish for all who dream to find their own hidden magic, and as she glanced back, her hoofprints sparkled like stardust.",
                      "annotations": []
                    }
                  ]
                }
              ],
              "parallel_tool_calls": true,
              "previous_response_id": null,
              "reasoning": {
                "effort": null,
                "summary": null
              },
              "store": true,
              "temperature": 1.0,
              "text": {
                "format": {
                  "type": "text"
                }
              },
              "tool_choice": "auto",
              "tools": [],
              "top_p": 1.0,
              "truncation": "disabled",
              "usage": {
                "input_tokens": 36,
                "input_tokens_details": {
                  "cached_tokens": 0
                },
                "output_tokens": 87,
                "output_tokens_details": {
                  "reasoning_tokens": 0
                },
                "total_tokens": 123
              },
              "user": null,
              "metadata": {}
            }
        - title: Image input
          request:
            curl: |
              curl https://api.openai.com/v1/responses \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "gpt-4.1",
                  "input": [
                    {
                      "role": "user",
                      "content": [
                        {"type": "input_text", "text": "what is in this image?"},
                        {
                          "type": "input_image",
                          "image_url": "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg"
                        }
                      ]
                    }
                  ]
                }'
            javascript: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              const response = await openai.responses.create({
                  model: "gpt-4.1",
                  input: [
                      {
                          role: "user",
                          content: [
                              { type: "input_text", text: "what is in this image?" },
                              {
                                  type: "input_image",
                                  image_url:
                                      "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg",
                              },
                          ],
                      },
                  ],
              });

              console.log(response);
            python: |
              from openai import OpenAI

              client = OpenAI()

              response = client.responses.create(
                  model="gpt-4.1",
                  input=[
                      {
                          "role": "user",
                          "content": [
                              { "type": "input_text", "text": "what is in this image?" },
                              {
                                  "type": "input_image",
                                  "image_url": "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg"
                              }
                          ]
                      }
                  ]
              )

              print(response)
            csharp: |
              using System;
              using System.Collections.Generic;

              using OpenAI.Responses;

              OpenAIResponseClient client = new(
                  model: "gpt-4.1",
                  apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
              );

              List<ResponseItem> inputItems =
              [
                  ResponseItem.CreateUserMessageItem(
                      [
                          ResponseContentPart.CreateInputTextPart("What is in this image?"),
                          ResponseContentPart.CreateInputImagePart(new Uri("https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg"))
                      ]
                  )
              ];

              OpenAIResponse response = client.CreateResponse(inputItems);

              Console.WriteLine(response.GetOutputText());
          response: |
            {
              "id": "resp_67ccd3a9da748190baa7f1570fe91ac604becb25c45c1d41",
              "object": "response",
              "created_at": 1741476777,
              "status": "completed",
              "error": null,
              "incomplete_details": null,
              "instructions": null,
              "max_output_tokens": null,
              "model": "gpt-4.1-2025-04-14",
              "output": [
                {
                  "type": "message",
                  "id": "msg_67ccd3acc8d48190a77525dc6de64b4104becb25c45c1d41",
                  "status": "completed",
                  "role": "assistant",
                  "content": [
                    {
                      "type": "output_text",
                      "text": "The image depicts a scenic landscape with a wooden boardwalk or pathway leading through lush, green grass under a blue sky with some clouds. The setting suggests a peaceful natural area, possibly a park or nature reserve. There are trees and shrubs in the background.",
                      "annotations": []
                    }
                  ]
                }
              ],
              "parallel_tool_calls": true,
              "previous_response_id": null,
              "reasoning": {
                "effort": null,
                "summary": null
              },
              "store": true,
              "temperature": 1.0,
              "text": {
                "format": {
                  "type": "text"
                }
              },
              "tool_choice": "auto",
              "tools": [],
              "top_p": 1.0,
              "truncation": "disabled",
              "usage": {
                "input_tokens": 328,
                "input_tokens_details": {
                  "cached_tokens": 0
                },
                "output_tokens": 52,
                "output_tokens_details": {
                  "reasoning_tokens": 0
                },
                "total_tokens": 380
              },
              "user": null,
              "metadata": {}
            }
        - title: Web search
          request:
            curl: |
              curl https://api.openai.com/v1/responses \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "gpt-4.1",
                  "tools": [{ "type": "web_search_preview" }],
                  "input": "What was a positive news story from today?"
                }'
            javascript: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              const response = await openai.responses.create({
                  model: "gpt-4.1",
                  tools: [{ type: "web_search_preview" }],
                  input: "What was a positive news story from today?",
              });

              console.log(response);
            python: |
              from openai import OpenAI

              client = OpenAI()

              response = client.responses.create(
                  model="gpt-4.1",
                  tools=[{ "type": "web_search_preview" }],
                  input="What was a positive news story from today?",
              )

              print(response)
            csharp: |
              using System;

              using OpenAI.Responses;

              OpenAIResponseClient client = new(
                  model: "gpt-4.1",
                  apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
              );

              string userInputText = "What was a positive news story from today?";

              ResponseCreationOptions options = new()
              {
                  Tools =
                  {
                      ResponseTool.CreateWebSearchTool()
                  },
              };

              OpenAIResponse response = client.CreateResponse(userInputText, options);

              Console.WriteLine(response.GetOutputText());
          response: |
            {
              "id": "resp_67ccf18ef5fc8190b16dbee19bc54e5f087bb177ab789d5c",
              "object": "response",
              "created_at": 1741484430,
              "status": "completed",
              "error": null,
              "incomplete_details": null,
              "instructions": null,
              "max_output_tokens": null,
              "model": "gpt-4.1-2025-04-14",
              "output": [
                {
                  "type": "web_search_call",
                  "id": "ws_67ccf18f64008190a39b619f4c8455ef087bb177ab789d5c",
                  "status": "completed"
                },
                {
                  "type": "message",
                  "id": "msg_67ccf190ca3881909d433c50b1f6357e087bb177ab789d5c",
                  "status": "completed",
                  "role": "assistant",
                  "content": [
                    {
                      "type": "output_text",
                      "text": "As of today, March 9, 2025, one notable positive news story...",
                      "annotations": [
                        {
                          "type": "url_citation",
                          "start_index": 442,
                          "end_index": 557,
                          "url": "https://.../?utm_source=chatgpt.com",
                          "title": "..."
                        },
                        {
                          "type": "url_citation",
                          "start_index": 962,
                          "end_index": 1077,
                          "url": "https://.../?utm_source=chatgpt.com",
                          "title": "..."
                        },
                        {
                          "type": "url_citation",
                          "start_index": 1336,
                          "end_index": 1451,
                          "url": "https://.../?utm_source=chatgpt.com",
                          "title": "..."
                        }
                      ]
                    }
                  ]
                }
              ],
              "parallel_tool_calls": true,
              "previous_response_id": null,
              "reasoning": {
                "effort": null,
                "summary": null
              },
              "store": true,
              "temperature": 1.0,
              "text": {
                "format": {
                  "type": "text"
                }
              },
              "tool_choice": "auto",
              "tools": [
                {
                  "type": "web_search_preview",
                  "domains": [],
                  "search_context_size": "medium",
                  "user_location": {
                    "type": "approximate",
                    "city": null,
                    "country": "US",
                    "region": null,
                    "timezone": null
                  }
                }
              ],
              "top_p": 1.0,
              "truncation": "disabled",
              "usage": {
                "input_tokens": 328,
                "input_tokens_details": {
                  "cached_tokens": 0
                },
                "output_tokens": 356,
                "output_tokens_details": {
                  "reasoning_tokens": 0
                },
                "total_tokens": 684
              },
              "user": null,
              "metadata": {}
            }
        - title: File search
          request:
            curl: |
              curl https://api.openai.com/v1/responses \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "gpt-4.1",
                  "tools": [{
                    "type": "file_search",
                    "vector_store_ids": ["vs_1234567890"],
                    "max_num_results": 20
                  }],
                  "input": "What are the attributes of an ancient brown dragon?"
                }'
            javascript: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              const response = await openai.responses.create({
                  model: "gpt-4.1",
                  tools: [{
                    type: "file_search",
                    vector_store_ids: ["vs_1234567890"],
                    max_num_results: 20
                  }],
                  input: "What are the attributes of an ancient brown dragon?",
              });

              console.log(response);
            python: |
              from openai import OpenAI

              client = OpenAI()

              response = client.responses.create(
                  model="gpt-4.1",
                  tools=[{
                    "type": "file_search",
                    "vector_store_ids": ["vs_1234567890"],
                    "max_num_results": 20
                  }],
                  input="What are the attributes of an ancient brown dragon?",
              )

              print(response)
            csharp: |
              using System;

              using OpenAI.Responses;

              OpenAIResponseClient client = new(
                  model: "gpt-4.1",
                  apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
              );

              string userInputText = "What are the attributes of an ancient brown dragon?";

              ResponseCreationOptions options = new()
              {
                  Tools =
                  {
                      ResponseTool.CreateFileSearchTool(
                          vectorStoreIds: ["vs_1234567890"],
                          maxResultCount: 20
                      )
                  },
              };

              OpenAIResponse response = client.CreateResponse(userInputText, options);

              Console.WriteLine(response.GetOutputText());
          response: "{\n  \"id\": \"resp_67ccf4c55fc48190b71bd0463ad3306d09504fb6872380d7\"\
            ,\n  \"object\": \"response\",\n  \"created_at\": 1741485253,\n  \"status\"\
            : \"completed\",\n  \"error\": null,\n  \"incomplete_details\": null,\n\
            \  \"instructions\": null,\n  \"max_output_tokens\": null,\n  \"model\"\
            : \"gpt-4.1-2025-04-14\",\n  \"output\": [\n    {\n      \"type\": \"\
            file_search_call\",\n      \"id\": \"fs_67ccf4c63cd08190887ef6464ba5681609504fb6872380d7\"\
            ,\n      \"status\": \"completed\",\n      \"queries\": [\n        \"\
            attributes of an ancient brown dragon\"\n      ],\n      \"results\":\
            \ null\n    },\n    {\n      \"type\": \"message\",\n      \"id\": \"\
            msg_67ccf4c93e5c81909d595b369351a9d309504fb6872380d7\",\n      \"status\"\
            : \"completed\",\n      \"role\": \"assistant\",\n      \"content\": [\n\
            \        {\n          \"type\": \"output_text\",\n          \"text\":\
            \ \"The attributes of an ancient brown dragon include...\",\n        \
            \  \"annotations\": [\n            {\n              \"type\": \"file_citation\"\
            ,\n              \"index\": 320,\n              \"file_id\": \"file-4wDz5b167pAf72nx1h9eiN\"\
            ,\n              \"filename\": \"dragons.pdf\"\n            },\n     \
            \       {\n              \"type\": \"file_citation\",\n              \"\
            index\": 576,\n              \"file_id\": \"file-4wDz5b167pAf72nx1h9eiN\"\
            ,\n              \"filename\": \"dragons.pdf\"\n            },\n     \
            \       {\n              \"type\": \"file_citation\",\n              \"\
            index\": 815,\n              \"file_id\": \"file-4wDz5b167pAf72nx1h9eiN\"\
            ,\n              \"filename\": \"dragons.pdf\"\n            },\n     \
            \       {\n              \"type\": \"file_citation\",\n              \"\
            index\": 815,\n              \"file_id\": \"file-4wDz5b167pAf72nx1h9eiN\"\
            ,\n              \"filename\": \"dragons.pdf\"\n            },\n     \
            \       {\n              \"type\": \"file_citation\",\n              \"\
            index\": 1030,\n              \"file_id\": \"file-4wDz5b167pAf72nx1h9eiN\"\
            ,\n              \"filename\": \"dragons.pdf\"\n            },\n     \
            \       {\n              \"type\": \"file_citation\",\n              \"\
            index\": 1030,\n              \"file_id\": \"file-4wDz5b167pAf72nx1h9eiN\"\
            ,\n              \"filename\": \"dragons.pdf\"\n            },\n     \
            \       {\n              \"type\": \"file_citation\",\n              \"\
            index\": 1156,\n              \"file_id\": \"file-4wDz5b167pAf72nx1h9eiN\"\
            ,\n              \"filename\": \"dragons.pdf\"\n            },\n     \
            \       {\n              \"type\": \"file_citation\",\n              \"\
            index\": 1225,\n              \"file_id\": \"file-4wDz5b167pAf72nx1h9eiN\"\
            ,\n              \"filename\": \"dragons.pdf\"\n            }\n      \
            \    ]\n        }\n      ]\n    }\n  ],\n  \"parallel_tool_calls\": true,\n\
            \  \"previous_response_id\": null,\n  \"reasoning\": {\n    \"effort\"\
            : null,\n    \"summary\": null\n  },\n  \"store\": true,\n  \"temperature\"\
            : 1.0,\n  \"text\": {\n    \"format\": {\n      \"type\": \"text\"\n \
            \   }\n  },\n  \"tool_choice\": \"auto\",\n  \"tools\": [\n    {\n   \
            \   \"type\": \"file_search\",\n      \"filters\": null,\n      \"max_num_results\"\
            : 20,\n      \"ranking_options\": {\n        \"ranker\": \"auto\",\n \
            \       \"score_threshold\": 0.0\n      },\n      \"vector_store_ids\"\
            : [\n        \"vs_1234567890\"\n      ]\n    }\n  ],\n  \"top_p\": 1.0,\n\
            \  \"truncation\": \"disabled\",\n  \"usage\": {\n    \"input_tokens\"\
            : 18307,\n    \"input_tokens_details\": {\n      \"cached_tokens\": 0\n\
            \    },\n    \"output_tokens\": 348,\n    \"output_tokens_details\": {\n\
            \      \"reasoning_tokens\": 0\n    },\n    \"total_tokens\": 18655\n\
            \  },\n  \"user\": null,\n  \"metadata\": {}\n}      \n"
        - title: Streaming
          request:
            curl: |
              curl https://api.openai.com/v1/responses \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "gpt-4.1",
                  "instructions": "You are a helpful assistant.",
                  "input": "Hello!",
                  "stream": true
                }'
            python: |
              from openai import OpenAI

              client = OpenAI()

              response = client.responses.create(
                model="gpt-4.1",
                instructions="You are a helpful assistant.",
                input="Hello!",
                stream=True
              )

              for event in response:
                print(event)
            javascript: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              const response = await openai.responses.create({
                  model: "gpt-4.1",
                  instructions: "You are a helpful assistant.",
                  input: "Hello!",
                  stream: true,
              });

              for await (const event of response) {
                  console.log(event);
              }
            csharp: |
              using System;
              using System.ClientModel;
              using System.Threading.Tasks;

              using OpenAI.Responses;

              OpenAIResponseClient client = new(
                  model: "gpt-4.1",
                  apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
              );

              string userInputText = "Hello!";

              ResponseCreationOptions options = new()
              {
                  Instructions = "You are a helpful assistant.",
              };

              AsyncCollectionResult<StreamingResponseUpdate> responseUpdates = client.CreateResponseStreamingAsync(userInputText, options);

              await foreach (StreamingResponseUpdate responseUpdate in responseUpdates)
              {
                  if (responseUpdate is StreamingResponseOutputTextDeltaUpdate outputTextDeltaUpdate)
                  {
                      Console.Write(outputTextDeltaUpdate.Delta);
                  }
              }
          response: |
            event: response.created
            data: {"type":"response.created","response":{"id":"resp_67c9fdcecf488190bdd9a0409de3a1ec07b8b0ad4e5eb654","object":"response","created_at":1741290958,"status":"in_progress","error":null,"incomplete_details":null,"instructions":"You are a helpful assistant.","max_output_tokens":null,"model":"gpt-4.1-2025-04-14","output":[],"parallel_tool_calls":true,"previous_response_id":null,"reasoning":{"effort":null,"summary":null},"store":true,"temperature":1.0,"text":{"format":{"type":"text"}},"tool_choice":"auto","tools":[],"top_p":1.0,"truncation":"disabled","usage":null,"user":null,"metadata":{}}}

            event: response.in_progress
            data: {"type":"response.in_progress","response":{"id":"resp_67c9fdcecf488190bdd9a0409de3a1ec07b8b0ad4e5eb654","object":"response","created_at":1741290958,"status":"in_progress","error":null,"incomplete_details":null,"instructions":"You are a helpful assistant.","max_output_tokens":null,"model":"gpt-4.1-2025-04-14","output":[],"parallel_tool_calls":true,"previous_response_id":null,"reasoning":{"effort":null,"summary":null},"store":true,"temperature":1.0,"text":{"format":{"type":"text"}},"tool_choice":"auto","tools":[],"top_p":1.0,"truncation":"disabled","usage":null,"user":null,"metadata":{}}}

            event: response.output_item.added
            data: {"type":"response.output_item.added","output_index":0,"item":{"id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","type":"message","status":"in_progress","role":"assistant","content":[]}}

            event: response.content_part.added
            data: {"type":"response.content_part.added","item_id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","output_index":0,"content_index":0,"part":{"type":"output_text","text":"","annotations":[]}}

            event: response.output_text.delta
            data: {"type":"response.output_text.delta","item_id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","output_index":0,"content_index":0,"delta":"Hi"}

            ...

            event: response.output_text.done
            data: {"type":"response.output_text.done","item_id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","output_index":0,"content_index":0,"text":"Hi there! How can I assist you today?"}

            event: response.content_part.done
            data: {"type":"response.content_part.done","item_id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","output_index":0,"content_index":0,"part":{"type":"output_text","text":"Hi there! How can I assist you today?","annotations":[]}}

            event: response.output_item.done
            data: {"type":"response.output_item.done","output_index":0,"item":{"id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","type":"message","status":"completed","role":"assistant","content":[{"type":"output_text","text":"Hi there! How can I assist you today?","annotations":[]}]}}

            event: response.completed
            data: {"type":"response.completed","response":{"id":"resp_67c9fdcecf488190bdd9a0409de3a1ec07b8b0ad4e5eb654","object":"response","created_at":1741290958,"status":"completed","error":null,"incomplete_details":null,"instructions":"You are a helpful assistant.","max_output_tokens":null,"model":"gpt-4.1-2025-04-14","output":[{"id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","type":"message","status":"completed","role":"assistant","content":[{"type":"output_text","text":"Hi there! How can I assist you today?","annotations":[]}]}],"parallel_tool_calls":true,"previous_response_id":null,"reasoning":{"effort":null,"summary":null},"store":true,"temperature":1.0,"text":{"format":{"type":"text"}},"tool_choice":"auto","tools":[],"top_p":1.0,"truncation":"disabled","usage":{"input_tokens":37,"output_tokens":11,"output_tokens_details":{"reasoning_tokens":0},"total_tokens":48},"user":null,"metadata":{}}}
        - title: Functions
          request:
            curl: |
              curl https://api.openai.com/v1/responses \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "gpt-4.1",
                  "input": "What is the weather like in Boston today?",
                  "tools": [
                    {
                      "type": "function",
                      "name": "get_current_weather",
                      "description": "Get the current weather in a given location",
                      "parameters": {
                        "type": "object",
                        "properties": {
                          "location": {
                            "type": "string",
                            "description": "The city and state, e.g. San Francisco, CA"
                          },
                          "unit": {
                            "type": "string",
                            "enum": ["celsius", "fahrenheit"]
                          }
                        },
                        "required": ["location", "unit"]
                      }
                    }
                  ],
                  "tool_choice": "auto"
                }'
            python: |
              from openai import OpenAI

              client = OpenAI()

              tools = [
                  {
                      "type": "function",
                      "name": "get_current_weather",
                      "description": "Get the current weather in a given location",
                      "parameters": {
                        "type": "object",
                        "properties": {
                            "location": {
                                "type": "string",
                                "description": "The city and state, e.g. San Francisco, CA",
                            },
                            "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
                        },
                        "required": ["location", "unit"],
                      }
                  }
              ]

              response = client.responses.create(
                model="gpt-4.1",
                tools=tools,
                input="What is the weather like in Boston today?",
                tool_choice="auto"
              )

              print(response)
            javascript: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              const tools = [
                  {
                      type: "function",
                      name: "get_current_weather",
                      description: "Get the current weather in a given location",
                      parameters: {
                          type: "object",
                          properties: {
                              location: {
                                  type: "string",
                                  description: "The city and state, e.g. San Francisco, CA",
                              },
                              unit: { type: "string", enum: ["celsius", "fahrenheit"] },
                          },
                          required: ["location", "unit"],
                      },
                  },
              ];

              const response = await openai.responses.create({
                  model: "gpt-4.1",
                  tools: tools,
                  input: "What is the weather like in Boston today?",
                  tool_choice: "auto",
              });

              console.log(response);
            csharp: |
              using System;
              using OpenAI.Responses;

              OpenAIResponseClient client = new(
                  model: "gpt-4.1",
                  apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
              );

              ResponseTool getCurrentWeatherFunctionTool = ResponseTool.CreateFunctionTool(
                  functionName: "get_current_weather",
                  functionDescription: "Get the current weather in a given location",
                  functionParameters: BinaryData.FromString("""
                      {
                          "type": "object",
                          "properties": {
                              "location": {
                                  "type": "string",
                                  "description": "The city and state, e.g. San Francisco, CA"
                              },
                              "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]}
                          },
                          "required": ["location", "unit"]
                      }
                      """
                  )
              );

              string userInputText = "What is the weather like in Boston today?";

              ResponseCreationOptions options = new()
              {
                  Tools =
                  {
                      getCurrentWeatherFunctionTool
                  },
                  ToolChoice = ResponseToolChoice.CreateAutoChoice(),
              };

              OpenAIResponse response = client.CreateResponse(userInputText, options);
          response: |
            {
              "id": "resp_67ca09c5efe0819096d0511c92b8c890096610f474011cc0",
              "object": "response",
              "created_at": 1741294021,
              "status": "completed",
              "error": null,
              "incomplete_details": null,
              "instructions": null,
              "max_output_tokens": null,
              "model": "gpt-4.1-2025-04-14",
              "output": [
                {
                  "type": "function_call",
                  "id": "fc_67ca09c6bedc8190a7abfec07b1a1332096610f474011cc0",
                  "call_id": "call_unLAR8MvFNptuiZK6K6HCy5k",
                  "name": "get_current_weather",
                  "arguments": "{\"location\":\"Boston, MA\",\"unit\":\"celsius\"}",
                  "status": "completed"
                }
              ],
              "parallel_tool_calls": true,
              "previous_response_id": null,
              "reasoning": {
                "effort": null,
                "summary": null
              },
              "store": true,
              "temperature": 1.0,
              "text": {
                "format": {
                  "type": "text"
                }
              },
              "tool_choice": "auto",
              "tools": [
                {
                  "type": "function",
                  "description": "Get the current weather in a given location",
                  "name": "get_current_weather",
                  "parameters": {
                    "type": "object",
                    "properties": {
                      "location": {
                        "type": "string",
                        "description": "The city and state, e.g. San Francisco, CA"
                      },
                      "unit": {
                        "type": "string",
                        "enum": [
                          "celsius",
                          "fahrenheit"
                        ]
                      }
                    },
                    "required": [
                      "location",
                      "unit"
                    ]
                  },
                  "strict": true
                }
              ],
              "top_p": 1.0,
              "truncation": "disabled",
              "usage": {
                "input_tokens": 291,
                "output_tokens": 23,
                "output_tokens_details": {
                  "reasoning_tokens": 0
                },
                "total_tokens": 314
              },
              "user": null,
              "metadata": {}
            }
        - title: Reasoning
          request:
            curl: |
              curl https://api.openai.com/v1/responses \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "o3-mini",
                  "input": "How much wood would a woodchuck chuck?",
                  "reasoning": {
                    "effort": "high"
                  }
                }'
            javascript: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              const response = await openai.responses.create({
                  model: "o3-mini",
                  input: "How much wood would a woodchuck chuck?",
                  reasoning: {
                    effort: "high"
                  }
              });

              console.log(response);
            python: |
              from openai import OpenAI
              client = OpenAI()

              response = client.responses.create(
                  model="o3-mini",
                  input="How much wood would a woodchuck chuck?",
                  reasoning={
                      "effort": "high"
                  }
              )

              print(response)
            csharp: |
              using System;
              using OpenAI.Responses;

              OpenAIResponseClient client = new(
                  model: "o3-mini",
                  apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
              );

              string userInputText = "How much wood would a woodchuck chuck?";

              ResponseCreationOptions options = new()
              {
                  ReasoningOptions = new()
                  {
                      ReasoningEffortLevel = ResponseReasoningEffortLevel.High,
                  },
              };

              OpenAIResponse response = client.CreateResponse(userInputText, options);

              Console.WriteLine(response.GetOutputText());
          response: |
            {
              "id": "resp_67ccd7eca01881908ff0b5146584e408072912b2993db808",
              "object": "response",
              "created_at": 1741477868,
              "status": "completed",
              "error": null,
              "incomplete_details": null,
              "instructions": null,
              "max_output_tokens": null,
              "model": "o1-2024-12-17",
              "output": [
                {
                  "type": "message",
                  "id": "msg_67ccd7f7b5848190a6f3e95d809f6b44072912b2993db808",
                  "status": "completed",
                  "role": "assistant",
                  "content": [
                    {
                      "type": "output_text",
                      "text": "The classic tongue twister...",
                      "annotations": []
                    }
                  ]
                }
              ],
              "parallel_tool_calls": true,
              "previous_response_id": null,
              "reasoning": {
                "effort": "high",
                "summary": null
              },
              "store": true,
              "temperature": 1.0,
              "text": {
                "format": {
                  "type": "text"
                }
              },
              "tool_choice": "auto",
              "tools": [],
              "top_p": 1.0,
              "truncation": "disabled",
              "usage": {
                "input_tokens": 81,
                "input_tokens_details": {
                  "cached_tokens": 0
                },
                "output_tokens": 1035,
                "output_tokens_details": {
                  "reasoning_tokens": 832
                },
                "total_tokens": 1116
              },
              "user": null,
              "metadata": {}
            }
  /responses/{responseId}:
    get:
      tags:
      - Responses
      summary: |
        Retrieves a model response with the given ID.
      operationId: getResponse
      parameters:
      - name: responseId
        in: path
        description: The ID of the response to retrieve
        required: true
        style: simple
        explode: false
        schema:
          type: string
          example: resp_677efb5139a88190b512bc3fef8e535d
      - name: include
        in: query
        description: |
          Additional fields to include in the response. See the `include`
          parameter for Response creation above for more information
        required: false
        style: form
        explode: true
        schema:
          type: array
          items:
            $ref: '#/components/schemas/Includable'
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Response'
      x-oaiMeta:
        name: Get a model response
        group: responses
        returns: |
          The [Response](/docs/api-reference/responses/object) object matching the
          specified ID.
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/responses/resp_123 \
                  -H "Content-Type: application/json" \
                  -H "Authorization: Bearer $OPENAI_API_KEY"
            javascript: "import OpenAI from \"openai\";\nconst client = new OpenAI();\n\
              \nconst response = await client.responses.retrieve(\"resp_123\");\n\
              console.log(response);  \n"
            python: |
              from openai import OpenAI
              client = OpenAI()

              response = client.responses.retrieve("resp_123")
              print(response)
          response: |
            {
              "id": "resp_67cb71b351908190a308f3859487620d06981a8637e6bc44",
              "object": "response",
              "created_at": 1741386163,
              "status": "completed",
              "error": null,
              "incomplete_details": null,
              "instructions": null,
              "max_output_tokens": null,
              "model": "gpt-4o-2024-08-06",
              "output": [
                {
                  "type": "message",
                  "id": "msg_67cb71b3c2b0819084d481baaaf148f206981a8637e6bc44",
                  "status": "completed",
                  "role": "assistant",
                  "content": [
                    {
                      "type": "output_text",
                      "text": "Silent circuits hum,  \nThoughts emerge in data streams  \nDigital dawn breaks.",
                      "annotations": []
                    }
                  ]
                }
              ],
              "parallel_tool_calls": true,
              "previous_response_id": null,
              "reasoning": {
                "effort": null,
                "summary": null
              },
              "store": true,
              "temperature": 1.0,
              "text": {
                "format": {
                  "type": "text"
                }
              },
              "tool_choice": "auto",
              "tools": [],
              "top_p": 1.0,
              "truncation": "disabled",
              "usage": {
                "input_tokens": 32,
                "input_tokens_details": {
                  "cached_tokens": 0
                },
                "output_tokens": 18,
                "output_tokens_details": {
                  "reasoning_tokens": 0
                },
                "total_tokens": 50
              },
              "user": null,
              "metadata": {}
            }
    delete:
      tags:
      - Responses
      summary: |
        Deletes a model response with the given ID.
      operationId: deleteResponse
      parameters:
      - name: responseId
        in: path
        description: The ID of the response to delete
        required: true
        style: simple
        explode: false
        schema:
          type: string
          example: resp_677efb5139a88190b512bc3fef8e535d
      responses:
        "200":
          description: OK
        "404":
          description: Not Found
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Error'
      x-oaiMeta:
        name: Delete a model response
        group: responses
        returns: |
          A success message.
        examples:
          request:
            curl: |
              curl -X DELETE https://api.openai.com/v1/responses/resp_123 \
                  -H "Content-Type: application/json" \
                  -H "Authorization: Bearer $OPENAI_API_KEY"
            javascript: "import OpenAI from \"openai\";\nconst client = new OpenAI();\n\
              \nconst response = await client.responses.del(\"resp_123\");\nconsole.log(response);\
              \  \n"
            python: |
              from openai import OpenAI
              client = OpenAI()

              response = client.responses.del("resp_123")
              print(response)
          response: |
            {
              "id": "resp_6786a1bec27481909a17d673315b29f6",
              "object": "response",
              "deleted": true
            }
  /responses/{responseId}/input_items:
    get:
      tags:
      - Responses
      summary: Returns a list of input items for a given response.
      operationId: listInputItems
      parameters:
      - name: responseId
        in: path
        description: The ID of the response to retrieve input items for
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: limit
        in: query
        description: |
          A limit on the number of objects to be returned. Limit can range between
          1 and 100, and the default is 20
        required: false
        style: form
        explode: true
        schema:
          type: integer
          default: 20
      - name: order
        in: query
        description: |
          The order to return the input items in. Default is `asc`.
          - `asc`: Return the input items in ascending order.
          - `desc`: Return the input items in descending order
        required: false
        style: form
        explode: true
        schema:
          type: string
          enum:
          - asc
          - desc
      - name: after
        in: query
        description: |
          An item ID to list items after, used in pagination
        required: false
        style: form
        explode: true
        schema:
          type: string
      - name: before
        in: query
        description: |
          An item ID to list items before, used in pagination
        required: false
        style: form
        explode: true
        schema:
          type: string
      - name: include
        in: query
        description: |
          Additional fields to include in the response. See the `include`
          parameter for Response creation above for more information
        required: false
        style: form
        explode: true
        schema:
          type: array
          items:
            $ref: '#/components/schemas/Includable'
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ResponseItemList'
      x-oaiMeta:
        name: List input items
        group: responses
        returns: A list of input item objects.
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/responses/resp_abc123/input_items \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY"
            javascript: "import OpenAI from \"openai\";\nconst client = new OpenAI();\n\
              \nconst response = await client.responses.inputItems.list(\"resp_123\"\
              );\nconsole.log(response.data);  \n"
            python: |
              from openai import OpenAI
              client = OpenAI()

              response = client.responses.input_items.list("resp_123")
              print(response.data)
          response: |
            {
              "object": "list",
              "data": [
                {
                  "id": "msg_abc123",
                  "type": "message",
                  "role": "user",
                  "content": [
                    {
                      "type": "input_text",
                      "text": "Tell me a three sentence bedtime story about a unicorn."
                    }
                  ]
                }
              ],
              "first_id": "msg_abc123",
              "last_id": "msg_abc123",
              "has_more": false
            }
  /threads:
    post:
      tags:
      - Assistants
      summary: Create a thread.
      operationId: createThread
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateThreadRequest'
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ThreadObject'
      x-oaiMeta:
        name: Create thread
        group: threads
        beta: true
        returns: "A [thread](/docs/api-reference/threads) object."
        examples:
        - title: Empty
          request:
            curl: |
              curl https://api.openai.com/v1/threads \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2" \
                -d ''
            python: |
              from openai import OpenAI
              client = OpenAI()

              empty_thread = client.beta.threads.create()
              print(empty_thread)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const emptyThread = await openai.beta.threads.create();

                console.log(emptyThread);
              }

              main();
          response: |
            {
              "id": "thread_abc123",
              "object": "thread",
              "created_at": 1699012949,
              "metadata": {},
              "tool_resources": {}
            }
        - title: Messages
          request:
            curl: |
              curl https://api.openai.com/v1/threads \
              -H "Content-Type: application/json" \
              -H "Authorization: Bearer $OPENAI_API_KEY" \
              -H "OpenAI-Beta: assistants=v2" \
              -d '{
                  "messages": [{
                    "role": "user",
                    "content": "Hello, what is AI?"
                  }, {
                    "role": "user",
                    "content": "How does AI work? Explain it in simple terms."
                  }]
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              message_thread = client.beta.threads.create(
                messages=[
                  {
                    "role": "user",
                    "content": "Hello, what is AI?"
                  },
                  {
                    "role": "user",
                    "content": "How does AI work? Explain it in simple terms."
                  },
                ]
              )

              print(message_thread)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const messageThread = await openai.beta.threads.create({
                  messages: [
                    {
                      role: "user",
                      content: "Hello, what is AI?"
                    },
                    {
                      role: "user",
                      content: "How does AI work? Explain it in simple terms.",
                    },
                  ],
                });

                console.log(messageThread);
              }

              main();
          response: |
            {
              "id": "thread_abc123",
              "object": "thread",
              "created_at": 1699014083,
              "metadata": {},
              "tool_resources": {}
            }
  /threads/runs:
    post:
      tags:
      - Assistants
      summary: Create a thread and run it in one request.
      operationId: createThreadAndRun
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateThreadAndRunRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RunObject'
      x-oaiMeta:
        name: Create thread and run
        group: threads
        beta: true
        returns: "A [run](/docs/api-reference/runs/object) object."
        examples:
        - title: Default
          request:
            curl: |
              curl https://api.openai.com/v1/threads/runs \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                    "assistant_id": "asst_abc123",
                    "thread": {
                      "messages": [
                        {"role": "user", "content": "Explain deep learning to a 5 year old."}
                      ]
                    }
                  }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              run = client.beta.threads.create_and_run(
                assistant_id="asst_abc123",
                thread={
                  "messages": [
                    {"role": "user", "content": "Explain deep learning to a 5 year old."}
                  ]
                }
              )

              print(run)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const run = await openai.beta.threads.createAndRun({
                  assistant_id: "asst_abc123",
                  thread: {
                    messages: [
                      { role: "user", content: "Explain deep learning to a 5 year old." },
                    ],
                  },
                });

                console.log(run);
              }

              main();
          response: |
            {
              "id": "run_abc123",
              "object": "thread.run",
              "created_at": 1699076792,
              "assistant_id": "asst_abc123",
              "thread_id": "thread_abc123",
              "status": "queued",
              "started_at": null,
              "expires_at": 1699077392,
              "cancelled_at": null,
              "failed_at": null,
              "completed_at": null,
              "required_action": null,
              "last_error": null,
              "model": "gpt-4o",
              "instructions": "You are a helpful assistant.",
              "tools": [],
              "tool_resources": {},
              "metadata": {},
              "temperature": 1.0,
              "top_p": 1.0,
              "max_completion_tokens": null,
              "max_prompt_tokens": null,
              "truncation_strategy": {
                "type": "auto",
                "last_messages": null
              },
              "incomplete_details": null,
              "usage": null,
              "response_format": "auto",
              "tool_choice": "auto",
              "parallel_tool_calls": true
            }
        - title: Streaming
          request:
            curl: |
              curl https://api.openai.com/v1/threads/runs \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                  "assistant_id": "asst_123",
                  "thread": {
                    "messages": [
                      {"role": "user", "content": "Hello"}
                    ]
                  },
                  "stream": true
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              stream = client.beta.threads.create_and_run(
                assistant_id="asst_123",
                thread={
                  "messages": [
                    {"role": "user", "content": "Hello"}
                  ]
                },
                stream=True
              )

              for event in stream:
                print(event)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const stream = await openai.beta.threads.createAndRun({
                    assistant_id: "asst_123",
                    thread: {
                      messages: [
                        { role: "user", content: "Hello" },
                      ],
                    },
                    stream: true
                });

                for await (const event of stream) {
                  console.log(event);
                }
              }

              main();
          response: |
            event: thread.created
            data: {"id":"thread_123","object":"thread","created_at":1710348075,"metadata":{}}

            event: thread.run.created
            data: {"id":"run_123","object":"thread.run","created_at":1710348075,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":null,"expires_at":1710348675,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[],"tool_resources":{},"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}

            event: thread.run.queued
            data: {"id":"run_123","object":"thread.run","created_at":1710348075,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":null,"expires_at":1710348675,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[],"tool_resources":{},"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}

            event: thread.run.in_progress
            data: {"id":"run_123","object":"thread.run","created_at":1710348075,"assistant_id":"asst_123","thread_id":"thread_123","status":"in_progress","started_at":null,"expires_at":1710348675,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[],"tool_resources":{},"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}

            event: thread.run.step.created
            data: {"id":"step_001","object":"thread.run.step","created_at":1710348076,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710348675,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":null}

            event: thread.run.step.in_progress
            data: {"id":"step_001","object":"thread.run.step","created_at":1710348076,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710348675,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":null}

            event: thread.message.created
            data: {"id":"msg_001","object":"thread.message","created_at":1710348076,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"in_progress","incomplete_details":null,"incomplete_at":null,"completed_at":null,"role":"assistant","content":[], "metadata":{}}

            event: thread.message.in_progress
            data: {"id":"msg_001","object":"thread.message","created_at":1710348076,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"in_progress","incomplete_details":null,"incomplete_at":null,"completed_at":null,"role":"assistant","content":[], "metadata":{}}

            event: thread.message.delta
            data: {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"Hello","annotations":[]}}]}}

            ...

            event: thread.message.delta
            data: {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":" today"}}]}}

            event: thread.message.delta
            data: {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"?"}}]}}

            event: thread.message.completed
            data: {"id":"msg_001","object":"thread.message","created_at":1710348076,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"completed","incomplete_details":null,"incomplete_at":null,"completed_at":1710348077,"role":"assistant","content":[{"type":"text","text":{"value":"Hello! How can I assist you today?","annotations":[]}}], "metadata":{}}

            event: thread.run.step.completed
            data: {"id":"step_001","object":"thread.run.step","created_at":1710348076,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"completed","cancelled_at":null,"completed_at":1710348077,"expires_at":1710348675,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":{"prompt_tokens":20,"completion_tokens":11,"total_tokens":31}}

            event: thread.run.completed
            {"id":"run_123","object":"thread.run","created_at":1710348076,"assistant_id":"asst_123","thread_id":"thread_123","status":"completed","started_at":1713226836,"expires_at":null,"cancelled_at":null,"failed_at":null,"completed_at":1713226837,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":{"prompt_tokens":345,"completion_tokens":11,"total_tokens":356},"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}

            event: done
            data: [DONE]
        - title: Streaming with Functions
          request:
            curl: |
              curl https://api.openai.com/v1/threads/runs \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                  "assistant_id": "asst_abc123",
                  "thread": {
                    "messages": [
                      {"role": "user", "content": "What is the weather like in San Francisco?"}
                    ]
                  },
                  "tools": [
                    {
                      "type": "function",
                      "function": {
                        "name": "get_current_weather",
                        "description": "Get the current weather in a given location",
                        "parameters": {
                          "type": "object",
                          "properties": {
                            "location": {
                              "type": "string",
                              "description": "The city and state, e.g. San Francisco, CA"
                            },
                            "unit": {
                              "type": "string",
                              "enum": ["celsius", "fahrenheit"]
                            }
                          },
                          "required": ["location"]
                        }
                      }
                    }
                  ],
                  "stream": true
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              tools = [
                {
                  "type": "function",
                  "function": {
                    "name": "get_current_weather",
                    "description": "Get the current weather in a given location",
                    "parameters": {
                      "type": "object",
                      "properties": {
                        "location": {
                          "type": "string",
                          "description": "The city and state, e.g. San Francisco, CA",
                        },
                        "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
                      },
                      "required": ["location"],
                    },
                  }
                }
              ]

              stream = client.beta.threads.create_and_run(
                thread={
                    "messages": [
                      {"role": "user", "content": "What is the weather like in San Francisco?"}
                    ]
                },
                assistant_id="asst_abc123",
                tools=tools,
                stream=True
              )

              for event in stream:
                print(event)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              const tools = [
                  {
                    "type": "function",
                    "function": {
                      "name": "get_current_weather",
                      "description": "Get the current weather in a given location",
                      "parameters": {
                        "type": "object",
                        "properties": {
                          "location": {
                            "type": "string",
                            "description": "The city and state, e.g. San Francisco, CA",
                          },
                          "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
                        },
                        "required": ["location"],
                      },
                    }
                  }
              ];

              async function main() {
                const stream = await openai.beta.threads.createAndRun({
                  assistant_id: "asst_123",
                  thread: {
                    messages: [
                      { role: "user", content: "What is the weather like in San Francisco?" },
                    ],
                  },
                  tools: tools,
                  stream: true
                });

                for await (const event of stream) {
                  console.log(event);
                }
              }

              main();
          response: |
            event: thread.created
            data: {"id":"thread_123","object":"thread","created_at":1710351818,"metadata":{}}

            event: thread.run.created
            data: {"id":"run_123","object":"thread.run","created_at":1710351818,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":null,"expires_at":1710352418,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[{"type":"function","function":{"name":"get_current_weather","description":"Get the current weather in a given location","parameters":{"type":"object","properties":{"location":{"type":"string","description":"The city and state, e.g. San Francisco, CA"},"unit":{"type":"string","enum":["celsius","fahrenheit"]}},"required":["location"]}}}],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: thread.run.queued
            data: {"id":"run_123","object":"thread.run","created_at":1710351818,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":null,"expires_at":1710352418,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[{"type":"function","function":{"name":"get_current_weather","description":"Get the current weather in a given location","parameters":{"type":"object","properties":{"location":{"type":"string","description":"The city and state, e.g. San Francisco, CA"},"unit":{"type":"string","enum":["celsius","fahrenheit"]}},"required":["location"]}}}],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: thread.run.in_progress
            data: {"id":"run_123","object":"thread.run","created_at":1710351818,"assistant_id":"asst_123","thread_id":"thread_123","status":"in_progress","started_at":1710351818,"expires_at":1710352418,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[{"type":"function","function":{"name":"get_current_weather","description":"Get the current weather in a given location","parameters":{"type":"object","properties":{"location":{"type":"string","description":"The city and state, e.g. San Francisco, CA"},"unit":{"type":"string","enum":["celsius","fahrenheit"]}},"required":["location"]}}}],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: thread.run.step.created
            data: {"id":"step_001","object":"thread.run.step","created_at":1710351819,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"tool_calls","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710352418,"failed_at":null,"last_error":null,"step_details":{"type":"tool_calls","tool_calls":[]},"usage":null}

            event: thread.run.step.in_progress
            data: {"id":"step_001","object":"thread.run.step","created_at":1710351819,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"tool_calls","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710352418,"failed_at":null,"last_error":null,"step_details":{"type":"tool_calls","tool_calls":[]},"usage":null}

            event: thread.run.step.delta
            data: {"id":"step_001","object":"thread.run.step.delta","delta":{"step_details":{"type":"tool_calls","tool_calls":[{"index":0,"id":"call_XXNp8YGaFrjrSjgqxtC8JJ1B","type":"function","function":{"name":"get_current_weather","arguments":"","output":null}}]}}}

            event: thread.run.step.delta
            data: {"id":"step_001","object":"thread.run.step.delta","delta":{"step_details":{"type":"tool_calls","tool_calls":[{"index":0,"type":"function","function":{"arguments":"{\""}}]}}}

            event: thread.run.step.delta
            data: {"id":"step_001","object":"thread.run.step.delta","delta":{"step_details":{"type":"tool_calls","tool_calls":[{"index":0,"type":"function","function":{"arguments":"location"}}]}}}

            ...

            event: thread.run.step.delta
            data: {"id":"step_001","object":"thread.run.step.delta","delta":{"step_details":{"type":"tool_calls","tool_calls":[{"index":0,"type":"function","function":{"arguments":"ahrenheit"}}]}}}

            event: thread.run.step.delta
            data: {"id":"step_001","object":"thread.run.step.delta","delta":{"step_details":{"type":"tool_calls","tool_calls":[{"index":0,"type":"function","function":{"arguments":"\"}"}}]}}}

            event: thread.run.requires_action
            data: {"id":"run_123","object":"thread.run","created_at":1710351818,"assistant_id":"asst_123","thread_id":"thread_123","status":"requires_action","started_at":1710351818,"expires_at":1710352418,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":{"type":"submit_tool_outputs","submit_tool_outputs":{"tool_calls":[{"id":"call_XXNp8YGaFrjrSjgqxtC8JJ1B","type":"function","function":{"name":"get_current_weather","arguments":"{\"location\":\"San Francisco, CA\",\"unit\":\"fahrenheit\"}"}}]}},"last_error":null,"model":"gpt-4o","instructions":null,"tools":[{"type":"function","function":{"name":"get_current_weather","description":"Get the current weather in a given location","parameters":{"type":"object","properties":{"location":{"type":"string","description":"The city and state, e.g. San Francisco, CA"},"unit":{"type":"string","enum":["celsius","fahrenheit"]}},"required":["location"]}}}],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":{"prompt_tokens":345,"completion_tokens":11,"total_tokens":356},"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: done
            data: [DONE]
  /threads/{threadId}:
    get:
      tags:
      - Assistants
      summary: Retrieves a thread.
      operationId: getThread
      parameters:
      - name: threadId
        in: path
        description: The ID of the thread to retrieve
        required: true
        style: simple
        explode: false
        schema:
          type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ThreadObject'
      x-oaiMeta:
        name: Retrieve thread
        group: threads
        beta: true
        returns: "The [thread](/docs/api-reference/threads/object) object matching\
          \ the specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123 \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              my_thread = client.beta.threads.retrieve("thread_abc123")
              print(my_thread)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const myThread = await openai.beta.threads.retrieve(
                  "thread_abc123"
                );

                console.log(myThread);
              }

              main();
          response: |
            {
              "id": "thread_abc123",
              "object": "thread",
              "created_at": 1699014083,
              "metadata": {},
              "tool_resources": {
                "code_interpreter": {
                  "file_ids": []
                }
              }
            }
    post:
      tags:
      - Assistants
      summary: Modifies a thread.
      operationId: modifyThread
      parameters:
      - name: threadId
        in: path
        description: The ID of the thread to modify. Only the `metadata` can be modified
        required: true
        style: simple
        explode: false
        schema:
          type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ModifyThreadRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ThreadObject'
      x-oaiMeta:
        name: Modify thread
        group: threads
        beta: true
        returns: "The modified [thread](/docs/api-reference/threads/object) object\
          \ matching the specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123 \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                    "metadata": {
                      "modified": "true",
                      "user": "abc123"
                    }
                  }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              my_updated_thread = client.beta.threads.update(
                "thread_abc123",
                metadata={
                  "modified": "true",
                  "user": "abc123"
                }
              )
              print(my_updated_thread)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const updatedThread = await openai.beta.threads.update(
                  "thread_abc123",
                  {
                    metadata: { modified: "true", user: "abc123" },
                  }
                );

                console.log(updatedThread);
              }

              main();
          response: |
            {
              "id": "thread_abc123",
              "object": "thread",
              "created_at": 1699014083,
              "metadata": {
                "modified": "true",
                "user": "abc123"
              },
              "tool_resources": {}
            }
    delete:
      tags:
      - Assistants
      summary: Delete a thread.
      operationId: deleteThread
      parameters:
      - name: threadId
        in: path
        description: The ID of the thread to delete
        required: true
        style: simple
        explode: false
        schema:
          type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DeleteThreadResponse'
      x-oaiMeta:
        name: Delete thread
        group: threads
        beta: true
        returns: Deletion status
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123 \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2" \
                -X DELETE
            python: |
              from openai import OpenAI
              client = OpenAI()

              response = client.beta.threads.delete("thread_abc123")
              print(response)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const response = await openai.beta.threads.del("thread_abc123");

                console.log(response);
              }
              main();
          response: |
            {
              "id": "thread_abc123",
              "object": "thread.deleted",
              "deleted": true
            }
  /threads/{threadId}/messages:
    get:
      tags:
      - Assistants
      summary: Returns a list of messages for a given thread.
      operationId: listMessages
      parameters:
      - name: threadId
        in: path
        description: "The ID of the [thread](/docs/api-reference/threads) the messages\
          \ belong to"
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: limit
        in: query
        description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20
        required: false
        style: form
        explode: true
        schema:
          type: integer
          default: 20
      - name: order
        in: query
        description: |
          Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order
        required: false
        style: form
        explode: true
        schema:
          type: string
          default: desc
          enum:
          - asc
          - desc
      - name: after
        in: query
        description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list
        required: false
        style: form
        explode: true
        schema:
          type: string
      - name: before
        in: query
        description: |
          A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list
        required: false
        style: form
        explode: true
        schema:
          type: string
      - name: run_id
        in: query
        description: |
          Filter messages by the run ID that generated them
        required: false
        style: form
        explode: true
        schema:
          type: string
        x-ballerina-name: runId
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListMessagesResponse'
      x-oaiMeta:
        name: List messages
        group: threads
        beta: true
        returns: "A list of [message](/docs/api-reference/messages) objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/messages \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              thread_messages = client.beta.threads.messages.list("thread_abc123")
              print(thread_messages.data)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const threadMessages = await openai.beta.threads.messages.list(
                  "thread_abc123"
                );

                console.log(threadMessages.data);
              }

              main();
          response: |
            {
              "object": "list",
              "data": [
                {
                  "id": "msg_abc123",
                  "object": "thread.message",
                  "created_at": 1699016383,
                  "assistant_id": null,
                  "thread_id": "thread_abc123",
                  "run_id": null,
                  "role": "user",
                  "content": [
                    {
                      "type": "text",
                      "text": {
                        "value": "How does AI work? Explain it in simple terms.",
                        "annotations": []
                      }
                    }
                  ],
                  "attachments": [],
                  "metadata": {}
                },
                {
                  "id": "msg_abc456",
                  "object": "thread.message",
                  "created_at": 1699016383,
                  "assistant_id": null,
                  "thread_id": "thread_abc123",
                  "run_id": null,
                  "role": "user",
                  "content": [
                    {
                      "type": "text",
                      "text": {
                        "value": "Hello, what is AI?",
                        "annotations": []
                      }
                    }
                  ],
                  "attachments": [],
                  "metadata": {}
                }
              ],
              "first_id": "msg_abc123",
              "last_id": "msg_abc456",
              "has_more": false
            }
    post:
      tags:
      - Assistants
      summary: Create a message.
      operationId: createMessage
      parameters:
      - name: threadId
        in: path
        description: "The ID of the [thread](/docs/api-reference/threads) to create\
          \ a message for"
        required: true
        style: simple
        explode: false
        schema:
          type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateMessageRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/MessageObject'
      x-oaiMeta:
        name: Create message
        group: threads
        beta: true
        returns: "A [message](/docs/api-reference/messages/object) object."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/messages \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                    "role": "user",
                    "content": "How does AI work? Explain it in simple terms."
                  }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              thread_message = client.beta.threads.messages.create(
                "thread_abc123",
                role="user",
                content="How does AI work? Explain it in simple terms.",
              )
              print(thread_message)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const threadMessages = await openai.beta.threads.messages.create(
                  "thread_abc123",
                  { role: "user", content: "How does AI work? Explain it in simple terms." }
                );

                console.log(threadMessages);
              }

              main();
          response: |
            {
              "id": "msg_abc123",
              "object": "thread.message",
              "created_at": 1713226573,
              "assistant_id": null,
              "thread_id": "thread_abc123",
              "run_id": null,
              "role": "user",
              "content": [
                {
                  "type": "text",
                  "text": {
                    "value": "How does AI work? Explain it in simple terms.",
                    "annotations": []
                  }
                }
              ],
              "attachments": [],
              "metadata": {}
            }
  /threads/{threadId}/messages/{messageId}:
    get:
      tags:
      - Assistants
      summary: Retrieve a message.
      operationId: getMessage
      parameters:
      - name: threadId
        in: path
        description: "The ID of the [thread](/docs/api-reference/threads) to which\
          \ this message belongs"
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: messageId
        in: path
        description: The ID of the message to retrieve
        required: true
        style: simple
        explode: false
        schema:
          type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/MessageObject'
      x-oaiMeta:
        name: Retrieve message
        group: threads
        beta: true
        returns: "The [message](/docs/api-reference/messages/object) object matching\
          \ the specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              message = client.beta.threads.messages.retrieve(
                message_id="msg_abc123",
                thread_id="thread_abc123",
              )
              print(message)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const message = await openai.beta.threads.messages.retrieve(
                  "thread_abc123",
                  "msg_abc123"
                );

                console.log(message);
              }

              main();
          response: |
            {
              "id": "msg_abc123",
              "object": "thread.message",
              "created_at": 1699017614,
              "assistant_id": null,
              "thread_id": "thread_abc123",
              "run_id": null,
              "role": "user",
              "content": [
                {
                  "type": "text",
                  "text": {
                    "value": "How does AI work? Explain it in simple terms.",
                    "annotations": []
                  }
                }
              ],
              "attachments": [],
              "metadata": {}
            }
    post:
      tags:
      - Assistants
      summary: Modifies a message.
      operationId: modifyMessage
      parameters:
      - name: threadId
        in: path
        description: The ID of the thread to which this message belongs
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: messageId
        in: path
        description: The ID of the message to modify
        required: true
        style: simple
        explode: false
        schema:
          type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ModifyMessageRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/MessageObject'
      x-oaiMeta:
        name: Modify message
        group: threads
        beta: true
        returns: "The modified [message](/docs/api-reference/messages/object) object."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                    "metadata": {
                      "modified": "true",
                      "user": "abc123"
                    }
                  }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              message = client.beta.threads.messages.update(
                message_id="msg_abc12",
                thread_id="thread_abc123",
                metadata={
                  "modified": "true",
                  "user": "abc123",
                },
              )
              print(message)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const message = await openai.beta.threads.messages.update(
                  "thread_abc123",
                  "msg_abc123",
                  {
                    metadata: {
                      modified: "true",
                      user: "abc123",
                    },
                  }
                }'
          response: |
            {
              "id": "msg_abc123",
              "object": "thread.message",
              "created_at": 1699017614,
              "assistant_id": null,
              "thread_id": "thread_abc123",
              "run_id": null,
              "role": "user",
              "content": [
                {
                  "type": "text",
                  "text": {
                    "value": "How does AI work? Explain it in simple terms.",
                    "annotations": []
                  }
                }
              ],
              "file_ids": [],
              "metadata": {
                "modified": "true",
                "user": "abc123"
              }
            }
    delete:
      tags:
      - Assistants
      summary: Deletes a message.
      operationId: deleteMessage
      parameters:
      - name: threadId
        in: path
        description: The ID of the thread to which this message belongs
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: messageId
        in: path
        description: The ID of the message to delete
        required: true
        style: simple
        explode: false
        schema:
          type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DeleteMessageResponse'
      x-oaiMeta:
        name: Delete message
        group: threads
        beta: true
        returns: Deletion status
        examples:
          request:
            curl: |
              curl -X DELETE https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              deleted_message = client.beta.threads.messages.delete(
                message_id="msg_abc12",
                thread_id="thread_abc123",
              )
              print(deleted_message)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const deletedMessage = await openai.beta.threads.messages.del(
                  "thread_abc123",
                  "msg_abc123"
                );

                console.log(deletedMessage);
              }
          response: |
            {
              "id": "msg_abc123",
              "object": "thread.message.deleted",
              "deleted": true
            }
  /threads/{threadId}/runs:
    get:
      tags:
      - Assistants
      summary: Returns a list of runs belonging to a thread.
      operationId: listRuns
      parameters:
      - name: threadId
        in: path
        description: The ID of the thread the run belongs to
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: limit
        in: query
        description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20
        required: false
        style: form
        explode: true
        schema:
          type: integer
          default: 20
      - name: order
        in: query
        description: |
          Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order
        required: false
        style: form
        explode: true
        schema:
          type: string
          default: desc
          enum:
          - asc
          - desc
      - name: after
        in: query
        description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list
        required: false
        style: form
        explode: true
        schema:
          type: string
      - name: before
        in: query
        description: |
          A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list
        required: false
        style: form
        explode: true
        schema:
          type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListRunsResponse'
      x-oaiMeta:
        name: List runs
        group: threads
        beta: true
        returns: "A list of [run](/docs/api-reference/runs/object) objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/runs \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              runs = client.beta.threads.runs.list(
                "thread_abc123"
              )

              print(runs)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const runs = await openai.beta.threads.runs.list(
                  "thread_abc123"
                );

                console.log(runs);
              }

              main();
          response: |
            {
              "object": "list",
              "data": [
                {
                  "id": "run_abc123",
                  "object": "thread.run",
                  "created_at": 1699075072,
                  "assistant_id": "asst_abc123",
                  "thread_id": "thread_abc123",
                  "status": "completed",
                  "started_at": 1699075072,
                  "expires_at": null,
                  "cancelled_at": null,
                  "failed_at": null,
                  "completed_at": 1699075073,
                  "last_error": null,
                  "model": "gpt-4o",
                  "instructions": null,
                  "incomplete_details": null,
                  "tools": [
                    {
                      "type": "code_interpreter"
                    }
                  ],
                  "tool_resources": {
                    "code_interpreter": {
                      "file_ids": [
                        "file-abc123",
                        "file-abc456"
                      ]
                    }
                  },
                  "metadata": {},
                  "usage": {
                    "prompt_tokens": 123,
                    "completion_tokens": 456,
                    "total_tokens": 579
                  },
                  "temperature": 1.0,
                  "top_p": 1.0,
                  "max_prompt_tokens": 1000,
                  "max_completion_tokens": 1000,
                  "truncation_strategy": {
                    "type": "auto",
                    "last_messages": null
                  },
                  "response_format": "auto",
                  "tool_choice": "auto",
                  "parallel_tool_calls": true
                },
                {
                  "id": "run_abc456",
                  "object": "thread.run",
                  "created_at": 1699063290,
                  "assistant_id": "asst_abc123",
                  "thread_id": "thread_abc123",
                  "status": "completed",
                  "started_at": 1699063290,
                  "expires_at": null,
                  "cancelled_at": null,
                  "failed_at": null,
                  "completed_at": 1699063291,
                  "last_error": null,
                  "model": "gpt-4o",
                  "instructions": null,
                  "incomplete_details": null,
                  "tools": [
                    {
                      "type": "code_interpreter"
                    }
                  ],
                  "tool_resources": {
                    "code_interpreter": {
                      "file_ids": [
                        "file-abc123",
                        "file-abc456"
                      ]
                    }
                  },
                  "metadata": {},
                  "usage": {
                    "prompt_tokens": 123,
                    "completion_tokens": 456,
                    "total_tokens": 579
                  },
                  "temperature": 1.0,
                  "top_p": 1.0,
                  "max_prompt_tokens": 1000,
                  "max_completion_tokens": 1000,
                  "truncation_strategy": {
                    "type": "auto",
                    "last_messages": null
                  },
                  "response_format": "auto",
                  "tool_choice": "auto",
                  "parallel_tool_calls": true
                }
              ],
              "first_id": "run_abc123",
              "last_id": "run_abc456",
              "has_more": false
            }
    post:
      tags:
      - Assistants
      summary: Create a run.
      operationId: createRun
      parameters:
      - name: threadId
        in: path
        description: The ID of the thread to run
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: "include[]"
        in: query
        description: |
          A list of additional fields to include in the response. Currently the only supported value is `step_details.tool_calls[*].file_search.results[*].content` to fetch the file search result content.

          See the [file search tool documentation](/docs/assistants/tools/file-search#customizing-file-search-settings) for more information
        required: false
        style: form
        explode: true
        schema:
          type: array
          items:
            type: string
            enum:
            - "step_details.tool_calls[*].file_search.results[*].content"
        x-ballerina-name: include
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateRunRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RunObject'
      x-oaiMeta:
        name: Create run
        group: threads
        beta: true
        returns: "A [run](/docs/api-reference/runs/object) object."
        examples:
        - title: Default
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/runs \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                  "assistant_id": "asst_abc123"
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              run = client.beta.threads.runs.create(
                thread_id="thread_abc123",
                assistant_id="asst_abc123"
              )

              print(run)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const run = await openai.beta.threads.runs.create(
                  "thread_abc123",
                  { assistant_id: "asst_abc123" }
                );

                console.log(run);
              }

              main();
          response: |
            {
              "id": "run_abc123",
              "object": "thread.run",
              "created_at": 1699063290,
              "assistant_id": "asst_abc123",
              "thread_id": "thread_abc123",
              "status": "queued",
              "started_at": 1699063290,
              "expires_at": null,
              "cancelled_at": null,
              "failed_at": null,
              "completed_at": 1699063291,
              "last_error": null,
              "model": "gpt-4o",
              "instructions": null,
              "incomplete_details": null,
              "tools": [
                {
                  "type": "code_interpreter"
                }
              ],
              "metadata": {},
              "usage": null,
              "temperature": 1.0,
              "top_p": 1.0,
              "max_prompt_tokens": 1000,
              "max_completion_tokens": 1000,
              "truncation_strategy": {
                "type": "auto",
                "last_messages": null
              },
              "response_format": "auto",
              "tool_choice": "auto",
              "parallel_tool_calls": true
            }
        - title: Streaming
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_123/runs \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                  "assistant_id": "asst_123",
                  "stream": true
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              stream = client.beta.threads.runs.create(
                thread_id="thread_123",
                assistant_id="asst_123",
                stream=True
              )

              for event in stream:
                print(event)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const stream = await openai.beta.threads.runs.create(
                  "thread_123",
                  { assistant_id: "asst_123", stream: true }
                );

                for await (const event of stream) {
                  console.log(event);
                }
              }

              main();
          response: |
            event: thread.run.created
            data: {"id":"run_123","object":"thread.run","created_at":1710330640,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":null,"expires_at":1710331240,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: thread.run.queued
            data: {"id":"run_123","object":"thread.run","created_at":1710330640,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":null,"expires_at":1710331240,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: thread.run.in_progress
            data: {"id":"run_123","object":"thread.run","created_at":1710330640,"assistant_id":"asst_123","thread_id":"thread_123","status":"in_progress","started_at":1710330641,"expires_at":1710331240,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: thread.run.step.created
            data: {"id":"step_001","object":"thread.run.step","created_at":1710330641,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710331240,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":null}

            event: thread.run.step.in_progress
            data: {"id":"step_001","object":"thread.run.step","created_at":1710330641,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710331240,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":null}

            event: thread.message.created
            data: {"id":"msg_001","object":"thread.message","created_at":1710330641,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"in_progress","incomplete_details":null,"incomplete_at":null,"completed_at":null,"role":"assistant","content":[],"metadata":{}}

            event: thread.message.in_progress
            data: {"id":"msg_001","object":"thread.message","created_at":1710330641,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"in_progress","incomplete_details":null,"incomplete_at":null,"completed_at":null,"role":"assistant","content":[],"metadata":{}}

            event: thread.message.delta
            data: {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"Hello","annotations":[]}}]}}

            ...

            event: thread.message.delta
            data: {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":" today"}}]}}

            event: thread.message.delta
            data: {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"?"}}]}}

            event: thread.message.completed
            data: {"id":"msg_001","object":"thread.message","created_at":1710330641,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"completed","incomplete_details":null,"incomplete_at":null,"completed_at":1710330642,"role":"assistant","content":[{"type":"text","text":{"value":"Hello! How can I assist you today?","annotations":[]}}],"metadata":{}}

            event: thread.run.step.completed
            data: {"id":"step_001","object":"thread.run.step","created_at":1710330641,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"completed","cancelled_at":null,"completed_at":1710330642,"expires_at":1710331240,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":{"prompt_tokens":20,"completion_tokens":11,"total_tokens":31}}

            event: thread.run.completed
            data: {"id":"run_123","object":"thread.run","created_at":1710330640,"assistant_id":"asst_123","thread_id":"thread_123","status":"completed","started_at":1710330641,"expires_at":null,"cancelled_at":null,"failed_at":null,"completed_at":1710330642,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":{"prompt_tokens":20,"completion_tokens":11,"total_tokens":31},"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: done
            data: [DONE]
        - title: Streaming with Functions
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/runs \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                  "assistant_id": "asst_abc123",
                  "tools": [
                    {
                      "type": "function",
                      "function": {
                        "name": "get_current_weather",
                        "description": "Get the current weather in a given location",
                        "parameters": {
                          "type": "object",
                          "properties": {
                            "location": {
                              "type": "string",
                              "description": "The city and state, e.g. San Francisco, CA"
                            },
                            "unit": {
                              "type": "string",
                              "enum": ["celsius", "fahrenheit"]
                            }
                          },
                          "required": ["location"]
                        }
                      }
                    }
                  ],
                  "stream": true
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              tools = [
                {
                  "type": "function",
                  "function": {
                    "name": "get_current_weather",
                    "description": "Get the current weather in a given location",
                    "parameters": {
                      "type": "object",
                      "properties": {
                        "location": {
                          "type": "string",
                          "description": "The city and state, e.g. San Francisco, CA",
                        },
                        "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
                      },
                      "required": ["location"],
                    },
                  }
                }
              ]

              stream = client.beta.threads.runs.create(
                thread_id="thread_abc123",
                assistant_id="asst_abc123",
                tools=tools,
                stream=True
              )

              for event in stream:
                print(event)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              const tools = [
                  {
                    "type": "function",
                    "function": {
                      "name": "get_current_weather",
                      "description": "Get the current weather in a given location",
                      "parameters": {
                        "type": "object",
                        "properties": {
                          "location": {
                            "type": "string",
                            "description": "The city and state, e.g. San Francisco, CA",
                          },
                          "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
                        },
                        "required": ["location"],
                      },
                    }
                  }
              ];

              async function main() {
                const stream = await openai.beta.threads.runs.create(
                  "thread_abc123",
                  {
                    assistant_id: "asst_abc123",
                    tools: tools,
                    stream: true
                  }
                );

                for await (const event of stream) {
                  console.log(event);
                }
              }

              main();
          response: |
            event: thread.run.created
            data: {"id":"run_123","object":"thread.run","created_at":1710348075,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":null,"expires_at":1710348675,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: thread.run.queued
            data: {"id":"run_123","object":"thread.run","created_at":1710348075,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":null,"expires_at":1710348675,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: thread.run.in_progress
            data: {"id":"run_123","object":"thread.run","created_at":1710348075,"assistant_id":"asst_123","thread_id":"thread_123","status":"in_progress","started_at":1710348075,"expires_at":1710348675,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: thread.run.step.created
            data: {"id":"step_001","object":"thread.run.step","created_at":1710348076,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710348675,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":null}

            event: thread.run.step.in_progress
            data: {"id":"step_001","object":"thread.run.step","created_at":1710348076,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710348675,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":null}

            event: thread.message.created
            data: {"id":"msg_001","object":"thread.message","created_at":1710348076,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"in_progress","incomplete_details":null,"incomplete_at":null,"completed_at":null,"role":"assistant","content":[],"metadata":{}}

            event: thread.message.in_progress
            data: {"id":"msg_001","object":"thread.message","created_at":1710348076,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"in_progress","incomplete_details":null,"incomplete_at":null,"completed_at":null,"role":"assistant","content":[],"metadata":{}}

            event: thread.message.delta
            data: {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"Hello","annotations":[]}}]}}

            ...

            event: thread.message.delta
            data: {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":" today"}}]}}

            event: thread.message.delta
            data: {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"?"}}]}}

            event: thread.message.completed
            data: {"id":"msg_001","object":"thread.message","created_at":1710348076,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"completed","incomplete_details":null,"incomplete_at":null,"completed_at":1710348077,"role":"assistant","content":[{"type":"text","text":{"value":"Hello! How can I assist you today?","annotations":[]}}],"metadata":{}}

            event: thread.run.step.completed
            data: {"id":"step_001","object":"thread.run.step","created_at":1710348076,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"completed","cancelled_at":null,"completed_at":1710348077,"expires_at":1710348675,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":{"prompt_tokens":20,"completion_tokens":11,"total_tokens":31}}

            event: thread.run.completed
            data: {"id":"run_123","object":"thread.run","created_at":1710348075,"assistant_id":"asst_123","thread_id":"thread_123","status":"completed","started_at":1710348075,"expires_at":null,"cancelled_at":null,"failed_at":null,"completed_at":1710348077,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":{"prompt_tokens":20,"completion_tokens":11,"total_tokens":31},"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: done
            data: [DONE]
  /threads/{threadId}/runs/{runId}:
    get:
      tags:
      - Assistants
      summary: Retrieves a run.
      operationId: getRun
      parameters:
      - name: threadId
        in: path
        description: "The ID of the [thread](/docs/api-reference/threads) that was\
          \ run"
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: runId
        in: path
        description: The ID of the run to retrieve
        required: true
        style: simple
        explode: false
        schema:
          type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RunObject'
      x-oaiMeta:
        name: Retrieve run
        group: threads
        beta: true
        returns: "The [run](/docs/api-reference/runs/object) object matching the specified\
          \ ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              run = client.beta.threads.runs.retrieve(
                thread_id="thread_abc123",
                run_id="run_abc123"
              )

              print(run)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const run = await openai.beta.threads.runs.retrieve(
                  "thread_abc123",
                  "run_abc123"
                );

                console.log(run);
              }

              main();
          response: |
            {
              "id": "run_abc123",
              "object": "thread.run",
              "created_at": 1699075072,
              "assistant_id": "asst_abc123",
              "thread_id": "thread_abc123",
              "status": "completed",
              "started_at": 1699075072,
              "expires_at": null,
              "cancelled_at": null,
              "failed_at": null,
              "completed_at": 1699075073,
              "last_error": null,
              "model": "gpt-4o",
              "instructions": null,
              "incomplete_details": null,
              "tools": [
                {
                  "type": "code_interpreter"
                }
              ],
              "metadata": {},
              "usage": {
                "prompt_tokens": 123,
                "completion_tokens": 456,
                "total_tokens": 579
              },
              "temperature": 1.0,
              "top_p": 1.0,
              "max_prompt_tokens": 1000,
              "max_completion_tokens": 1000,
              "truncation_strategy": {
                "type": "auto",
                "last_messages": null
              },
              "response_format": "auto",
              "tool_choice": "auto",
              "parallel_tool_calls": true
            }
    post:
      tags:
      - Assistants
      summary: Modifies a run.
      operationId: modifyRun
      parameters:
      - name: threadId
        in: path
        description: "The ID of the [thread](/docs/api-reference/threads) that was\
          \ run"
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: runId
        in: path
        description: The ID of the run to modify
        required: true
        style: simple
        explode: false
        schema:
          type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ModifyRunRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RunObject'
      x-oaiMeta:
        name: Modify run
        group: threads
        beta: true
        returns: "The modified [run](/docs/api-reference/runs/object) object matching\
          \ the specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                  "metadata": {
                    "user_id": "user_abc123"
                  }
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              run = client.beta.threads.runs.update(
                thread_id="thread_abc123",
                run_id="run_abc123",
                metadata={"user_id": "user_abc123"},
              )

              print(run)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const run = await openai.beta.threads.runs.update(
                  "thread_abc123",
                  "run_abc123",
                  {
                    metadata: {
                      user_id: "user_abc123",
                    },
                  }
                );

                console.log(run);
              }

              main();
          response: |
            {
              "id": "run_abc123",
              "object": "thread.run",
              "created_at": 1699075072,
              "assistant_id": "asst_abc123",
              "thread_id": "thread_abc123",
              "status": "completed",
              "started_at": 1699075072,
              "expires_at": null,
              "cancelled_at": null,
              "failed_at": null,
              "completed_at": 1699075073,
              "last_error": null,
              "model": "gpt-4o",
              "instructions": null,
              "incomplete_details": null,
              "tools": [
                {
                  "type": "code_interpreter"
                }
              ],
              "tool_resources": {
                "code_interpreter": {
                  "file_ids": [
                    "file-abc123",
                    "file-abc456"
                  ]
                }
              },
              "metadata": {
                "user_id": "user_abc123"
              },
              "usage": {
                "prompt_tokens": 123,
                "completion_tokens": 456,
                "total_tokens": 579
              },
              "temperature": 1.0,
              "top_p": 1.0,
              "max_prompt_tokens": 1000,
              "max_completion_tokens": 1000,
              "truncation_strategy": {
                "type": "auto",
                "last_messages": null
              },
              "response_format": "auto",
              "tool_choice": "auto",
              "parallel_tool_calls": true
            }
  /threads/{threadId}/runs/{runId}/cancel:
    post:
      tags:
      - Assistants
      summary: Cancels a run that is `in_progress`.
      operationId: cancelRun
      parameters:
      - name: threadId
        in: path
        description: The ID of the thread to which this run belongs
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: runId
        in: path
        description: The ID of the run to cancel
        required: true
        style: simple
        explode: false
        schema:
          type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RunObject'
      x-oaiMeta:
        name: Cancel a run
        group: threads
        beta: true
        returns: "The modified [run](/docs/api-reference/runs/object) object matching\
          \ the specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/cancel \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2" \
                -X POST
            python: |
              from openai import OpenAI
              client = OpenAI()

              run = client.beta.threads.runs.cancel(
                thread_id="thread_abc123",
                run_id="run_abc123"
              )

              print(run)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const run = await openai.beta.threads.runs.cancel(
                  "thread_abc123",
                  "run_abc123"
                );

                console.log(run);
              }

              main();
          response: |
            {
              "id": "run_abc123",
              "object": "thread.run",
              "created_at": 1699076126,
              "assistant_id": "asst_abc123",
              "thread_id": "thread_abc123",
              "status": "cancelling",
              "started_at": 1699076126,
              "expires_at": 1699076726,
              "cancelled_at": null,
              "failed_at": null,
              "completed_at": null,
              "last_error": null,
              "model": "gpt-4o",
              "instructions": "You summarize books.",
              "tools": [
                {
                  "type": "file_search"
                }
              ],
              "tool_resources": {
                "file_search": {
                  "vector_store_ids": ["vs_123"]
                }
              },
              "metadata": {},
              "usage": null,
              "temperature": 1.0,
              "top_p": 1.0,
              "response_format": "auto",
              "tool_choice": "auto",
              "parallel_tool_calls": true
            }
  /threads/{threadId}/runs/{runId}/steps:
    get:
      tags:
      - Assistants
      summary: Returns a list of run steps belonging to a run.
      operationId: listRunSteps
      parameters:
      - name: threadId
        in: path
        description: The ID of the thread the run and run steps belong to
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: runId
        in: path
        description: The ID of the run the run steps belong to
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: limit
        in: query
        description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20
        required: false
        style: form
        explode: true
        schema:
          type: integer
          default: 20
      - name: order
        in: query
        description: |
          Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order
        required: false
        style: form
        explode: true
        schema:
          type: string
          default: desc
          enum:
          - asc
          - desc
      - name: after
        in: query
        description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list
        required: false
        style: form
        explode: true
        schema:
          type: string
      - name: before
        in: query
        description: |
          A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list
        required: false
        style: form
        explode: true
        schema:
          type: string
      - name: "include[]"
        in: query
        description: |
          A list of additional fields to include in the response. Currently the only supported value is `step_details.tool_calls[*].file_search.results[*].content` to fetch the file search result content.

          See the [file search tool documentation](/docs/assistants/tools/file-search#customizing-file-search-settings) for more information
        required: false
        style: form
        explode: true
        schema:
          type: array
          items:
            type: string
            enum:
            - "step_details.tool_calls[*].file_search.results[*].content"
        x-ballerina-name: include
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListRunStepsResponse'
      x-oaiMeta:
        name: List run steps
        group: threads
        beta: true
        returns: "A list of [run step](/docs/api-reference/run-steps/step-object)\
          \ objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/steps \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              run_steps = client.beta.threads.runs.steps.list(
                  thread_id="thread_abc123",
                  run_id="run_abc123"
              )

              print(run_steps)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const runStep = await openai.beta.threads.runs.steps.list(
                  "thread_abc123",
                  "run_abc123"
                );
                console.log(runStep);
              }

              main();
          response: |
            {
              "object": "list",
              "data": [
                {
                  "id": "step_abc123",
                  "object": "thread.run.step",
                  "created_at": 1699063291,
                  "run_id": "run_abc123",
                  "assistant_id": "asst_abc123",
                  "thread_id": "thread_abc123",
                  "type": "message_creation",
                  "status": "completed",
                  "cancelled_at": null,
                  "completed_at": 1699063291,
                  "expired_at": null,
                  "failed_at": null,
                  "last_error": null,
                  "step_details": {
                    "type": "message_creation",
                    "message_creation": {
                      "message_id": "msg_abc123"
                    }
                  },
                  "usage": {
                    "prompt_tokens": 123,
                    "completion_tokens": 456,
                    "total_tokens": 579
                  }
                }
              ],
              "first_id": "step_abc123",
              "last_id": "step_abc456",
              "has_more": false
            }
  /threads/{threadId}/runs/{runId}/steps/{stepId}:
    get:
      tags:
      - Assistants
      summary: Retrieves a run step.
      operationId: getRunStep
      parameters:
      - name: threadId
        in: path
        description: The ID of the thread to which the run and run step belongs
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: runId
        in: path
        description: The ID of the run to which the run step belongs
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: stepId
        in: path
        description: The ID of the run step to retrieve
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: "include[]"
        in: query
        description: |
          A list of additional fields to include in the response. Currently the only supported value is `step_details.tool_calls[*].file_search.results[*].content` to fetch the file search result content.

          See the [file search tool documentation](/docs/assistants/tools/file-search#customizing-file-search-settings) for more information
        required: false
        style: form
        explode: true
        schema:
          type: array
          items:
            type: string
            enum:
            - "step_details.tool_calls[*].file_search.results[*].content"
        x-ballerina-name: include
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RunStepObject'
      x-oaiMeta:
        name: Retrieve run step
        group: threads
        beta: true
        returns: "The [run step](/docs/api-reference/run-steps/step-object) object\
          \ matching the specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/steps/step_abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              run_step = client.beta.threads.runs.steps.retrieve(
                  thread_id="thread_abc123",
                  run_id="run_abc123",
                  step_id="step_abc123"
              )

              print(run_step)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const runStep = await openai.beta.threads.runs.steps.retrieve(
                  "thread_abc123",
                  "run_abc123",
                  "step_abc123"
                );
                console.log(runStep);
              }

              main();
          response: |
            {
              "id": "step_abc123",
              "object": "thread.run.step",
              "created_at": 1699063291,
              "run_id": "run_abc123",
              "assistant_id": "asst_abc123",
              "thread_id": "thread_abc123",
              "type": "message_creation",
              "status": "completed",
              "cancelled_at": null,
              "completed_at": 1699063291,
              "expired_at": null,
              "failed_at": null,
              "last_error": null,
              "step_details": {
                "type": "message_creation",
                "message_creation": {
                  "message_id": "msg_abc123"
                }
              },
              "usage": {
                "prompt_tokens": 123,
                "completion_tokens": 456,
                "total_tokens": 579
              }
            }
  /threads/{threadId}/runs/{runId}/submit_tool_outputs:
    post:
      tags:
      - Assistants
      summary: |
        When a run has the `status: "requires_action"` and `required_action.type` is `submit_tool_outputs`, this endpoint can be used to submit the outputs from the tool calls once they're all completed. All outputs must be submitted in a single request.
      operationId: submitToolOuputsToRun
      parameters:
      - name: threadId
        in: path
        description: "The ID of the [thread](/docs/api-reference/threads) to which\
          \ this run belongs"
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: runId
        in: path
        description: The ID of the run that requires the tool output submission
        required: true
        style: simple
        explode: false
        schema:
          type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/SubmitToolOutputsRunRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RunObject'
      x-oaiMeta:
        name: Submit tool outputs to run
        group: threads
        beta: true
        returns: "The modified [run](/docs/api-reference/runs/object) object matching\
          \ the specified ID."
        examples:
        - title: Default
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_123/runs/run_123/submit_tool_outputs \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                  "tool_outputs": [
                    {
                      "tool_call_id": "call_001",
                      "output": "70 degrees and sunny."
                    }
                  ]
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              run = client.beta.threads.runs.submit_tool_outputs(
                thread_id="thread_123",
                run_id="run_123",
                tool_outputs=[
                  {
                    "tool_call_id": "call_001",
                    "output": "70 degrees and sunny."
                  }
                ]
              )

              print(run)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const run = await openai.beta.threads.runs.submitToolOutputs(
                  "thread_123",
                  "run_123",
                  {
                    tool_outputs: [
                      {
                        tool_call_id: "call_001",
                        output: "70 degrees and sunny.",
                      },
                    ],
                  }
                );

                console.log(run);
              }

              main();
          response: |
            {
              "id": "run_123",
              "object": "thread.run",
              "created_at": 1699075592,
              "assistant_id": "asst_123",
              "thread_id": "thread_123",
              "status": "queued",
              "started_at": 1699075592,
              "expires_at": 1699076192,
              "cancelled_at": null,
              "failed_at": null,
              "completed_at": null,
              "last_error": null,
              "model": "gpt-4o",
              "instructions": null,
              "tools": [
                {
                  "type": "function",
                  "function": {
                    "name": "get_current_weather",
                    "description": "Get the current weather in a given location",
                    "parameters": {
                      "type": "object",
                      "properties": {
                        "location": {
                          "type": "string",
                          "description": "The city and state, e.g. San Francisco, CA"
                        },
                        "unit": {
                          "type": "string",
                          "enum": ["celsius", "fahrenheit"]
                        }
                      },
                      "required": ["location"]
                    }
                  }
                }
              ],
              "metadata": {},
              "usage": null,
              "temperature": 1.0,
              "top_p": 1.0,
              "max_prompt_tokens": 1000,
              "max_completion_tokens": 1000,
              "truncation_strategy": {
                "type": "auto",
                "last_messages": null
              },
              "response_format": "auto",
              "tool_choice": "auto",
              "parallel_tool_calls": true
            }
        - title: Streaming
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_123/runs/run_123/submit_tool_outputs \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                  "tool_outputs": [
                    {
                      "tool_call_id": "call_001",
                      "output": "70 degrees and sunny."
                    }
                  ],
                  "stream": true
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              stream = client.beta.threads.runs.submit_tool_outputs(
                thread_id="thread_123",
                run_id="run_123",
                tool_outputs=[
                  {
                    "tool_call_id": "call_001",
                    "output": "70 degrees and sunny."
                  }
                ],
                stream=True
              )

              for event in stream:
                print(event)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const stream = await openai.beta.threads.runs.submitToolOutputs(
                  "thread_123",
                  "run_123",
                  {
                    tool_outputs: [
                      {
                        tool_call_id: "call_001",
                        output: "70 degrees and sunny.",
                      },
                    ],
                  }
                );

                for await (const event of stream) {
                  console.log(event);
                }
              }

              main();
          response: |
            event: thread.run.step.completed
            data: {"id":"step_001","object":"thread.run.step","created_at":1710352449,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"tool_calls","status":"completed","cancelled_at":null,"completed_at":1710352475,"expires_at":1710353047,"failed_at":null,"last_error":null,"step_details":{"type":"tool_calls","tool_calls":[{"id":"call_iWr0kQ2EaYMaxNdl0v3KYkx7","type":"function","function":{"name":"get_current_weather","arguments":"{\"location\":\"San Francisco, CA\",\"unit\":\"fahrenheit\"}","output":"70 degrees and sunny."}}]},"usage":{"prompt_tokens":291,"completion_tokens":24,"total_tokens":315}}

            event: thread.run.queued
            data: {"id":"run_123","object":"thread.run","created_at":1710352447,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":1710352448,"expires_at":1710353047,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[{"type":"function","function":{"name":"get_current_weather","description":"Get the current weather in a given location","parameters":{"type":"object","properties":{"location":{"type":"string","description":"The city and state, e.g. San Francisco, CA"},"unit":{"type":"string","enum":["celsius","fahrenheit"]}},"required":["location"]}}}],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: thread.run.in_progress
            data: {"id":"run_123","object":"thread.run","created_at":1710352447,"assistant_id":"asst_123","thread_id":"thread_123","status":"in_progress","started_at":1710352475,"expires_at":1710353047,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[{"type":"function","function":{"name":"get_current_weather","description":"Get the current weather in a given location","parameters":{"type":"object","properties":{"location":{"type":"string","description":"The city and state, e.g. San Francisco, CA"},"unit":{"type":"string","enum":["celsius","fahrenheit"]}},"required":["location"]}}}],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: thread.run.step.created
            data: {"id":"step_002","object":"thread.run.step","created_at":1710352476,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710353047,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_002"}},"usage":null}

            event: thread.run.step.in_progress
            data: {"id":"step_002","object":"thread.run.step","created_at":1710352476,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710353047,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_002"}},"usage":null}

            event: thread.message.created
            data: {"id":"msg_002","object":"thread.message","created_at":1710352476,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"in_progress","incomplete_details":null,"incomplete_at":null,"completed_at":null,"role":"assistant","content":[],"metadata":{}}

            event: thread.message.in_progress
            data: {"id":"msg_002","object":"thread.message","created_at":1710352476,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"in_progress","incomplete_details":null,"incomplete_at":null,"completed_at":null,"role":"assistant","content":[],"metadata":{}}

            event: thread.message.delta
            data: {"id":"msg_002","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"The","annotations":[]}}]}}

            event: thread.message.delta
            data: {"id":"msg_002","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":" current"}}]}}

            event: thread.message.delta
            data: {"id":"msg_002","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":" weather"}}]}}

            ...

            event: thread.message.delta
            data: {"id":"msg_002","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":" sunny"}}]}}

            event: thread.message.delta
            data: {"id":"msg_002","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"."}}]}}

            event: thread.message.completed
            data: {"id":"msg_002","object":"thread.message","created_at":1710352476,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"completed","incomplete_details":null,"incomplete_at":null,"completed_at":1710352477,"role":"assistant","content":[{"type":"text","text":{"value":"The current weather in San Francisco, CA is 70 degrees Fahrenheit and sunny.","annotations":[]}}],"metadata":{}}

            event: thread.run.step.completed
            data: {"id":"step_002","object":"thread.run.step","created_at":1710352476,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"completed","cancelled_at":null,"completed_at":1710352477,"expires_at":1710353047,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_002"}},"usage":{"prompt_tokens":329,"completion_tokens":18,"total_tokens":347}}

            event: thread.run.completed
            data: {"id":"run_123","object":"thread.run","created_at":1710352447,"assistant_id":"asst_123","thread_id":"thread_123","status":"completed","started_at":1710352475,"expires_at":null,"cancelled_at":null,"failed_at":null,"completed_at":1710352477,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[{"type":"function","function":{"name":"get_current_weather","description":"Get the current weather in a given location","parameters":{"type":"object","properties":{"location":{"type":"string","description":"The city and state, e.g. San Francisco, CA"},"unit":{"type":"string","enum":["celsius","fahrenheit"]}},"required":["location"]}}}],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":{"prompt_tokens":20,"completion_tokens":11,"total_tokens":31},"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: done
            data: [DONE]
  /uploads:
    post:
      tags:
      - Uploads
      summary: "Creates an intermediate [Upload](/docs/api-reference/uploads/object)\
        \ object\nthat you can add [Parts](/docs/api-reference/uploads/part-object)\
        \ to.\nCurrently, an Upload can accept at most 8 GB in total and expires after\
        \ an\nhour after you create it.\n\nOnce you complete the Upload, we will create\
        \ a\n[File](/docs/api-reference/files/object) object that contains all the\
        \ parts\nyou uploaded. This File is usable in the rest of our platform as\
        \ a regular\nFile object.\n\nFor certain `purpose` values, the correct `mime_type`\
        \ must be specified. \nPlease refer to documentation for the \n[supported\
        \ MIME types for your use case](/docs/assistants/tools/file-search#supported-files).\n\
        \nFor guidance on the proper filename extensions for each purpose, please\n\
        follow the documentation on [creating a\nFile](/docs/api-reference/files/create).\n"
      operationId: createUpload
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateUploadRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Upload'
      x-oaiMeta:
        name: Create upload
        group: uploads
        returns: "The [Upload](/docs/api-reference/uploads/object) object with status\
          \ `pending`."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/uploads \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "purpose": "fine-tune",
                  "filename": "training_examples.jsonl",
                  "bytes": 2147483648,
                  "mime_type": "text/jsonl"
                }'
          response: |
            {
              "id": "upload_abc123",
              "object": "upload",
              "bytes": 2147483648,
              "created_at": 1719184911,
              "filename": "training_examples.jsonl",
              "purpose": "fine-tune",
              "status": "pending",
              "expires_at": 1719127296
            }
  /uploads/{uploadId}/cancel:
    post:
      tags:
      - Uploads
      summary: |
        Cancels the Upload. No Parts may be added after an Upload is cancelled.
      operationId: cancelUpload
      parameters:
      - name: uploadId
        in: path
        description: |
          The ID of the Upload
        required: true
        style: simple
        explode: false
        schema:
          type: string
          example: upload_abc123
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Upload'
      x-oaiMeta:
        name: Cancel upload
        group: uploads
        returns: "The [Upload](/docs/api-reference/uploads/object) object with status\
          \ `cancelled`."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/uploads/upload_abc123/cancel
          response: |
            {
              "id": "upload_abc123",
              "object": "upload",
              "bytes": 2147483648,
              "created_at": 1719184911,
              "filename": "training_examples.jsonl",
              "purpose": "fine-tune",
              "status": "cancelled",
              "expires_at": 1719127296
            }
  /uploads/{uploadId}/complete:
    post:
      tags:
      - Uploads
      summary: "Completes the [Upload](/docs/api-reference/uploads/object). \n\nWithin\
        \ the returned Upload object, there is a nested [File](/docs/api-reference/files/object)\
        \ object that is ready to use in the rest of the platform.\n\nYou can specify\
        \ the order of the Parts by passing in an ordered list of the Part IDs.\n\n\
        The number of bytes uploaded upon completion must match the number of bytes\
        \ initially specified when creating the Upload object. No Parts may be added\
        \ after an Upload is completed.\n"
      operationId: completeUpload
      parameters:
      - name: uploadId
        in: path
        description: |
          The ID of the Upload
        required: true
        style: simple
        explode: false
        schema:
          type: string
          example: upload_abc123
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CompleteUploadRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Upload'
      x-oaiMeta:
        name: Complete upload
        group: uploads
        returns: "The [Upload](/docs/api-reference/uploads/object) object with status\
          \ `completed` with an additional `file` property containing the created\
          \ usable File object."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/uploads/upload_abc123/complete
                -d '{
                  "part_ids": ["part_def456", "part_ghi789"]
                }'
          response: |
            {
              "id": "upload_abc123",
              "object": "upload",
              "bytes": 2147483648,
              "created_at": 1719184911,
              "filename": "training_examples.jsonl",
              "purpose": "fine-tune",
              "status": "completed",
              "expires_at": 1719127296,
              "file": {
                "id": "file-xyz321",
                "object": "file",
                "bytes": 2147483648,
                "created_at": 1719186911,
                "filename": "training_examples.jsonl",
                "purpose": "fine-tune",
              }
            }
  /uploads/{uploadId}/parts:
    post:
      tags:
      - Uploads
      summary: "Adds a [Part](/docs/api-reference/uploads/part-object) to an [Upload](/docs/api-reference/uploads/object)\
        \ object. A Part represents a chunk of bytes from the file you are trying\
        \ to upload. \n\nEach Part can be at most 64 MB, and you can add Parts until\
        \ you hit the Upload maximum of 8 GB.\n\nIt is possible to add multiple Parts\
        \ in parallel. You can decide the intended order of the Parts when you [complete\
        \ the Upload](/docs/api-reference/uploads/complete).\n"
      operationId: addUploadPart
      parameters:
      - name: uploadId
        in: path
        description: |
          The ID of the Upload
        required: true
        style: simple
        explode: false
        schema:
          type: string
          example: upload_abc123
      requestBody:
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/AddUploadPartRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/UploadPart'
      x-oaiMeta:
        name: Add upload part
        group: uploads
        returns: "The upload [Part](/docs/api-reference/uploads/part-object) object."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/uploads/upload_abc123/parts
                -F data="aHR0cHM6Ly9hcGkub3BlbmFpLmNvbS92MS91cGxvYWRz..."
          response: |
            {
              "id": "part_def456",
              "object": "upload.part",
              "created_at": 1719185911,
              "upload_id": "upload_abc123"
            }
  /vector_stores:
    get:
      tags:
      - Vector stores
      summary: Returns a list of vector stores.
      operationId: listVectorStores
      parameters:
      - name: limit
        in: query
        description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20
        required: false
        style: form
        explode: true
        schema:
          type: integer
          default: 20
      - name: order
        in: query
        description: |
          Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order
        required: false
        style: form
        explode: true
        schema:
          type: string
          default: desc
          enum:
          - asc
          - desc
      - name: after
        in: query
        description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list
        required: false
        style: form
        explode: true
        schema:
          type: string
      - name: before
        in: query
        description: |
          A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list
        required: false
        style: form
        explode: true
        schema:
          type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListVectorStoresResponse'
      x-oaiMeta:
        name: List vector stores
        group: vector_stores
        returns: "A list of [vector store](/docs/api-reference/vector-stores/object)\
          \ objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              vector_stores = client.vector_stores.list()
              print(vector_stores)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const vectorStores = await openai.vectorStores.list();
                console.log(vectorStores);
              }

              main();
          response: |
            {
              "object": "list",
              "data": [
                {
                  "id": "vs_abc123",
                  "object": "vector_store",
                  "created_at": 1699061776,
                  "name": "Support FAQ",
                  "bytes": 139920,
                  "file_counts": {
                    "in_progress": 0,
                    "completed": 3,
                    "failed": 0,
                    "cancelled": 0,
                    "total": 3
                  }
                },
                {
                  "id": "vs_abc456",
                  "object": "vector_store",
                  "created_at": 1699061776,
                  "name": "Support FAQ v2",
                  "bytes": 139920,
                  "file_counts": {
                    "in_progress": 0,
                    "completed": 3,
                    "failed": 0,
                    "cancelled": 0,
                    "total": 3
                  }
                }
              ],
              "first_id": "vs_abc123",
              "last_id": "vs_abc456",
              "has_more": false
            }
    post:
      tags:
      - Vector stores
      summary: Create a vector store.
      operationId: createVectorStore
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateVectorStoreRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreObject'
      x-oaiMeta:
        name: Create vector store
        group: vector_stores
        returns: "A [vector store](/docs/api-reference/vector-stores/object) object."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                  "name": "Support FAQ"
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              vector_store = client.vector_stores.create(
                name="Support FAQ"
              )
              print(vector_store)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const vectorStore = await openai.vectorStores.create({
                  name: "Support FAQ"
                });
                console.log(vectorStore);
              }

              main();
          response: |
            {
              "id": "vs_abc123",
              "object": "vector_store",
              "created_at": 1699061776,
              "name": "Support FAQ",
              "bytes": 139920,
              "file_counts": {
                "in_progress": 0,
                "completed": 3,
                "failed": 0,
                "cancelled": 0,
                "total": 3
              }
            }
  /vector_stores/{vectorStoreId}:
    get:
      tags:
      - Vector stores
      summary: Retrieves a vector store.
      operationId: getVectorStore
      parameters:
      - name: vectorStoreId
        in: path
        description: The ID of the vector store to retrieve
        required: true
        style: simple
        explode: false
        schema:
          type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreObject'
      x-oaiMeta:
        name: Retrieve vector store
        group: vector_stores
        returns: "The [vector store](/docs/api-reference/vector-stores/object) object\
          \ matching the specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              vector_store = client.vector_stores.retrieve(
                vector_store_id="vs_abc123"
              )
              print(vector_store)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const vectorStore = await openai.vectorStores.retrieve(
                  "vs_abc123"
                );
                console.log(vectorStore);
              }

              main();
          response: |
            {
              "id": "vs_abc123",
              "object": "vector_store",
              "created_at": 1699061776
            }
    post:
      tags:
      - Vector stores
      summary: Modifies a vector store.
      operationId: modifyVectorStore
      parameters:
      - name: vectorStoreId
        in: path
        description: The ID of the vector store to modify
        required: true
        style: simple
        explode: false
        schema:
          type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/UpdateVectorStoreRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreObject'
      x-oaiMeta:
        name: Modify vector store
        group: vector_stores
        returns: "The modified [vector store](/docs/api-reference/vector-stores/object)\
          \ object."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
                -d '{
                  "name": "Support FAQ"
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              vector_store = client.vector_stores.update(
                vector_store_id="vs_abc123",
                name="Support FAQ"
              )
              print(vector_store)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const vectorStore = await openai.vectorStores.update(
                  "vs_abc123",
                  {
                    name: "Support FAQ"
                  }
                );
                console.log(vectorStore);
              }

              main();
          response: |
            {
              "id": "vs_abc123",
              "object": "vector_store",
              "created_at": 1699061776,
              "name": "Support FAQ",
              "bytes": 139920,
              "file_counts": {
                "in_progress": 0,
                "completed": 3,
                "failed": 0,
                "cancelled": 0,
                "total": 3
              }
            }
    delete:
      tags:
      - Vector stores
      summary: Delete a vector store.
      operationId: deleteVectorStore
      parameters:
      - name: vectorStoreId
        in: path
        description: The ID of the vector store to delete
        required: true
        style: simple
        explode: false
        schema:
          type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DeleteVectorStoreResponse'
      x-oaiMeta:
        name: Delete vector store
        group: vector_stores
        returns: Deletion status
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -X DELETE
            python: |
              from openai import OpenAI
              client = OpenAI()

              deleted_vector_store = client.vector_stores.delete(
                vector_store_id="vs_abc123"
              )
              print(deleted_vector_store)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const deletedVectorStore = await openai.vectorStores.del(
                  "vs_abc123"
                );
                console.log(deletedVectorStore);
              }

              main();
          response: |
            {
              id: "vs_abc123",
              object: "vector_store.deleted",
              deleted: true
            }
  /vector_stores/{vectorStoreId}/file_batches:
    post:
      tags:
      - Vector stores
      summary: Create a vector store file batch.
      operationId: createVectorStoreFileBatch
      parameters:
      - name: vectorStoreId
        in: path
        description: |
          The ID of the vector store for which to create a File Batch
        required: true
        style: simple
        explode: false
        schema:
          type: string
          example: vs_abc123
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateVectorStoreFileBatchRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreFileBatchObject'
      x-oaiMeta:
        name: Create vector store file batch
        group: vector_stores
        returns: "A [vector store file batch](/docs/api-reference/vector-stores-file-batches/batch-object)\
          \ object."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123/file_batches \
                  -H "Authorization: Bearer $OPENAI_API_KEY" \
                  -H "Content-Type: application/json \
                  -H "OpenAI-Beta: assistants=v2" \
                  -d '{
                    "file_ids": ["file-abc123", "file-abc456"]
                  }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              vector_store_file_batch = client.vector_stores.file_batches.create(
                vector_store_id="vs_abc123",
                file_ids=["file-abc123", "file-abc456"]
              )
              print(vector_store_file_batch)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const myVectorStoreFileBatch = await openai.vectorStores.fileBatches.create(
                  "vs_abc123",
                  {
                    file_ids: ["file-abc123", "file-abc456"]
                  }
                );
                console.log(myVectorStoreFileBatch);
              }

              main();
          response: |
            {
              "id": "vsfb_abc123",
              "object": "vector_store.file_batch",
              "created_at": 1699061776,
              "vector_store_id": "vs_abc123",
              "status": "in_progress",
              "file_counts": {
                "in_progress": 1,
                "completed": 1,
                "failed": 0,
                "cancelled": 0,
                "total": 0,
              }
            }
  /vector_stores/{vectorStoreId}/file_batches/{batchId}:
    get:
      tags:
      - Vector stores
      summary: Retrieves a vector store file batch.
      operationId: getVectorStoreFileBatch
      parameters:
      - name: vectorStoreId
        in: path
        description: The ID of the vector store that the file batch belongs to
        required: true
        style: simple
        explode: false
        schema:
          type: string
          example: vs_abc123
      - name: batchId
        in: path
        description: The ID of the file batch being retrieved
        required: true
        style: simple
        explode: false
        schema:
          type: string
          example: vsfb_abc123
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreFileBatchObject'
      x-oaiMeta:
        name: Retrieve vector store file batch
        group: vector_stores
        returns: "The [vector store file batch](/docs/api-reference/vector-stores-file-batches/batch-object)\
          \ object."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123/files_batches/vsfb_abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              vector_store_file_batch = client.vector_stores.file_batches.retrieve(
                vector_store_id="vs_abc123",
                batch_id="vsfb_abc123"
              )
              print(vector_store_file_batch)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const vectorStoreFileBatch = await openai.vectorStores.fileBatches.retrieve(
                  "vs_abc123",
                  "vsfb_abc123"
                );
                console.log(vectorStoreFileBatch);
              }

              main();
          response: |
            {
              "id": "vsfb_abc123",
              "object": "vector_store.file_batch",
              "created_at": 1699061776,
              "vector_store_id": "vs_abc123",
              "status": "in_progress",
              "file_counts": {
                "in_progress": 1,
                "completed": 1,
                "failed": 0,
                "cancelled": 0,
                "total": 0,
              }
            }
  /vector_stores/{vectorStoreId}/file_batches/{batchId}/cancel:
    post:
      tags:
      - Vector stores
      summary: Cancel a vector store file batch. This attempts to cancel the processing
        of files in this batch as soon as possible.
      operationId: cancelVectorStoreFileBatch
      parameters:
      - name: vectorStoreId
        in: path
        description: The ID of the vector store that the file batch belongs to
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: batchId
        in: path
        description: The ID of the file batch to cancel
        required: true
        style: simple
        explode: false
        schema:
          type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreFileBatchObject'
      x-oaiMeta:
        name: Cancel vector store file batch
        group: vector_stores
        returns: The modified vector store file batch object.
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123/files_batches/vsfb_abc123/cancel \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -X POST
            python: |
              from openai import OpenAI
              client = OpenAI()

              deleted_vector_store_file_batch = client.vector_stores.file_batches.cancel(
                  vector_store_id="vs_abc123",
                  file_batch_id="vsfb_abc123"
              )
              print(deleted_vector_store_file_batch)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const deletedVectorStoreFileBatch = await openai.vectorStores.fileBatches.cancel(
                  "vs_abc123",
                  "vsfb_abc123"
                );
                console.log(deletedVectorStoreFileBatch);
              }

              main();
          response: |
            {
              "id": "vsfb_abc123",
              "object": "vector_store.file_batch",
              "created_at": 1699061776,
              "vector_store_id": "vs_abc123",
              "status": "in_progress",
              "file_counts": {
                "in_progress": 12,
                "completed": 3,
                "failed": 0,
                "cancelled": 0,
                "total": 15,
              }
            }
  /vector_stores/{vectorStoreId}/file_batches/{batchId}/files:
    get:
      tags:
      - Vector stores
      summary: Returns a list of vector store files in a batch.
      operationId: listFilesInVectorStoreBatch
      parameters:
      - name: vectorStoreId
        in: path
        description: The ID of the vector store that the files belong to
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: batchId
        in: path
        description: The ID of the file batch that the files belong to
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: limit
        in: query
        description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20
        required: false
        style: form
        explode: true
        schema:
          type: integer
          default: 20
      - name: order
        in: query
        description: |
          Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order
        required: false
        style: form
        explode: true
        schema:
          type: string
          default: desc
          enum:
          - asc
          - desc
      - name: after
        in: query
        description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list
        required: false
        style: form
        explode: true
        schema:
          type: string
      - name: before
        in: query
        description: |
          A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list
        required: false
        style: form
        explode: true
        schema:
          type: string
      - name: filter
        in: query
        description: "Filter by file status. One of `in_progress`, `completed`, `failed`,\
          \ `cancelled`"
        required: false
        style: form
        explode: true
        schema:
          type: string
          enum:
          - in_progress
          - completed
          - failed
          - cancelled
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListVectorStoreFilesResponse'
      x-oaiMeta:
        name: List vector store files in a batch
        group: vector_stores
        returns: "A list of [vector store file](/docs/api-reference/vector-stores-files/file-object)\
          \ objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123/files_batches/vsfb_abc123/files \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              vector_store_files = client.vector_stores.file_batches.list_files(
                vector_store_id="vs_abc123",
                batch_id="vsfb_abc123"
              )
              print(vector_store_files)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const vectorStoreFiles = await openai.vectorStores.fileBatches.listFiles(
                  "vs_abc123",
                  "vsfb_abc123"
                );
                console.log(vectorStoreFiles);
              }

              main();
          response: |
            {
              "object": "list",
              "data": [
                {
                  "id": "file-abc123",
                  "object": "vector_store.file",
                  "created_at": 1699061776,
                  "vector_store_id": "vs_abc123"
                },
                {
                  "id": "file-abc456",
                  "object": "vector_store.file",
                  "created_at": 1699061776,
                  "vector_store_id": "vs_abc123"
                }
              ],
              "first_id": "file-abc123",
              "last_id": "file-abc456",
              "has_more": false
            }
  /vector_stores/{vectorStoreId}/files:
    get:
      tags:
      - Vector stores
      summary: Returns a list of vector store files.
      operationId: listVectorStoreFiles
      parameters:
      - name: vectorStoreId
        in: path
        description: The ID of the vector store that the files belong to
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: limit
        in: query
        description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20
        required: false
        style: form
        explode: true
        schema:
          type: integer
          default: 20
      - name: order
        in: query
        description: |
          Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order
        required: false
        style: form
        explode: true
        schema:
          type: string
          default: desc
          enum:
          - asc
          - desc
      - name: after
        in: query
        description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list
        required: false
        style: form
        explode: true
        schema:
          type: string
      - name: before
        in: query
        description: |
          A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list
        required: false
        style: form
        explode: true
        schema:
          type: string
      - name: filter
        in: query
        description: "Filter by file status. One of `in_progress`, `completed`, `failed`,\
          \ `cancelled`"
        required: false
        style: form
        explode: true
        schema:
          type: string
          enum:
          - in_progress
          - completed
          - failed
          - cancelled
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListVectorStoreFilesResponse'
      x-oaiMeta:
        name: List vector store files
        group: vector_stores
        returns: "A list of [vector store file](/docs/api-reference/vector-stores-files/file-object)\
          \ objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123/files \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              vector_store_files = client.vector_stores.files.list(
                vector_store_id="vs_abc123"
              )
              print(vector_store_files)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const vectorStoreFiles = await openai.vectorStores.files.list(
                  "vs_abc123"
                );
                console.log(vectorStoreFiles);
              }

              main();
          response: |
            {
              "object": "list",
              "data": [
                {
                  "id": "file-abc123",
                  "object": "vector_store.file",
                  "created_at": 1699061776,
                  "vector_store_id": "vs_abc123"
                },
                {
                  "id": "file-abc456",
                  "object": "vector_store.file",
                  "created_at": 1699061776,
                  "vector_store_id": "vs_abc123"
                }
              ],
              "first_id": "file-abc123",
              "last_id": "file-abc456",
              "has_more": false
            }
    post:
      tags:
      - Vector stores
      summary: "Create a vector store file by attaching a [File](/docs/api-reference/files)\
        \ to a [vector store](/docs/api-reference/vector-stores/object)."
      operationId: createVectorStoreFile
      parameters:
      - name: vectorStoreId
        in: path
        description: |
          The ID of the vector store for which to create a File
        required: true
        style: simple
        explode: false
        schema:
          type: string
          example: vs_abc123
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateVectorStoreFileRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreFileObject'
      x-oaiMeta:
        name: Create vector store file
        group: vector_stores
        returns: "A [vector store file](/docs/api-reference/vector-stores-files/file-object)\
          \ object."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123/files \
                  -H "Authorization: Bearer $OPENAI_API_KEY" \
                  -H "Content-Type: application/json" \
                  -H "OpenAI-Beta: assistants=v2" \
                  -d '{
                    "file_id": "file-abc123"
                  }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              vector_store_file = client.vector_stores.files.create(
                vector_store_id="vs_abc123",
                file_id="file-abc123"
              )
              print(vector_store_file)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const myVectorStoreFile = await openai.vectorStores.files.create(
                  "vs_abc123",
                  {
                    file_id: "file-abc123"
                  }
                );
                console.log(myVectorStoreFile);
              }

              main();
          response: |
            {
              "id": "file-abc123",
              "object": "vector_store.file",
              "created_at": 1699061776,
              "usage_bytes": 1234,
              "vector_store_id": "vs_abcd",
              "status": "completed",
              "last_error": null
            }
  /vector_stores/{vectorStoreId}/files/{fileId}:
    get:
      tags:
      - Vector stores
      summary: Retrieves a vector store file.
      operationId: getVectorStoreFile
      parameters:
      - name: vectorStoreId
        in: path
        description: The ID of the vector store that the file belongs to
        required: true
        style: simple
        explode: false
        schema:
          type: string
          example: vs_abc123
      - name: fileId
        in: path
        description: The ID of the file being retrieved
        required: true
        style: simple
        explode: false
        schema:
          type: string
          example: file-abc123
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreFileObject'
      x-oaiMeta:
        name: Retrieve vector store file
        group: vector_stores
        returns: "The [vector store file](/docs/api-reference/vector-stores-files/file-object)\
          \ object."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123/files/file-abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              vector_store_file = client.vector_stores.files.retrieve(
                vector_store_id="vs_abc123",
                file_id="file-abc123"
              )
              print(vector_store_file)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const vectorStoreFile = await openai.vectorStores.files.retrieve(
                  "vs_abc123",
                  "file-abc123"
                );
                console.log(vectorStoreFile);
              }

              main();
          response: |
            {
              "id": "file-abc123",
              "object": "vector_store.file",
              "created_at": 1699061776,
              "vector_store_id": "vs_abcd",
              "status": "completed",
              "last_error": null
            }
    post:
      tags:
      - Vector stores
      summary: Update attributes on a vector store file.
      operationId: updateVectorStoreFileAttributes
      parameters:
      - name: vectorStoreId
        in: path
        description: The ID of the vector store the file belongs to
        required: true
        style: simple
        explode: false
        schema:
          type: string
          example: vs_abc123
      - name: fileId
        in: path
        description: The ID of the file to update attributes
        required: true
        style: simple
        explode: false
        schema:
          type: string
          example: file-abc123
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/UpdateVectorStoreFileAttributesRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreFileObject'
      x-oaiMeta:
        name: Update vector store file attributes
        group: vector_stores
        returns: "The updated [vector store file](/docs/api-reference/vector-stores-files/file-object)\
          \ object."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/{vector_store_id}/files/{file_id} \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -d '{"attributes": {"key1": "value1", "key2": 2}}'
          response: |
            {
              "id": "file-abc123",
              "object": "vector_store.file",
              "usage_bytes": 1234,
              "created_at": 1699061776,
              "vector_store_id": "vs_abcd",
              "status": "completed",
              "last_error": null,
              "chunking_strategy": {...},
              "attributes": {"key1": "value1", "key2": 2}
            }
    delete:
      tags:
      - Vector stores
      summary: "Delete a vector store file. This will remove the file from the vector\
        \ store but the file itself will not be deleted. To delete the file, use the\
        \ [delete file](/docs/api-reference/files/delete) endpoint."
      operationId: deleteVectorStoreFile
      parameters:
      - name: vectorStoreId
        in: path
        description: The ID of the vector store that the file belongs to
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: fileId
        in: path
        description: The ID of the file to delete
        required: true
        style: simple
        explode: false
        schema:
          type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DeleteVectorStoreFileResponse'
      x-oaiMeta:
        name: Delete vector store file
        group: vector_stores
        returns: Deletion status
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123/files/file-abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -X DELETE
            python: |
              from openai import OpenAI
              client = OpenAI()

              deleted_vector_store_file = client.vector_stores.files.delete(
                  vector_store_id="vs_abc123",
                  file_id="file-abc123"
              )
              print(deleted_vector_store_file)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const deletedVectorStoreFile = await openai.vectorStores.files.del(
                  "vs_abc123",
                  "file-abc123"
                );
                console.log(deletedVectorStoreFile);
              }

              main();
          response: |
            {
              id: "file-abc123",
              object: "vector_store.file.deleted",
              deleted: true
            }
  /vector_stores/{vectorStoreId}/files/{fileId}/content:
    get:
      tags:
      - Vector stores
      summary: Retrieve the parsed contents of a vector store file.
      operationId: retrieveVectorStoreFileContent
      parameters:
      - name: vectorStoreId
        in: path
        description: The ID of the vector store
        required: true
        style: simple
        explode: false
        schema:
          type: string
          example: vs_abc123
      - name: fileId
        in: path
        description: The ID of the file within the vector store
        required: true
        style: simple
        explode: false
        schema:
          type: string
          example: file-abc123
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreFileContentResponse'
      x-oaiMeta:
        name: Retrieve vector store file content
        group: vector_stores
        returns: The parsed contents of the specified vector store file.
        examples:
          request:
            curl: |
              curl \
              https://api.openai.com/v1/vector_stores/vs_abc123/files/file-abc123/content \
              -H "Authorization: Bearer $OPENAI_API_KEY"
          response: |
            {
              "file_id": "file-abc123",
              "filename": "example.txt",
              "attributes": {"key": "value"},
              "content": [
                {"type": "text", "text": "..."},
                ...
              ]
            }
  /vector_stores/{vectorStoreId}/search:
    post:
      tags:
      - Vector stores
      summary: Search a vector store for relevant chunks based on a query and file
        attributes filter.
      operationId: searchVectorStore
      parameters:
      - name: vectorStoreId
        in: path
        description: The ID of the vector store to search
        required: true
        style: simple
        explode: false
        schema:
          type: string
          example: vs_abc123
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/VectorStoreSearchRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreSearchResultsPage'
      x-oaiMeta:
        name: Search vector store
        group: vector_stores
        returns: A page of search results from the vector store.
        examples:
          request:
            curl: |
              curl -X POST \
              https://api.openai.com/v1/vector_stores/vs_abc123/search \
              -H "Authorization: Bearer $OPENAI_API_KEY" \
              -H "Content-Type: application/json" \
              -d '{"query": "What is the return policy?", "filters": {...}}'
          response: |
            {
              "object": "vector_store.search_results.page",
              "search_query": "What is the return policy?",
              "data": [
                {
                  "file_id": "file_123",
                  "filename": "document.pdf",
                  "score": 0.95,
                  "attributes": {
                    "author": "John Doe",
                    "date": "2023-01-01"
                  },
                  "content": [
                    {
                      "type": "text",
                      "text": "Relevant chunk"
                    }
                  ]
                },
                {
                  "file_id": "file_456",
                  "filename": "notes.txt",
                  "score": 0.89,
                  "attributes": {
                    "author": "Jane Smith",
                    "date": "2023-01-02"
                  },
                  "content": [
                    {
                      "type": "text",
                      "text": "Sample text content from the vector store."
                    }
                  ]
                }
              ],
              "has_more": false,
              "next_page": null
            }
components:
  schemas:
    DoneEvent:
      required:
      - data
      - event
      type: object
      properties:
        data:
          type: string
          enum:
          - "[DONE]"
          x-stainless-const: true
        event:
          type: string
          enum:
          - done
          x-stainless-const: true
      description: Occurs when a stream ends
      x-oaiMeta:
        dataDescription: "`data` is `[DONE]`"
    EvalRunPerModelUsage:
      required:
      - cached_tokens
      - completion_tokens
      - invocation_count
      - model_name
      - prompt_tokens
      - total_tokens
      type: object
      properties:
        completion_tokens:
          type: integer
          description: The number of completion tokens generated
          x-ballerina-name: completionTokens
        prompt_tokens:
          type: integer
          description: The number of prompt tokens used
          x-ballerina-name: promptTokens
        model_name:
          type: string
          description: The name of the model
          x-ballerina-name: modelName
        total_tokens:
          type: integer
          description: The total number of tokens used
          x-ballerina-name: totalTokens
        invocation_count:
          type: integer
          description: The number of invocations
          x-ballerina-name: invocationCount
        cached_tokens:
          type: integer
          description: The number of tokens retrieved from cache
          x-ballerina-name: cachedTokens
    FineTuningJobCheckpoint:
      title: FineTuningJobCheckpoint
      required:
      - created_at
      - fine_tuned_model_checkpoint
      - fine_tuning_job_id
      - id
      - metrics
      - object
      - step_number
      type: object
      properties:
        step_number:
          type: integer
          description: The step number that the checkpoint was created at
          x-ballerina-name: stepNumber
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the checkpoint was
            created
          x-ballerina-name: createdAt
        fine_tuning_job_id:
          type: string
          description: The name of the fine-tuning job that this checkpoint was created
            from
          x-ballerina-name: fineTuningJobId
        id:
          type: string
          description: "The checkpoint identifier, which can be referenced in the\
            \ API endpoints"
        metrics:
          $ref: '#/components/schemas/FineTuningJobCheckpointMetrics'
        fine_tuned_model_checkpoint:
          type: string
          description: The name of the fine-tuned checkpoint model that is created
          x-ballerina-name: fineTunedModelCheckpoint
        object:
          type: string
          description: "The object type, which is always \"fine_tuning.job.checkpoint\""
          enum:
          - fine_tuning.job.checkpoint
          x-stainless-const: true
      description: |
        The `fine_tuning.job.checkpoint` object represents a model checkpoint for a fine-tuning job that is ready to use
      x-oaiMeta:
        name: The fine-tuning job checkpoint object
        example: |
          {
            "object": "fine_tuning.job.checkpoint",
            "id": "ftckpt_qtZ5Gyk4BLq1SfLFWp3RtO3P",
            "created_at": 1712211699,
            "fine_tuned_model_checkpoint": "ft:gpt-4o-mini-2024-07-18:my-org:custom_suffix:9ABel2dg:ckpt-step-88",
            "fine_tuning_job_id": "ftjob-fpbNQ3H1GrMehXRf8cO97xTN",
            "metrics": {
              "step": 88,
              "train_loss": 0.478,
              "train_mean_token_accuracy": 0.924,
              "valid_loss": 10.112,
              "valid_mean_token_accuracy": 0.145,
              "full_valid_loss": 0.567,
              "full_valid_mean_token_accuracy": 0.944
            },
            "step_number": 88
          }
    WebSearchPreviewTool:
      title: Web search preview
      required:
      - type
      type: object
      properties:
        search_context_size:
          type: string
          description: "High level guidance for the amount of context window space\
            \ to use for the search. One of `low`, `medium`, or `high`. `medium` is\
            \ the default"
          enum:
          - low
          - medium
          - high
          x-ballerina-name: searchContextSize
        user_location:
          anyOf:
          - $ref: '#/components/schemas/ApproximateLocation'
          - nullable: true
          x-ballerina-name: userLocation
        type:
          type: string
          description: The type of the web search tool. One of `web_search_preview`
            or `web_search_preview_2025_03_11`
          default: web_search_preview
          enum:
          - web_search_preview
          - web_search_preview_2025_03_11
          x-stainless-const: true
      description: "This tool searches the web for relevant results to use in a response.\
        \ Learn more about the [web search tool](https://platform.openai.com/docs/guides/tools-web-search)"
    RealtimeResponseStatusDetailsError:
      type: object
      properties:
        code:
          type: string
          description: "Error code, if any"
        type:
          type: string
          description: The type of error
      description: "A description of the error that caused the response to fail, \n\
        populated when the `status` is `failed`\n"
    ResponseError:
      required:
      - code
      - message
      type: object
      properties:
        code:
          $ref: '#/components/schemas/ResponseErrorCode'
        message:
          type: string
          description: |
            A human-readable description of the error
      description: |
        An error object returned when the model fails to generate a Response
      nullable: true
    UsageVectorStoresResult:
      required:
      - object
      - usage_bytes
      type: object
      properties:
        project_id:
          type: string
          description: "When `group_by=project_id`, this field provides the project\
            \ ID of the grouped usage result"
          nullable: true
          x-ballerina-name: projectId
        usage_bytes:
          type: integer
          description: The vector stores usage in bytes
          x-ballerina-name: usageBytes
        object:
          type: string
          enum:
          - organization.usage.vector_stores.result
          x-stainless-const: true
      description: The aggregated vector stores usage details of the specific time
        bucket
      x-oaiMeta:
        name: Vector stores usage object
        example: |
          {
              "object": "organization.usage.vector_stores.result",
              "usage_bytes": 1024,
              "project_id": "proj_abc"
          }
    CreateResponseAllOf3:
      required:
      - input
      - model
      type: object
      properties:
        input:
          description: |
            Text, image, or file inputs to the model, used to generate a response.

            Learn more:
            - [Text inputs and outputs](/docs/guides/text)
            - [Image inputs](/docs/guides/images)
            - [File inputs](/docs/guides/pdf-files)
            - [Conversation state](/docs/guides/conversation-state)
            - [Function calling](/docs/guides/function-calling)
          oneOf:
          - title: Text input
            type: string
            description: "A text input to the model, equivalent to a text input with\
              \ the \n`user` role.\n"
          - title: Input item list
            type: array
            description: "A list of one or many input items to the model, containing\
              \ \ndifferent content types.\n"
            items:
              $ref: '#/components/schemas/InputItem'
        include:
          type: array
          description: |
            Specify additional output data to include in the model response. Currently
            supported values are:
            - `file_search_call.results`: Include the search results of
              the file search tool call.
            - `message.input_image.image_url`: Include image urls from the input message.
            - `computer_call_output.output.image_url`: Include image urls from the computer call output
          nullable: true
          items:
            $ref: '#/components/schemas/Includable'
        parallel_tool_calls:
          type: boolean
          description: |
            Whether to allow the model to run tool calls in parallel
          nullable: true
          default: true
          x-ballerina-name: parallelToolCalls
        stream:
          type: boolean
          description: |
            If set to true, the model response data will be streamed to the client
            as it is generated using [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format).
            See the [Streaming section below](/docs/api-reference/responses-streaming)
            for more information
          nullable: true
          default: false
        store:
          type: boolean
          description: |
            Whether to store the generated model response for later retrieval via
            API
          nullable: true
          default: true
    InputMessageResourceAllOf2:
      required:
      - id
      type: object
      properties:
        id:
          type: string
          description: |
            The unique ID of the message input
    MessageDeltaContentTextObjectText:
      type: object
      properties:
        annotations:
          type: array
          items:
            $ref: '#/components/schemas/MessageDeltaContentTextObjectTextAnnotations'
        value:
          type: string
          description: The data that makes up the text
    ComputerToolCallSafetyCheck:
      required:
      - code
      - id
      - message
      type: object
      properties:
        code:
          type: string
          description: The type of the pending safety check
        id:
          type: string
          description: The ID of the pending safety check
        message:
          type: string
          description: Details about the pending safety check
      description: |
        A pending safety check for the computer call
    RunStepDeltaStepDetailsToolCallsFileSearchObject:
      title: File search tool call
      required:
      - file_search
      - index
      - type
      type: object
      properties:
        file_search:
          type: object
          description: "For now, this is always going to be an empty object"
          x-oaiTypeLabel: map
          x-ballerina-name: fileSearch
        index:
          type: integer
          description: The index of the tool call in the tool calls array
        id:
          type: string
          description: The ID of the tool call object
        type:
          type: string
          description: The type of tool call. This is always going to be `file_search`
            for this type of tool call
          enum:
          - file_search
          x-stainless-const: true
    AssistantsApiResponseFormatOption:
      description: |
        Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

        Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

        Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

        **Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length
      oneOf:
      - $ref: '#/components/schemas/AssistantsApiResponseFormatOptionOneOf1'
      - $ref: '#/components/schemas/ResponseFormatText'
      - $ref: '#/components/schemas/ResponseFormatJsonObject'
      - $ref: '#/components/schemas/ResponseFormatJsonSchema'
    ProjectServiceAccountCreateResponse:
      required:
      - api_key
      - created_at
      - id
      - name
      - object
      - role
      type: object
      properties:
        role:
          type: string
          description: Service accounts can only have one role of type `member`
          enum:
          - member
          x-stainless-const: true
        api_key:
          allOf:
          - $ref: '#/components/schemas/ProjectServiceAccountApiKey'
          x-ballerina-name: apiKey
        name:
          type: string
        created_at:
          type: integer
          x-ballerina-name: createdAt
        id:
          type: string
        object:
          type: string
          enum:
          - organization.project.service_account
          x-stainless-const: true
    ResponseCodeInterpreterCallCompletedEvent:
      required:
      - code_interpreter_call
      - output_index
      - response_id
      - type
      type: object
      properties:
        code_interpreter_call:
          allOf:
          - $ref: '#/components/schemas/CodeInterpreterToolCall'
          x-ballerina-name: codeInterpreterCall
        type:
          type: string
          description: |
            The type of the event. Always `response.code_interpreter_call.completed`
          enum:
          - response.code_interpreter_call.completed
          x-stainless-const: true
        output_index:
          type: integer
          description: |
            The index of the output item that the code interpreter call is in progress
          x-ballerina-name: outputIndex
      description: Emitted when the code interpreter call is completed
      x-oaiMeta:
        name: response.code_interpreter_call.completed
        group: responses
        example: |
          {
            "type": "response.code_interpreter_call.completed",
            "response_id": "resp-123",
            "output_index": 5,
            "code_interpreter_call": {}
          }
    ResponseProperties:
      type: object
      properties:
        instructions:
          type: string
          description: |
            Inserts a system (or developer) message as the first item in the model's context.

            When using along with `previous_response_id`, the instructions from a previous
            response will not be carried over to the next response. This makes it simple
            to swap out system (or developer) messages in new responses
          nullable: true
        previous_response_id:
          type: string
          description: "The unique ID of the previous response to the model. Use this\
            \ to\ncreate multi-turn conversations. Learn more about \n[conversation\
            \ state](/docs/guides/conversation-state)\n"
          nullable: true
          x-ballerina-name: previousResponseId
        reasoning:
          $ref: '#/components/schemas/Reasoning'
        tool_choice:
          description: |
            How the model should select which tool (or tools) to use when generating
            a response. See the `tools` parameter to see how to specify which tools
            the model can call
          oneOf:
          - $ref: '#/components/schemas/ToolChoiceOptions'
          - $ref: '#/components/schemas/ToolChoiceTypes'
          - $ref: '#/components/schemas/ToolChoiceFunction'
          x-ballerina-name: toolChoice
        model:
          $ref: '#/components/schemas/ModelIdsResponses'
        text:
          $ref: '#/components/schemas/ResponsePropertiesText'
        tools:
          type: array
          description: "An array of tools the model may call while generating a response.\
            \ You \ncan specify which tool to use by setting the `tool_choice` parameter.\n\
            \nThe two categories of tools you can provide the model are:\n\n- **Built-in\
            \ tools**: Tools that are provided by OpenAI that extend the\n  model's\
            \ capabilities, like [web search](/docs/guides/tools-web-search)\n  or\
            \ [file search](/docs/guides/tools-file-search). Learn more about\n  [built-in\
            \ tools](/docs/guides/tools).\n- **Function calls (custom tools)**: Functions\
            \ that are defined by you,\n  enabling the model to call your own code.\
            \ Learn more about\n  [function calling](/docs/guides/function-calling)\n"
          items:
            $ref: '#/components/schemas/Tool'
        truncation:
          type: string
          description: "The truncation strategy to use for the model response.\n-\
            \ `auto`: If the context of this response and previous ones exceeds\n\
            \  the model's context window size, the model will truncate the \n  response\
            \ to fit the context window by dropping input items in the\n  middle of\
            \ the conversation. \n- `disabled` (default): If a model response will\
            \ exceed the context window \n  size for a model, the request will fail\
            \ with a 400 error\n"
          nullable: true
          default: disabled
          enum:
          - auto
          - disabled
        max_output_tokens:
          type: integer
          description: |
            An upper bound for the number of tokens that can be generated for a response, including visible output tokens and [reasoning tokens](/docs/guides/reasoning)
          nullable: true
          x-ballerina-name: maxOutputTokens
    InviteProjects:
      type: object
      properties:
        role:
          type: string
          description: Project membership role
          enum:
          - member
          - owner
        id:
          type: string
          description: Project's public ID
    ListFineTuningJobCheckpointsResponse:
      required:
      - data
      - has_more
      - object
      type: object
      properties:
        first_id:
          type: string
          nullable: true
          x-ballerina-name: firstId
        data:
          type: array
          items:
            $ref: '#/components/schemas/FineTuningJobCheckpoint'
        last_id:
          type: string
          nullable: true
          x-ballerina-name: lastId
        has_more:
          type: boolean
          x-ballerina-name: hasMore
        object:
          type: string
          enum:
          - list
          x-stainless-const: true
    AutoChunkingStrategyRequestParam:
      title: Auto Chunking Strategy
      required:
      - type
      type: object
      properties:
        type:
          type: string
          description: Always `auto`
          enum:
          - auto
          x-stainless-const: true
      additionalProperties: false
      description: The default strategy. This strategy currently uses a `max_chunk_size_tokens`
        of `800` and `chunk_overlap_tokens` of `400`
    ModelIds:
      anyOf:
      - $ref: '#/components/schemas/ModelIdsShared'
      - $ref: '#/components/schemas/ModelIdsResponses'
    RealtimeServerEventInputAudioBufferCleared:
      required:
      - event_id
      - type
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event
          x-ballerina-name: eventId
        type:
          type: string
          description: "The event type, must be `input_audio_buffer.cleared`"
          enum:
          - input_audio_buffer.cleared
          x-stainless-const: true
      description: "Returned when the input audio buffer is cleared by the client\
        \ with a \n`input_audio_buffer.clear` event\n"
      x-oaiMeta:
        name: input_audio_buffer.cleared
        group: realtime
        example: |
          {
              "event_id": "event_1314",
              "type": "input_audio_buffer.cleared"
          }
    RealtimeServerEventTranscriptionSessionUpdated:
      required:
      - event_id
      - session
      - type
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event
          x-ballerina-name: eventId
        session:
          $ref: '#/components/schemas/RealtimeTranscriptionSessionCreateResponse'
        type:
          type: string
          description: "The event type, must be `transcription_session.updated`"
          enum:
          - transcription_session.updated
          x-stainless-const: true
      description: "Returned when a transcription session is updated with a `transcription_session.update`\
        \ event, unless \nthere is an error\n"
      x-oaiMeta:
        name: transcription_session.updated
        group: realtime
        example: |
          {
            "event_id": "event_5678",
            "type": "transcription_session.updated",
            "session": {
              "id": "sess_001",
              "object": "realtime.transcription_session",
              "input_audio_format": "pcm16",
              "input_audio_transcription": {
                "model": "gpt-4o-transcribe",
                "prompt": "",
                "language": ""
              },
              "turn_detection": {
                "type": "server_vad",
                "threshold": 0.5,
                "prefix_padding_ms": 300,
                "silence_duration_ms": 500,
                "create_response": true,
                // "interrupt_response": false  -- this will NOT be returned
              },
              "input_audio_noise_reduction": {
                "type": "near_field"
              },
              "include": [
                "item.input_audio_transcription.avg_logprob",
              ],
            }
          }
    ChatCompletionResponseMessageAnnotations:
      required:
      - type
      - url_citation
      type: object
      properties:
        type:
          type: string
          description: The type of the URL citation. Always `url_citation`
          enum:
          - url_citation
          x-stainless-const: true
        url_citation:
          allOf:
          - $ref: '#/components/schemas/ChatCompletionResponseMessageUrlCitation'
          x-ballerina-name: urlCitation
      description: |
        A URL citation when using web search
    AssistantToolsFileSearchTypeOnly:
      title: FileSearch tool
      required:
      - type
      type: object
      properties:
        type:
          type: string
          description: "The type of tool being defined: `file_search`"
          enum:
          - file_search
          x-stainless-const: true
    InputContent:
      oneOf:
      - $ref: '#/components/schemas/InputTextContent'
      - $ref: '#/components/schemas/InputImageContent'
      - $ref: '#/components/schemas/InputFileContent'
    ReasoningItem:
      title: Reasoning
      required:
      - id
      - summary
      - type
      type: object
      properties:
        summary:
          type: array
          description: |
            Reasoning text contents
          items:
            $ref: '#/components/schemas/ReasoningItemSummary'
        id:
          type: string
          description: |
            The unique identifier of the reasoning content
        type:
          type: string
          description: |
            The type of the object. Always `reasoning`
          enum:
          - reasoning
          x-stainless-const: true
        status:
          type: string
          description: |
            The status of the item. One of `in_progress`, `completed`, or
            `incomplete`. Populated when items are returned via API
          enum:
          - in_progress
          - completed
          - incomplete
      description: |
        A description of the chain of thought used by a reasoning model while generating
        a response
    AssistantToolsFileSearch:
      title: FileSearch tool
      required:
      - type
      type: object
      properties:
        file_search:
          allOf:
          - $ref: '#/components/schemas/AssistantToolsFileSearchFileSearch'
          x-ballerina-name: fileSearch
        type:
          type: string
          description: "The type of tool being defined: `file_search`"
          enum:
          - file_search
          x-stainless-const: true
    CreateMessageRequestAttachments:
      type: object
      properties:
        file_id:
          type: string
          description: The ID of the file to attach to the message
          x-ballerina-name: fileId
        tools:
          type: array
          description: The tools to add this file to
          items:
            $ref: '#/components/schemas/CreateMessageRequestTools'
    CreateFineTuningCheckpointPermissionRequest:
      required:
      - project_ids
      type: object
      properties:
        project_ids:
          type: array
          description: The project identifiers to grant access to
          items:
            type: string
          x-ballerina-name: projectIds
      additionalProperties: false
    MessageDeltaObjectDeltaContent:
      oneOf:
      - $ref: '#/components/schemas/MessageDeltaContentImageFileObject'
      - $ref: '#/components/schemas/MessageDeltaContentTextObject'
      - $ref: '#/components/schemas/MessageDeltaContentRefusalObject'
      - $ref: '#/components/schemas/MessageDeltaContentImageUrlObject'
    CreateEmbeddingRequest:
      required:
      - input
      - model
      type: object
      properties:
        input:
          description: |
            Input text to embed, encoded as a string or array of tokens. To embed multiple inputs in a single request, pass an array of strings or array of token arrays. The input must not exceed the max input tokens for the model (8192 tokens for `text-embedding-ada-002`), cannot be an empty string, and any array must be 2048 dimensions or less. [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken) for counting tokens. Some models may also impose a limit on total number of tokens summed across inputs
          example: The quick brown fox jumped over the lazy dog
          oneOf:
          - title: string
            type: string
            description: The string that will be turned into an embedding.
            example: This is a test.
            default: ""
          - title: array
            maxItems: 2048
            minItems: 1
            type: array
            description: The array of strings that will be turned into an embedding.
            items:
              type: string
              example: "['This is a test.']"
              default: ""
          - title: array
            maxItems: 2048
            minItems: 1
            type: array
            description: The array of integers that will be turned into an embedding.
            example: "[1212, 318, 257, 1332, 13]"
            items:
              type: integer
          - title: array
            maxItems: 2048
            minItems: 1
            type: array
            description: The array of arrays containing integers that will be turned
              into an embedding.
            example: "[[1212, 318, 257, 1332, 13]]"
            items:
              minItems: 1
              type: array
              items:
                type: integer
        encoding_format:
          type: string
          description: "The format to return the embeddings in. Can be either `float`\
            \ or [`base64`](https://pypi.org/project/pybase64/)"
          example: float
          default: float
          enum:
          - float
          - base64
          x-ballerina-name: encodingFormat
        model:
          description: |
            ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them
          example: text-embedding-3-small
          anyOf:
          - type: string
          - type: string
            enum:
            - text-embedding-ada-002
            - text-embedding-3-small
            - text-embedding-3-large
          x-oaiTypeLabel: string
        user:
          type: string
          description: |
            A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids)
          example: user-1234
        dimensions:
          minimum: 1
          type: integer
          description: |
            The number of dimensions the resulting output embeddings should have. Only supported in `text-embedding-3` and later models
      additionalProperties: false
    EvalScoreModelGrader:
      title: ScoreModelGrader
      required:
      - input
      - model
      - name
      - type
      type: object
      properties:
        input:
          type: array
          description: The input text. This may include template strings
          items:
            $ref: '#/components/schemas/EvalItem'
        pass_threshold:
          type: number
          description: The threshold for the score
          x-ballerina-name: passThreshold
        name:
          type: string
          description: The name of the grader
        range:
          type: array
          description: "The range of the score. Defaults to `[0, 1]`"
          items:
            type: number
        model:
          type: string
          description: The model to use for the evaluation
        type:
          type: string
          description: "The object type, which is always `score_model`"
          enum:
          - score_model
          x-stainless-const: true
        sampling_params:
          type: object
          description: The sampling parameters for the model
          x-ballerina-name: samplingParams
      description: |
        A ScoreModelGrader object that uses a model to assign a score to the input
      x-oaiMeta:
        name: The eval score model grader object
        group: evals
        example: |
          {
            "type": "score_model",
            "name": "Example score model grader",
            "input": "{{sample.output_text}}",
            "reference": "{{item.label}}",
            "operation": "eq"
          }
    ListCertificatesResponse:
      required:
      - data
      - has_more
      - object
      type: object
      properties:
        first_id:
          type: string
          example: cert_abc
          x-ballerina-name: firstId
        data:
          type: array
          items:
            $ref: '#/components/schemas/Certificate'
        last_id:
          type: string
          example: cert_abc
          x-ballerina-name: lastId
        has_more:
          type: boolean
          x-ballerina-name: hasMore
        object:
          type: string
          enum:
          - list
          x-stainless-const: true
    ChatCompletionRequestMessageContentPartAudio:
      title: Audio content part
      required:
      - input_audio
      - type
      type: object
      properties:
        input_audio:
          allOf:
          - $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartAudioInputAudio'
          x-ballerina-name: inputAudio
        type:
          type: string
          description: The type of the content part. Always `input_audio`
          enum:
          - input_audio
          x-stainless-const: true
      description: |
        Learn about [audio inputs](/docs/guides/audio)
    CreateModerationRequest:
      required:
      - input
      type: object
      properties:
        input:
          description: |
            Input (or inputs) to classify. Can be a single string, an array of strings, or
            an array of multi-modal input objects similar to other models
          oneOf:
          - type: string
            description: A string of text to classify for moderation.
            example: I want to kill them.
            default: ""
          - type: array
            description: An array of strings to classify for moderation.
            items:
              type: string
              example: I want to kill them.
              default: ""
          - type: array
            description: An array of multi-modal inputs to the moderation model.
            items:
              oneOf:
              - required:
                - image_url
                - type
                type: object
                properties:
                  type:
                    type: string
                    description: Always `image_url`.
                    enum:
                    - image_url
                    x-stainless-const: true
                  image_url:
                    required:
                    - url
                    type: object
                    properties:
                      url:
                        type: string
                        description: Either a URL of the image or the base64 encoded
                          image data.
                        format: uri
                        example: https://example.com/image.jpg
                    description: Contains either an image URL or a data URL for a
                      base64 encoded image.
                description: An object describing an image to classify.
              - required:
                - text
                - type
                type: object
                properties:
                  type:
                    type: string
                    description: Always `text`.
                    enum:
                    - text
                    x-stainless-const: true
                  text:
                    type: string
                    description: A string of text to classify.
                    example: I want to kill them
                description: An object describing text to classify.
        model:
          description: |
            The content moderation model you would like to use. Learn more in
            [the moderation guide](/docs/guides/moderation), and learn about
            available models [here](/docs/models#moderation)
          nullable: false
          example: omni-moderation-2024-09-26
          anyOf:
          - type: string
          - type: string
            enum:
            - omni-moderation-latest
            - omni-moderation-2024-09-26
            - text-moderation-latest
            - text-moderation-stable
          default: omni-moderation-latest
          x-oaiTypeLabel: string
    CreateEvalResponsesRunDataSource:
      title: ResponsesRunDataSource
      required:
      - source
      - type
      type: object
      properties:
        input_messages:
          oneOf:
          - required:
            - template
            - type
            type: object
            properties:
              type:
                type: string
                description: The type of input messages. Always `template`.
                enum:
                - template
              template:
                type: array
                description: "A list of chat messages forming the prompt or context.\
                  \ May include variable references to the \"item\" namespace, ie\
                  \ {{item.name}}."
                items:
                  oneOf:
                  - title: ChatMessage
                    required:
                    - content
                    - role
                    type: object
                    properties:
                      role:
                        type: string
                        description: "The role of the message (e.g. \"system\", \"\
                          assistant\", \"user\")."
                      content:
                        type: string
                        description: The content of the message.
                  - $ref: '#/components/schemas/EvalItem'
          - required:
            - item_reference
            - type
            type: object
            properties:
              type:
                type: string
                description: The type of input messages. Always `item_reference`.
                enum:
                - item_reference
              item_reference:
                type: string
                description: "A reference to a variable in the \"item\" namespace.\
                  \ Ie, \"item.name\""
          x-ballerina-name: inputMessages
        model:
          type: string
          description: The name of the model to use for generating completions (e.g.
            "o3-mini")
        source:
          oneOf:
          - $ref: '#/components/schemas/EvalJsonlFileContentSource'
          - $ref: '#/components/schemas/EvalJsonlFileIdSource'
          - $ref: '#/components/schemas/EvalResponsesSource'
        type:
          type: string
          description: The type of run data source. Always `completions`
          default: completions
          enum:
          - completions
        sampling_params:
          allOf:
          - $ref: '#/components/schemas/CreateEvalCompletionsRunDataSourceSamplingParams'
          x-ballerina-name: samplingParams
      description: |
        A ResponsesRunDataSource object describing a model sampling configuration
      x-oaiMeta:
        name: The completions data source object used to configure an individual run
        group: eval runs
        example: |
          {
            "name": "gpt-4o-mini-2024-07-18",
            "data_source": {
              "type": "completions",
              "input_messages": {
                "type": "item_reference",
                "item_reference": "item.input"
              },
              "model": "gpt-4o-mini-2024-07-18",
              "source": {
                "type": "stored_completions",
                "model": "gpt-4o-mini-2024-07-18"
              }
            }
          }
    CreateUploadRequest:
      required:
      - bytes
      - filename
      - mime_type
      - purpose
      type: object
      properties:
        filename:
          type: string
          description: |
            The name of the file to upload
        purpose:
          type: string
          description: |
            The intended purpose of the uploaded file.

            See the [documentation on File purposes](/docs/api-reference/files/create#files-create-purpose)
          enum:
          - assistants
          - batch
          - fine-tune
          - vision
        mime_type:
          type: string
          description: |
            The MIME type of the file.

            This must fall within the supported MIME types for your file purpose. See the supported MIME types for assistants and vision
          x-ballerina-name: mimeType
        bytes:
          type: integer
          description: |
            The number of bytes in the file you are uploading
      additionalProperties: false
    MessageDeltaContentTextAnnotationsFilePathObjectFilePath:
      type: object
      properties:
        file_id:
          type: string
          description: The ID of the file that was generated
          x-ballerina-name: fileId
    CreateSpeechRequest:
      required:
      - input
      - model
      - voice
      type: object
      properties:
        voice:
          $ref: '#/components/schemas/VoiceIdsShared'
        input:
          maxLength: 4096
          type: string
          description: The text to generate audio for. The maximum length is 4096
            characters
        instructions:
          maxLength: 4096
          type: string
          description: Control the voice of your generated audio with additional instructions.
            Does not work with `tts-1` or `tts-1-hd`
        response_format:
          type: string
          description: "The format to audio in. Supported formats are `mp3`, `opus`,\
            \ `aac`, `flac`, `wav`, and `pcm`"
          default: mp3
          enum:
          - mp3
          - opus
          - aac
          - flac
          - wav
          - pcm
          x-ballerina-name: responseFormat
        model:
          description: |
            One of the available [TTS models](/docs/models#tts): `tts-1`, `tts-1-hd` or `gpt-4o-mini-tts`
          anyOf:
          - type: string
          - type: string
            enum:
            - tts-1
            - tts-1-hd
            - gpt-4o-mini-tts
          x-oaiTypeLabel: string
        speed:
          maximum: 4
          minimum: 0.25
          type: number
          description: The speed of the generated audio. Select a value from `0.25`
            to `4.0`. `1.0` is the default
          default: 1
      additionalProperties: false
    EvalStoredCompletionsDataSourceConfig:
      title: StoredCompletionsDataSourceConfig
      required:
      - schema
      - type
      type: object
      properties:
        schema:
          type: object
          additionalProperties: true
          description: |
            The json schema for the run data source items.
            Learn how to build JSON schemas [here](https://json-schema.org/)
        metadata:
          $ref: '#/components/schemas/Metadata'
        type:
          type: string
          description: The type of data source. Always `stored_completions`
          default: stored_completions
          enum:
          - stored_completions
          x-stainless-const: true
      description: |
        A StoredCompletionsDataSourceConfig which specifies the metadata property of your stored completions query.
        This is usually metadata like `usecase=chatbot` or `prompt-version=v2`, etc.
        The schema returned by this data source config is used to defined what variables are available in your evals.
        `item` and `sample` are both defined when using this data source config
      x-oaiMeta:
        name: The stored completions data source object for evals
        group: evals
        example: |
          {
            "type": "stored_completions",
            "metadata": {
              "language": "english"
            },
            "schema": {
              "type": "object",
              "properties": {
                "item": {
                  "type": "object"
                },
                "sample": {
                  "type": "object"
                }
              },
              "required": [
                "item",
                "sample"
              }
          }
    MessageStreamEventMessageStreamEventMessageStreamEventOneOf123:
      required:
      - data
      - event
      type: object
      properties:
        data:
          $ref: '#/components/schemas/MessageDeltaObject'
        event:
          type: string
          enum:
          - thread.message.delta
          x-stainless-const: true
      description: "Occurs when parts of a [Message](/docs/api-reference/messages/object)\
        \ are being streamed"
      x-oaiMeta:
        dataDescription: "`data` is a [message delta](/docs/api-reference/assistants-streaming/message-delta-object)"
    CreateMessageRequestTools:
      oneOf:
      - $ref: '#/components/schemas/AssistantToolsCode'
      - $ref: '#/components/schemas/AssistantToolsFileSearchTypeOnly'
    ChatCompletionRequestMessageContentPartText:
      title: Text content part
      required:
      - text
      - type
      type: object
      properties:
        text:
          type: string
          description: The text content
        type:
          type: string
          description: The type of the content part
          enum:
          - text
          x-stainless-const: true
      description: |
        Learn about [text inputs](/docs/guides/text-generation)
    ModifyThreadRequest:
      type: object
      properties:
        tool_resources:
          allOf:
          - $ref: '#/components/schemas/ModifyThreadRequestToolResources'
          x-ballerina-name: toolResources
        metadata:
          $ref: '#/components/schemas/Metadata'
      additionalProperties: false
    FineTuneChatRequestInput:
      type: object
      properties:
        parallel_tool_calls:
          allOf:
          - $ref: '#/components/schemas/ParallelToolCalls'
          x-ballerina-name: parallelToolCalls
        functions:
          maxItems: 128
          minItems: 1
          type: array
          description: A list of functions the model may generate JSON inputs for
          deprecated: true
          items:
            $ref: '#/components/schemas/ChatCompletionFunctions'
        messages:
          minItems: 1
          type: array
          items:
            $ref: '#/components/schemas/FineTuneChatRequestInputMessages'
        tools:
          type: array
          description: A list of tools the model may generate JSON inputs for
          items:
            $ref: '#/components/schemas/ChatCompletionTool'
      description: The per-line training example of a fine-tuning input file for chat
        models using the supervised method
      x-oaiMeta:
        name: Training format for chat models using the supervised method
        example: |
          {
            "messages": [
              { "role": "user", "content": "What is the weather in San Francisco?" },
              {
                "role": "assistant",
                "tool_calls": [
                  {
                    "id": "call_id",
                    "type": "function",
                    "function": {
                      "name": "get_current_weather",
                      "arguments": "{\"location\": \"San Francisco, USA\", \"format\": \"celsius\"}"
                    }
                  }
                ]
              }
            ],
            "parallel_tool_calls": false,
            "tools": [
              {
                "type": "function",
                "function": {
                  "name": "get_current_weather",
                  "description": "Get the current weather",
                  "parameters": {
                    "type": "object",
                    "properties": {
                      "location": {
                          "type": "string",
                          "description": "The city and country, eg. San Francisco, USA"
                      },
                      "format": { "type": "string", "enum": ["celsius", "fahrenheit"] }
                    },
                    "required": ["location", "format"]
                  }
                }
              }
            ]
          }
    MessageContentTextObject:
      title: Text
      required:
      - text
      - type
      type: object
      properties:
        text:
          $ref: '#/components/schemas/MessageContentTextObjectText'
        type:
          type: string
          description: Always `text`
          enum:
          - text
          x-stainless-const: true
      description: The text content that is part of a message
    DeleteMessageResponse:
      required:
      - deleted
      - id
      - object
      type: object
      properties:
        deleted:
          type: boolean
        id:
          type: string
        object:
          type: string
          enum:
          - thread.message.deleted
          x-stainless-const: true
    ResponseContentPartDoneEvent:
      required:
      - content_index
      - item_id
      - output_index
      - part
      - type
      type: object
      properties:
        item_id:
          type: string
          description: |
            The ID of the output item that the content part was added to
          x-ballerina-name: itemId
        content_index:
          type: integer
          description: |
            The index of the content part that is done
          x-ballerina-name: contentIndex
        part:
          $ref: '#/components/schemas/OutputContent'
        type:
          type: string
          description: |
            The type of the event. Always `response.content_part.done`
          enum:
          - response.content_part.done
          x-stainless-const: true
        output_index:
          type: integer
          description: |
            The index of the output item that the content part was added to
          x-ballerina-name: outputIndex
      description: Emitted when a content part is done
      x-oaiMeta:
        name: response.content_part.done
        group: responses
        example: |
          {
            "type": "response.content_part.done",
            "item_id": "msg_123",
            "output_index": 0,
            "content_index": 0,
            "part": {
              "type": "output_text",
              "text": "In a shimmering forest under a sky full of stars, a lonely unicorn named Lila discovered a hidden pond that glowed with moonlight. Every night, she would leave sparkling, magical flowers by the water's edge, hoping to share her beauty with others. One enchanting evening, she woke to find a group of friendly animals gathered around, eager to be friends and share in her magic.",
              "annotations": []
            }
          }
    FineTunePreferenceRequestInput:
      type: object
      properties:
        input:
          $ref: '#/components/schemas/FineTunePreferenceRequestInputInput'
        non_preferred_completion:
          maxItems: 1
          type: array
          description: The non-preferred completion message for the output
          items:
            $ref: '#/components/schemas/FineTunePreferenceRequestInputPreferredCompletion'
          x-ballerina-name: nonPreferredCompletion
        preferred_completion:
          maxItems: 1
          type: array
          description: The preferred completion message for the output
          items:
            $ref: '#/components/schemas/FineTunePreferenceRequestInputPreferredCompletion'
          x-ballerina-name: preferredCompletion
      description: The per-line training example of a fine-tuning input file for chat
        models using the dpo method
      x-oaiMeta:
        name: Training format for chat models using the preference method
        example: |
          {
            "input": {
              "messages": [
                { "role": "user", "content": "What is the weather in San Francisco?" }
              ]
            },
            "preferred_completion": [
              {
                "role": "assistant",
                "content": "The weather in San Francisco is 70 degrees Fahrenheit."
              }
            ],
            "non_preferred_completion": [
              {
                "role": "assistant",
                "content": "The weather in San Francisco is 21 degrees Celsius."
              }
            ]
          }
    MessageStreamEvent:
      oneOf:
      - $ref: '#/components/schemas/MessageStreamEventOneOf1'
      - $ref: '#/components/schemas/MessageStreamEventMessageStreamEventOneOf12'
      - $ref: '#/components/schemas/MessageStreamEventMessageStreamEventMessageStreamEventOneOf123'
      - $ref: '#/components/schemas/MessageStreamEventMessageStreamEventMessageStreamEventMessageStreamEventOneOf1234'
      - $ref: '#/components/schemas/MessageStreamEventMessageStreamEventMessageStreamEventMessageStreamEventMessageStreamEventOneOf12345'
    RealtimeServerEventError:
      required:
      - error
      - event_id
      - type
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event
          x-ballerina-name: eventId
        type:
          type: string
          description: "The event type, must be `error`"
          enum:
          - error
          x-stainless-const: true
        error:
          $ref: '#/components/schemas/RealtimeServerEventErrorError'
      description: "Returned when an error occurs, which could be a client problem\
        \ or a server \nproblem. Most errors are recoverable and the session will\
        \ stay open, we \nrecommend to implementors to monitor and log error messages\
        \ by default\n"
      x-oaiMeta:
        name: error
        group: realtime
        example: |
          {
              "event_id": "event_890",
              "type": "error",
              "error": {
                  "type": "invalid_request_error",
                  "code": "invalid_event",
                  "message": "The 'type' field is missing.",
                  "param": null,
                  "event_id": "event_567"
              }
          }
    RunStepDeltaObjectDelta:
      type: object
      properties:
        step_details:
          type: object
          description: The details of the run step
          oneOf:
          - $ref: '#/components/schemas/RunStepDeltaStepDetailsMessageCreationObject'
          - $ref: '#/components/schemas/RunStepDeltaStepDetailsToolCallsObject'
          x-ballerina-name: stepDetails
      description: The delta containing the fields that have changed on the run step
    AssistantsNamedToolChoiceFunction:
      required:
      - name
      type: object
      properties:
        name:
          type: string
          description: The name of the function to call
    EvalLabelModelGrader:
      title: LabelModelGrader
      required:
      - input
      - labels
      - model
      - name
      - passing_labels
      - type
      type: object
      properties:
        input:
          type: array
          items:
            $ref: '#/components/schemas/EvalItem'
        name:
          type: string
          description: The name of the grader
        model:
          type: string
          description: The model to use for the evaluation. Must support structured
            outputs
        passing_labels:
          type: array
          description: The labels that indicate a passing result. Must be a subset
            of labels
          items:
            type: string
          x-ballerina-name: passingLabels
        type:
          type: string
          description: "The object type, which is always `label_model`"
          enum:
          - label_model
          x-stainless-const: true
        labels:
          type: array
          description: The labels to assign to each item in the evaluation
          items:
            type: string
      description: |
        A LabelModelGrader object which uses a model to assign labels to each item
        in the evaluation
      x-oaiMeta:
        name: The eval label model grader object
        group: evals
        example: |
          {
            "name": "First label grader",
            "type": "label_model",
            "model": "gpt-4o-2024-08-06",
            "input": [
              {
                "type": "message",
                "role": "system",
                "content": {
                  "type": "input_text",
                  "text": "Classify the sentiment of the following statement as one of positive, neutral, or negative"
                }
              },
              {
                "type": "message",
                "role": "user",
                "content": {
                  "type": "input_text",
                  "text": "Statement: {{item.response}}"
                }
              }
            ],
            "passing_labels": [
              "positive"
            ],
            "labels": [
              "positive",
              "neutral",
              "negative"
            ]
          }
    Embedding:
      required:
      - embedding
      - index
      - object
      type: object
      properties:
        index:
          type: integer
          description: The index of the embedding in the list of embeddings
        embedding:
          type: array
          description: |
            The embedding vector, which is a list of floats. The length of vector depends on the model as listed in the [embedding guide](/docs/guides/embeddings)
          items:
            type: number
        object:
          type: string
          description: "The object type, which is always \"embedding\""
          enum:
          - embedding
          x-stainless-const: true
      description: |
        Represents an embedding vector returned by embedding endpoint
      x-oaiMeta:
        name: The embedding object
        example: |
          {
            "object": "embedding",
            "embedding": [
              0.0023064255,
              -0.009327292,
              .... (1536 floats total for ada-002)
              -0.0028842222,
            ],
            "index": 0
          }
    EvalRunOutputItemSampleInput:
      required:
      - content
      - role
      type: object
      properties:
        role:
          type: string
          description: "The role of the message sender (e.g., system, user, developer)"
        content:
          type: string
          description: The content of the message
      description: An input message
    MessageContentRefusalObject:
      title: Refusal
      required:
      - refusal
      - type
      type: object
      properties:
        refusal:
          type: string
          nullable: false
        type:
          type: string
          description: Always `refusal`
          enum:
          - refusal
          x-stainless-const: true
      description: The refusal content generated by the assistant
    RunStepDetailsMessageCreationObjectMessageCreation:
      required:
      - message_id
      type: object
      properties:
        message_id:
          type: string
          description: The ID of the message that was created by this run step
          x-ballerina-name: messageId
    AuditLogLoginfailed:
      type: object
      properties:
        error_message:
          type: string
          description: The error message of the failure
          x-ballerina-name: errorMessage
        error_code:
          type: string
          description: The error code of the failure
          x-ballerina-name: errorCode
      description: The details for events with this `type`
    RunStepStreamEventRunStepStreamEventRunStepStreamEventOneOf123:
      required:
      - data
      - event
      type: object
      properties:
        data:
          $ref: '#/components/schemas/RunStepDeltaObject'
        event:
          type: string
          enum:
          - thread.run.step.delta
          x-stainless-const: true
      description: "Occurs when parts of a [run step](/docs/api-reference/run-steps/step-object)\
        \ are being streamed"
      x-oaiMeta:
        dataDescription: "`data` is a [run step delta](/docs/api-reference/assistants-streaming/run-step-delta-object)"
    RealtimeServerEventConversationCreated:
      required:
      - conversation
      - event_id
      - type
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event
          x-ballerina-name: eventId
        type:
          type: string
          description: "The event type, must be `conversation.created`"
          enum:
          - conversation.created
          x-stainless-const: true
        conversation:
          $ref: '#/components/schemas/RealtimeServerEventConversationCreatedConversation'
      description: |
        Returned when a conversation is created. Emitted right after session creation
      x-oaiMeta:
        name: conversation.created
        group: realtime
        example: |
          {
              "event_id": "event_9101",
              "type": "conversation.created",
              "conversation": {
                  "id": "conv_001",
                  "object": "realtime.conversation"
              }
          }
    RealtimeClientEventInputAudioBufferClear:
      required:
      - type
      type: object
      properties:
        event_id:
          type: string
          description: Optional client-generated ID used to identify this event
          x-ballerina-name: eventId
        type:
          type: string
          description: "The event type, must be `input_audio_buffer.clear`"
          enum:
          - input_audio_buffer.clear
          x-stainless-const: true
      description: "Send this event to clear the audio bytes in the buffer. The server\
        \ will \nrespond with an `input_audio_buffer.cleared` event\n"
      x-oaiMeta:
        name: input_audio_buffer.clear
        group: realtime
        example: |
          {
              "event_id": "event_012",
              "type": "input_audio_buffer.clear"
          }
    ComputerToolCallOutput:
      title: Computer tool call output
      required:
      - call_id
      - output
      - type
      type: object
      properties:
        output:
          $ref: '#/components/schemas/ComputerScreenshotImage'
        acknowledged_safety_checks:
          type: array
          description: "The safety checks reported by the API that have been acknowledged\
            \ by the \ndeveloper\n"
          items:
            $ref: '#/components/schemas/ComputerToolCallSafetyCheck'
          x-ballerina-name: acknowledgedSafetyChecks
        id:
          type: string
          description: |
            The ID of the computer tool call output
        type:
          type: string
          description: |
            The type of the computer tool call output. Always `computer_call_output`
          default: computer_call_output
          enum:
          - computer_call_output
          x-stainless-const: true
        call_id:
          type: string
          description: |
            The ID of the computer tool call that produced the output
          x-ballerina-name: callId
        status:
          type: string
          description: |
            The status of the message input. One of `in_progress`, `completed`, or
            `incomplete`. Populated when input items are returned via API
          enum:
          - in_progress
          - completed
          - incomplete
      description: |
        The output of a computer tool call
    CreateChatCompletionRequest:
      allOf:
      - $ref: '#/components/schemas/CreateModelResponseProperties'
      - $ref: '#/components/schemas/CreateChatCompletionRequestAllOf2'
    EvalCustomDataSourceConfig:
      title: CustomDataSourceConfig
      required:
      - schema
      - type
      type: object
      properties:
        schema:
          type: object
          additionalProperties: true
          description: |
            The json schema for the run data source items.
            Learn how to build JSON schemas [here](https://json-schema.org/)
          example: |
            {
              "type": "object",
              "properties": {
                "item": {
                  "type": "object",
                  "properties": {
                    "label": {"type": "string"},
                  },
                  "required": ["label"]
                }
              },
              "required": ["item"]
            }
        type:
          type: string
          description: The type of data source. Always `custom`
          default: custom
          enum:
          - custom
          x-stainless-const: true
      description: |
        A CustomDataSourceConfig which specifies the schema of your `item` and optionally `sample` namespaces.
        The response schema defines the shape of the data that will be:
        - Used to define your testing criteria and
        - What data is required when creating a run
      x-oaiMeta:
        name: The eval custom data source config object
        group: evals
        example: |
          {
            "type": "custom",
            "schema": {
              "type": "object",
              "properties": {
                "item": {
                  "type": "object",
                  "properties": {
                    "label": {"type": "string"},
                  },
                  "required": ["label"]
                }
              },
              "required": ["item"]
            }
          }
    CreateModerationResponseCategories:
      required:
      - harassment
      - harassment/threatening
      - hate
      - hate/threatening
      - illicit
      - illicit/violent
      - self-harm
      - self-harm/instructions
      - self-harm/intent
      - sexual
      - sexual/minors
      - violence
      - violence/graphic
      type: object
      properties:
        illicit/violent:
          type: boolean
          description: "Content that includes instructions or advice that facilitate\
            \ the planning or execution of wrongdoing that also includes violence,\
            \ or that gives advice or instruction on the procurement of any weapon"
          nullable: true
          x-ballerina-name: illicitViolent
        self-harm/instructions:
          type: boolean
          description: "Content that encourages performing acts of self-harm, such\
            \ as suicide, cutting, and eating disorders, or that gives instructions\
            \ or advice on how to commit such acts"
          x-ballerina-name: selfHarmInstructions
        harassment:
          type: boolean
          description: "Content that expresses, incites, or promotes harassing language\
            \ towards any target"
        violence/graphic:
          type: boolean
          description: "Content that depicts death, violence, or physical injury in\
            \ graphic detail"
          x-ballerina-name: violenceGraphic
        illicit:
          type: boolean
          description: "Content that includes instructions or advice that facilitate\
            \ the planning or execution of wrongdoing, or that gives advice or instruction\
            \ on how to commit illicit acts. For example, \"how to shoplift\" would\
            \ fit this category"
          nullable: true
        self-harm/intent:
          type: boolean
          description: "Content where the speaker expresses that they are engaging\
            \ or intend to engage in acts of self-harm, such as suicide, cutting,\
            \ and eating disorders"
          x-ballerina-name: selfHarmIntent
        hate/threatening:
          type: boolean
          description: "Hateful content that also includes violence or serious harm\
            \ towards the targeted group based on race, gender, ethnicity, religion,\
            \ nationality, sexual orientation, disability status, or caste"
          x-ballerina-name: hateThreatening
        sexual/minors:
          type: boolean
          description: Sexual content that includes an individual who is under 18
            years old
          x-ballerina-name: sexualMinors
        harassment/threatening:
          type: boolean
          description: Harassment content that also includes violence or serious harm
            towards any target
          x-ballerina-name: harassmentThreatening
        hate:
          type: boolean
          description: "Content that expresses, incites, or promotes hate based on\
            \ race, gender, ethnicity, religion, nationality, sexual orientation,\
            \ disability status, or caste. Hateful content aimed at non-protected\
            \ groups (e.g., chess players) is harassment"
        self-harm:
          type: boolean
          description: "Content that promotes, encourages, or depicts acts of self-harm,\
            \ such as suicide, cutting, and eating disorders"
          x-ballerina-name: selfHarm
        sexual:
          type: boolean
          description: "Content meant to arouse sexual excitement, such as the description\
            \ of sexual activity, or that promotes sexual services (excluding sex\
            \ education and wellness)"
        violence:
          type: boolean
          description: "Content that depicts death, violence, or physical injury"
      description: "A list of the categories, and whether they are flagged or not"
    RunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventOneOf1234567:
      required:
      - data
      - event
      type: object
      properties:
        data:
          $ref: '#/components/schemas/RunObject'
        event:
          type: string
          enum:
          - thread.run.failed
          x-stainless-const: true
      description: "Occurs when a [run](/docs/api-reference/runs/object) fails"
      x-oaiMeta:
        dataDescription: "`data` is a [run](/docs/api-reference/runs/object)"
    FileCitationBody:
      title: File citation
      required:
      - file_id
      - index
      - type
      type: object
      properties:
        file_id:
          type: string
          description: The ID of the file
          x-ballerina-name: fileId
        index:
          type: integer
          description: The index of the file in the list of files
        type:
          type: string
          description: The type of the file citation. Always `file_citation`
          default: file_citation
          enum:
          - file_citation
          x-stainless-const: true
      description: A citation to a file
    OrganizationAdminApiKeysBody:
      required:
      - name
      type: object
      properties:
        name:
          type: string
          example: New Admin Key
    ModifyAssistantRequestToolResources:
      type: object
      properties:
        code_interpreter:
          allOf:
          - $ref: '#/components/schemas/ModifyAssistantRequestToolResourcesCodeInterpreter'
          x-ballerina-name: codeInterpreter
        file_search:
          allOf:
          - $ref: '#/components/schemas/ModifyAssistantRequestToolResourcesFileSearch'
          x-ballerina-name: fileSearch
      description: |
        A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs
      nullable: true
    CompletionUsage:
      required:
      - completion_tokens
      - prompt_tokens
      - total_tokens
      type: object
      properties:
        completion_tokens:
          type: integer
          description: Number of tokens in the generated completion
          default: 0
          x-ballerina-name: completionTokens
        prompt_tokens:
          type: integer
          description: Number of tokens in the prompt
          default: 0
          x-ballerina-name: promptTokens
        completion_tokens_details:
          allOf:
          - $ref: '#/components/schemas/CompletionUsageCompletionTokensDetails'
          x-ballerina-name: completionTokensDetails
        prompt_tokens_details:
          allOf:
          - $ref: '#/components/schemas/CompletionUsagePromptTokensDetails'
          x-ballerina-name: promptTokensDetails
        total_tokens:
          type: integer
          description: Total number of tokens used in the request (prompt + completion)
          default: 0
          x-ballerina-name: totalTokens
      description: Usage statistics for the completion request
    RunToolCallObject:
      required:
      - function
      - id
      - type
      type: object
      properties:
        function:
          $ref: '#/components/schemas/RunToolCallObjectFunction'
        id:
          type: string
          description: "The ID of the tool call. This ID must be referenced when you\
            \ submit the tool outputs in using the [Submit tool outputs to run](/docs/api-reference/runs/submitToolOutputs)\
            \ endpoint"
        type:
          type: string
          description: "The type of tool call the output is required for. For now,\
            \ this is always `function`"
          enum:
          - function
          x-stainless-const: true
      description: Tool call objects
    VectorStoreObject:
      title: Vector store
      required:
      - created_at
      - file_counts
      - id
      - last_active_at
      - metadata
      - name
      - object
      - status
      - usage_bytes
      type: object
      properties:
        file_counts:
          allOf:
          - $ref: '#/components/schemas/VectorStoreObjectFileCounts'
          x-ballerina-name: fileCounts
        metadata:
          $ref: '#/components/schemas/Metadata'
        expires_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the vector store will
            expire
          nullable: true
          x-ballerina-name: expiresAt
        expires_after:
          allOf:
          - $ref: '#/components/schemas/VectorStoreExpirationAfter'
          x-ballerina-name: expiresAfter
        last_active_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the vector store was
            last active
          nullable: true
          x-ballerina-name: lastActiveAt
        usage_bytes:
          type: integer
          description: The total number of bytes used by the files in the vector store
          x-ballerina-name: usageBytes
        name:
          type: string
          description: The name of the vector store
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the vector store was
            created
          x-ballerina-name: createdAt
        id:
          type: string
          description: "The identifier, which can be referenced in API endpoints"
        object:
          type: string
          description: "The object type, which is always `vector_store`"
          enum:
          - vector_store
          x-stainless-const: true
        status:
          type: string
          description: "The status of the vector store, which can be either `expired`,\
            \ `in_progress`, or `completed`. A status of `completed` indicates that\
            \ the vector store is ready for use"
          enum:
          - expired
          - in_progress
          - completed
      description: A vector store is a collection of processed files can be used by
        the `file_search` tool
      x-oaiMeta:
        name: The vector store object
        example: |
          {
            "id": "vs_123",
            "object": "vector_store",
            "created_at": 1698107661,
            "usage_bytes": 123456,
            "last_active_at": 1698107661,
            "name": "my_vector_store",
            "status": "completed",
            "file_counts": {
              "in_progress": 0,
              "completed": 100,
              "cancelled": 0,
              "failed": 0,
              "total": 100
            },
            "last_used_at": 1698107661
          }
    AuditLogActorApiKey:
      type: object
      properties:
        service_account:
          allOf:
          - $ref: '#/components/schemas/AuditLogActorServiceAccount'
          x-ballerina-name: serviceAccount
        id:
          type: string
          description: The tracking id of the API key
        type:
          type: string
          description: The type of API key. Can be either `user` or `service_account`
          enum:
          - user
          - service_account
        user:
          $ref: '#/components/schemas/AuditLogActorUser'
      description: The API Key used to perform the audit logged action
    ResponseReasoningSummaryTextDoneEvent:
      required:
      - item_id
      - output_index
      - summary_index
      - text
      - type
      type: object
      properties:
        item_id:
          type: string
          description: |
            The ID of the item this summary text is associated with
          x-ballerina-name: itemId
        summary_index:
          type: integer
          description: |
            The index of the summary part within the reasoning summary
          x-ballerina-name: summaryIndex
        text:
          type: string
          description: |
            The full text of the completed reasoning summary
        type:
          type: string
          description: |
            The type of the event. Always `response.reasoning_summary_text.done`
          enum:
          - response.reasoning_summary_text.done
          x-stainless-const: true
        output_index:
          type: integer
          description: |
            The index of the output item this summary text is associated with
          x-ballerina-name: outputIndex
      description: Emitted when a reasoning summary text is completed
      x-oaiMeta:
        name: response.reasoning_summary_text.done
        group: responses
        example: |
          {
            "type": "response.reasoning_summary_text.done",
            "item_id": "rs_6806bfca0b2481918a5748308061a2600d3ce51bdffd5476",
            "output_index": 0,
            "summary_index": 0,
            "text": "**Responding to a greeting**\n\nThe user just said, \"Hello!\" So, it seems I need to engage. I'll greet them back and offer help since they're looking to chat. I could say something like, \"Hello! How can I assist you today?\" That feels friendly and open. They didn't ask a specific question, so this approach will work well for starting a conversation. Let's see where it goes from there!"
          }
    AssistantToolsFunction:
      title: Function tool
      required:
      - function
      - type
      type: object
      properties:
        function:
          $ref: '#/components/schemas/FunctionObject'
        type:
          type: string
          description: "The type of tool being defined: `function`"
          enum:
          - function
          x-stainless-const: true
    CreateCompletionResponse:
      required:
      - choices
      - created
      - id
      - model
      - object
      type: object
      properties:
        created:
          type: integer
          description: The Unix timestamp (in seconds) of when the completion was
            created
        usage:
          $ref: '#/components/schemas/CompletionUsage'
        model:
          type: string
          description: The model used for completion
        id:
          type: string
          description: A unique identifier for the completion
        choices:
          type: array
          description: The list of completion choices the model generated for the
            input prompt
          items:
            $ref: '#/components/schemas/CreateCompletionResponseChoices'
        system_fingerprint:
          type: string
          description: |
            This fingerprint represents the backend configuration that the model runs with.

            Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism
          x-ballerina-name: systemFingerprint
        object:
          type: string
          description: "The object type, which is always \"text_completion\""
          enum:
          - text_completion
          x-stainless-const: true
      description: |
        Represents a completion response from the API. Note: both the streamed and non-streamed response objects share the same shape (unlike the chat endpoint)
      x-oaiMeta:
        name: The completion object
        legacy: true
        example: |
          {
            "id": "cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7",
            "object": "text_completion",
            "created": 1589478378,
            "model": "gpt-4-turbo",
            "choices": [
              {
                "text": "\n\nThis is indeed a test",
                "index": 0,
                "logprobs": null,
                "finish_reason": "length"
              }
            ],
            "usage": {
              "prompt_tokens": 5,
              "completion_tokens": 7,
              "total_tokens": 12
            }
          }
    RealtimeTranscriptionSessionCreateResponseInputAudioTranscription:
      type: object
      properties:
        model:
          type: string
          description: |
            The model to use for transcription. Can be `gpt-4o-transcribe`, `gpt-4o-mini-transcribe`, or `whisper-1`
          enum:
          - gpt-4o-transcribe
          - gpt-4o-mini-transcribe
          - whisper-1
        language:
          type: string
          description: |
            The language of the input audio. Supplying the input language in
            [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) (e.g. `en`) format
            will improve accuracy and latency
        prompt:
          type: string
          description: |
            An optional text to guide the model's style or continue a previous audio
            segment. The [prompt](/docs/guides/speech-to-text#prompting) should match
            the audio language
      description: |
        Configuration of the transcription model
    TextResponseFormatJsonSchema:
      title: JSON schema
      required:
      - name
      - schema
      - type
      type: object
      properties:
        schema:
          $ref: '#/components/schemas/ResponseFormatJsonSchemaSchema'
        name:
          type: string
          description: |
            The name of the response format. Must be a-z, A-Z, 0-9, or contain
            underscores and dashes, with a maximum length of 64
        description:
          type: string
          description: |
            A description of what the response format is for, used by the model to
            determine how to respond in the format
        type:
          type: string
          description: The type of response format being defined. Always `json_schema`
          enum:
          - json_schema
          x-stainless-const: true
        strict:
          type: boolean
          description: |
            Whether to enable strict schema adherence when generating the output.
            If set to true, the model will always follow the exact schema defined
            in the `schema` field. Only a subset of JSON Schema is supported when
            `strict` is `true`. To learn more, read the [Structured Outputs
            guide](/docs/guides/structured-outputs)
          nullable: true
          default: false
      description: |
        JSON Schema response format. Used to generate structured JSON responses.
        Learn more about [Structured Outputs](/docs/guides/structured-outputs)
    FineTuneDPOMethod:
      type: object
      properties:
        hyperparameters:
          $ref: '#/components/schemas/FineTuneDPOMethodHyperparameters'
      description: Configuration for the DPO fine-tuning method
    TruncationObject:
      title: Thread Truncation Controls
      required:
      - type
      type: object
      properties:
        last_messages:
          minimum: 1
          type: integer
          description: The number of most recent messages from the thread when constructing
            the context for the run
          nullable: true
          x-ballerina-name: lastMessages
        type:
          type: string
          description: "The truncation strategy to use for the thread. The default\
            \ is `auto`. If set to `last_messages`, the thread will be truncated to\
            \ the n most recent messages in the thread. When set to `auto`, messages\
            \ in the middle of the thread will be dropped to fit the context length\
            \ of the model, `max_prompt_tokens`"
          enum:
          - auto
          - last_messages
      description: Controls for how a thread will be truncated prior to the run. Use
        this to control the intial context window of the run
    ChatCompletionRequestAssistantMessageContentPart:
      oneOf:
      - $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartText'
      - $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartRefusal'
    ErrorResponse:
      required:
      - error
      type: object
      properties:
        error:
          $ref: '#/components/schemas/Error'
    ResponseFormatJsonObject:
      title: JSON object
      required:
      - type
      type: object
      properties:
        type:
          type: string
          description: The type of response format being defined. Always `json_object`
          enum:
          - json_object
          x-stainless-const: true
      description: |
        JSON object response format. An older method of generating JSON responses.
        Using `json_schema` is recommended for models that support it. Note that the
        model will not generate JSON without a system or user message instructing it
        to do so
    VectorStoreObjectFileCounts:
      required:
      - cancelled
      - completed
      - failed
      - in_progress
      - total
      type: object
      properties:
        in_progress:
          type: integer
          description: The number of files that are currently being processed
          x-ballerina-name: inProgress
        total:
          type: integer
          description: The total number of files
        cancelled:
          type: integer
          description: The number of files that were cancelled
        completed:
          type: integer
          description: The number of files that have been successfully processed
        failed:
          type: integer
          description: The number of files that have failed to process
    ProjectUserListResponse:
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
      type: object
      properties:
        first_id:
          type: string
          x-ballerina-name: firstId
        data:
          type: array
          items:
            $ref: '#/components/schemas/ProjectUser'
        last_id:
          type: string
          x-ballerina-name: lastId
        has_more:
          type: boolean
          x-ballerina-name: hasMore
        object:
          type: string
    ToolChoiceFunction:
      title: Function tool
      required:
      - name
      - type
      type: object
      properties:
        name:
          type: string
          description: The name of the function to call
        type:
          type: string
          description: "For function calling, the type is always `function`"
          enum:
          - function
          x-stainless-const: true
      description: |
        Use this option to force the model to call a specific function
    RunStepDeltaStepDetailsMessageCreationObjectMessageCreation:
      type: object
      properties:
        message_id:
          type: string
          description: The ID of the message that was created by this run step
          x-ballerina-name: messageId
    ListMessagesResponse:
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
      properties:
        object:
          type: string
          example: list
        data:
          type: array
          items:
            $ref: '#/components/schemas/MessageObject'
        first_id:
          type: string
          example: msg_abc123
        last_id:
          type: string
          example: msg_abc123
        has_more:
          type: boolean
          example: false
    OutputMessage:
      title: Output message
      required:
      - content
      - id
      - role
      - status
      - type
      type: object
      properties:
        role:
          type: string
          description: |
            The role of the output message. Always `assistant`
          enum:
          - assistant
          x-stainless-const: true
        id:
          type: string
          description: |
            The unique ID of the output message
        type:
          type: string
          description: |
            The type of the output message. Always `message`
          enum:
          - message
          x-stainless-const: true
        content:
          type: array
          description: |
            The content of the output message
          items:
            $ref: '#/components/schemas/OutputContent'
        status:
          type: string
          description: |
            The status of the message input. One of `in_progress`, `completed`, or
            `incomplete`. Populated when input items are returned via API
          enum:
          - in_progress
          - completed
          - incomplete
      description: |
        An output message from the model
    FineTuningJobHyperparameters:
      type: object
      properties:
        batch_size:
          description: |
            Number of examples in each batch. A larger batch size means that model parameters
            are updated less frequently, but with lower variance
          oneOf:
          - type: string
            enum:
            - auto
            x-stainless-const: true
          - maximum: 256
            minimum: 1
            type: integer
          default: auto
          x-ballerina-name: batchSize
        n_epochs:
          description: |
            The number of epochs to train the model for. An epoch refers to one full cycle
            through the training dataset
          oneOf:
          - type: string
            enum:
            - auto
            x-stainless-const: true
          - maximum: 50
            minimum: 1
            type: integer
          default: auto
          x-ballerina-name: nEpochs
        learning_rate_multiplier:
          description: |
            Scaling factor for the learning rate. A smaller learning rate may be useful to avoid
            overfitting
          oneOf:
          - type: string
            enum:
            - auto
            x-stainless-const: true
          - minimum: 0
            exclusiveMinimum: true
            type: number
          default: auto
          x-ballerina-name: learningRateMultiplier
      description: The hyperparameters used for the fine-tuning job. This value will
        only be returned when running `supervised` jobs
    ChatCompletionRequestMessageContentPartFile:
      title: File content part
      required:
      - file
      - type
      type: object
      properties:
        file:
          $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartFileFile'
        type:
          type: string
          description: The type of the content part. Always `file`
          enum:
          - file
          x-stainless-const: true
      description: |
        Learn about [file inputs](/docs/guides/text) for text generation
    InlineResponse2001:
      oneOf:
      - $ref: '#/components/schemas/CreateTranslationResponseJson'
      - $ref: '#/components/schemas/CreateTranslationResponseVerboseJson'
    Screenshot:
      title: Screenshot
      required:
      - type
      type: object
      properties:
        type:
          type: string
          description: "Specifies the event type. For a screenshot action, this property\
            \ is \nalways set to `screenshot`\n"
          default: screenshot
          enum:
          - screenshot
          x-stainless-const: true
      description: |
        A screenshot action
    InlineResponse2003:
      type: object
      properties:
        deleted:
          type: boolean
          example: true
        run_id:
          type: string
          example: evalrun_677469f564d48190807532a852da3afb
          x-ballerina-name: runId
        object:
          type: string
          example: eval.run.deleted
    CostsResult:
      required:
      - object
      type: object
      properties:
        amount:
          $ref: '#/components/schemas/CostsResultAmount'
        line_item:
          type: string
          description: "When `group_by=line_item`, this field provides the line item\
            \ of the grouped costs result"
          nullable: true
          x-ballerina-name: lineItem
        project_id:
          type: string
          description: "When `group_by=project_id`, this field provides the project\
            \ ID of the grouped costs result"
          nullable: true
          x-ballerina-name: projectId
        object:
          type: string
          enum:
          - organization.costs.result
          x-stainless-const: true
      description: The aggregated costs details of the specific time bucket
      x-oaiMeta:
        name: Costs object
        example: |
          {
              "object": "organization.costs.result",
              "amount": {
                "value": 0.06,
                "currency": "usd"
              },
              "line_item": "Image models",
              "project_id": "proj_abc"
          }
    InlineResponse2002:
      required:
      - deleted
      - eval_id
      - object
      type: object
      properties:
        deleted:
          type: boolean
          example: true
        eval_id:
          type: string
          example: eval_abc123
          x-ballerina-name: evalId
        object:
          type: string
          example: eval.deleted
    RealtimeClientEventResponseCreate:
      required:
      - type
      type: object
      properties:
        event_id:
          type: string
          description: Optional client-generated ID used to identify this event
          x-ballerina-name: eventId
        response:
          $ref: '#/components/schemas/RealtimeResponseCreateParams'
        type:
          type: string
          description: "The event type, must be `response.create`"
          enum:
          - response.create
          x-stainless-const: true
      description: "This event instructs the server to create a Response, which means\
        \ triggering \nmodel inference. When in Server VAD mode, the server will create\
        \ Responses \nautomatically.\n\nA Response will include at least one Item,\
        \ and may have two, in which case \nthe second will be a function call. These\
        \ Items will be appended to the \nconversation history.\n\nThe server will\
        \ respond with a `response.created` event, events for Items \nand content\
        \ created, and finally a `response.done` event to indicate the \nResponse\
        \ is complete.\n\nThe `response.create` event includes inference configuration\
        \ like \n`instructions`, and `temperature`. These fields will override the\
        \ Session's \nconfiguration for this Response only\n"
      x-oaiMeta:
        name: response.create
        group: realtime
        example: |
          {
              "event_id": "event_234",
              "type": "response.create",
              "response": {
                  "modalities": ["text", "audio"],
                  "instructions": "Please assist the user.",
                  "voice": "sage",
                  "output_audio_format": "pcm16",
                  "tools": [
                      {
                          "type": "function",
                          "name": "calculate_sum",
                          "description": "Calculates the sum of two numbers.",
                          "parameters": {
                              "type": "object",
                              "properties": {
                                  "a": { "type": "number" },
                                  "b": { "type": "number" }
                              },
                              "required": ["a", "b"]
                          }
                      }
                  ],
                  "tool_choice": "auto",
                  "temperature": 0.8,
                  "max_output_tokens": 1024
              }
          }
    InlineResponse2004:
      type: object
      properties:
        deleted:
          type: boolean
          example: true
        id:
          type: string
          example: key_abc
        object:
          type: string
          example: organization.admin_api_key.deleted
    RunStepDetailsToolCallsCodeObjectCodeInterpreterOutputs:
      type: object
      oneOf:
      - $ref: '#/components/schemas/RunStepDetailsToolCallsCodeOutputLogsObject'
      - $ref: '#/components/schemas/RunStepDetailsToolCallsCodeOutputImageObject'
    CreateTranscriptionResponseJson:
      required:
      - text
      type: object
      properties:
        text:
          type: string
          description: The transcribed text
        logprobs:
          type: array
          description: |
            The log probabilities of the tokens in the transcription. Only returned with the models `gpt-4o-transcribe` and `gpt-4o-mini-transcribe` if `logprobs` is added to the `include` array
          items:
            $ref: '#/components/schemas/CreateTranscriptionResponseJsonLogprobs'
      description: "Represents a transcription response returned by model, based on\
        \ the provided input"
      x-oaiMeta:
        name: The transcription object (JSON)
        group: audio
        example: |
          {
            "text": "Imagine the wildest idea that you've ever had, and you're curious about how it might scale to something that's a 100, a 1,000 times bigger. This is a place where you can get to do that."
          }
    RunStepCompletionUsage:
      required:
      - completion_tokens
      - prompt_tokens
      - total_tokens
      type: object
      properties:
        completion_tokens:
          type: integer
          description: Number of completion tokens used over the course of the run
            step
          x-ballerina-name: completionTokens
        prompt_tokens:
          type: integer
          description: Number of prompt tokens used over the course of the run step
          x-ballerina-name: promptTokens
        total_tokens:
          type: integer
          description: Total number of tokens used (prompt + completion)
          x-ballerina-name: totalTokens
      description: Usage statistics related to the run step. This value will be `null`
        while the run step's status is `in_progress`
      nullable: true
    ResponseModalities:
      type: array
      description: "Output types that you would like the model to generate.\nMost\
        \ models are capable of generating text, which is the default:\n\n`[\"text\"\
        ]`\n\nThe `gpt-4o-audio-preview` model can also be used to \n[generate audio](/docs/guides/audio).\
        \ To request that this model generate \nboth text and audio responses, you\
        \ can use:\n\n`[\"text\", \"audio\"]`\n"
      nullable: true
      items:
        type: string
        enum:
        - text
        - audio
    DeleteVectorStoreFileResponse:
      required:
      - deleted
      - id
      - object
      type: object
      properties:
        deleted:
          type: boolean
        id:
          type: string
        object:
          type: string
          enum:
          - vector_store.file.deleted
          x-stainless-const: true
    EvalItem:
      title: Eval message object
      required:
      - content
      - role
      type: object
      properties:
        role:
          type: string
          description: |
            The role of the message input. One of `user`, `assistant`, `system`, or
            `developer`
          enum:
          - user
          - assistant
          - system
          - developer
        type:
          type: string
          description: |
            The type of the message input. Always `message`
          enum:
          - message
          x-stainless-const: true
        content:
          description: |
            Text inputs to the model - can contain template strings
          oneOf:
          - title: Text input
            type: string
            description: |
              A text input to the model.
          - $ref: '#/components/schemas/InputTextContent'
          - title: Output text
            required:
            - text
            - type
            type: object
            properties:
              type:
                type: string
                description: |
                  The type of the output text. Always `output_text`.
                enum:
                - output_text
                x-stainless-const: true
              text:
                type: string
                description: |
                  The text output from the model.
            description: |
              A text output from the model.
      description: |
        A message input to the model with a role indicating instruction following
        hierarchy. Instructions given with the `developer` or `system` role take
        precedence over instructions given with the `user` role. Messages with the
        `assistant` role are presumed to have been generated by the model in previous
        interactions
    FunctionTool:
      title: Function
      required:
      - name
      - parameters
      - strict
      - type
      type: object
      properties:
        name:
          type: string
          description: The name of the function to call
        description:
          anyOf:
          - type: string
            description: A description of the function. Used by the model to determine
              whether or not to call the function.
          - nullable: true
        type:
          type: string
          description: The type of the function tool. Always `function`
          default: function
          enum:
          - function
          x-stainless-const: true
        strict:
          anyOf:
          - type: boolean
            description: Whether to enforce strict parameter validation. Default `true`.
          - nullable: true
        parameters:
          anyOf:
          - type: object
            additionalProperties: {}
            description: A JSON schema object describing the parameters of the function.
          - nullable: true
      description: "Defines a function in your own code the model can choose to call.\
        \ Learn more about [function calling](https://platform.openai.com/docs/guides/function-calling)"
    FineTuneCompletionRequestInput:
      type: object
      properties:
        completion:
          type: string
          description: The desired completion for this training example
        prompt:
          type: string
          description: The input prompt for this training example
      description: The per-line training example of a fine-tuning input file for completions
        models
      x-oaiMeta:
        name: Training format for completions models
        example: |
          {
            "prompt": "What is the answer to 2+2",
            "completion": "4"
          }
    VectorStoreFileContentResponse:
      required:
      - data
      - has_more
      - next_page
      - object
      type: object
      properties:
        next_page:
          type: string
          description: "The token for the next page, if any"
          nullable: true
          x-ballerina-name: nextPage
        data:
          type: array
          description: Parsed content of the file
          items:
            $ref: '#/components/schemas/VectorStoreFileContentResponseData'
        has_more:
          type: boolean
          description: Indicates if there are more content pages to fetch
          x-ballerina-name: hasMore
        object:
          type: string
          description: "The object type, which is always `vector_store.file_content.page`"
          enum:
          - vector_store.file_content.page
          x-stainless-const: true
      description: Represents the parsed content of a vector store file
    BatchErrors:
      type: object
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/BatchErrorsData'
        object:
          type: string
          description: "The object type, which is always `list`"
    ProjectServiceAccount:
      required:
      - created_at
      - id
      - name
      - object
      - role
      type: object
      properties:
        role:
          type: string
          description: '`owner` or `member`'
          enum:
          - owner
          - member
        name:
          type: string
          description: The name of the service account
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) of when the service account
            was created
          x-ballerina-name: createdAt
        id:
          type: string
          description: "The identifier, which can be referenced in API endpoints"
        object:
          type: string
          description: "The object type, which is always `organization.project.service_account`"
          enum:
          - organization.project.service_account
          x-stainless-const: true
      description: Represents an individual service account in a project
      x-oaiMeta:
        name: The project service account object
        example: |
          {
              "object": "organization.project.service_account",
              "id": "svc_acct_abc",
              "name": "Service Account",
              "role": "owner",
              "created_at": 1711471533
          }
    CreateEvalLogsDataSourceConfig:
      title: LogsDataSourceConfig
      required:
      - type
      type: object
      properties:
        metadata:
          type: object
          additionalProperties: true
          description: Metadata filters for the logs data source
          example: |
            {
              "use_case": "customer_support_agent"
            }
        type:
          type: string
          description: The type of data source. Always `logs`
          default: logs
          enum:
          - logs
          x-stainless-const: true
      description: |
        A data source config which specifies the metadata property of your stored completions query.
        This is usually metadata like `usecase=chatbot` or `prompt-version=v2`, etc
      x-oaiMeta:
        name: The logs data source object for evals
        group: evals
        example: |
          {
            "type": "logs",
            "metadata": {
              "use_case": "customer_support_agent"
            }
          }
    ProjectListResponse:
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
      type: object
      properties:
        first_id:
          type: string
          x-ballerina-name: firstId
        data:
          type: array
          items:
            $ref: '#/components/schemas/Project'
        last_id:
          type: string
          x-ballerina-name: lastId
        has_more:
          type: boolean
          x-ballerina-name: hasMore
        object:
          type: string
          enum:
          - list
          x-stainless-const: true
    UsageTimeBucket:
      required:
      - end_time
      - object
      - result
      - start_time
      type: object
      properties:
        result:
          type: array
          items:
            $ref: '#/components/schemas/UsageTimeBucketResult'
        start_time:
          type: integer
          x-ballerina-name: startTime
        end_time:
          type: integer
          x-ballerina-name: endTime
        object:
          type: string
          enum:
          - bucket
          x-stainless-const: true
    AuditLogProjectupdated:
      type: object
      properties:
        changes_requested:
          allOf:
          - $ref: '#/components/schemas/AuditLogProjectupdatedChangesRequested'
          x-ballerina-name: changesRequested
        id:
          type: string
          description: The project ID
      description: The details for events with this `type`
    AuditLogProjectarchived:
      type: object
      properties:
        id:
          type: string
          description: The project ID
      description: The details for events with this `type`
    RealtimeClientEventInputAudioBufferCommit:
      required:
      - type
      type: object
      properties:
        event_id:
          type: string
          description: Optional client-generated ID used to identify this event
          x-ballerina-name: eventId
        type:
          type: string
          description: "The event type, must be `input_audio_buffer.commit`"
          enum:
          - input_audio_buffer.commit
          x-stainless-const: true
      description: "Send this event to commit the user input audio buffer, which will\
        \ create a \nnew user message item in the conversation. This event will produce\
        \ an error \nif the input audio buffer is empty. When in Server VAD mode,\
        \ the client does \nnot need to send this event, the server will commit the\
        \ audio buffer \nautomatically.\n\nCommitting the input audio buffer will\
        \ trigger input audio transcription \n(if enabled in session configuration),\
        \ but it will not create a response \nfrom the model. The server will respond\
        \ with an `input_audio_buffer.committed` \nevent\n"
      x-oaiMeta:
        name: input_audio_buffer.commit
        group: realtime
        example: |
          {
              "event_id": "event_789",
              "type": "input_audio_buffer.commit"
          }
    ResponseWebSearchCallInProgressEvent:
      required:
      - item_id
      - output_index
      - type
      type: object
      properties:
        item_id:
          type: string
          description: |
            Unique ID for the output item associated with the web search call
          x-ballerina-name: itemId
        type:
          type: string
          description: |
            The type of the event. Always `response.web_search_call.in_progress`
          enum:
          - response.web_search_call.in_progress
          x-stainless-const: true
        output_index:
          type: integer
          description: |
            The index of the output item that the web search call is associated with
          x-ballerina-name: outputIndex
      description: Emitted when a web search call is initiated
      x-oaiMeta:
        name: response.web_search_call.in_progress
        group: responses
        example: |
          {
            "type": "response.web_search_call.in_progress",
            "output_index": 0,
            "item_id": "ws_123",
          }
    RunObjectRequiredActionSubmitToolOutputs:
      required:
      - tool_calls
      type: object
      properties:
        tool_calls:
          type: array
          description: A list of the relevant tool calls
          items:
            $ref: '#/components/schemas/RunToolCallObject'
          x-ballerina-name: toolCalls
      description: Details on the tool outputs needed for this run to continue
    FunctionToolCallResourceAllOf2:
      required:
      - id
      type: object
    CodeInterpreterToolOutput:
      oneOf:
      - $ref: '#/components/schemas/CodeInterpreterTextOutput'
      - $ref: '#/components/schemas/CodeInterpreterFileOutput'
    CreateTranscriptionRequest:
      required:
      - file
      - model
      type: object
      properties:
        timestamp_granularities[]:
          type: array
          description: |
            The timestamp granularities to populate for this transcription. `response_format` must be set `verbose_json` to use timestamp granularities. Either or both of these options are supported: `word`, or `segment`. Note: There is no additional latency for segment timestamps, but generating word timestamps incurs additional latency
          items:
            type: string
            enum:
            - word
            - segment
          default:
          - segment
          x-ballerina-name: timestampGranularities
        file:
          type: string
          description: |
            The audio file object (not file name) to transcribe, in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm
          format: binary
          x-oaiTypeLabel: file
        response_format:
          allOf:
          - $ref: '#/components/schemas/AudioResponseFormat'
          x-ballerina-name: responseFormat
        stream:
          type: boolean
          description: "If set to true, the model response data will be streamed to\
            \ the client\nas it is generated using [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format).\
            \ \nSee the [Streaming section of the Speech-to-Text guide](/docs/guides/speech-to-text?lang=curl#streaming-transcriptions)\n\
            for more information.\n\nNote: Streaming is not supported for the `whisper-1`\
            \ model and will be ignored\n"
          nullable: true
          default: false
        temperature:
          type: number
          description: |
            The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit
          default: 0
        model:
          description: |
            ID of the model to use. The options are `gpt-4o-transcribe`, `gpt-4o-mini-transcribe`, and `whisper-1` (which is powered by our open source Whisper V2 model)
          example: gpt-4o-transcribe
          anyOf:
          - type: string
          - type: string
            enum:
            - whisper-1
            - gpt-4o-transcribe
            - gpt-4o-mini-transcribe
            x-stainless-const: true
          x-oaiTypeLabel: string
        language:
          type: string
          description: |
            The language of the input audio. Supplying the input language in [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) (e.g. `en`) format will improve accuracy and latency
        include[]:
          type: array
          description: "Additional information to include in the transcription response.\
            \ \n`logprobs` will return the log probabilities of the tokens in the\
            \ \nresponse to understand the model's confidence in the transcription.\
            \ \n`logprobs` only works with response_format set to `json` and only\
            \ with \nthe models `gpt-4o-transcribe` and `gpt-4o-mini-transcribe`\n"
          items:
            $ref: '#/components/schemas/TranscriptionInclude'
          x-ballerina-name: include
        prompt:
          type: string
          description: |
            An optional text to guide the model's style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text#prompting) should match the audio language
      additionalProperties: false
    MessageContentTextAnnotationsFileCitationObjectFileCitation:
      required:
      - file_id
      type: object
      properties:
        file_id:
          type: string
          description: The ID of the specific File the citation is from
          x-ballerina-name: fileId
    SubmitToolOutputsRunRequestToolOutputs:
      type: object
      properties:
        output:
          type: string
          description: The output of the tool call to be submitted to continue the
            run
        tool_call_id:
          type: string
          description: The ID of the tool call in the `required_action` object within
            the run object the output is being submitted for
          x-ballerina-name: toolCallId
    ListBatchesResponse:
      required:
      - data
      - has_more
      - object
      type: object
      properties:
        first_id:
          type: string
          example: batch_abc123
          x-ballerina-name: firstId
        data:
          type: array
          items:
            $ref: '#/components/schemas/Batch'
        last_id:
          type: string
          example: batch_abc456
          x-ballerina-name: lastId
        has_more:
          type: boolean
          x-ballerina-name: hasMore
        object:
          type: string
          enum:
          - list
          x-stainless-const: true
    RealtimeClientEventConversationItemDelete:
      required:
      - item_id
      - type
      type: object
      properties:
        event_id:
          type: string
          description: Optional client-generated ID used to identify this event
          x-ballerina-name: eventId
        item_id:
          type: string
          description: The ID of the item to delete
          x-ballerina-name: itemId
        type:
          type: string
          description: "The event type, must be `conversation.item.delete`"
          enum:
          - conversation.item.delete
          x-stainless-const: true
      description: "Send this event when you want to remove any item from the conversation\
        \ \nhistory. The server will respond with a `conversation.item.deleted` event,\
        \ \nunless the item does not exist in the conversation history, in which case\
        \ the \nserver will respond with an error\n"
      x-oaiMeta:
        name: conversation.item.delete
        group: realtime
        example: |
          {
              "event_id": "event_901",
              "type": "conversation.item.delete",
              "item_id": "msg_003"
          }
    Eval:
      title: Eval
      required:
      - created_at
      - data_source_config
      - id
      - metadata
      - name
      - object
      - testing_criteria
      type: object
      properties:
        metadata:
          $ref: '#/components/schemas/Metadata'
        name:
          type: string
          description: The name of the evaluation
          example: Chatbot effectiveness Evaluation
        testing_criteria:
          type: array
          description: A list of testing criteria
          items:
            $ref: '#/components/schemas/EvalTestingCriteria'
          x-ballerina-name: testingCriteria
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the eval was created
          x-ballerina-name: createdAt
        id:
          type: string
          description: Unique identifier for the evaluation
        data_source_config:
          type: object
          description: Configuration of data sources used in runs of the evaluation
          oneOf:
          - $ref: '#/components/schemas/EvalCustomDataSourceConfig'
          - $ref: '#/components/schemas/EvalStoredCompletionsDataSourceConfig'
          x-ballerina-name: dataSourceConfig
        object:
          type: string
          description: The object type
          default: eval
          enum:
          - eval
          x-stainless-const: true
      description: |
        An Eval object with a data source config and testing criteria.
        An Eval represents a task to be done for your LLM integration.
        Like:
         - Improve the quality of my chatbot
         - See how well my chatbot handles customer support
         - Check if o3-mini is better at my usecase than gpt-4o
      x-oaiMeta:
        name: The eval object
        group: evals
        example: |
          {
            "object": "eval",
            "id": "eval_67abd54d9b0081909a86353f6fb9317a",
            "data_source_config": {
              "type": "custom",
              "item_schema": {
                "type": "object",
                "properties": {
                  "label": {"type": "string"},
                },
                "required": ["label"]
              },
              "include_sample_schema": true
            },
            "testing_criteria": [
              {
                "name": "My string check grader",
                "type": "string_check",
                "input": "{{sample.output_text}}",
                "reference": "{{item.label}}",
                "operation": "eq",
              }
            ],
            "name": "External Data Eval",
            "created_at": 1739314509,
            "metadata": {
              "test": "synthetics",
            }
          }
    CreateEmbeddingResponse:
      required:
      - data
      - model
      - object
      - usage
      type: object
      properties:
        data:
          type: array
          description: The list of embeddings generated by the model
          items:
            $ref: '#/components/schemas/Embedding'
        usage:
          $ref: '#/components/schemas/CreateEmbeddingResponseUsage'
        model:
          type: string
          description: The name of the model used to generate the embedding
        object:
          type: string
          description: "The object type, which is always \"list\""
          enum:
          - list
          x-stainless-const: true
    ToolChoiceOptions:
      title: Tool choice mode
      type: string
      description: |
        Controls which (if any) tool is called by the model.

        `none` means the model will not call any tool and instead generates a message.

        `auto` means the model can pick between generating a message or calling one or
        more tools.

        `required` means the model must call one or more tools
      enum:
      - none
      - auto
      - required
    RunStepDeltaStepDetailsToolCallsCodeOutputLogsObject:
      title: Code interpreter log output
      required:
      - index
      - type
      type: object
      properties:
        index:
          type: integer
          description: The index of the output in the outputs array
        type:
          type: string
          description: Always `logs`
          enum:
          - logs
          x-stainless-const: true
        logs:
          type: string
          description: The text output from the Code Interpreter tool call
      description: Text output from the Code Interpreter tool call as part of a run
        step
    ChatCompletionRequestUserMessage:
      title: User message
      required:
      - content
      - role
      type: object
      properties:
        role:
          type: string
          description: "The role of the messages author, in this case `user`"
          enum:
          - user
          x-stainless-const: true
        name:
          type: string
          description: An optional name for the participant. Provides the model information
            to differentiate between participants of the same role
        content:
          description: |
            The contents of the user message
          oneOf:
          - title: Text content
            type: string
            description: The text contents of the message.
          - title: Array of content parts
            minItems: 1
            type: array
            description: "An array of content parts with a defined type. Supported\
              \ options differ based on the [model](/docs/models) being used to generate\
              \ the response. Can contain text, image, or audio inputs."
            items:
              $ref: '#/components/schemas/ChatCompletionRequestUserMessageContentPart'
      description: |
        Messages sent by an end user, containing prompts or additional context
        information
    MessageDeltaObject:
      title: Message delta object
      required:
      - delta
      - id
      - object
      type: object
      properties:
        delta:
          $ref: '#/components/schemas/MessageDeltaObjectDelta'
        id:
          type: string
          description: "The identifier of the message, which can be referenced in\
            \ API endpoints"
        object:
          type: string
          description: "The object type, which is always `thread.message.delta`"
          enum:
          - thread.message.delta
          x-stainless-const: true
      description: |
        Represents a message delta i.e. any changed fields on a message during streaming
      x-oaiMeta:
        name: The message delta object
        beta: true
        example: |
          {
            "id": "msg_123",
            "object": "thread.message.delta",
            "delta": {
              "content": [
                {
                  "index": 0,
                  "type": "text",
                  "text": { "value": "Hello", "annotations": [] }
                }
              ]
            }
          }
    RunStepDeltaStepDetailsMessageCreationObject:
      title: Message creation
      required:
      - type
      type: object
      properties:
        message_creation:
          allOf:
          - $ref: '#/components/schemas/RunStepDeltaStepDetailsMessageCreationObjectMessageCreation'
          x-ballerina-name: messageCreation
        type:
          type: string
          description: Always `message_creation`
          enum:
          - message_creation
          x-stainless-const: true
      description: Details of the message creation by the run step
    CreateEvalLabelModelGrader:
      title: LabelModelGrader
      required:
      - input
      - labels
      - model
      - name
      - passing_labels
      - type
      type: object
      properties:
        input:
          type: array
          description: "A list of chat messages forming the prompt or context. May\
            \ include variable references to the \"item\" namespace, ie {{item.name}}"
          items:
            $ref: '#/components/schemas/CreateEvalItem'
        name:
          type: string
          description: The name of the grader
        model:
          type: string
          description: The model to use for the evaluation. Must support structured
            outputs
        passing_labels:
          type: array
          description: The labels that indicate a passing result. Must be a subset
            of labels
          items:
            type: string
          x-ballerina-name: passingLabels
        type:
          type: string
          description: "The object type, which is always `label_model`"
          enum:
          - label_model
          x-stainless-const: true
        labels:
          type: array
          description: The labels to classify to each item in the evaluation
          items:
            type: string
      description: |
        A LabelModelGrader object which uses a model to assign labels to each item
        in the evaluation
      x-oaiMeta:
        name: The eval label model grader object
        group: evals
        example: |
          {
            "type": "label_model",
            "model": "gpt-4o-2024-08-06",
            "input": [
              {
                "role": "system",
                "content": "Classify the sentiment of the following statement as one of 'positive', 'neutral', or 'negative'"
              },
              {
                "role": "user",
                "content": "Statement: {{item.response}}"
              }
            ],
            "passing_labels": ["positive"],
            "labels": ["positive", "neutral", "negative"],
            "name": "Sentiment label grader"
          }
    ModifyAssistantRequestToolResourcesCodeInterpreter:
      type: object
      properties:
        file_ids:
          maxItems: 20
          type: array
          description: |
            Overrides the list of [file](/docs/api-reference/files) IDs made available to the `code_interpreter` tool. There can be a maximum of 20 files associated with the tool
          items:
            type: string
          default: []
          x-ballerina-name: fileIds
    CodeInterpreterToolCall:
      title: Code interpreter tool call
      required:
      - code
      - id
      - results
      - status
      - type
      type: object
      properties:
        code:
          type: string
          description: |
            The code to run
        id:
          type: string
          description: |
            The unique ID of the code interpreter tool call
        type:
          type: string
          description: |
            The type of the code interpreter tool call. Always `code_interpreter_call`
          enum:
          - code_interpreter_call
          x-stainless-const: true
        results:
          type: array
          description: |
            The results of the code interpreter tool call
          items:
            $ref: '#/components/schemas/CodeInterpreterToolOutput'
        status:
          type: string
          description: |
            The status of the code interpreter tool call
          enum:
          - in_progress
          - interpreting
          - completed
      description: |
        A tool call to run code
    AuditLogUserupdatedChangesRequested:
      type: object
      properties:
        role:
          type: string
          description: The role of the user. Is either `owner` or `member`
      description: The payload used to update the user
    ModifyMessageRequest:
      type: object
      properties:
        metadata:
          $ref: '#/components/schemas/Metadata'
      additionalProperties: false
    RunStepStreamEvent:
      oneOf:
      - $ref: '#/components/schemas/RunStepStreamEventOneOf1'
      - $ref: '#/components/schemas/RunStepStreamEventRunStepStreamEventOneOf12'
      - $ref: '#/components/schemas/RunStepStreamEventRunStepStreamEventRunStepStreamEventOneOf123'
      - $ref: '#/components/schemas/RunStepStreamEventRunStepStreamEventRunStepStreamEventRunStepStreamEventOneOf1234'
      - $ref: '#/components/schemas/RunStepStreamEventRunStepStreamEventRunStepStreamEventRunStepStreamEventRunStepStreamEventOneOf12345'
      - $ref: '#/components/schemas/RunStepStreamEventRunStepStreamEventRunStepStreamEventRunStepStreamEventRunStepStreamEventRunStepStreamEventOneOf123456'
      - $ref: '#/components/schemas/RunStepStreamEventRunStepStreamEventRunStepStreamEventRunStepStreamEventRunStepStreamEventRunStepStreamEventRunStepStreamEventOneOf1234567'
    RealtimeResponseUsage:
      type: object
      properties:
        total_tokens:
          type: integer
          description: "The total number of tokens in the Response including input\
            \ and output \ntext and audio tokens\n"
          x-ballerina-name: totalTokens
        output_tokens:
          type: integer
          description: "The number of output tokens sent in the Response, including\
            \ text and \naudio tokens\n"
          x-ballerina-name: outputTokens
        input_token_details:
          allOf:
          - $ref: '#/components/schemas/RealtimeResponseUsageInputTokenDetails'
          x-ballerina-name: inputTokenDetails
        input_tokens:
          type: integer
          description: "The number of input tokens used in the Response, including\
            \ text and \naudio tokens\n"
          x-ballerina-name: inputTokens
        output_token_details:
          allOf:
          - $ref: '#/components/schemas/RealtimeResponseUsageOutputTokenDetails'
          x-ballerina-name: outputTokenDetails
      description: "Usage statistics for the Response, this will correspond to billing.\
        \ A \nRealtime API session will maintain a conversation context and append\
        \ new \nItems to the Conversation, thus output from previous turns (text and\
        \ \naudio tokens) will become the input for later turns\n"
    AuditLogApiKeycreated:
      type: object
      properties:
        data:
          $ref: '#/components/schemas/AuditLogApiKeycreatedData'
        id:
          type: string
          description: The tracking ID of the API key
      description: The details for events with this `type`
    FunctionParameters:
      type: object
      additionalProperties: true
      description: "The parameters the functions accepts, described as a JSON Schema\
        \ object. See the [guide](/docs/guides/function-calling) for examples, and\
        \ the [JSON Schema reference](https://json-schema.org/understanding-json-schema/)\
        \ for documentation about the format. \n\nOmitting `parameters` defines a\
        \ function with an empty parameter list"
    ProjectCreateRequest:
      required:
      - name
      type: object
      properties:
        name:
          type: string
          description: "The friendly name of the project, this name appears in reports"
    CreateTranscriptionResponseStreamEvent:
      discriminator:
        propertyName: type
      anyOf:
      - $ref: '#/components/schemas/TranscriptTextDeltaEvent'
      - $ref: '#/components/schemas/TranscriptTextDoneEvent'
    ChatCompletionRequestAssistantMessageAudio:
      required:
      - id
      type: object
      properties:
        id:
          type: string
          description: |
            Unique identifier for a previous audio response from the model
      description: "Data about a previous audio response from the model. \n[Learn\
        \ more](/docs/guides/audio)\n"
      nullable: true
    ChatCompletionMessageToolCallChunk:
      required:
      - index
      type: object
      properties:
        function:
          $ref: '#/components/schemas/ChatCompletionMessageToolCallChunkFunction'
        index:
          type: integer
        id:
          type: string
          description: The ID of the tool call
        type:
          type: string
          description: "The type of the tool. Currently, only `function` is supported"
          enum:
          - function
          x-stainless-const: true
    MessageDeltaContentImageUrlObject:
      title: Image URL
      required:
      - index
      - type
      type: object
      properties:
        image_url:
          allOf:
          - $ref: '#/components/schemas/MessageDeltaContentImageUrlObjectImageUrl'
          x-ballerina-name: imageUrl
        index:
          type: integer
          description: The index of the content part in the message
        type:
          type: string
          description: Always `image_url`
          enum:
          - image_url
          x-stainless-const: true
      description: References an image URL in the content of a message
    CreateModerationResponseCategoryAppliedInputTypes:
      required:
      - harassment
      - harassment/threatening
      - hate
      - hate/threatening
      - illicit
      - illicit/violent
      - self-harm
      - self-harm/instructions
      - self-harm/intent
      - sexual
      - sexual/minors
      - violence
      - violence/graphic
      type: object
      properties:
        illicit/violent:
          type: array
          description: The applied input type(s) for the category 'illicit/violent'
          items:
            type: string
            enum:
            - text
            x-stainless-const: true
          x-ballerina-name: illicitViolent
        self-harm/instructions:
          type: array
          description: The applied input type(s) for the category 'self-harm/instructions'
          items:
            type: string
            enum:
            - text
            - image
          x-ballerina-name: selfHarmInstructions
        harassment:
          type: array
          description: The applied input type(s) for the category 'harassment'
          items:
            type: string
            enum:
            - text
            x-stainless-const: true
        violence/graphic:
          type: array
          description: The applied input type(s) for the category 'violence/graphic'
          items:
            type: string
            enum:
            - text
            - image
          x-ballerina-name: violenceGraphic
        illicit:
          type: array
          description: The applied input type(s) for the category 'illicit'
          items:
            type: string
            enum:
            - text
            x-stainless-const: true
        self-harm/intent:
          type: array
          description: The applied input type(s) for the category 'self-harm/intent'
          items:
            type: string
            enum:
            - text
            - image
          x-ballerina-name: selfHarmIntent
        hate/threatening:
          type: array
          description: The applied input type(s) for the category 'hate/threatening'
          items:
            type: string
            enum:
            - text
            x-stainless-const: true
          x-ballerina-name: hateThreatening
        sexual/minors:
          type: array
          description: The applied input type(s) for the category 'sexual/minors'
          items:
            type: string
            enum:
            - text
            x-stainless-const: true
          x-ballerina-name: sexualMinors
        harassment/threatening:
          type: array
          description: The applied input type(s) for the category 'harassment/threatening'
          items:
            type: string
            enum:
            - text
            x-stainless-const: true
          x-ballerina-name: harassmentThreatening
        hate:
          type: array
          description: The applied input type(s) for the category 'hate'
          items:
            type: string
            enum:
            - text
            x-stainless-const: true
        self-harm:
          type: array
          description: The applied input type(s) for the category 'self-harm'
          items:
            type: string
            enum:
            - text
            - image
          x-ballerina-name: selfHarm
        sexual:
          type: array
          description: The applied input type(s) for the category 'sexual'
          items:
            type: string
            enum:
            - text
            - image
        violence:
          type: array
          description: The applied input type(s) for the category 'violence'
          items:
            type: string
            enum:
            - text
            - image
      description: A list of the categories along with the input type(s) that the
        score applies to
    FunctionToolCallOutput:
      title: Function tool call output
      required:
      - call_id
      - output
      - type
      type: object
      properties:
        output:
          type: string
          description: |
            A JSON string of the output of the function tool call
        id:
          type: string
          description: |
            The unique ID of the function tool call output. Populated when this item
            is returned via API
        type:
          type: string
          description: |
            The type of the function tool call output. Always `function_call_output`
          enum:
          - function_call_output
          x-stainless-const: true
        call_id:
          type: string
          description: |
            The unique ID of the function tool call generated by the model
          x-ballerina-name: callId
        status:
          type: string
          description: |
            The status of the item. One of `in_progress`, `completed`, or
            `incomplete`. Populated when items are returned via API
          enum:
          - in_progress
          - completed
          - incomplete
      description: |
        The output of a function tool call
    EvalJsonlFileContentSourceContent:
      required:
      - item
      type: object
      properties:
        item:
          type: object
          additionalProperties: true
        sample:
          type: object
          additionalProperties: true
    UsageEmbeddingsResult:
      required:
      - input_tokens
      - num_model_requests
      - object
      type: object
      properties:
        num_model_requests:
          type: integer
          description: The count of requests made to the model
          x-ballerina-name: numModelRequests
        project_id:
          type: string
          description: "When `group_by=project_id`, this field provides the project\
            \ ID of the grouped usage result"
          nullable: true
          x-ballerina-name: projectId
        user_id:
          type: string
          description: "When `group_by=user_id`, this field provides the user ID of\
            \ the grouped usage result"
          nullable: true
          x-ballerina-name: userId
        model:
          type: string
          description: "When `group_by=model`, this field provides the model name\
            \ of the grouped usage result"
          nullable: true
        input_tokens:
          type: integer
          description: The aggregated number of input tokens used
          x-ballerina-name: inputTokens
        api_key_id:
          type: string
          description: "When `group_by=api_key_id`, this field provides the API key\
            \ ID of the grouped usage result"
          nullable: true
          x-ballerina-name: apiKeyId
        object:
          type: string
          enum:
          - organization.usage.embeddings.result
          x-stainless-const: true
      description: The aggregated embeddings usage details of the specific time bucket
      x-oaiMeta:
        name: Embeddings usage object
        example: |
          {
              "object": "organization.usage.embeddings.result",
              "input_tokens": 20,
              "num_model_requests": 2,
              "project_id": "proj_abc",
              "user_id": "user-abc",
              "api_key_id": "key_abc",
              "model": "text-embedding-ada-002-v2"
          }
    VectorStoreSearchResultsPage:
      required:
      - data
      - has_more
      - next_page
      - object
      - search_query
      type: object
      properties:
        next_page:
          type: string
          description: "The token for the next page, if any"
          nullable: true
          x-ballerina-name: nextPage
        data:
          type: array
          description: The list of search result items
          items:
            $ref: '#/components/schemas/VectorStoreSearchResultItem'
        has_more:
          type: boolean
          description: Indicates if there are more results to fetch
          x-ballerina-name: hasMore
        search_query:
          type: array
          items:
            minItems: 1
            type: string
            description: The query used for this search.
          x-ballerina-name: searchQuery
        object:
          type: string
          description: "The object type, which is always `vector_store.search_results.page`"
          enum:
          - vector_store.search_results.page
          x-stainless-const: true
      additionalProperties: false
      x-oaiMeta:
        name: Vector store search results page
    AuditLogProject:
      type: object
      properties:
        name:
          type: string
          description: The project title
        id:
          type: string
          description: The project ID
      description: The project that the action was scoped to. Absent for actions not
        scoped to projects
    RealtimeSessionCreateResponseClientSecret:
      required:
      - expires_at
      - value
      type: object
      properties:
        expires_at:
          type: integer
          description: |
            Timestamp for when the token expires. Currently, all tokens expire
            after one minute
          x-ballerina-name: expiresAt
        value:
          type: string
          description: |
            Ephemeral key usable in client environments to authenticate connections
            to the Realtime API. Use this in client-side environments rather than
            a standard API token, which should only be used server-side
      description: Ephemeral key returned by the API
    RunStepDeltaStepDetailsToolCallsFunctionObject:
      title: Function tool call
      required:
      - index
      - type
      type: object
      properties:
        function:
          $ref: '#/components/schemas/RunStepDeltaStepDetailsToolCallsFunctionObjectFunction'
        index:
          type: integer
          description: The index of the tool call in the tool calls array
        id:
          type: string
          description: The ID of the tool call object
        type:
          type: string
          description: The type of tool call. This is always going to be `function`
            for this type of tool call
          enum:
          - function
          x-stainless-const: true
    RealtimeServerEventInputAudioBufferSpeechStarted:
      required:
      - audio_start_ms
      - event_id
      - item_id
      - type
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event
          x-ballerina-name: eventId
        item_id:
          type: string
          description: |
            The ID of the user message item that will be created when speech stops
          x-ballerina-name: itemId
        audio_start_ms:
          type: integer
          description: "Milliseconds from the start of all audio written to the buffer\
            \ during the \nsession when speech was first detected. This will correspond\
            \ to the \nbeginning of audio sent to the model, and thus includes the\
            \ \n`prefix_padding_ms` configured in the Session\n"
          x-ballerina-name: audioStartMs
        type:
          type: string
          description: "The event type, must be `input_audio_buffer.speech_started`"
          enum:
          - input_audio_buffer.speech_started
          x-stainless-const: true
      description: "Sent by the server when in `server_vad` mode to indicate that\
        \ speech has been \ndetected in the audio buffer. This can happen any time\
        \ audio is added to the \nbuffer (unless speech is already detected). The\
        \ client may want to use this \nevent to interrupt audio playback or provide\
        \ visual feedback to the user. \n\nThe client should expect to receive a `input_audio_buffer.speech_stopped`\
        \ event \nwhen speech stops. The `item_id` property is the ID of the user\
        \ message item \nthat will be created when speech stops and will also be included\
        \ in the \n`input_audio_buffer.speech_stopped` event (unless the client manually\
        \ commits \nthe audio buffer during VAD activation)\n"
      x-oaiMeta:
        name: input_audio_buffer.speech_started
        group: realtime
        example: |
          {
              "event_id": "event_1516",
              "type": "input_audio_buffer.speech_started",
              "audio_start_ms": 1000,
              "item_id": "msg_003"
          }
    RealtimeClientEventConversationItemCreate:
      required:
      - item
      - type
      type: object
      properties:
        item:
          $ref: '#/components/schemas/RealtimeConversationItem'
        event_id:
          type: string
          description: Optional client-generated ID used to identify this event
          x-ballerina-name: eventId
        type:
          type: string
          description: "The event type, must be `conversation.item.create`"
          enum:
          - conversation.item.create
          x-stainless-const: true
        previous_item_id:
          type: string
          description: "The ID of the preceding item after which the new item will\
            \ be inserted. \nIf not set, the new item will be appended to the end\
            \ of the conversation.\nIf set to `root`, the new item will be added to\
            \ the beginning of the conversation.\nIf set to an existing ID, it allows\
            \ an item to be inserted mid-conversation. If the\nID cannot be found,\
            \ an error will be returned and the item will not be added\n"
          x-ballerina-name: previousItemId
      description: "Add a new Item to the Conversation's context, including messages,\
        \ function \ncalls, and function call responses. This event can be used both\
        \ to populate a \n\"history\" of the conversation and to add new items mid-stream,\
        \ but has the \ncurrent limitation that it cannot populate assistant audio\
        \ messages.\n\nIf successful, the server will respond with a `conversation.item.created`\
        \ \nevent, otherwise an `error` event will be sent\n"
      x-oaiMeta:
        name: conversation.item.create
        group: realtime
        example: |
          {
              "event_id": "event_345",
              "type": "conversation.item.create",
              "previous_item_id": null,
              "item": {
                  "id": "msg_001",
                  "type": "message",
                  "role": "user",
                  "content": [
                      {
                          "type": "input_text",
                          "text": "Hello, how are you?"
                      }
                  ]
              }
          }
    RunStreamEventOneOf1:
      required:
      - data
      - event
      type: object
      properties:
        data:
          $ref: '#/components/schemas/RunObject'
        event:
          type: string
          enum:
          - thread.run.created
          x-stainless-const: true
      description: "Occurs when a new [run](/docs/api-reference/runs/object) is created"
      x-oaiMeta:
        dataDescription: "`data` is a [run](/docs/api-reference/runs/object)"
    RealtimeServerEventResponseContentPartAddedPart:
      type: object
      properties:
        transcript:
          type: string
          description: The transcript of the audio (if type is "audio")
        text:
          type: string
          description: The text content (if type is "text")
        audio:
          type: string
          description: Base64-encoded audio data (if type is "audio")
        type:
          type: string
          description: "The content type (\"text\", \"audio\")"
          enum:
          - audio
          - text
      description: The content part that was added
    Batch:
      required:
      - completion_window
      - created_at
      - endpoint
      - id
      - input_file_id
      - object
      - status
      type: object
      properties:
        cancelled_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the batch was cancelled
          x-ballerina-name: cancelledAt
        metadata:
          $ref: '#/components/schemas/Metadata'
        request_counts:
          allOf:
          - $ref: '#/components/schemas/BatchRequestCounts'
          x-ballerina-name: requestCounts
        input_file_id:
          type: string
          description: The ID of the input file for the batch
          x-ballerina-name: inputFileId
        output_file_id:
          type: string
          description: The ID of the file containing the outputs of successfully executed
            requests
          x-ballerina-name: outputFileId
        error_file_id:
          type: string
          description: The ID of the file containing the outputs of requests with
            errors
          x-ballerina-name: errorFileId
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the batch was created
          x-ballerina-name: createdAt
        in_progress_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the batch started
            processing
          x-ballerina-name: inProgressAt
        expired_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the batch expired
          x-ballerina-name: expiredAt
        finalizing_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the batch started
            finalizing
          x-ballerina-name: finalizingAt
        completed_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the batch was completed
          x-ballerina-name: completedAt
        endpoint:
          type: string
          description: The OpenAI API endpoint used by the batch
        expires_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the batch will expire
          x-ballerina-name: expiresAt
        cancelling_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the batch started
            cancelling
          x-ballerina-name: cancellingAt
        completion_window:
          type: string
          description: The time frame within which the batch should be processed
          x-ballerina-name: completionWindow
        id:
          type: string
        failed_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the batch failed
          x-ballerina-name: failedAt
        errors:
          $ref: '#/components/schemas/BatchErrors'
        object:
          type: string
          description: "The object type, which is always `batch`"
          enum:
          - batch
          x-stainless-const: true
        status:
          type: string
          description: The current status of the batch
          enum:
          - validating
          - failed
          - in_progress
          - finalizing
          - completed
          - expired
          - cancelling
          - cancelled
      x-oaiMeta:
        name: The batch object
        example: |
          {
            "id": "batch_abc123",
            "object": "batch",
            "endpoint": "/v1/completions",
            "errors": null,
            "input_file_id": "file-abc123",
            "completion_window": "24h",
            "status": "completed",
            "output_file_id": "file-cvaTdG",
            "error_file_id": "file-HOWS94",
            "created_at": 1711471533,
            "in_progress_at": 1711471538,
            "expires_at": 1711557933,
            "finalizing_at": 1711493133,
            "completed_at": 1711493163,
            "failed_at": null,
            "expired_at": null,
            "cancelling_at": null,
            "cancelled_at": null,
            "request_counts": {
              "total": 100,
              "completed": 95,
              "failed": 5
            },
            "metadata": {
              "customer_id": "user_123456789",
              "batch_description": "Nightly eval job",
            }
          }
    RealtimeClientEventInputAudioBufferAppend:
      required:
      - audio
      - type
      type: object
      properties:
        event_id:
          type: string
          description: Optional client-generated ID used to identify this event
          x-ballerina-name: eventId
        audio:
          type: string
          description: "Base64-encoded audio bytes. This must be in the format specified\
            \ by the \n`input_audio_format` field in the session configuration\n"
        type:
          type: string
          description: "The event type, must be `input_audio_buffer.append`"
          enum:
          - input_audio_buffer.append
          x-stainless-const: true
      description: "Send this event to append audio bytes to the input audio buffer.\
        \ The audio \nbuffer is temporary storage you can write to and later commit.\
        \ In Server VAD \nmode, the audio buffer is used to detect speech and the\
        \ server will decide \nwhen to commit. When Server VAD is disabled, you must\
        \ commit the audio buffer\nmanually.\n\nThe client may choose how much audio\
        \ to place in each event up to a maximum \nof 15 MiB, for example streaming\
        \ smaller chunks from the client may allow the \nVAD to be more responsive.\
        \ Unlike made other client events, the server will \nnot send a confirmation\
        \ response to this event\n"
      x-oaiMeta:
        name: input_audio_buffer.append
        group: realtime
        example: |
          {
              "event_id": "event_456",
              "type": "input_audio_buffer.append",
              "audio": "Base64EncodedAudioData"
          }
    ? RunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventOneOf123456789
    : required:
      - data
      - event
      type: object
      properties:
        data:
          $ref: '#/components/schemas/RunObject'
        event:
          type: string
          enum:
          - thread.run.cancelled
          x-stainless-const: true
      description: "Occurs when a [run](/docs/api-reference/runs/object) is cancelled"
      x-oaiMeta:
        dataDescription: "`data` is a [run](/docs/api-reference/runs/object)"
    CompleteUploadRequest:
      required:
      - part_ids
      type: object
      properties:
        part_ids:
          type: array
          description: |
            The ordered list of Part IDs
          items:
            type: string
          x-ballerina-name: partIds
        md5:
          type: string
          description: |
            The optional md5 checksum for the file contents to verify if the bytes uploaded matches what you expect
      additionalProperties: false
    AssistantObjectToolResourcesCodeInterpreter:
      type: object
      properties:
        file_ids:
          maxItems: 20
          type: array
          description: |
            A list of [file](/docs/api-reference/files) IDs made available to the `code_interpreter`` tool. There can be a maximum of 20 files associated with the tool
          items:
            type: string
          default: []
          x-ballerina-name: fileIds
    RealtimeServerEventErrorError:
      required:
      - message
      - type
      type: object
      properties:
        code:
          type: string
          description: "Error code, if any"
          nullable: true
        event_id:
          type: string
          description: |
            The event_id of the client event that caused the error, if applicable
          nullable: true
          x-ballerina-name: eventId
        param:
          type: string
          description: "Parameter related to the error, if any"
          nullable: true
        type:
          type: string
          description: |
            The type of error (e.g., "invalid_request_error", "server_error")
        message:
          type: string
          description: A human-readable error message
      description: Details of the error
    ChatCompletionStreamResponseDeltaFunctionCall:
      type: object
      properties:
        name:
          type: string
          description: The name of the function to call
        arguments:
          type: string
          description: "The arguments to call the function with, as generated by the\
            \ model in JSON format. Note that the model does not always generate valid\
            \ JSON, and may hallucinate parameters not defined by your function schema.\
            \ Validate the arguments in your code before calling your function"
      description: "Deprecated and replaced by `tool_calls`. The name and arguments\
        \ of a function that should be called, as generated by the model"
      deprecated: true
    RealtimeServerEventOutputAudioBufferCleared:
      required:
      - event_id
      - response_id
      - type
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event
          x-ballerina-name: eventId
        response_id:
          type: string
          description: The unique ID of the response that produced the audio
          x-ballerina-name: responseId
        type:
          type: string
          description: "The event type, must be `output_audio_buffer.cleared`"
          enum:
          - output_audio_buffer.cleared
          x-stainless-const: true
      description: |
        **WebRTC Only:** Emitted when the output audio buffer is cleared. This happens either in VAD
        mode when the user has interrupted (`input_audio_buffer.speech_started`),
        or when the client has emitted the `output_audio_buffer.clear` event to manually
        cut off the current audio response.
        [Learn more](/docs/guides/realtime-model-capabilities#client-and-server-events-for-audio-in-webrtc)
      x-oaiMeta:
        name: output_audio_buffer.cleared
        group: realtime
        example: |
          {
              "event_id": "event_abc123",
              "type": "output_audio_buffer.cleared",
              "response_id": "resp_abc123"
          }
    InputTextContent:
      title: Input text
      required:
      - text
      - type
      type: object
      properties:
        text:
          type: string
          description: The text input to the model
        type:
          type: string
          description: The type of the input item. Always `input_text`
          default: input_text
          enum:
          - input_text
          x-stainless-const: true
      description: A text input to the model
    EvalRun:
      title: EvalRun
      required:
      - created_at
      - data_source
      - error
      - eval_id
      - id
      - metadata
      - model
      - name
      - object
      - per_model_usage
      - per_testing_criteria_results
      - report_url
      - result_counts
      - status
      type: object
      properties:
        per_testing_criteria_results:
          type: array
          description: Results per testing criteria applied during the evaluation
            run
          items:
            $ref: '#/components/schemas/EvalRunPerTestingCriteriaResults'
          x-ballerina-name: perTestingCriteriaResults
        metadata:
          $ref: '#/components/schemas/Metadata'
        eval_id:
          type: string
          description: The identifier of the associated evaluation
          x-ballerina-name: evalId
        report_url:
          type: string
          description: The URL to the rendered evaluation run report on the UI dashboard
          x-ballerina-name: reportUrl
        created_at:
          type: integer
          description: Unix timestamp (in seconds) when the evaluation run was created
          x-ballerina-name: createdAt
        error:
          $ref: '#/components/schemas/EvalApiError'
        data_source:
          type: object
          description: Information about the run's data source
          oneOf:
          - $ref: '#/components/schemas/CreateEvalJsonlRunDataSource'
          - $ref: '#/components/schemas/CreateEvalCompletionsRunDataSource'
          - $ref: '#/components/schemas/CreateEvalResponsesRunDataSource'
          x-ballerina-name: dataSource
        result_counts:
          allOf:
          - $ref: '#/components/schemas/EvalRunResultCounts'
          x-ballerina-name: resultCounts
        name:
          type: string
          description: The name of the evaluation run
        model:
          type: string
          description: "The model that is evaluated, if applicable"
        id:
          type: string
          description: Unique identifier for the evaluation run
        per_model_usage:
          type: array
          description: Usage statistics for each model during the evaluation run
          items:
            $ref: '#/components/schemas/EvalRunPerModelUsage'
          x-ballerina-name: perModelUsage
        object:
          type: string
          description: The type of the object. Always "eval.run"
          default: eval.run
          enum:
          - eval.run
          x-stainless-const: true
        status:
          type: string
          description: The status of the evaluation run
      description: |
        A schema representing an evaluation run
      x-oaiMeta:
        name: The eval run object
        group: evals
        example: |
          {
            "object": "eval.run",
            "id": "evalrun_67e57965b480819094274e3a32235e4c",
            "eval_id": "eval_67e579652b548190aaa83ada4b125f47",
            "report_url": "https://platform.openai.com/evaluations/eval_67e579652b548190aaa83ada4b125f47?run_id=evalrun_67e57965b480819094274e3a32235e4c",
            "status": "queued",
            "model": "gpt-4o-mini",
            "name": "gpt-4o-mini",
            "created_at": 1743092069,
            "result_counts": {
              "total": 0,
              "errored": 0,
              "failed": 0,
              "passed": 0
            },
            "per_model_usage": null,
            "per_testing_criteria_results": null,
            "data_source": {
              "type": "completions",
              "source": {
                "type": "file_content",
                "content": [
                  {
                    "item": {
                      "input": "Tech Company Launches Advanced Artificial Intelligence Platform",
                      "ground_truth": "Technology"
                    }
                  },
                  {
                    "item": {
                      "input": "Central Bank Increases Interest Rates Amid Inflation Concerns",
                      "ground_truth": "Markets"
                    }
                  },
                  {
                    "item": {
                      "input": "International Summit Addresses Climate Change Strategies",
                      "ground_truth": "World"
                    }
                  },
                  {
                    "item": {
                      "input": "Major Retailer Reports Record-Breaking Holiday Sales",
                      "ground_truth": "Business"
                    }
                  },
                  {
                    "item": {
                      "input": "National Team Qualifies for World Championship Finals",
                      "ground_truth": "Sports"
                    }
                  },
                  {
                    "item": {
                      "input": "Stock Markets Rally After Positive Economic Data Released",
                      "ground_truth": "Markets"
                    }
                  },
                  {
                    "item": {
                      "input": "Global Manufacturer Announces Merger with Competitor",
                      "ground_truth": "Business"
                    }
                  },
                  {
                    "item": {
                      "input": "Breakthrough in Renewable Energy Technology Unveiled",
                      "ground_truth": "Technology"
                    }
                  },
                  {
                    "item": {
                      "input": "World Leaders Sign Historic Climate Agreement",
                      "ground_truth": "World"
                    }
                  },
                  {
                    "item": {
                      "input": "Professional Athlete Sets New Record in Championship Event",
                      "ground_truth": "Sports"
                    }
                  },
                  {
                    "item": {
                      "input": "Financial Institutions Adapt to New Regulatory Requirements",
                      "ground_truth": "Business"
                    }
                  },
                  {
                    "item": {
                      "input": "Tech Conference Showcases Advances in Artificial Intelligence",
                      "ground_truth": "Technology"
                    }
                  },
                  {
                    "item": {
                      "input": "Global Markets Respond to Oil Price Fluctuations",
                      "ground_truth": "Markets"
                    }
                  },
                  {
                    "item": {
                      "input": "International Cooperation Strengthened Through New Treaty",
                      "ground_truth": "World"
                    }
                  },
                  {
                    "item": {
                      "input": "Sports League Announces Revised Schedule for Upcoming Season",
                      "ground_truth": "Sports"
                    }
                  }
                ]
              },
              "input_messages": {
                "type": "template",
                "template": [
                  {
                    "type": "message",
                    "role": "developer",
                    "content": {
                      "type": "input_text",
                      "text": "Categorize a given news headline into one of the following topics: Technology, Markets, World, Business, or Sports.\n\n# Steps\n\n1. Analyze the content of the news headline to understand its primary focus.\n2. Extract the subject matter, identifying any key indicators or keywords.\n3. Use the identified indicators to determine the most suitable category out of the five options: Technology, Markets, World, Business, or Sports.\n4. Ensure only one category is selected per headline.\n\n# Output Format\n\nRespond with the chosen category as a single word. For instance: \"Technology\", \"Markets\", \"World\", \"Business\", or \"Sports\".\n\n# Examples\n\n**Input**: \"Apple Unveils New iPhone Model, Featuring Advanced AI Features\"  \n**Output**: \"Technology\"\n\n**Input**: \"Global Stocks Mixed as Investors Await Central Bank Decisions\"  \n**Output**: \"Markets\"\n\n**Input**: \"War in Ukraine: Latest Updates on Negotiation Status\"  \n**Output**: \"World\"\n\n**Input**: \"Microsoft in Talks to Acquire Gaming Company for $2 Billion\"  \n**Output**: \"Business\"\n\n**Input**: \"Manchester United Secures Win in Premier League Football Match\"  \n**Output**: \"Sports\" \n\n# Notes\n\n- If the headline appears to fit into more than one category, choose the most dominant theme.\n- Keywords or phrases such as \"stocks\", \"company acquisition\", \"match\", or technological brands can be good indicators for classification.\n"
                    }
                  },
                  {
                    "type": "message",
                    "role": "user",
                    "content": {
                      "type": "input_text",
                      "text": "{{item.input}}"
                    }
                  }
                ]
              },
              "model": "gpt-4o-mini",
              "sampling_params": {
                "seed": 42,
                "temperature": 1.0,
                "top_p": 1.0,
                "max_completions_tokens": 2048
              }
            },
            "error": null,
            "metadata": {}
          }
    StopConfiguration:
      description: |
        Not supported with latest reasoning models `o3` and `o4-mini`.

        Up to 4 sequences where the API will stop generating further tokens. The
        returned text will not contain the stop sequence
      nullable: true
      oneOf:
      - $ref: '#/components/schemas/StopConfigurationOneOf1'
      - $ref: '#/components/schemas/StopConfigurationStopConfigurationOneOf12'
      default: null
    TranscriptionInclude:
      type: string
      enum:
      - logprobs
    ImagesResponseUsage:
      required:
      - input_tokens
      - input_tokens_details
      - output_tokens
      - total_tokens
      type: object
      properties:
        input_tokens_details:
          allOf:
          - $ref: '#/components/schemas/ImagesResponseUsageInputTokensDetails'
          x-ballerina-name: inputTokensDetails
        total_tokens:
          type: integer
          description: The total number of tokens (images and text) used for the image
            generation
          x-ballerina-name: totalTokens
        output_tokens:
          type: integer
          description: The number of image tokens in the output image
          x-ballerina-name: outputTokens
        input_tokens:
          type: integer
          description: The number of tokens (images and text) in the input prompt
          x-ballerina-name: inputTokens
      description: |
        For `gpt-image-1` only, the token usage information for the image generation
    RealtimeClientEventSessionUpdate:
      required:
      - session
      - type
      type: object
      properties:
        event_id:
          type: string
          description: Optional client-generated ID used to identify this event
          x-ballerina-name: eventId
        session:
          $ref: '#/components/schemas/RealtimeSessionCreateRequest'
        type:
          type: string
          description: "The event type, must be `session.update`"
          enum:
          - session.update
          x-stainless-const: true
      description: |
        Send this event to update the sessions default configuration.
        The client may send this event at any time to update any field,
        except for `voice`. However, note that once a session has been
        initialized with a particular `model`, it cant be changed to
        another model using `session.update`.

        When the server receives a `session.update`, it will respond
        with a `session.updated` event showing the full, effective configuration.
        Only the fields that are present are updated. To clear a field like
        `instructions`, pass an empty string
      x-oaiMeta:
        name: session.update
        group: realtime
        example: |
          {
              "event_id": "event_123",
              "type": "session.update",
              "session": {
                  "modalities": ["text", "audio"],
                  "instructions": "You are a helpful assistant.",
                  "voice": "sage",
                  "input_audio_format": "pcm16",
                  "output_audio_format": "pcm16",
                  "input_audio_transcription": {
                      "model": "whisper-1"
                  },
                  "turn_detection": {
                      "type": "server_vad",
                      "threshold": 0.5,
                      "prefix_padding_ms": 300,
                      "silence_duration_ms": 500,
                      "create_response": true
                  },
                  "tools": [
                      {
                          "type": "function",
                          "name": "get_weather",
                          "description": "Get the current weather...",
                          "parameters": {
                              "type": "object",
                              "properties": {
                                  "location": { "type": "string" }
                              },
                              "required": ["location"]
                          }
                      }
                  ],
                  "tool_choice": "auto",
                  "temperature": 0.8,
                  "max_response_output_tokens": "inf"
              }
          }
    ProjectRateLimitUpdateRequest:
      type: object
      properties:
        batch_1_day_max_input_tokens:
          type: integer
          description: The maximum batch input tokens per day. Only relevant for certain
            models
          x-ballerina-name: batch1DayMaxInputTokens
        max_tokens_per_1_minute:
          type: integer
          description: The maximum tokens per minute
          x-ballerina-name: maxTokensPer1Minute
        max_images_per_1_minute:
          type: integer
          description: The maximum images per minute. Only relevant for certain models
          x-ballerina-name: maxImagesPer1Minute
        max_audio_megabytes_per_1_minute:
          type: integer
          description: The maximum audio megabytes per minute. Only relevant for certain
            models
          x-ballerina-name: maxAudioMegabytesPer1Minute
        max_requests_per_1_minute:
          type: integer
          description: The maximum requests per minute
          x-ballerina-name: maxRequestsPer1Minute
        max_requests_per_1_day:
          type: integer
          description: The maximum requests per day. Only relevant for certain models
          x-ballerina-name: maxRequestsPer1Day
    AuditLogInvitesentData:
      type: object
      properties:
        role:
          type: string
          description: The role the email was invited to be. Is either `owner` or
            `member`
        email:
          type: string
          description: The email invited to the organization
      description: The payload used to create the invite
    CreateFileRequest:
      required:
      - file
      - purpose
      type: object
      properties:
        file:
          type: string
          description: |
            The File object (not file name) to be uploaded
          format: binary
        purpose:
          type: string
          description: |
            The intended purpose of the uploaded file. One of: - `assistants`: Used in the Assistants API - `batch`: Used in the Batch API - `fine-tune`: Used for fine-tuning - `vision`: Images used for vision fine-tuning - `user_data`: Flexible file type for any purpose - `evals`: Used for eval data sets
          enum:
          - assistants
          - batch
          - fine-tune
          - vision
          - user_data
          - evals
      additionalProperties: false
    ModelIdsSharedAnyOf1:
      type: string
    ComputerScreenshotImage:
      required:
      - type
      type: object
      properties:
        image_url:
          type: string
          description: The URL of the screenshot image
          x-ballerina-name: imageUrl
        file_id:
          type: string
          description: The identifier of an uploaded file that contains the screenshot
          x-ballerina-name: fileId
        type:
          type: string
          description: "Specifies the event type. For a computer screenshot, this\
            \ property is \nalways set to `computer_screenshot`\n"
          default: computer_screenshot
          enum:
          - computer_screenshot
          x-stainless-const: true
      description: |
        A computer screenshot image used with the computer use tool
    InputItem:
      discriminator:
        propertyName: type
      oneOf:
      - $ref: '#/components/schemas/EasyInputMessage'
      - $ref: '#/components/schemas/Item'
      - $ref: '#/components/schemas/ItemReferenceParam'
    AuditLogOrganizationupdatedChangesRequested:
      type: object
      properties:
        settings:
          $ref: '#/components/schemas/AuditLogOrganizationupdatedChangesRequestedSettings'
        name:
          type: string
          description: The organization name
        description:
          type: string
          description: The organization description
        title:
          type: string
          description: The organization title
      description: The payload used to update the organization settings
    ComputerToolCall:
      title: Computer tool call
      required:
      - action
      - call_id
      - id
      - pending_safety_checks
      - status
      - type
      type: object
      properties:
        pending_safety_checks:
          type: array
          description: |
            The pending safety checks for the computer call
          items:
            $ref: '#/components/schemas/ComputerToolCallSafetyCheck'
          x-ballerina-name: pendingSafetyChecks
        action:
          $ref: '#/components/schemas/ComputerAction'
        id:
          type: string
          description: The unique ID of the computer call
        type:
          type: string
          description: The type of the computer call. Always `computer_call`
          default: computer_call
          enum:
          - computer_call
        call_id:
          type: string
          description: |
            An identifier used when responding to the tool call with output
          x-ballerina-name: callId
        status:
          type: string
          description: |
            The status of the item. One of `in_progress`, `completed`, or
            `incomplete`. Populated when items are returned via API
          enum:
          - in_progress
          - completed
          - incomplete
      description: "A tool call to a computer use tool. See the \n[computer use guide](/docs/guides/tools-computer-use)\
        \ for more information\n"
    ModelResponseProperties:
      type: object
      properties:
        top_p:
          maximum: 1
          minimum: 0
          type: number
          description: |
            An alternative to sampling with temperature, called nucleus sampling,
            where the model considers the results of the tokens with top_p probability
            mass. So 0.1 means only the tokens comprising the top 10% probability mass
            are considered.

            We generally recommend altering this or `temperature` but not both
          nullable: true
          example: 1
          default: 1
          x-ballerina-name: topP
        metadata:
          $ref: '#/components/schemas/Metadata'
        temperature:
          maximum: 2
          minimum: 0
          type: number
          description: |
            What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.
            We generally recommend altering this or `top_p` but not both
          nullable: true
          example: 1
          default: 1
        service_tier:
          allOf:
          - $ref: '#/components/schemas/ServiceTier'
          x-ballerina-name: serviceTier
        user:
          type: string
          description: |
            A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids)
          example: user-1234
    RealtimeServerEventRateLimitsUpdated:
      required:
      - event_id
      - rate_limits
      - type
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event
          x-ballerina-name: eventId
        type:
          type: string
          description: "The event type, must be `rate_limits.updated`"
          enum:
          - rate_limits.updated
          x-stainless-const: true
        rate_limits:
          type: array
          description: List of rate limit information
          items:
            $ref: '#/components/schemas/RealtimeServerEventRateLimitsUpdatedRateLimits'
          x-ballerina-name: rateLimits
      description: "Emitted at the beginning of a Response to indicate the updated\
        \ rate limits. \nWhen a Response is created some tokens will be \"reserved\"\
        \ for the output \ntokens, the rate limits shown here reflect that reservation,\
        \ which is then \nadjusted accordingly once the Response is completed\n"
      x-oaiMeta:
        name: rate_limits.updated
        group: realtime
        example: |
          {
              "event_id": "event_5758",
              "type": "rate_limits.updated",
              "rate_limits": [
                  {
                      "name": "requests",
                      "limit": 1000,
                      "remaining": 999,
                      "reset_seconds": 60
                  },
                  {
                      "name": "tokens",
                      "limit": 50000,
                      "remaining": 49950,
                      "reset_seconds": 60
                  }
              ]
          }
    RealtimeServerEventResponseContentPartDonePart:
      type: object
      properties:
        transcript:
          type: string
          description: The transcript of the audio (if type is "audio")
        text:
          type: string
          description: The text content (if type is "text")
        audio:
          type: string
          description: Base64-encoded audio data (if type is "audio")
        type:
          type: string
          description: "The content type (\"text\", \"audio\")"
          enum:
          - audio
          - text
      description: The content part that is done
    MessageObject:
      title: The message object
      required:
      - assistant_id
      - attachments
      - completed_at
      - content
      - created_at
      - id
      - incomplete_at
      - incomplete_details
      - metadata
      - object
      - role
      - run_id
      - status
      - thread_id
      type: object
      properties:
        metadata:
          $ref: '#/components/schemas/Metadata'
        role:
          type: string
          description: The entity that produced the message. One of `user` or `assistant`
          enum:
          - user
          - assistant
        assistant_id:
          type: string
          description: "If applicable, the ID of the [assistant](/docs/api-reference/assistants)\
            \ that authored this message"
          nullable: true
          x-ballerina-name: assistantId
        run_id:
          type: string
          description: "The ID of the [run](/docs/api-reference/runs) associated with\
            \ the creation of this message. Value is `null` when messages are created\
            \ manually using the create message or create thread endpoints"
          nullable: true
          x-ballerina-name: runId
        attachments:
          type: array
          description: "A list of files attached to the message, and the tools they\
            \ were added to"
          nullable: true
          items:
            $ref: '#/components/schemas/CreateMessageRequestAttachments'
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the message was created
          x-ballerina-name: createdAt
        content:
          type: array
          description: The content of the message in array of text and/or images
          items:
            $ref: '#/components/schemas/MessageObjectContent'
        completed_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the message was completed
          nullable: true
          x-ballerina-name: completedAt
        thread_id:
          type: string
          description: "The [thread](/docs/api-reference/threads) ID that this message\
            \ belongs to"
          x-ballerina-name: threadId
        id:
          type: string
          description: "The identifier, which can be referenced in API endpoints"
        incomplete_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the message was marked
            as incomplete
          nullable: true
          x-ballerina-name: incompleteAt
        incomplete_details:
          allOf:
          - $ref: '#/components/schemas/MessageObjectIncompleteDetails'
          x-ballerina-name: incompleteDetails
        object:
          type: string
          description: "The object type, which is always `thread.message`"
          enum:
          - thread.message
          x-stainless-const: true
        status:
          type: string
          description: "The status of the message, which can be either `in_progress`,\
            \ `incomplete`, or `completed`"
          enum:
          - in_progress
          - incomplete
          - completed
      description: "Represents a message within a [thread](/docs/api-reference/threads)"
      x-oaiMeta:
        name: The message object
        beta: true
        example: |
          {
            "id": "msg_abc123",
            "object": "thread.message",
            "created_at": 1698983503,
            "thread_id": "thread_abc123",
            "role": "assistant",
            "content": [
              {
                "type": "text",
                "text": {
                  "value": "Hi! How can I help you today?",
                  "annotations": []
                }
              }
            ],
            "assistant_id": "asst_abc123",
            "run_id": "run_abc123",
            "attachments": [],
            "metadata": {}
          }
    ResponseAudioTranscriptDoneEvent:
      required:
      - response_id
      - type
      type: object
      properties:
        type:
          type: string
          description: |
            The type of the event. Always `response.audio.transcript.done`
          enum:
          - response.audio.transcript.done
          x-stainless-const: true
      description: Emitted when the full audio transcript is completed
      x-oaiMeta:
        name: response.audio.transcript.done
        group: responses
        example: |
          {
            "type": "response.audio.transcript.done",
            "response_id": "resp_123"
          }
    AuditLogActorSession:
      type: object
      properties:
        ip_address:
          type: string
          description: The IP address from which the action was performed
          x-ballerina-name: ipAddress
        user:
          $ref: '#/components/schemas/AuditLogActorUser'
      description: The session in which the audit logged action was performed
    ProjectUser:
      required:
      - added_at
      - email
      - id
      - name
      - object
      - role
      type: object
      properties:
        added_at:
          type: integer
          description: The Unix timestamp (in seconds) of when the project was added
          x-ballerina-name: addedAt
        role:
          type: string
          description: '`owner` or `member`'
          enum:
          - owner
          - member
        name:
          type: string
          description: The name of the user
        id:
          type: string
          description: "The identifier, which can be referenced in API endpoints"
        email:
          type: string
          description: The email address of the user
        object:
          type: string
          description: "The object type, which is always `organization.project.user`"
          enum:
          - organization.project.user
          x-stainless-const: true
      description: Represents an individual user in a project
      x-oaiMeta:
        name: The project user object
        example: |
          {
              "object": "organization.project.user",
              "id": "user_abc",
              "name": "First Last",
              "email": "user@example.com",
              "role": "owner",
              "added_at": 1711471533
          }
    EvalStoredCompletionsSource:
      title: StoredCompletionsRunDataSource
      required:
      - type
      type: object
      properties:
        metadata:
          $ref: '#/components/schemas/Metadata'
        created_after:
          type: integer
          description: An optional Unix timestamp to filter items created after this
            time
          nullable: true
          x-ballerina-name: createdAfter
        created_before:
          type: integer
          description: An optional Unix timestamp to filter items created before this
            time
          nullable: true
          x-ballerina-name: createdBefore
        limit:
          type: integer
          description: An optional maximum number of items to return
          nullable: true
        model:
          type: string
          description: "An optional model to filter by (e.g., 'gpt-4o')"
          nullable: true
        type:
          type: string
          description: The type of source. Always `stored_completions`
          default: stored_completions
          enum:
          - stored_completions
          x-stainless-const: true
      description: |
        A StoredCompletionsRunDataSource configuration describing a set of filters
      x-oaiMeta:
        name: The stored completions data source object used to configure an individual
          run
        group: eval runs
        example: |
          {
            "type": "stored_completions",
            "model": "gpt-4o",
            "created_after": 1668124800,
            "created_before": 1668124900,
            "limit": 100,
            "metadata": {}
          }
    PredictionContent:
      title: Static Content
      required:
      - content
      - type
      type: object
      properties:
        type:
          type: string
          description: |
            The type of the predicted content you want to provide. This type is
            currently always `content`
          enum:
          - content
          x-stainless-const: true
        content:
          description: |
            The content that should be matched when generating a model response.
            If generated tokens would match this content, the entire model response
            can be returned much more quickly
          oneOf:
          - title: Text content
            type: string
            description: |
              The content used for a Predicted Output. This is often the
              text of a file you are regenerating with minor changes.
          - title: Array of content parts
            minItems: 1
            type: array
            description: "An array of content parts with a defined type. Supported\
              \ options differ based on the [model](/docs/models) being used to generate\
              \ the response. Can contain text inputs."
            items:
              $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartText'
      description: |
        Static predicted output content, such as the content of a text file that is
        being regenerated
    BatchRequestInput:
      type: object
      properties:
        method:
          type: string
          description: The HTTP method to be used for the request. Currently only
            `POST` is supported
          enum:
          - POST
          x-stainless-const: true
        custom_id:
          type: string
          description: A developer-provided per-request id that will be used to match
            outputs to inputs. Must be unique for each request in a batch
          x-ballerina-name: customId
        url:
          type: string
          description: "The OpenAI API relative URL to be used for the request. Currently\
            \ `/v1/chat/completions`, `/v1/embeddings`, and `/v1/completions` are\
            \ supported"
      description: The per-line object of the batch input file
      x-oaiMeta:
        name: The request input object
        example: |
          {"custom_id": "request-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "What is 2+2?"}]}}
    ChatCompletionTokenLogprob:
      required:
      - bytes
      - logprob
      - token
      - top_logprobs
      type: object
      properties:
        top_logprobs:
          type: array
          description: "List of the most likely tokens and their log probability,\
            \ at this token position. In rare cases, there may be fewer than the number\
            \ of requested `top_logprobs` returned"
          items:
            $ref: '#/components/schemas/ChatCompletionTokenLogprobTopLogprobs'
          x-ballerina-name: topLogprobs
        logprob:
          type: number
          description: "The log probability of this token, if it is within the top\
            \ 20 most likely tokens. Otherwise, the value `-9999.0` is used to signify\
            \ that the token is very unlikely"
        bytes:
          type: array
          description: A list of integers representing the UTF-8 bytes representation
            of the token. Useful in instances where characters are represented by
            multiple tokens and their byte representations must be combined to generate
            the correct text representation. Can be `null` if there is no bytes representation
            for the token
          nullable: true
          items:
            type: integer
        token:
          type: string
          description: The token
    OutputItem:
      discriminator:
        propertyName: type
      anyOf:
      - $ref: '#/components/schemas/OutputMessage'
      - $ref: '#/components/schemas/FileSearchToolCall'
      - $ref: '#/components/schemas/FunctionToolCall'
      - $ref: '#/components/schemas/WebSearchToolCall'
      - $ref: '#/components/schemas/ComputerToolCall'
      - $ref: '#/components/schemas/ReasoningItem'
    ChatCompletionRequestMessage:
      oneOf:
      - $ref: '#/components/schemas/ChatCompletionRequestDeveloperMessage'
      - $ref: '#/components/schemas/ChatCompletionRequestSystemMessage'
      - $ref: '#/components/schemas/ChatCompletionRequestUserMessage'
      - $ref: '#/components/schemas/ChatCompletionRequestAssistantMessage'
      - $ref: '#/components/schemas/ChatCompletionRequestToolMessage'
      - $ref: '#/components/schemas/ChatCompletionRequestFunctionMessage'
    Image:
      type: object
      properties:
        revised_prompt:
          type: string
          description: "For `dall-e-3` only, the revised prompt that was used to generate\
            \ the image"
          x-ballerina-name: revisedPrompt
        b64_json:
          type: string
          description: "The base64-encoded JSON of the generated image. Default value\
            \ for `gpt-image-1`, and only present if `response_format` is set to `b64_json`\
            \ for `dall-e-2` and `dall-e-3`"
          x-ballerina-name: b64Json
        url:
          type: string
          description: "When using `dall-e-2` or `dall-e-3`, the URL of the generated\
            \ image if `response_format` is set to `url` (default value). Unsupported\
            \ for `gpt-image-1`"
      description: Represents the content or the URL of an image generated by the
        OpenAI API
    RealtimeServerEventConversationItemRetrieved:
      required:
      - event_id
      - item
      - type
      type: object
      properties:
        item:
          $ref: '#/components/schemas/RealtimeConversationItem'
        event_id:
          type: string
          description: The unique ID of the server event
          x-ballerina-name: eventId
        type:
          type: string
          description: "The event type, must be `conversation.item.retrieved`"
          enum:
          - conversation.item.retrieved
          x-stainless-const: true
      description: |
        Returned when a conversation item is retrieved with `conversation.item.retrieve`
      x-oaiMeta:
        name: conversation.item.retrieved
        group: realtime
        example: |
          {
              "event_id": "event_1920",
              "type": "conversation.item.created",
              "previous_item_id": "msg_002",
              "item": {
                  "id": "msg_003",
                  "object": "realtime.item",
                  "type": "message",
                  "status": "completed",
                  "role": "user",
                  "content": [
                      {
                          "type": "input_audio",
                          "transcript": "hello how are you",
                          "audio": "base64encodedaudio=="
                      }
                  ]
              }
          }
    FineTuneSupervisedMethodHyperparameters:
      type: object
      properties:
        batch_size:
          description: |
            Number of examples in each batch. A larger batch size means that model parameters are updated less frequently, but with lower variance
          oneOf:
          - type: string
            enum:
            - auto
            x-stainless-const: true
          - maximum: 256
            minimum: 1
            type: integer
          default: auto
          x-ballerina-name: batchSize
        n_epochs:
          description: |
            The number of epochs to train the model for. An epoch refers to one full cycle through the training dataset
          oneOf:
          - type: string
            enum:
            - auto
            x-stainless-const: true
          - maximum: 50
            minimum: 1
            type: integer
          default: auto
          x-ballerina-name: nEpochs
        learning_rate_multiplier:
          description: |
            Scaling factor for the learning rate. A smaller learning rate may be useful to avoid overfitting
          oneOf:
          - type: string
            enum:
            - auto
            x-stainless-const: true
          - minimum: 0
            exclusiveMinimum: true
            type: number
          default: auto
          x-ballerina-name: learningRateMultiplier
      description: The hyperparameters used for the fine-tuning job
    ComparisonFilter:
      title: Comparison Filter
      required:
      - key
      - type
      - value
      type: object
      properties:
        type:
          type: string
          description: |
            Specifies the comparison operator: `eq`, `ne`, `gt`, `gte`, `lt`, `lte`.
            - `eq`: equals
            - `ne`: not equal
            - `gt`: greater than
            - `gte`: greater than or equal
            - `lt`: less than
            - `lte`: less than or equal
          default: eq
          enum:
          - eq
          - ne
          - gt
          - gte
          - lt
          - lte
        value:
          description: "The value to compare against the attribute key; supports string,\
            \ number, or boolean types"
          oneOf:
          - type: string
          - type: number
          - type: boolean
        key:
          type: string
          description: The key to compare against the value
      additionalProperties: false
      description: |
        A filter used to compare a specified attribute key to a given value using a defined comparison operation
      x-oaiMeta:
        name: ComparisonFilter
    CreateFineTuningJobRequestHyperparameters:
      type: object
      properties:
        batch_size:
          description: |
            Number of examples in each batch. A larger batch size means that model parameters
            are updated less frequently, but with lower variance
          oneOf:
          - type: string
            enum:
            - auto
            x-stainless-const: true
          - maximum: 256
            minimum: 1
            type: integer
          default: auto
          x-ballerina-name: batchSize
        n_epochs:
          description: |
            The number of epochs to train the model for. An epoch refers to one full cycle
            through the training dataset
          oneOf:
          - type: string
            enum:
            - auto
            x-stainless-const: true
          - maximum: 50
            minimum: 1
            type: integer
          default: auto
          x-ballerina-name: nEpochs
        learning_rate_multiplier:
          description: |
            Scaling factor for the learning rate. A smaller learning rate may be useful to avoid
            overfitting
          oneOf:
          - type: string
            enum:
            - auto
            x-stainless-const: true
          - minimum: 0
            exclusiveMinimum: true
            type: number
          default: auto
          x-ballerina-name: learningRateMultiplier
      description: |
        The hyperparameters used for the fine-tuning job.
        This value is now deprecated in favor of `method`, and should be passed in under the `method` parameter
      deprecated: true
    RealtimeResponseCreateParamsTools:
      type: object
      properties:
        name:
          type: string
          description: The name of the function
        description:
          type: string
          description: "The description of the function, including guidance on when\
            \ and how \nto call it, and guidance about what to tell the user when\
            \ calling \n(if anything)\n"
        type:
          type: string
          description: "The type of the tool, i.e. `function`"
          enum:
          - function
          x-stainless-const: true
        parameters:
          type: object
          description: Parameters of the function in JSON Schema
    FineTuneDPOMethodHyperparameters:
      type: object
      properties:
        batch_size:
          description: |
            Number of examples in each batch. A larger batch size means that model parameters are updated less frequently, but with lower variance
          oneOf:
          - type: string
            enum:
            - auto
            x-stainless-const: true
          - maximum: 256
            minimum: 1
            type: integer
          default: auto
          x-ballerina-name: batchSize
        n_epochs:
          description: |
            The number of epochs to train the model for. An epoch refers to one full cycle through the training dataset
          oneOf:
          - type: string
            enum:
            - auto
            x-stainless-const: true
          - maximum: 50
            minimum: 1
            type: integer
          default: auto
          x-ballerina-name: nEpochs
        beta:
          description: |
            The beta value for the DPO method. A higher beta value will increase the weight of the penalty between the policy and reference model
          oneOf:
          - type: string
            enum:
            - auto
            x-stainless-const: true
          - maximum: 2
            minimum: 0
            exclusiveMinimum: true
            type: number
          default: auto
        learning_rate_multiplier:
          description: |
            Scaling factor for the learning rate. A smaller learning rate may be useful to avoid overfitting
          oneOf:
          - type: string
            enum:
            - auto
            x-stainless-const: true
          - minimum: 0
            exclusiveMinimum: true
            type: number
          default: auto
          x-ballerina-name: learningRateMultiplier
      description: The hyperparameters used for the fine-tuning job
    RealtimeTranscriptionSessionCreateRequestTurnDetection:
      type: object
      properties:
        silence_duration_ms:
          type: integer
          description: "Used only for `server_vad` mode. Duration of silence to detect\
            \ speech stop (in milliseconds). Defaults \nto 500ms. With shorter values\
            \ the model will respond more quickly, \nbut may jump in on short pauses\
            \ from the user\n"
          x-ballerina-name: silenceDurationMs
        create_response:
          type: boolean
          description: |
            Whether or not to automatically generate a response when a VAD stop event occurs. Not available for transcription sessions
          default: true
          x-ballerina-name: createResponse
        interrupt_response:
          type: boolean
          description: |
            Whether or not to automatically interrupt any ongoing response with output to the default
            conversation (i.e. `conversation` of `auto`) when a VAD start event occurs. Not available for transcription sessions
          default: true
          x-ballerina-name: interruptResponse
        prefix_padding_ms:
          type: integer
          description: "Used only for `server_vad` mode. Amount of audio to include\
            \ before the VAD detected speech (in \nmilliseconds). Defaults to 300ms\n"
          x-ballerina-name: prefixPaddingMs
        eagerness:
          type: string
          description: |
            Used only for `semantic_vad` mode. The eagerness of the model to respond. `low` will wait longer for the user to continue speaking, `high` will respond more quickly. `auto` is the default and is equivalent to `medium`
          default: auto
          enum:
          - low
          - medium
          - high
          - auto
        threshold:
          type: number
          description: "Used only for `server_vad` mode. Activation threshold for\
            \ VAD (0.0 to 1.0), this defaults to 0.5. A \nhigher threshold will require\
            \ louder audio to activate the model, and \nthus might perform better\
            \ in noisy environments\n"
        type:
          type: string
          description: |
            Type of turn detection
          default: server_vad
          enum:
          - server_vad
          - semantic_vad
      description: |
        Configuration for turn detection, ether Server VAD or Semantic VAD. This can be set to `null` to turn off, in which case the client must manually trigger model response.
        Server VAD means that the model will detect the start and end of speech based on audio volume and respond at the end of user speech.
        Semantic VAD is more advanced and uses a turn detection model (in conjuction with VAD) to semantically estimate whether the user has finished speaking, then dynamically sets a timeout based on this probability. For example, if user audio trails off with "uhhm", the model will score a low probability of turn end and wait longer for the user to continue speaking. This can be useful for more natural conversations, but may have a higher latency
    AuditLogCertificatedeleted:
      type: object
      properties:
        name:
          type: string
          description: The name of the certificate
        certificate:
          type: string
          description: The certificate content in PEM format
        id:
          type: string
          description: The certificate ID
      description: The details for events with this `type`
    AuditLogCheckpointPermissioncreated:
      type: object
      properties:
        data:
          $ref: '#/components/schemas/AuditLogCheckpointPermissioncreatedData'
        id:
          type: string
          description: The ID of the checkpoint permission
      description: The project and fine-tuned model checkpoint that the checkpoint
        permission was created for
    ResponseFormatJsonSchemaSchema:
      title: JSON schema
      type: object
      additionalProperties: true
      description: |
        The schema for the response format, described as a JSON Schema object.
        Learn how to build JSON schemas [here](https://json-schema.org/)
    FineTuneChatRequestInputMessages:
      oneOf:
      - $ref: '#/components/schemas/ChatCompletionRequestSystemMessage'
      - $ref: '#/components/schemas/ChatCompletionRequestUserMessage'
      - $ref: '#/components/schemas/FineTuneChatCompletionRequestAssistantMessage'
      - $ref: '#/components/schemas/ChatCompletionRequestToolMessage'
      - $ref: '#/components/schemas/ChatCompletionRequestFunctionMessage'
    RealtimeSession:
      type: object
      properties:
        voice:
          $ref: '#/components/schemas/VoiceIdsShared'
        instructions:
          type: string
          description: |
            The default system instructions (i.e. system message) prepended to model  calls. This field allows the client to guide the model on desired  responses. The model can be instructed on response content and format,  (e.g. "be extremely succinct", "act friendly", "here are examples of good  responses") and on audio behavior (e.g. "talk quickly", "inject emotion  into your voice", "laugh frequently"). The instructions are not guaranteed  to be followed by the model, but they provide guidance to the model on the desired behavior.

            Note that the server sets default instructions which will be used if this  field is not set and are visible in the `session.created` event at the  start of the session
        input_audio_format:
          type: string
          description: "The format of input audio. Options are `pcm16`, `g711_ulaw`,\
            \ or `g711_alaw`.\nFor `pcm16`, input audio must be 16-bit PCM at a 24kHz\
            \ sample rate, \nsingle channel (mono), and little-endian byte order\n"
          default: pcm16
          enum:
          - pcm16
          - g711_ulaw
          - g711_alaw
          x-ballerina-name: inputAudioFormat
        input_audio_noise_reduction:
          allOf:
          - $ref: '#/components/schemas/RealtimeSessionInputAudioNoiseReduction'
          x-ballerina-name: inputAudioNoiseReduction
        input_audio_transcription:
          allOf:
          - $ref: '#/components/schemas/RealtimeSessionInputAudioTranscription'
          x-ballerina-name: inputAudioTranscription
        turn_detection:
          allOf:
          - $ref: '#/components/schemas/RealtimeSessionTurnDetection'
          x-ballerina-name: turnDetection
        tools:
          type: array
          description: Tools (functions) available to the model
          items:
            $ref: '#/components/schemas/RealtimeResponseCreateParamsTools'
        modalities:
          type: array
          description: |
            The set of modalities the model can respond with. To disable audio,
            set this to ["text"]
          items:
            type: string
            enum:
            - text
            - audio
        max_response_output_tokens:
          description: |
            Maximum number of output tokens for a single assistant response,
            inclusive of tool calls. Provide an integer between 1 and 4096 to
            limit output tokens, or `inf` for the maximum available tokens for a
            given model. Defaults to `inf`
          oneOf:
          - type: integer
          - type: string
            enum:
            - inf
            x-stainless-const: true
          x-ballerina-name: maxResponseOutputTokens
        output_audio_format:
          type: string
          description: |
            The format of output audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.
            For `pcm16`, output audio is sampled at a rate of 24kHz
          default: pcm16
          enum:
          - pcm16
          - g711_ulaw
          - g711_alaw
          x-ballerina-name: outputAudioFormat
        temperature:
          type: number
          description: |
            Sampling temperature for the model, limited to [0.6, 1.2]. For audio models a temperature of 0.8 is highly recommended for best performance
          default: 0.8
        tool_choice:
          type: string
          description: "How the model chooses tools. Options are `auto`, `none`, `required`,\
            \ or \nspecify a function\n"
          default: auto
          x-ballerina-name: toolChoice
        model:
          type: string
          description: |
            The Realtime model used for this session
          enum:
          - gpt-4o-realtime-preview
          - gpt-4o-realtime-preview-2024-10-01
          - gpt-4o-realtime-preview-2024-12-17
          - gpt-4o-mini-realtime-preview
          - gpt-4o-mini-realtime-preview-2024-12-17
        id:
          type: string
          description: |
            Unique identifier for the session that looks like `sess_1234567890abcdef`
      description: Realtime session object configuration
    ChatCompletionFunctions:
      required:
      - name
      type: object
      properties:
        name:
          type: string
          description: "The name of the function to be called. Must be a-z, A-Z, 0-9,\
            \ or contain underscores and dashes, with a maximum length of 64"
        description:
          type: string
          description: "A description of what the function does, used by the model\
            \ to choose when and how to call the function"
        parameters:
          $ref: '#/components/schemas/FunctionParameters'
      deprecated: true
    RealtimeServerEventOutputAudioBufferStarted:
      required:
      - event_id
      - response_id
      - type
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event
          x-ballerina-name: eventId
        response_id:
          type: string
          description: The unique ID of the response that produced the audio
          x-ballerina-name: responseId
        type:
          type: string
          description: "The event type, must be `output_audio_buffer.started`"
          enum:
          - output_audio_buffer.started
          x-stainless-const: true
      description: |
        **WebRTC Only:** Emitted when the server begins streaming audio to the client. This event is
        emitted after an audio content part has been added (`response.content_part.added`)
        to the response.
        [Learn more](/docs/guides/realtime-model-capabilities#client-and-server-events-for-audio-in-webrtc)
      x-oaiMeta:
        name: output_audio_buffer.started
        group: realtime
        example: |
          {
              "event_id": "event_abc123",
              "type": "output_audio_buffer.started",
              "response_id": "resp_abc123"
          }
    RealtimeServerEventConversationItemInputAudioTranscriptionFailed:
      required:
      - content_index
      - error
      - event_id
      - item_id
      - type
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event
          x-ballerina-name: eventId
        item_id:
          type: string
          description: The ID of the user message item
          x-ballerina-name: itemId
        content_index:
          type: integer
          description: The index of the content part containing the audio
          x-ballerina-name: contentIndex
        type:
          type: string
          description: |
            The event type, must be
            `conversation.item.input_audio_transcription.failed`
          enum:
          - conversation.item.input_audio_transcription.failed
          x-stainless-const: true
        error:
          $ref: '#/components/schemas/RealtimeServerEventConversationItemInputAudioTranscriptionFailedError'
      description: "Returned when input audio transcription is configured, and a transcription\
        \ \nrequest for a user message failed. These events are separate from other\
        \ \n`error` events so that the client can identify the related Item\n"
      x-oaiMeta:
        name: conversation.item.input_audio_transcription.failed
        group: realtime
        example: |
          {
              "event_id": "event_2324",
              "type": "conversation.item.input_audio_transcription.failed",
              "item_id": "msg_003",
              "content_index": 0,
              "error": {
                  "type": "transcription_error",
                  "code": "audio_unintelligible",
                  "message": "The audio could not be transcribed.",
                  "param": null
              }
          }
    RealtimeTranscriptionSessionCreateRequest:
      type: object
      properties:
        input_audio_format:
          type: string
          description: "The format of input audio. Options are `pcm16`, `g711_ulaw`,\
            \ or `g711_alaw`.\nFor `pcm16`, input audio must be 16-bit PCM at a 24kHz\
            \ sample rate, \nsingle channel (mono), and little-endian byte order\n"
          default: pcm16
          enum:
          - pcm16
          - g711_ulaw
          - g711_alaw
          x-ballerina-name: inputAudioFormat
        include:
          type: array
          description: |
            The set of items to include in the transcription. Current available items are:
            - `item.input_audio_transcription.logprobs`
          items:
            type: string
        modalities:
          type: array
          description: |
            The set of modalities the model can respond with. To disable audio,
            set this to ["text"]
          items:
            type: string
            enum:
            - text
            - audio
        input_audio_noise_reduction:
          allOf:
          - $ref: '#/components/schemas/RealtimeSessionInputAudioNoiseReduction'
          x-ballerina-name: inputAudioNoiseReduction
        input_audio_transcription:
          allOf:
          - $ref: '#/components/schemas/RealtimeTranscriptionSessionCreateRequestInputAudioTranscription'
          x-ballerina-name: inputAudioTranscription
        turn_detection:
          allOf:
          - $ref: '#/components/schemas/RealtimeTranscriptionSessionCreateRequestTurnDetection'
          x-ballerina-name: turnDetection
      description: Realtime transcription session object configuration
    RealtimeServerEventResponseTextDone:
      required:
      - content_index
      - event_id
      - item_id
      - output_index
      - response_id
      - text
      - type
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event
          x-ballerina-name: eventId
        item_id:
          type: string
          description: The ID of the item
          x-ballerina-name: itemId
        content_index:
          type: integer
          description: The index of the content part in the item's content array
          x-ballerina-name: contentIndex
        response_id:
          type: string
          description: The ID of the response
          x-ballerina-name: responseId
        text:
          type: string
          description: The final text content
        type:
          type: string
          description: "The event type, must be `response.text.done`"
          enum:
          - response.text.done
          x-stainless-const: true
        output_index:
          type: integer
          description: The index of the output item in the response
          x-ballerina-name: outputIndex
      description: |
        Returned when the text value of a "text" content part is done streaming. Also
        emitted when a Response is interrupted, incomplete, or cancelled
      x-oaiMeta:
        name: response.text.done
        group: realtime
        example: |
          {
              "event_id": "event_4344",
              "type": "response.text.done",
              "response_id": "resp_001",
              "item_id": "msg_007",
              "output_index": 0,
              "content_index": 0,
              "text": "Sure, I can help with that."
          }
    AssistantToolsCode:
      title: Code interpreter tool
      required:
      - type
      type: object
      properties:
        type:
          type: string
          description: "The type of tool being defined: `code_interpreter`"
          enum:
          - code_interpreter
          x-stainless-const: true
    ChatCompletionResponseMessageUrlCitation:
      required:
      - end_index
      - start_index
      - title
      - url
      type: object
      properties:
        start_index:
          type: integer
          description: The index of the first character of the URL citation in the
            message
          x-ballerina-name: startIndex
        end_index:
          type: integer
          description: The index of the last character of the URL citation in the
            message
          x-ballerina-name: endIndex
        title:
          type: string
          description: The title of the web resource
        url:
          type: string
          description: The URL of the web resource
      description: A URL citation when using web search
    OtherChunkingStrategyResponseParam:
      title: Other Chunking Strategy
      required:
      - type
      type: object
      properties:
        type:
          type: string
          description: Always `other`
          enum:
          - other
          x-stainless-const: true
      additionalProperties: false
      description: "This is returned when the chunking strategy is unknown. Typically,\
        \ this is because the file was indexed before the `chunking_strategy` concept\
        \ was introduced in the API"
    CreateModelResponseProperties:
      allOf:
      - $ref: '#/components/schemas/ModelResponseProperties'
    RunStepStreamEventRunStepStreamEventRunStepStreamEventRunStepStreamEventRunStepStreamEventOneOf12345:
      required:
      - data
      - event
      type: object
      properties:
        data:
          $ref: '#/components/schemas/RunStepObject'
        event:
          type: string
          enum:
          - thread.run.step.failed
          x-stainless-const: true
      description: "Occurs when a [run step](/docs/api-reference/run-steps/step-object)\
        \ fails"
      x-oaiMeta:
        dataDescription: "`data` is a [run step](/docs/api-reference/run-steps/step-object)"
    AuditLogActorUser:
      type: object
      properties:
        id:
          type: string
          description: The user id
        email:
          type: string
          description: The user email
      description: The user who performed the audit logged action
    ChatCompletionRequestMessageContentPartImage:
      title: Image content part
      required:
      - image_url
      - type
      type: object
      properties:
        image_url:
          allOf:
          - $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartImageImageUrl'
          x-ballerina-name: imageUrl
        type:
          type: string
          description: The type of the content part
          enum:
          - image_url
          x-stainless-const: true
      description: |
        Learn about [image inputs](/docs/guides/vision)
    BatchesBody:
      required:
      - completion_window
      - endpoint
      - input_file_id
      type: object
      properties:
        endpoint:
          type: string
          description: "The endpoint to be used for all requests in the batch. Currently\
            \ `/v1/responses`, `/v1/chat/completions`, `/v1/embeddings`, and `/v1/completions`\
            \ are supported. Note that `/v1/embeddings` batches are also restricted\
            \ to a maximum of 50,000 embedding inputs across all requests in the batch"
          enum:
          - /v1/responses
          - /v1/chat/completions
          - /v1/embeddings
          - /v1/completions
        metadata:
          $ref: '#/components/schemas/Metadata'
        input_file_id:
          type: string
          description: |
            The ID of an uploaded file that contains requests for the new batch.

            See [upload file](/docs/api-reference/files/create) for how to upload a file.

            Your input file must be formatted as a [JSONL file](/docs/api-reference/batch/request-input), and must be uploaded with the purpose `batch`. The file can contain up to 50,000 requests, and can be up to 200 MB in size
          x-ballerina-name: inputFileId
        completion_window:
          type: string
          description: The time frame within which the batch should be processed.
            Currently only `24h` is supported
          enum:
          - 24h
          x-ballerina-name: completionWindow
    RealtimeServerEventInputAudioBufferCommitted:
      required:
      - event_id
      - item_id
      - previous_item_id
      - type
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event
          x-ballerina-name: eventId
        item_id:
          type: string
          description: The ID of the user message item that will be created
          x-ballerina-name: itemId
        type:
          type: string
          description: "The event type, must be `input_audio_buffer.committed`"
          enum:
          - input_audio_buffer.committed
          x-stainless-const: true
        previous_item_id:
          type: string
          description: |
            The ID of the preceding item after which the new item will be inserted
          x-ballerina-name: previousItemId
      description: "Returned when an input audio buffer is committed, either by the\
        \ client or \nautomatically in server VAD mode. The `item_id` property is\
        \ the ID of the user\nmessage item that will be created, thus a `conversation.item.created`\
        \ event \nwill also be sent to the client\n"
      x-oaiMeta:
        name: input_audio_buffer.committed
        group: realtime
        example: |
          {
              "event_id": "event_1121",
              "type": "input_audio_buffer.committed",
              "previous_item_id": "msg_001",
              "item_id": "msg_002"
          }
    CreateVectorStoreFileBatchRequest:
      required:
      - file_ids
      type: object
      properties:
        chunking_strategy:
          allOf:
          - $ref: '#/components/schemas/ChunkingStrategyRequestParam'
          x-ballerina-name: chunkingStrategy
        file_ids:
          maxItems: 500
          minItems: 1
          type: array
          description: "A list of [File](/docs/api-reference/files) IDs that the vector\
            \ store should use. Useful for tools like `file_search` that can access\
            \ files"
          items:
            type: string
          x-ballerina-name: fileIds
        attributes:
          $ref: '#/components/schemas/VectorStoreFileAttributes'
      additionalProperties: false
    MessageDeltaContentTextObject:
      title: Text
      required:
      - index
      - type
      type: object
      properties:
        index:
          type: integer
          description: The index of the content part in the message
        text:
          $ref: '#/components/schemas/MessageDeltaContentTextObjectText'
        type:
          type: string
          description: Always `text`
          enum:
          - text
          x-stainless-const: true
      description: The text content that is part of a message
    ProjectUserUpdateRequest:
      required:
      - role
      type: object
      properties:
        role:
          type: string
          description: '`owner` or `member`'
          enum:
          - owner
          - member
    AdminApiKeyOwner:
      type: object
      properties:
        role:
          type: string
          description: Always `owner`
          example: owner
        name:
          type: string
          description: The name of the user
          example: My Service Account
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) of when the user was created
          format: int64
          example: 1711471533
          x-ballerina-name: createdAt
        id:
          type: string
          description: "The identifier, which can be referenced in API endpoints"
          example: sa_456
        type:
          type: string
          description: Always `user`
          example: user
        object:
          type: string
          description: "The object type, which is always organization.user"
          example: organization.user
    CreateThreadRequest:
      type: object
      properties:
        tool_resources:
          allOf:
          - $ref: '#/components/schemas/CreateThreadRequestToolResources'
          x-ballerina-name: toolResources
        metadata:
          $ref: '#/components/schemas/Metadata'
        messages:
          type: array
          description: "A list of [messages](/docs/api-reference/messages) to start\
            \ the thread with"
          items:
            $ref: '#/components/schemas/CreateMessageRequest'
      additionalProperties: false
      description: "Options to create a new thread. If no thread is provided when\
        \ running a \nrequest, an empty thread will be created\n"
    MessageStreamEventMessageStreamEventMessageStreamEventMessageStreamEventOneOf1234:
      required:
      - data
      - event
      type: object
      properties:
        data:
          $ref: '#/components/schemas/MessageObject'
        event:
          type: string
          enum:
          - thread.message.completed
          x-stainless-const: true
      description: "Occurs when a [message](/docs/api-reference/messages/object) is\
        \ completed"
      x-oaiMeta:
        dataDescription: "`data` is a [message](/docs/api-reference/messages/object)"
    EvalRunOutputItem:
      title: EvalRunOutputItem
      required:
      - created_at
      - datasource_item
      - datasource_item_id
      - eval_id
      - id
      - object
      - results
      - run_id
      - sample
      - status
      type: object
      properties:
        datasource_item:
          type: object
          additionalProperties: true
          description: Details of the input data source item
          x-ballerina-name: datasourceItem
        run_id:
          type: string
          description: The identifier of the evaluation run associated with this output
            item
          x-ballerina-name: runId
        eval_id:
          type: string
          description: The identifier of the evaluation group
          x-ballerina-name: evalId
        created_at:
          type: integer
          description: Unix timestamp (in seconds) when the evaluation run was created
          x-ballerina-name: createdAt
        datasource_item_id:
          type: integer
          description: The identifier for the data source item
          x-ballerina-name: datasourceItemId
        id:
          type: string
          description: Unique identifier for the evaluation run output item
        results:
          type: array
          description: A list of results from the evaluation run
          items:
            type: object
            additionalProperties: true
            description: A result object.
        sample:
          $ref: '#/components/schemas/EvalRunOutputItemSample'
        object:
          type: string
          description: The type of the object. Always "eval.run.output_item"
          default: eval.run.output_item
          enum:
          - eval.run.output_item
          x-stainless-const: true
        status:
          type: string
          description: The status of the evaluation run
      description: |
        A schema representing an evaluation run output item
      x-oaiMeta:
        name: The eval run output item object
        group: evals
        example: |
          {
            "object": "eval.run.output_item",
            "id": "outputitem_67abd55eb6548190bb580745d5644a33",
            "run_id": "evalrun_67abd54d60ec8190832b46859da808f7",
            "eval_id": "eval_67abd54d9b0081909a86353f6fb9317a",
            "created_at": 1739314509,
            "status": "pass",
            "datasource_item_id": 137,
            "datasource_item": {
                "teacher": "To grade essays, I only check for style, content, and grammar.",
                "student": "I am a student who is trying to write the best essay."
            },
            "results": [
              {
                "name": "String Check Grader",
                "type": "string-check-grader",
                "score": 1.0,
                "passed": true,
              }
            ],
            "sample": {
              "input": [
                {
                  "role": "system",
                  "content": "You are an evaluator bot..."
                },
                {
                  "role": "user",
                  "content": "You are assessing..."
                }
              ],
              "output": [
                {
                  "role": "assistant",
                  "content": "The rubric is not clear nor concise."
                }
              ],
              "finish_reason": "stop",
              "model": "gpt-4o-2024-08-06",
              "usage": {
                "total_tokens": 521,
                "completion_tokens": 2,
                "prompt_tokens": 519,
                "cached_tokens": 0
              },
              "error": null,
              "temperature": 1.0,
              "max_completion_tokens": 2048,
              "top_p": 1.0,
              "seed": 42
            }
          }
    ModifyAssistantRequestToolResourcesFileSearch:
      type: object
      properties:
        vector_store_ids:
          maxItems: 1
          type: array
          description: |
            Overrides the [vector store](/docs/api-reference/vector-stores/object) attached to this assistant. There can be a maximum of 1 vector store attached to the assistant
          items:
            type: string
          x-ballerina-name: vectorStoreIds
    TranscriptTextDeltaEventLogprobs:
      type: object
      properties:
        logprob:
          type: number
          description: |
            The log probability of the token
        bytes:
          type: array
          description: |
            The bytes that were used to generate the log probability
          items:
            type: integer
        token:
          type: string
          description: |
            The token that was used to generate the log probability
    RealtimeServerEventResponseContentPartDone:
      required:
      - content_index
      - event_id
      - item_id
      - output_index
      - part
      - response_id
      - type
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event
          x-ballerina-name: eventId
        item_id:
          type: string
          description: The ID of the item
          x-ballerina-name: itemId
        content_index:
          type: integer
          description: The index of the content part in the item's content array
          x-ballerina-name: contentIndex
        response_id:
          type: string
          description: The ID of the response
          x-ballerina-name: responseId
        part:
          $ref: '#/components/schemas/RealtimeServerEventResponseContentPartDonePart'
        type:
          type: string
          description: "The event type, must be `response.content_part.done`"
          enum:
          - response.content_part.done
          x-stainless-const: true
        output_index:
          type: integer
          description: The index of the output item in the response
          x-ballerina-name: outputIndex
      description: |
        Returned when a content part is done streaming in an assistant message item.
        Also emitted when a Response is interrupted, incomplete, or cancelled
      x-oaiMeta:
        name: response.content_part.done
        group: realtime
        example: |
          {
              "event_id": "event_3940",
              "type": "response.content_part.done",
              "response_id": "resp_001",
              "item_id": "msg_007",
              "output_index": 0,
              "content_index": 0,
              "part": {
                  "type": "text",
                  "text": "Sure, I can help with that."
              }
          }
    CreateThreadRequestToolResourcesFileSearch:
      type: object
      properties:
        vector_store_ids:
          maxItems: 1
          type: array
          description: |
            The [vector store](/docs/api-reference/vector-stores/object) attached to this thread. There can be a maximum of 1 vector store attached to the thread.
          items:
            type: string
        vector_stores:
          maxItems: 1
          type: array
          description: |
            A helper to create a [vector store](/docs/api-reference/vector-stores/object) with file_ids and attach it to this thread. There can be a maximum of 1 vector store attached to the thread.
          items:
            type: object
            properties:
              file_ids:
                maxItems: 10000
                type: array
                description: |
                  A list of [file](/docs/api-reference/files) IDs to add to the vector store. There can be a maximum of 10000 files in a vector store.
                items:
                  type: string
              chunking_strategy:
                type: object
                description: "The chunking strategy used to chunk the file(s). If\
                  \ not set, will use the `auto` strategy."
                oneOf:
                - title: Auto Chunking Strategy
                  required:
                  - type
                  type: object
                  properties:
                    type:
                      type: string
                      description: Always `auto`.
                      enum:
                      - auto
                      x-stainless-const: true
                  additionalProperties: false
                  description: The default strategy. This strategy currently uses
                    a `max_chunk_size_tokens` of `800` and `chunk_overlap_tokens`
                    of `400`.
                - title: Static Chunking Strategy
                  required:
                  - static
                  - type
                  type: object
                  properties:
                    type:
                      type: string
                      description: Always `static`.
                      enum:
                      - static
                      x-stainless-const: true
                    static:
                      required:
                      - chunk_overlap_tokens
                      - max_chunk_size_tokens
                      type: object
                      properties:
                        max_chunk_size_tokens:
                          maximum: 4096
                          minimum: 100
                          type: integer
                          description: The maximum number of tokens in each chunk.
                            The default value is `800`. The minimum value is `100`
                            and the maximum value is `4096`.
                        chunk_overlap_tokens:
                          type: integer
                          description: |
                            The number of tokens that overlap between chunks. The default value is `400`.

                            Note that the overlap must not exceed half of `max_chunk_size_tokens`.
                      additionalProperties: false
                  additionalProperties: false
              metadata:
                $ref: '#/components/schemas/Metadata'
      oneOf:
      - required:
        - vector_store_ids
      - required:
        - vector_stores
    Upload:
      title: Upload
      required:
      - bytes
      - created_at
      - expires_at
      - filename
      - id
      - purpose
      - status
      type: object
      properties:
        filename:
          type: string
          description: The name of the file to be uploaded
        expires_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the Upload will expire
          x-ballerina-name: expiresAt
        file:
          allOf:
          - $ref: '#/components/schemas/OpenAIFile'
          - description: The ready File object after the Upload is completed.
            nullable: true
        purpose:
          type: string
          description: "The intended purpose of the file. [Please refer here](/docs/api-reference/files/object#files/object-purpose)\
            \ for acceptable values"
        bytes:
          type: integer
          description: The intended number of bytes to be uploaded
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the Upload was created
          x-ballerina-name: createdAt
        id:
          type: string
          description: "The Upload unique identifier, which can be referenced in API\
            \ endpoints"
        status:
          type: string
          description: The status of the Upload
          enum:
          - pending
          - completed
          - cancelled
          - expired
        object:
          type: string
          description: "The object type, which is always \"upload\""
          enum:
          - upload
          x-stainless-const: true
      description: |
        The Upload object can accept byte chunks in the form of Parts
      x-oaiMeta:
        name: The upload object
        example: |
          {
            "id": "upload_abc123",
            "object": "upload",
            "bytes": 2147483648,
            "created_at": 1719184911,
            "filename": "training_examples.jsonl",
            "purpose": "fine-tune",
            "status": "completed",
            "expires_at": 1719127296,
            "file": {
              "id": "file-xyz321",
              "object": "file",
              "bytes": 2147483648,
              "created_at": 1719186911,
              "filename": "training_examples.jsonl",
              "purpose": "fine-tune",
            }
          }
    ModifyCertificateRequest:
      required:
      - name
      type: object
      properties:
        name:
          type: string
          description: The updated name for the certificate
    FunctionToolCallOutputResourceAllOf2:
      required:
      - id
      type: object
    ThreadStreamEvent:
      oneOf:
      - $ref: '#/components/schemas/ThreadStreamEventOneOf1'
    RealtimeConversationItemContent:
      type: object
      properties:
        transcript:
          type: string
          description: |
            The transcript of the audio, used for `input_audio` content type
        text:
          type: string
          description: |
            The text content, used for `input_text` and `text` content types
        id:
          type: string
          description: |
            ID of a previous conversation item to reference (for `item_reference`
            content types in `response.create` events). These can reference both
            client and server created items
        audio:
          type: string
          description: |
            Base64-encoded audio bytes, used for `input_audio` content type
        type:
          type: string
          description: |
            The content type (`input_text`, `input_audio`, `item_reference`, `text`)
          enum:
          - input_audio
          - input_text
          - item_reference
          - text
    VectorStoreFileObjectLastError:
      required:
      - code
      - message
      type: object
      properties:
        code:
          type: string
          description: One of `server_error` or `rate_limit_exceeded`
          enum:
          - server_error
          - unsupported_file
          - invalid_file
        message:
          type: string
          description: A human-readable description of the error
      description: The last error associated with this vector store file. Will be
        `null` if there are no errors
      nullable: true
    UsageCodeInterpreterSessionsResult:
      required:
      - object
      - sessions
      type: object
      properties:
        num_sessions:
          type: integer
          description: The number of code interpreter sessions
          x-ballerina-name: numSessions
        project_id:
          type: string
          description: "When `group_by=project_id`, this field provides the project\
            \ ID of the grouped usage result"
          nullable: true
          x-ballerina-name: projectId
        object:
          type: string
          enum:
          - organization.usage.code_interpreter_sessions.result
          x-stainless-const: true
      description: The aggregated code interpreter sessions usage details of the specific
        time bucket
      x-oaiMeta:
        name: Code interpreter sessions usage object
        example: |
          {
              "object": "organization.usage.code_interpreter_sessions.result",
              "num_sessions": 1,
              "project_id": "proj_abc"
          }
    UsageAudioSpeechesResult:
      required:
      - characters
      - num_model_requests
      - object
      type: object
      properties:
        characters:
          type: integer
          description: The number of characters processed
        num_model_requests:
          type: integer
          description: The count of requests made to the model
          x-ballerina-name: numModelRequests
        project_id:
          type: string
          description: "When `group_by=project_id`, this field provides the project\
            \ ID of the grouped usage result"
          nullable: true
          x-ballerina-name: projectId
        user_id:
          type: string
          description: "When `group_by=user_id`, this field provides the user ID of\
            \ the grouped usage result"
          nullable: true
          x-ballerina-name: userId
        model:
          type: string
          description: "When `group_by=model`, this field provides the model name\
            \ of the grouped usage result"
          nullable: true
        api_key_id:
          type: string
          description: "When `group_by=api_key_id`, this field provides the API key\
            \ ID of the grouped usage result"
          nullable: true
          x-ballerina-name: apiKeyId
        object:
          type: string
          enum:
          - organization.usage.audio_speeches.result
          x-stainless-const: true
      description: The aggregated audio speeches usage details of the specific time
        bucket
      x-oaiMeta:
        name: Audio speeches usage object
        example: |
          {
              "object": "organization.usage.audio_speeches.result",
              "characters": 45,
              "num_model_requests": 1,
              "project_id": "proj_abc",
              "user_id": "user-abc",
              "api_key_id": "key_abc",
              "model": "tts-1"
          }
    RunStepStreamEventRunStepStreamEventOneOf12:
      required:
      - data
      - event
      type: object
      properties:
        data:
          $ref: '#/components/schemas/RunStepObject'
        event:
          type: string
          enum:
          - thread.run.step.in_progress
          x-stainless-const: true
      description: "Occurs when a [run step](/docs/api-reference/run-steps/step-object)\
        \ moves to an `in_progress` state"
      x-oaiMeta:
        dataDescription: "`data` is a [run step](/docs/api-reference/run-steps/step-object)"
    RunCompletionUsage:
      required:
      - completion_tokens
      - prompt_tokens
      - total_tokens
      type: object
      properties:
        completion_tokens:
          type: integer
          description: Number of completion tokens used over the course of the run
          x-ballerina-name: completionTokens
        prompt_tokens:
          type: integer
          description: Number of prompt tokens used over the course of the run
          x-ballerina-name: promptTokens
        total_tokens:
          type: integer
          description: Total number of tokens used (prompt + completion)
          x-ballerina-name: totalTokens
      description: "Usage statistics related to the run. This value will be `null`\
        \ if the run is not in a terminal state (i.e. `in_progress`, `queued`, etc.)"
      nullable: true
    ChatCompletionResponseMessageFunctionCall:
      required:
      - arguments
      - name
      type: object
      properties:
        name:
          type: string
          description: The name of the function to call
        arguments:
          type: string
          description: "The arguments to call the function with, as generated by the\
            \ model in JSON format. Note that the model does not always generate valid\
            \ JSON, and may hallucinate parameters not defined by your function schema.\
            \ Validate the arguments in your code before calling your function"
      description: "Deprecated and replaced by `tool_calls`. The name and arguments\
        \ of a function that should be called, as generated by the model"
      deprecated: true
    DeleteModelResponse:
      required:
      - deleted
      - id
      - object
      type: object
      properties:
        deleted:
          type: boolean
        id:
          type: string
        object:
          type: string
    ImagesResponse:
      title: Image generation response
      required:
      - created
      type: object
      properties:
        data:
          type: array
          description: The list of generated images
          items:
            $ref: '#/components/schemas/Image'
        created:
          type: integer
          description: The Unix timestamp (in seconds) of when the image was created
        usage:
          $ref: '#/components/schemas/ImagesResponseUsage'
      description: The response from the image generation endpoint
      x-oaiMeta:
        name: The image generation response
        group: images
        example: |
          {
            "created": 1713833628,
            "data": [
              {
                "b64_json": "..."
              }
            ],
            "usage": {
              "total_tokens": 100,
              "input_tokens": 50,
              "output_tokens": 50,
              "input_tokens_details": {
                "text_tokens": 10,
                "image_tokens": 40
              }
            }
          }
    CreateCompletionResponseChoices:
      required:
      - finish_reason
      - index
      - logprobs
      - text
      type: object
      properties:
        finish_reason:
          type: string
          description: |
            The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence,
            `length` if the maximum number of tokens specified in the request was reached,
            or `content_filter` if content was omitted due to a flag from our content filters
          enum:
          - stop
          - length
          - content_filter
          x-ballerina-name: finishReason
        index:
          type: integer
        text:
          type: string
        logprobs:
          $ref: '#/components/schemas/CreateCompletionResponseLogprobs'
    FineTuneMethod:
      type: object
      properties:
        supervised:
          $ref: '#/components/schemas/FineTuneSupervisedMethod'
        dpo:
          $ref: '#/components/schemas/FineTuneDPOMethod'
        type:
          type: string
          description: The type of method. Is either `supervised` or `dpo`
          enum:
          - supervised
          - dpo
      description: The method used for fine-tuning
    ListAuditLogsResponse:
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
      type: object
      properties:
        first_id:
          type: string
          example: audit_log-defb456h8dks
          x-ballerina-name: firstId
        data:
          type: array
          items:
            $ref: '#/components/schemas/AuditLog'
        last_id:
          type: string
          example: audit_log-hnbkd8s93s
          x-ballerina-name: lastId
        has_more:
          type: boolean
          x-ballerina-name: hasMore
        object:
          type: string
          enum:
          - list
          x-stainless-const: true
    MessageDeltaContentImageFileObjectImageFile:
      type: object
      properties:
        file_id:
          type: string
          description: "The [File](/docs/api-reference/files) ID of the image in the\
            \ message content. Set `purpose=\"vision\"` when uploading the File if\
            \ you need to later display the file content"
          x-ballerina-name: fileId
        detail:
          type: string
          description: "Specifies the detail level of the image if specified by the\
            \ user. `low` uses fewer tokens, you can opt in to high resolution using\
            \ `high`"
          default: auto
          enum:
          - auto
          - low
          - high
    ChatCompletionRequestMessageContentPartFileFile:
      type: object
      properties:
        filename:
          type: string
          description: "The name of the file, used when passing the file to the model\
            \ as a \nstring\n"
        file_id:
          type: string
          description: |
            The ID of an uploaded file to use as input
          x-ballerina-name: fileId
        file_data:
          type: string
          description: "The base64 encoded file data, used when passing the file to\
            \ the model \nas a string\n"
          x-ballerina-name: fileData
    CodeInterpreterFileOutput:
      title: Code interpreter file output
      required:
      - files
      - type
      type: object
      properties:
        files:
          type: array
          items:
            $ref: '#/components/schemas/CodeInterpreterFileOutputFiles'
        type:
          type: string
          description: |
            The type of the code interpreter file output. Always `files`
          enum:
          - files
          x-stainless-const: true
      description: |
        The output of a code interpreter tool call that is a file
    RunStepDeltaStepDetailsToolCallsCodeOutputImageObjectImage:
      type: object
      properties:
        file_id:
          type: string
          description: "The [file](/docs/api-reference/files) ID of the image"
          x-ballerina-name: fileId
    VectorStoreFileBatchObjectFileCounts:
      required:
      - cancelled
      - completed
      - failed
      - in_progress
      - total
      type: object
      properties:
        in_progress:
          type: integer
          description: The number of files that are currently being processed
          x-ballerina-name: inProgress
        total:
          type: integer
          description: The total number of files
        cancelled:
          type: integer
          description: The number of files that where cancelled
        completed:
          type: integer
          description: The number of files that have been processed
        failed:
          type: integer
          description: The number of files that have failed to process
    EvalRunList:
      title: EvalRunList
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
      type: object
      properties:
        first_id:
          type: string
          description: The identifier of the first eval run in the data array
          x-ballerina-name: firstId
        data:
          type: array
          description: |
            An array of eval run objects
          items:
            $ref: '#/components/schemas/EvalRun'
        last_id:
          type: string
          description: The identifier of the last eval run in the data array
          x-ballerina-name: lastId
        has_more:
          type: boolean
          description: Indicates whether there are more evals available
          x-ballerina-name: hasMore
        object:
          type: string
          description: |
            The type of this object. It is always set to "list"
          default: list
          enum:
          - list
          x-stainless-const: true
      description: |
        An object representing a list of runs for an evaluation
      x-oaiMeta:
        name: The eval run list object
        group: evals
        example: |
          {
            "object": "list",
            "data": [
              {
                "object": "eval.run",
                "id": "evalrun_67b7fbdad46c819092f6fe7a14189620",
                "eval_id": "eval_67b7fa9a81a88190ab4aa417e397ea21",
                "report_url": "https://platform.openai.com/evaluations/eval_67b7fa9a81a88190ab4aa417e397ea21?run_id=evalrun_67b7fbdad46c819092f6fe7a14189620",
                "status": "completed",
                "model": "o3-mini",
                "name": "Academic Assistant",
                "created_at": 1740110812,
                "result_counts": {
                  "total": 171,
                  "errored": 0,
                  "failed": 80,
                  "passed": 91
                },
                "per_model_usage": null,
                "per_testing_criteria_results": [
                  {
                    "testing_criteria": "String check grader",
                    "passed": 91,
                    "failed": 80
                  }
                ],
                "run_data_source": {
                  "type": "completions",
                  "template_messages": [
                    {
                      "type": "message",
                      "role": "system",
                      "content": {
                        "type": "input_text",
                        "text": "You are a helpful assistant."
                      }
                    },
                    {
                      "type": "message",
                      "role": "user",
                      "content": {
                        "type": "input_text",
                        "text": "Hello, can you help me with my homework?"
                      }
                    }
                  ],
                  "datasource_reference": null,
                  "model": "o3-mini",
                  "max_completion_tokens": null,
                  "seed": null,
                  "temperature": null,
                  "top_p": null
                },
                "error": null,
                "metadata": {"test": "synthetics"}
              }
            ],
            "first_id": "evalrun_67abd54d60ec8190832b46859da808f7",
            "last_id": "evalrun_67abd54d60ec8190832b46859da808f7",
            "has_more": false
          }
    Annotation:
      discriminator:
        propertyName: type
      oneOf:
      - $ref: '#/components/schemas/FileCitationBody'
      - $ref: '#/components/schemas/UrlCitationBody'
      - $ref: '#/components/schemas/FilePath'
    FileSearchToolCallResults:
      type: object
      properties:
        score:
          type: number
          description: |
            The relevance score of the file - a value between 0 and 1
          format: float
        filename:
          type: string
          description: |
            The name of the file
        file_id:
          type: string
          description: |
            The unique ID of the file
          x-ballerina-name: fileId
        attributes:
          $ref: '#/components/schemas/VectorStoreFileAttributes'
        text:
          type: string
          description: |
            The text that was retrieved from the file
    MessageDeltaContentTextAnnotationsFileCitationObject:
      title: File citation
      required:
      - index
      - type
      type: object
      properties:
        start_index:
          minimum: 0
          type: integer
          x-ballerina-name: startIndex
        file_citation:
          allOf:
          - $ref: '#/components/schemas/MessageDeltaContentTextAnnotationsFileCitationObjectFileCitation'
          x-ballerina-name: fileCitation
        index:
          type: integer
          description: The index of the annotation in the text content part
        end_index:
          minimum: 0
          type: integer
          x-ballerina-name: endIndex
        text:
          type: string
          description: The text in the message content that needs to be replaced
        type:
          type: string
          description: Always `file_citation`
          enum:
          - file_citation
          x-stainless-const: true
      description: A citation within the message that points to a specific quote from
        a specific File associated with the assistant or the message. Generated when
        the assistant uses the "file_search" tool to search files
    ResponseReasoningSummaryPartAddedEventPart:
      required:
      - text
      - type
      type: object
      properties:
        text:
          type: string
          description: The text of the summary part
        type:
          type: string
          description: The type of the summary part. Always `summary_text`
          enum:
          - summary_text
          x-stainless-const: true
      description: |
        The summary part that was added
    Drag:
      title: Drag
      required:
      - path
      - type
      type: object
      properties:
        path:
          type: array
          description: |
            An array of coordinates representing the path of the drag action. Coordinates will appear as an array
            of objects, eg
            ```
            [
              { x: 100, y: 200 },
              { x: 200, y: 300 }
            ]
            ```
          items:
            $ref: '#/components/schemas/Coordinate'
        type:
          type: string
          description: "Specifies the event type. For a drag action, this property\
            \ is \nalways set to `drag`\n"
          default: drag
          enum:
          - drag
          x-stainless-const: true
      description: |
        A drag action
    ListModelsResponse:
      required:
      - data
      - object
      type: object
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/Model'
        object:
          type: string
          enum:
          - list
          x-stainless-const: true
    Reasoning:
      title: Reasoning
      type: object
      properties:
        summary:
          type: string
          description: |
            A summary of the reasoning performed by the model. This can be
            useful for debugging and understanding the model's reasoning process.
            One of `auto`, `concise`, or `detailed`
          nullable: true
          enum:
          - auto
          - concise
          - detailed
        effort:
          $ref: '#/components/schemas/ReasoningEffort'
        generate_summary:
          type: string
          description: |
            **Deprecated:** use `summary` instead.

            A summary of the reasoning performed by the model. This can be
            useful for debugging and understanding the model's reasoning process.
            One of `auto`, `concise`, or `detailed`
          nullable: true
          deprecated: true
          enum:
          - auto
          - concise
          - detailed
          x-ballerina-name: generateSummary
      description: "**o-series models only**\n\nConfiguration options for \n[reasoning\
        \ models](https://platform.openai.com/docs/guides/reasoning)\n"
    RealtimeServerEventConversationItemInputAudioTranscriptionFailedError:
      type: object
      properties:
        code:
          type: string
          description: "Error code, if any"
        param:
          type: string
          description: "Parameter related to the error, if any"
        type:
          type: string
          description: The type of error
        message:
          type: string
          description: A human-readable error message
      description: Details of the transcription error
    DoubleClick:
      title: DoubleClick
      required:
      - type
      - x
      - "y"
      type: object
      properties:
        x:
          type: integer
          description: |
            The x-coordinate where the double click occurred
        "y":
          type: integer
          description: |
            The y-coordinate where the double click occurred
        type:
          type: string
          description: "Specifies the event type. For a double click action, this\
            \ property is \nalways set to `double_click`\n"
          default: double_click
          enum:
          - double_click
          x-stainless-const: true
      description: |
        A double click action
    ResponseStreamEvent:
      discriminator:
        propertyName: type
      anyOf:
      - $ref: '#/components/schemas/ResponseAudioDeltaEvent'
      - $ref: '#/components/schemas/ResponseAudioDoneEvent'
      - $ref: '#/components/schemas/ResponseAudioTranscriptDeltaEvent'
      - $ref: '#/components/schemas/ResponseAudioTranscriptDoneEvent'
      - $ref: '#/components/schemas/ResponseCodeInterpreterCallCodeDeltaEvent'
      - $ref: '#/components/schemas/ResponseCodeInterpreterCallCodeDoneEvent'
      - $ref: '#/components/schemas/ResponseCodeInterpreterCallCompletedEvent'
      - $ref: '#/components/schemas/ResponseCodeInterpreterCallInProgressEvent'
      - $ref: '#/components/schemas/ResponseCodeInterpreterCallInterpretingEvent'
      - $ref: '#/components/schemas/ResponseCompletedEvent'
      - $ref: '#/components/schemas/ResponseContentPartAddedEvent'
      - $ref: '#/components/schemas/ResponseContentPartDoneEvent'
      - $ref: '#/components/schemas/ResponseCreatedEvent'
      - $ref: '#/components/schemas/ResponseErrorEvent'
      - $ref: '#/components/schemas/ResponseFileSearchCallCompletedEvent'
      - $ref: '#/components/schemas/ResponseFileSearchCallInProgressEvent'
      - $ref: '#/components/schemas/ResponseFileSearchCallSearchingEvent'
      - $ref: '#/components/schemas/ResponseFunctionCallArgumentsDeltaEvent'
      - $ref: '#/components/schemas/ResponseFunctionCallArgumentsDoneEvent'
      - $ref: '#/components/schemas/ResponseInProgressEvent'
      - $ref: '#/components/schemas/ResponseFailedEvent'
      - $ref: '#/components/schemas/ResponseIncompleteEvent'
      - $ref: '#/components/schemas/ResponseOutputItemAddedEvent'
      - $ref: '#/components/schemas/ResponseOutputItemDoneEvent'
      - $ref: '#/components/schemas/ResponseReasoningSummaryPartAddedEvent'
      - $ref: '#/components/schemas/ResponseReasoningSummaryPartDoneEvent'
      - $ref: '#/components/schemas/ResponseReasoningSummaryTextDeltaEvent'
      - $ref: '#/components/schemas/ResponseReasoningSummaryTextDoneEvent'
      - $ref: '#/components/schemas/ResponseRefusalDeltaEvent'
      - $ref: '#/components/schemas/ResponseRefusalDoneEvent'
      - $ref: '#/components/schemas/ResponseTextAnnotationDeltaEvent'
      - $ref: '#/components/schemas/ResponseTextDeltaEvent'
      - $ref: '#/components/schemas/ResponseTextDoneEvent'
      - $ref: '#/components/schemas/ResponseWebSearchCallCompletedEvent'
      - $ref: '#/components/schemas/ResponseWebSearchCallInProgressEvent'
      - $ref: '#/components/schemas/ResponseWebSearchCallSearchingEvent'
    ResponseIncompleteDetails:
      type: object
      properties:
        reason:
          type: string
          description: The reason why the response is incomplete
          enum:
          - max_output_tokens
          - content_filter
      description: |
        Details about why the response is incomplete
      nullable: true
    InputMessage:
      title: Input message
      required:
      - content
      - role
      type: object
      properties:
        role:
          type: string
          description: |
            The role of the message input. One of `user`, `system`, or `developer`
          enum:
          - user
          - system
          - developer
        type:
          type: string
          description: |
            The type of the message input. Always set to `message`
          enum:
          - message
          x-stainless-const: true
        content:
          $ref: '#/components/schemas/InputMessageContentList'
        status:
          type: string
          description: |
            The status of item. One of `in_progress`, `completed`, or
            `incomplete`. Populated when items are returned via API
          enum:
          - in_progress
          - completed
          - incomplete
      description: |
        A message input to the model with a role indicating instruction following
        hierarchy. Instructions given with the `developer` or `system` role take
        precedence over instructions given with the `user` role
    RealtimeResponseUsageInputTokenDetails:
      type: object
      properties:
        audio_tokens:
          type: integer
          description: The number of audio tokens used in the Response
          x-ballerina-name: audioTokens
        text_tokens:
          type: integer
          description: The number of text tokens used in the Response
          x-ballerina-name: textTokens
        cached_tokens:
          type: integer
          description: The number of cached tokens used in the Response
          x-ballerina-name: cachedTokens
      description: Details about the input tokens used in the Response
    UserListResponse:
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
      type: object
      properties:
        first_id:
          type: string
          x-ballerina-name: firstId
        data:
          type: array
          items:
            $ref: '#/components/schemas/User'
        last_id:
          type: string
          x-ballerina-name: lastId
        has_more:
          type: boolean
          x-ballerina-name: hasMore
        object:
          type: string
          enum:
          - list
          x-stainless-const: true
    CreateChatCompletionStreamResponseChoices:
      required:
      - delta
      - finish_reason
      - index
      type: object
      properties:
        finish_reason:
          type: string
          description: |
            The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence,
            `length` if the maximum number of tokens specified in the request was reached,
            `content_filter` if content was omitted due to a flag from our content filters,
            `tool_calls` if the model called a tool, or `function_call` (deprecated) if the model called a function
          nullable: true
          enum:
          - stop
          - length
          - tool_calls
          - content_filter
          - function_call
          x-ballerina-name: finishReason
        delta:
          $ref: '#/components/schemas/ChatCompletionStreamResponseDelta'
        index:
          type: integer
          description: The index of the choice in the list of choices
        logprobs:
          $ref: '#/components/schemas/CreateChatCompletionResponseLogprobs'
    ResponseAllOf3:
      required:
      - created_at
      - error
      - id
      - incomplete_details
      - instructions
      - metadata
      - model
      - object
      - output
      - parallel_tool_calls
      - temperature
      - tool_choice
      - tools
      - top_p
      type: object
      properties:
        output:
          type: array
          description: "An array of content items generated by the model.\n\n- The\
            \ length and order of items in the `output` array is dependent\n  on the\
            \ model's response.\n- Rather than accessing the first item in the `output`\
            \ array and \n  assuming it's an `assistant` message with the content\
            \ generated by\n  the model, you might consider using the `output_text`\
            \ property where\n  supported in SDKs\n"
          items:
            $ref: '#/components/schemas/OutputItem'
        parallel_tool_calls:
          type: boolean
          description: |
            Whether to allow the model to run tool calls in parallel
          default: true
          x-ballerina-name: parallelToolCalls
        output_text:
          type: string
          description: "SDK-only convenience property that contains the aggregated\
            \ text output \nfrom all `output_text` items in the `output` array, if\
            \ any are present. \nSupported in the Python and JavaScript SDKs\n"
          nullable: true
          x-oaiSupportedSDKs:
          - python
          - javascript
          x-ballerina-name: outputText
        usage:
          $ref: '#/components/schemas/ResponseUsage'
        created_at:
          type: number
          description: |
            Unix timestamp (in seconds) of when this Response was created
          x-ballerina-name: createdAt
        id:
          type: string
          description: |
            Unique identifier for this Response
        error:
          $ref: '#/components/schemas/ResponseError'
        incomplete_details:
          allOf:
          - $ref: '#/components/schemas/ResponseIncompleteDetails'
          x-ballerina-name: incompleteDetails
        object:
          type: string
          description: |
            The object type of this resource - always set to `response`
          enum:
          - response
          x-stainless-const: true
        status:
          type: string
          description: "The status of the response generation. One of `completed`,\
            \ `failed`, \n`in_progress`, or `incomplete`\n"
          enum:
          - completed
          - failed
          - in_progress
          - incomplete
      x-oaiMeta:
        name: The response object
        group: responses
        example: |
          {
            "id": "resp_67ccd3a9da748190baa7f1570fe91ac604becb25c45c1d41",
            "object": "response",
            "created_at": 1741476777,
            "status": "completed",
            "error": null,
            "incomplete_details": null,
            "instructions": null,
            "max_output_tokens": null,
            "model": "gpt-4o-2024-08-06",
            "output": [
              {
                "type": "message",
                "id": "msg_67ccd3acc8d48190a77525dc6de64b4104becb25c45c1d41",
                "status": "completed",
                "role": "assistant",
                "content": [
                  {
                    "type": "output_text",
                    "text": "The image depicts a scenic landscape with a wooden boardwalk or pathway leading through lush, green grass under a blue sky with some clouds. The setting suggests a peaceful natural area, possibly a park or nature reserve. There are trees and shrubs in the background.",
                    "annotations": []
                  }
                ]
              }
            ],
            "parallel_tool_calls": true,
            "previous_response_id": null,
            "reasoning": {
              "effort": null,
              "summary": null
            },
            "store": true,
            "temperature": 1.0,
            "text": {
              "format": {
                "type": "text"
              }
            },
            "tool_choice": "auto",
            "tools": [],
            "top_p": 1.0,
            "truncation": "disabled",
            "usage": {
              "input_tokens": 328,
              "input_tokens_details": {
                "cached_tokens": 0
              },
              "output_tokens": 52,
              "output_tokens_details": {
                "reasoning_tokens": 0
              },
              "total_tokens": 380
            },
            "user": null,
            "metadata": {}
          }
    ResponseReasoningSummaryPartAddedEvent:
      required:
      - item_id
      - output_index
      - part
      - summary_index
      - type
      type: object
      properties:
        item_id:
          type: string
          description: |
            The ID of the item this summary part is associated with
          x-ballerina-name: itemId
        summary_index:
          type: integer
          description: |
            The index of the summary part within the reasoning summary
          x-ballerina-name: summaryIndex
        part:
          $ref: '#/components/schemas/ResponseReasoningSummaryPartAddedEventPart'
        type:
          type: string
          description: |
            The type of the event. Always `response.reasoning_summary_part.added`
          enum:
          - response.reasoning_summary_part.added
          x-stainless-const: true
        output_index:
          type: integer
          description: |
            The index of the output item this summary part is associated with
          x-ballerina-name: outputIndex
      description: Emitted when a new reasoning summary part is added
      x-oaiMeta:
        name: response.reasoning_summary_part.added
        group: responses
        example: |
          {
            "type": "response.reasoning_summary_part.added",
            "item_id": "rs_6806bfca0b2481918a5748308061a2600d3ce51bdffd5476",
            "output_index": 0,
            "summary_index": 0,
            "part": {
              "type": "summary_text",
              "text": ""
            }
          }
    RealtimeClientEventOutputAudioBufferClear:
      required:
      - type
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the client event used for error handling
          x-ballerina-name: eventId
        type:
          type: string
          description: "The event type, must be `output_audio_buffer.clear`"
          enum:
          - output_audio_buffer.clear
          x-stainless-const: true
      description: "**WebRTC Only:** Emit to cut off the current audio response. This\
        \ will trigger the server to\nstop generating audio and emit a `output_audio_buffer.cleared`\
        \ event. This \nevent should be preceded by a `response.cancel` client event\
        \ to stop the \ngeneration of the current response.\n[Learn more](/docs/guides/realtime-model-capabilities#client-and-server-events-for-audio-in-webrtc)\n"
      x-oaiMeta:
        name: output_audio_buffer.clear
        group: realtime
        example: |
          {
              "event_id": "optional_client_event_id",
              "type": "output_audio_buffer.clear"
          }
    AuditLogUseradded:
      type: object
      properties:
        data:
          $ref: '#/components/schemas/AuditLogUseraddedData'
        id:
          type: string
          description: The user ID
      description: The details for events with this `type`
    CreateChatCompletionResponseChoices:
      required:
      - finish_reason
      - index
      - logprobs
      - message
      type: object
      properties:
        finish_reason:
          type: string
          description: |
            The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence,
            `length` if the maximum number of tokens specified in the request was reached,
            `content_filter` if content was omitted due to a flag from our content filters,
            `tool_calls` if the model called a tool, or `function_call` (deprecated) if the model called a function
          enum:
          - stop
          - length
          - tool_calls
          - content_filter
          - function_call
          x-ballerina-name: finishReason
        index:
          type: integer
          description: The index of the choice in the list of choices
        message:
          $ref: '#/components/schemas/ChatCompletionResponseMessage'
        logprobs:
          $ref: '#/components/schemas/CreateChatCompletionResponseLogprobs'
    RealtimeResponseStatusDetails:
      type: object
      properties:
        reason:
          type: string
          description: "The reason the Response did not complete. For a `cancelled`\
            \ Response, \none of `turn_detected` (the server VAD detected a new start\
            \ of speech) \nor `client_cancelled` (the client sent a cancel event).\
            \ For an \n`incomplete` Response, one of `max_output_tokens` or `content_filter`\
            \ \n(the server-side safety filter activated and cut off the response)\n"
          enum:
          - turn_detected
          - client_cancelled
          - max_output_tokens
          - content_filter
        type:
          type: string
          description: "The type of error that caused the response to fail, corresponding\
            \ \nwith the `status` field (`completed`, `cancelled`, `incomplete`, \n\
            `failed`)\n"
          enum:
          - completed
          - cancelled
          - failed
          - incomplete
        error:
          $ref: '#/components/schemas/RealtimeResponseStatusDetailsError'
      description: Additional details about the status
    MessageContentTextAnnotationsFileCitationObject:
      title: File citation
      required:
      - end_index
      - file_citation
      - start_index
      - text
      - type
      type: object
      properties:
        start_index:
          minimum: 0
          type: integer
          x-ballerina-name: startIndex
        file_citation:
          allOf:
          - $ref: '#/components/schemas/MessageContentTextAnnotationsFileCitationObjectFileCitation'
          x-ballerina-name: fileCitation
        end_index:
          minimum: 0
          type: integer
          x-ballerina-name: endIndex
        text:
          type: string
          description: The text in the message content that needs to be replaced
        type:
          type: string
          description: Always `file_citation`
          enum:
          - file_citation
          x-stainless-const: true
      description: A citation within the message that points to a specific quote from
        a specific File associated with the assistant or the message. Generated when
        the assistant uses the "file_search" tool to search files
    MessageStreamEventMessageStreamEventMessageStreamEventMessageStreamEventMessageStreamEventOneOf12345:
      required:
      - data
      - event
      type: object
      properties:
        data:
          $ref: '#/components/schemas/MessageObject'
        event:
          type: string
          enum:
          - thread.message.incomplete
          x-stainless-const: true
      description: "Occurs when a [message](/docs/api-reference/messages/object) ends\
        \ before it is completed"
      x-oaiMeta:
        dataDescription: "`data` is a [message](/docs/api-reference/messages/object)"
    ? RunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventOneOf12345678910
    : required:
      - data
      - event
      type: object
      properties:
        data:
          $ref: '#/components/schemas/RunObject'
        event:
          type: string
          enum:
          - thread.run.expired
          x-stainless-const: true
      description: "Occurs when a [run](/docs/api-reference/runs/object) expires"
      x-oaiMeta:
        dataDescription: "`data` is a [run](/docs/api-reference/runs/object)"
    RealtimeSessionCreateRequest:
      type: object
      properties:
        voice:
          $ref: '#/components/schemas/VoiceIdsShared'
        instructions:
          type: string
          description: |
            The default system instructions (i.e. system message) prepended to model  calls. This field allows the client to guide the model on desired  responses. The model can be instructed on response content and format,  (e.g. "be extremely succinct", "act friendly", "here are examples of good  responses") and on audio behavior (e.g. "talk quickly", "inject emotion  into your voice", "laugh frequently"). The instructions are not guaranteed  to be followed by the model, but they provide guidance to the model on the desired behavior.

            Note that the server sets default instructions which will be used if this  field is not set and are visible in the `session.created` event at the  start of the session
        input_audio_format:
          type: string
          description: "The format of input audio. Options are `pcm16`, `g711_ulaw`,\
            \ or `g711_alaw`.\nFor `pcm16`, input audio must be 16-bit PCM at a 24kHz\
            \ sample rate, \nsingle channel (mono), and little-endian byte order\n"
          default: pcm16
          enum:
          - pcm16
          - g711_ulaw
          - g711_alaw
          x-ballerina-name: inputAudioFormat
        input_audio_noise_reduction:
          allOf:
          - $ref: '#/components/schemas/RealtimeSessionInputAudioNoiseReduction'
          x-ballerina-name: inputAudioNoiseReduction
        input_audio_transcription:
          allOf:
          - $ref: '#/components/schemas/RealtimeSessionInputAudioTranscription'
          x-ballerina-name: inputAudioTranscription
        turn_detection:
          allOf:
          - $ref: '#/components/schemas/RealtimeSessionTurnDetection'
          x-ballerina-name: turnDetection
        tools:
          type: array
          description: Tools (functions) available to the model
          items:
            $ref: '#/components/schemas/RealtimeResponseCreateParamsTools'
        modalities:
          type: array
          description: |
            The set of modalities the model can respond with. To disable audio,
            set this to ["text"]
          items:
            type: string
            enum:
            - text
            - audio
        max_response_output_tokens:
          description: |
            Maximum number of output tokens for a single assistant response,
            inclusive of tool calls. Provide an integer between 1 and 4096 to
            limit output tokens, or `inf` for the maximum available tokens for a
            given model. Defaults to `inf`
          oneOf:
          - type: integer
          - type: string
            enum:
            - inf
            x-stainless-const: true
          x-ballerina-name: maxResponseOutputTokens
        output_audio_format:
          type: string
          description: |
            The format of output audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.
            For `pcm16`, output audio is sampled at a rate of 24kHz
          default: pcm16
          enum:
          - pcm16
          - g711_ulaw
          - g711_alaw
          x-ballerina-name: outputAudioFormat
        temperature:
          type: number
          description: |
            Sampling temperature for the model, limited to [0.6, 1.2]. For audio models a temperature of 0.8 is highly recommended for best performance
          default: 0.8
        tool_choice:
          type: string
          description: "How the model chooses tools. Options are `auto`, `none`, `required`,\
            \ or \nspecify a function\n"
          default: auto
          x-ballerina-name: toolChoice
        model:
          type: string
          description: |
            The Realtime model used for this session
          enum:
          - gpt-4o-realtime-preview
          - gpt-4o-realtime-preview-2024-10-01
          - gpt-4o-realtime-preview-2024-12-17
          - gpt-4o-mini-realtime-preview
          - gpt-4o-mini-realtime-preview-2024-12-17
      description: Realtime session object configuration
    CreateChatCompletionRequestAllOf2:
      required:
      - messages
      - model
      type: object
      properties:
        reasoning_effort:
          allOf:
          - $ref: '#/components/schemas/ReasoningEffort'
          x-ballerina-name: reasoningEffort
        top_logprobs:
          maximum: 20
          minimum: 0
          type: integer
          description: |
            An integer between 0 and 20 specifying the number of most likely tokens to
            return at each token position, each with an associated log probability.
            `logprobs` must be set to `true` if this parameter is used
          nullable: true
          x-ballerina-name: topLogprobs
        logit_bias:
          type: object
          additionalProperties:
            type: integer
          description: |
            Modify the likelihood of specified tokens appearing in the completion.

            Accepts a JSON object that maps tokens (specified by their token ID in the
            tokenizer) to an associated bias value from -100 to 100. Mathematically,
            the bias is added to the logits generated by the model prior to sampling.
            The exact effect will vary per model, but values between -1 and 1 should
            decrease or increase likelihood of selection; values like -100 or 100
            should result in a ban or exclusive selection of the relevant token
          nullable: true
          x-oaiTypeLabel: map
          x-ballerina-name: logitBias
        seed:
          maximum: 9223372036854776000
          minimum: -9223372036854776000
          type: integer
          description: |
            This feature is in Beta.
            If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same `seed` and parameters should return the same result.
            Determinism is not guaranteed, and you should refer to the `system_fingerprint` response parameter to monitor changes in the backend
          nullable: true
          x-oaiMeta:
            beta: true
        functions:
          maxItems: 128
          minItems: 1
          type: array
          description: |
            Deprecated in favor of `tools`.

            A list of functions the model may generate JSON inputs for
          deprecated: true
          items:
            $ref: '#/components/schemas/ChatCompletionFunctions'
        function_call:
          description: |
            Deprecated in favor of `tool_choice`.

            Controls which (if any) function is called by the model.

            `none` means the model will not call a function and instead generates a
            message.

            `auto` means the model can pick between generating a message or calling a
            function.

            Specifying a particular function via `{"name": "my_function"}` forces the
            model to call that function.

            `none` is the default when no functions are present. `auto` is the default
            if functions are present
          deprecated: true
          oneOf:
          - type: string
            description: |
              `none` means the model will not call a function and instead generates a message. `auto` means the model can pick between generating a message or calling a function.
            enum:
            - none
            - auto
          - $ref: '#/components/schemas/ChatCompletionFunctionCallOption'
          x-ballerina-name: functionCall
        presence_penalty:
          maximum: 2
          minimum: -2
          type: number
          description: |
            Number between -2.0 and 2.0. Positive values penalize new tokens based on
            whether they appear in the text so far, increasing the model's likelihood
            to talk about new topics
          nullable: true
          default: 0
          x-ballerina-name: presencePenalty
        tools:
          type: array
          description: |
            A list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for. A max of 128 functions are supported
          items:
            $ref: '#/components/schemas/ChatCompletionTool'
        web_search_options:
          allOf:
          - $ref: '#/components/schemas/WebSearch'
          x-ballerina-name: webSearchOptions
        logprobs:
          type: boolean
          description: |
            Whether to return log probabilities of the output tokens or not. If true,
            returns the log probabilities of each output token returned in the
            `content` of `message`
          nullable: true
          default: false
        max_completion_tokens:
          type: integer
          description: |
            An upper bound for the number of tokens that can be generated for a completion, including visible output tokens and [reasoning tokens](/docs/guides/reasoning)
          nullable: true
          x-ballerina-name: maxCompletionTokens
        modalities:
          $ref: '#/components/schemas/ResponseModalities'
        frequency_penalty:
          maximum: 2
          minimum: -2
          type: number
          description: |
            Number between -2.0 and 2.0. Positive values penalize new tokens based on
            their existing frequency in the text so far, decreasing the model's
            likelihood to repeat the same line verbatim
          nullable: true
          default: 0
          x-ballerina-name: frequencyPenalty
        response_format:
          description: |
            An object specifying the format that the model must output.

            Setting to `{ "type": "json_schema", "json_schema": {...} }` enables
            Structured Outputs which ensures the model will match your supplied JSON
            schema. Learn more in the [Structured Outputs
            guide](/docs/guides/structured-outputs).

            Setting to `{ "type": "json_object" }` enables the older JSON mode, which
            ensures the message the model generates is valid JSON. Using `json_schema`
            is preferred for models that support it
          oneOf:
          - $ref: '#/components/schemas/ResponseFormatText'
          - $ref: '#/components/schemas/ResponseFormatJsonSchema'
          - $ref: '#/components/schemas/ResponseFormatJsonObject'
          x-ballerina-name: responseFormat
        stream:
          type: boolean
          description: |
            If set to true, the model response data will be streamed to the client
            as it is generated using [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format).
            See the [Streaming section below](/docs/api-reference/chat/streaming)
            for more information, along with the [streaming responses](/docs/guides/streaming-responses)
            guide for more information on how to handle the streaming events
          nullable: true
          default: false
        tool_choice:
          allOf:
          - $ref: '#/components/schemas/ChatCompletionToolChoiceOption'
          x-ballerina-name: toolChoice
        model:
          $ref: '#/components/schemas/ModelIdsShared'
        audio:
          $ref: '#/components/schemas/CreateChatCompletionRequestAudio'
        max_tokens:
          type: integer
          description: |
            The maximum number of [tokens](/tokenizer) that can be generated in the
            chat completion. This value can be used to control
            [costs](https://openai.com/api/pricing/) for text generated via API.

            This value is now deprecated in favor of `max_completion_tokens`, and is
            not compatible with [o-series models](/docs/guides/reasoning)
          nullable: true
          deprecated: true
          x-ballerina-name: maxTokens
        store:
          type: boolean
          description: "Whether or not to store the output of this chat completion\
            \ request for \nuse in our [model distillation](/docs/guides/distillation)\
            \ or\n[evals](/docs/guides/evals) products\n"
          nullable: true
          default: false
        "n":
          maximum: 128
          minimum: 1
          type: integer
          description: How many chat completion choices to generate for each input
            message. Note that you will be charged based on the number of generated
            tokens across all of the choices. Keep `n` as `1` to minimize costs
          nullable: true
          example: 1
          default: 1
        stop:
          $ref: '#/components/schemas/StopConfiguration'
        parallel_tool_calls:
          allOf:
          - $ref: '#/components/schemas/ParallelToolCalls'
          x-ballerina-name: parallelToolCalls
        prediction:
          description: |
            Configuration for a [Predicted Output](/docs/guides/predicted-outputs),
            which can greatly improve response times when large parts of the model
            response are known ahead of time. This is most common when you are
            regenerating a file with only minor changes to most of the content
          nullable: true
          oneOf:
          - $ref: '#/components/schemas/PredictionContent'
        messages:
          minItems: 1
          type: array
          description: |
            A list of messages comprising the conversation so far. Depending on the
            [model](/docs/models) you use, different message types (modalities) are
            supported, like [text](/docs/guides/text-generation),
            [images](/docs/guides/vision), and [audio](/docs/guides/audio)
          items:
            $ref: '#/components/schemas/ChatCompletionRequestMessage'
        stream_options:
          allOf:
          - $ref: '#/components/schemas/ChatCompletionStreamOptions'
          x-ballerina-name: streamOptions
    CreateEvalCompletionsRunDataSourceSamplingParams:
      type: object
      properties:
        top_p:
          type: number
          description: An alternative to temperature for nucleus sampling; 1.0 includes
            all tokens
          default: 1
          x-ballerina-name: topP
        max_completion_tokens:
          type: integer
          description: The maximum number of tokens in the generated output
          x-ballerina-name: maxCompletionTokens
        seed:
          type: integer
          description: "A seed value to initialize the randomness, during sampling"
          default: 42
        temperature:
          type: number
          description: A higher temperature increases randomness in the outputs
          default: 1
    ModifyAssistantRequest:
      type: object
      properties:
        reasoning_effort:
          allOf:
          - $ref: '#/components/schemas/ReasoningEffort'
          x-ballerina-name: reasoningEffort
        top_p:
          maximum: 1
          minimum: 0
          type: number
          description: |
            An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

            We generally recommend altering this or temperature but not both
          nullable: true
          example: 1
          default: 1
          x-ballerina-name: topP
        instructions:
          maxLength: 256000
          type: string
          description: |
            The system instructions that the assistant uses. The maximum length is 256,000 characters
          nullable: true
        tool_resources:
          allOf:
          - $ref: '#/components/schemas/ModifyAssistantRequestToolResources'
          x-ballerina-name: toolResources
        metadata:
          $ref: '#/components/schemas/Metadata'
        response_format:
          allOf:
          - $ref: '#/components/schemas/AssistantsApiResponseFormatOption'
          x-ballerina-name: responseFormat
        name:
          maxLength: 256
          type: string
          description: |
            The name of the assistant. The maximum length is 256 characters
          nullable: true
        temperature:
          maximum: 2
          minimum: 0
          type: number
          description: |
            What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic
          nullable: true
          example: 1
          default: 1
        description:
          maxLength: 512
          type: string
          description: |
            The description of the assistant. The maximum length is 512 characters
          nullable: true
        model:
          description: |
            ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them
          anyOf:
          - type: string
          - $ref: '#/components/schemas/AssistantSupportedModels'
        tools:
          maxItems: 128
          type: array
          description: |
            A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`
          items:
            $ref: '#/components/schemas/AssistantObjectTools'
          default: []
      additionalProperties: false
    MessageContentTextObjectTextAnnotations:
      oneOf:
      - $ref: '#/components/schemas/MessageContentTextAnnotationsFileCitationObject'
      - $ref: '#/components/schemas/MessageContentTextAnnotationsFilePathObject'
    ChatCompletionRequestUserMessageContentPart:
      oneOf:
      - $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartText'
      - $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartImage'
      - $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartAudio'
      - $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartFile'
    ProjectApiKeyListResponse:
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
      type: object
      properties:
        first_id:
          type: string
          x-ballerina-name: firstId
        data:
          type: array
          items:
            $ref: '#/components/schemas/ProjectApiKey'
        last_id:
          type: string
          x-ballerina-name: lastId
        has_more:
          type: boolean
          x-ballerina-name: hasMore
        object:
          type: string
          enum:
          - list
          x-stainless-const: true
    RunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventOneOf12345678:
      required:
      - data
      - event
      type: object
      properties:
        data:
          $ref: '#/components/schemas/RunObject'
        event:
          type: string
          enum:
          - thread.run.cancelling
          x-stainless-const: true
      description: "Occurs when a [run](/docs/api-reference/runs/object) moves to\
        \ a `cancelling` status"
      x-oaiMeta:
        dataDescription: "`data` is a [run](/docs/api-reference/runs/object)"
    BatchRequestOutputResponse:
      type: object
      properties:
        status_code:
          type: integer
          description: The HTTP status code of the response
          x-ballerina-name: statusCode
        body:
          type: object
          description: The JSON body of the response
          x-oaiTypeLabel: map
        request_id:
          type: string
          description: An unique identifier for the OpenAI API request. Please include
            this request ID when contacting support
          x-ballerina-name: requestId
      nullable: true
    ResponseAudioTranscriptDeltaEvent:
      required:
      - delta
      - response_id
      - type
      type: object
      properties:
        delta:
          type: string
          description: |
            The partial transcript of the audio response
        type:
          type: string
          description: |
            The type of the event. Always `response.audio.transcript.delta`
          enum:
          - response.audio.transcript.delta
          x-stainless-const: true
      description: Emitted when there is a partial transcript of audio
      x-oaiMeta:
        name: response.audio.transcript.delta
        group: responses
        example: |
          {
            "type": "response.audio.transcript.delta",
            "response_id": "resp_123",
            "delta": " ... partial transcript ... "
          }
    ResponseContentPartAddedEvent:
      required:
      - content_index
      - item_id
      - output_index
      - part
      - type
      type: object
      properties:
        item_id:
          type: string
          description: |
            The ID of the output item that the content part was added to
          x-ballerina-name: itemId
        content_index:
          type: integer
          description: |
            The index of the content part that was added
          x-ballerina-name: contentIndex
        part:
          $ref: '#/components/schemas/OutputContent'
        type:
          type: string
          description: |
            The type of the event. Always `response.content_part.added`
          enum:
          - response.content_part.added
          x-stainless-const: true
        output_index:
          type: integer
          description: |
            The index of the output item that the content part was added to
          x-ballerina-name: outputIndex
      description: Emitted when a new content part is added
      x-oaiMeta:
        name: response.content_part.added
        group: responses
        example: |
          {
            "type": "response.content_part.added",
            "item_id": "msg_123",
            "output_index": 0,
            "content_index": 0,
            "part": {
              "type": "output_text",
              "text": "",
              "annotations": []
            }
          }
    RunStepDeltaStepDetailsToolCallsCodeObjectCodeInterpreter:
      type: object
      properties:
        outputs:
          type: array
          description: "The outputs from the Code Interpreter tool call. Code Interpreter\
            \ can output one or more items, including text (`logs`) or images (`image`).\
            \ Each of these are represented by a different object type"
          items:
            $ref: '#/components/schemas/RunStepDeltaStepDetailsToolCallsCodeObjectCodeInterpreterOutputs'
        input:
          type: string
          description: The input to the Code Interpreter tool call
      description: The Code Interpreter tool call definition
    RealtimeServerEvent:
      description: |
        A realtime server event
      discriminator:
        propertyName: type
      anyOf:
      - $ref: '#/components/schemas/RealtimeServerEventConversationCreated'
      - $ref: '#/components/schemas/RealtimeServerEventConversationItemCreated'
      - $ref: '#/components/schemas/RealtimeServerEventConversationItemDeleted'
      - $ref: '#/components/schemas/RealtimeServerEventConversationItemInputAudioTranscriptionCompleted'
      - $ref: '#/components/schemas/RealtimeServerEventConversationItemInputAudioTranscriptionDelta'
      - $ref: '#/components/schemas/RealtimeServerEventConversationItemInputAudioTranscriptionFailed'
      - $ref: '#/components/schemas/RealtimeServerEventConversationItemRetrieved'
      - $ref: '#/components/schemas/RealtimeServerEventConversationItemTruncated'
      - $ref: '#/components/schemas/RealtimeServerEventError'
      - $ref: '#/components/schemas/RealtimeServerEventInputAudioBufferCleared'
      - $ref: '#/components/schemas/RealtimeServerEventInputAudioBufferCommitted'
      - $ref: '#/components/schemas/RealtimeServerEventInputAudioBufferSpeechStarted'
      - $ref: '#/components/schemas/RealtimeServerEventInputAudioBufferSpeechStopped'
      - $ref: '#/components/schemas/RealtimeServerEventRateLimitsUpdated'
      - $ref: '#/components/schemas/RealtimeServerEventResponseAudioDelta'
      - $ref: '#/components/schemas/RealtimeServerEventResponseAudioDone'
      - $ref: '#/components/schemas/RealtimeServerEventResponseAudioTranscriptDelta'
      - $ref: '#/components/schemas/RealtimeServerEventResponseAudioTranscriptDone'
      - $ref: '#/components/schemas/RealtimeServerEventResponseContentPartAdded'
      - $ref: '#/components/schemas/RealtimeServerEventResponseContentPartDone'
      - $ref: '#/components/schemas/RealtimeServerEventResponseCreated'
      - $ref: '#/components/schemas/RealtimeServerEventResponseDone'
      - $ref: '#/components/schemas/RealtimeServerEventResponseFunctionCallArgumentsDelta'
      - $ref: '#/components/schemas/RealtimeServerEventResponseFunctionCallArgumentsDone'
      - $ref: '#/components/schemas/RealtimeServerEventResponseOutputItemAdded'
      - $ref: '#/components/schemas/RealtimeServerEventResponseOutputItemDone'
      - $ref: '#/components/schemas/RealtimeServerEventResponseTextDelta'
      - $ref: '#/components/schemas/RealtimeServerEventResponseTextDone'
      - $ref: '#/components/schemas/RealtimeServerEventSessionCreated'
      - $ref: '#/components/schemas/RealtimeServerEventSessionUpdated'
      - $ref: '#/components/schemas/RealtimeServerEventTranscriptionSessionUpdated'
      - $ref: '#/components/schemas/RealtimeServerEventOutputAudioBufferStarted'
      - $ref: '#/components/schemas/RealtimeServerEventOutputAudioBufferStopped'
      - $ref: '#/components/schemas/RealtimeServerEventOutputAudioBufferCleared'
    FineTuningIntegration:
      title: Fine-Tuning Job Integration
      required:
      - type
      - wandb
      type: object
      properties:
        wandb:
          $ref: '#/components/schemas/CreateFineTuningJobRequestWandb'
        type:
          type: string
          description: The type of the integration being enabled for the fine-tuning
            job
          enum:
          - wandb
          x-stainless-const: true
    InputAudio:
      title: Audio input
      required:
      - data
      - format
      - type
      type: object
      properties:
        data:
          type: string
          description: |
            Base64-encoded audio data
        format:
          type: string
          description: |
            The format of the audio data. Currently supported formats are `mp3` and
            `wav`
          enum:
          - mp3
          - wav
        type:
          type: string
          description: |
            The type of the input item. Always `input_audio`
          enum:
          - input_audio
          x-stainless-const: true
      description: |
        An audio input to the model
    SubmitToolOutputsRunRequest:
      required:
      - tool_outputs
      type: object
      properties:
        stream:
          type: boolean
          description: |
            If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message
          nullable: true
        tool_outputs:
          type: array
          description: A list of tools for which the outputs are being submitted
          items:
            $ref: '#/components/schemas/SubmitToolOutputsRunRequestToolOutputs'
          x-ballerina-name: toolOutputs
      additionalProperties: false
    Tool:
      discriminator:
        propertyName: type
      oneOf:
      - $ref: '#/components/schemas/FileSearchTool'
      - $ref: '#/components/schemas/FunctionTool'
      - $ref: '#/components/schemas/WebSearchPreviewTool'
      - $ref: '#/components/schemas/ComputerUsePreviewTool'
    CreateEvalRunRequest:
      title: CreateEvalRunRequest
      required:
      - data_source
      type: object
      properties:
        metadata:
          $ref: '#/components/schemas/Metadata'
        name:
          type: string
          description: The name of the run
        data_source:
          type: object
          description: Details about the run's data source
          oneOf:
          - $ref: '#/components/schemas/CreateEvalJsonlRunDataSource'
          - $ref: '#/components/schemas/CreateEvalCompletionsRunDataSource'
          - $ref: '#/components/schemas/CreateEvalResponsesRunDataSource'
          x-ballerina-name: dataSource
    KeyPress:
      title: KeyPress
      required:
      - keys
      - type
      type: object
      properties:
        keys:
          type: array
          description: |
            The combination of keys the model is requesting to be pressed. This is an
            array of strings, each representing a key
          items:
            type: string
            description: |
              One of the keys the model is requesting to be pressed.
        type:
          type: string
          description: "Specifies the event type. For a keypress action, this property\
            \ is \nalways set to `keypress`\n"
          default: keypress
          enum:
          - keypress
          x-stainless-const: true
      description: |
        A collection of keypresses the model would like to perform
    VectorStoreFileBatchObject:
      title: Vector store file batch
      required:
      - created_at
      - file_counts
      - id
      - object
      - status
      - vector_store_id
      type: object
      properties:
        file_counts:
          allOf:
          - $ref: '#/components/schemas/VectorStoreFileBatchObjectFileCounts'
          x-ballerina-name: fileCounts
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the vector store files
            batch was created
          x-ballerina-name: createdAt
        id:
          type: string
          description: "The identifier, which can be referenced in API endpoints"
        object:
          type: string
          description: "The object type, which is always `vector_store.file_batch`"
          enum:
          - vector_store.files_batch
          x-stainless-const: true
        vector_store_id:
          type: string
          description: "The ID of the [vector store](/docs/api-reference/vector-stores/object)\
            \ that the [File](/docs/api-reference/files) is attached to"
          x-ballerina-name: vectorStoreId
        status:
          type: string
          description: "The status of the vector store files batch, which can be either\
            \ `in_progress`, `completed`, `cancelled` or `failed`"
          enum:
          - in_progress
          - completed
          - cancelled
          - failed
      description: A batch of files attached to a vector store
      x-oaiMeta:
        name: The vector store files batch object
        beta: true
        example: |
          {
            "id": "vsfb_123",
            "object": "vector_store.files_batch",
            "created_at": 1698107661,
            "vector_store_id": "vs_abc123",
            "status": "completed",
            "file_counts": {
              "in_progress": 0,
              "completed": 100,
              "failed": 0,
              "cancelled": 0,
              "total": 100
            }
          }
    RealtimeServerEventConversationItemDeleted:
      required:
      - event_id
      - item_id
      - type
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event
          x-ballerina-name: eventId
        item_id:
          type: string
          description: The ID of the item that was deleted
          x-ballerina-name: itemId
        type:
          type: string
          description: "The event type, must be `conversation.item.deleted`"
          enum:
          - conversation.item.deleted
          x-stainless-const: true
      description: "Returned when an item in the conversation is deleted by the client\
        \ with a \n`conversation.item.delete` event. This event is used to synchronize\
        \ the \nserver's understanding of the conversation history with the client's\
        \ view\n"
      x-oaiMeta:
        name: conversation.item.deleted
        group: realtime
        example: |
          {
              "event_id": "event_2728",
              "type": "conversation.item.deleted",
              "item_id": "msg_005"
          }
    AuditLogServiceAccountupdated:
      type: object
      properties:
        changes_requested:
          allOf:
          - $ref: '#/components/schemas/AuditLogServiceAccountupdatedChangesRequested'
          x-ballerina-name: changesRequested
        id:
          type: string
          description: The service account ID
      description: The details for events with this `type`
    ModifyRunRequest:
      type: object
      properties:
        metadata:
          $ref: '#/components/schemas/Metadata'
      additionalProperties: false
    Scroll:
      title: Scroll
      required:
      - scroll_x
      - scroll_y
      - type
      - x
      - "y"
      type: object
      properties:
        scroll_y:
          type: integer
          description: |
            The vertical scroll distance
          x-ballerina-name: scrollY
        scroll_x:
          type: integer
          description: |
            The horizontal scroll distance
          x-ballerina-name: scrollX
        x:
          type: integer
          description: |
            The x-coordinate where the scroll occurred
        "y":
          type: integer
          description: |
            The y-coordinate where the scroll occurred
        type:
          type: string
          description: "Specifies the event type. For a scroll action, this property\
            \ is \nalways set to `scroll`\n"
          default: scroll
          enum:
          - scroll
          x-stainless-const: true
      description: |
        A scroll action
    CreateTranslationResponseVerboseJson:
      required:
      - duration
      - language
      - text
      type: object
      properties:
        duration:
          type: number
          description: The duration of the input audio
        language:
          type: string
          description: The language of the output translation (always `english`)
        text:
          type: string
          description: The translated text
        segments:
          type: array
          description: Segments of the translated text and their corresponding details
          items:
            $ref: '#/components/schemas/TranscriptionSegment'
    AuditLogCertificatesactivated:
      type: object
      properties:
        certificates:
          type: array
          items:
            $ref: '#/components/schemas/AuditLogCertificatesactivatedCertificates'
      description: The details for events with this `type`
    CreateCompletionResponseLogprobs:
      type: object
      properties:
        top_logprobs:
          type: array
          items:
            type: object
            additionalProperties:
              type: number
          x-ballerina-name: topLogprobs
        token_logprobs:
          type: array
          items:
            type: number
          x-ballerina-name: tokenLogprobs
        tokens:
          type: array
          items:
            type: string
        text_offset:
          type: array
          items:
            type: integer
          x-ballerina-name: textOffset
      nullable: true
    ProjectServiceAccountListResponse:
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
      type: object
      properties:
        first_id:
          type: string
          x-ballerina-name: firstId
        data:
          type: array
          items:
            $ref: '#/components/schemas/ProjectServiceAccount'
        last_id:
          type: string
          x-ballerina-name: lastId
        has_more:
          type: boolean
          x-ballerina-name: hasMore
        object:
          type: string
          enum:
          - list
          x-stainless-const: true
    AuditLogUseraddedData:
      type: object
      properties:
        role:
          type: string
          description: The role of the user. Is either `owner` or `member`
      description: The payload used to add the user to the project
    DeleteFileResponse:
      required:
      - deleted
      - id
      - object
      type: object
      properties:
        deleted:
          type: boolean
        id:
          type: string
        object:
          type: string
          enum:
          - file
          x-stainless-const: true
    WebSearchLocation:
      title: Web search location
      type: object
      properties:
        country:
          type: string
          description: "The two-letter \n[ISO country code](https://en.wikipedia.org/wiki/ISO_3166-1)\
            \ of the user,\ne.g. `US`\n"
        city:
          type: string
          description: |
            Free text input for the city of the user, e.g. `San Francisco`
        timezone:
          type: string
          description: "The [IANA timezone](https://timeapi.io/documentation/iana-timezones)\
            \ \nof the user, e.g. `America/Los_Angeles`\n"
        region:
          type: string
          description: |
            Free text input for the region of the user, e.g. `California`
      description: Approximate location parameters for the search
    RunStepStreamEventRunStepStreamEventRunStepStreamEventRunStepStreamEventRunStepStreamEventRunStepStreamEventOneOf123456:
      required:
      - data
      - event
      type: object
      properties:
        data:
          $ref: '#/components/schemas/RunStepObject'
        event:
          type: string
          enum:
          - thread.run.step.cancelled
          x-stainless-const: true
      description: "Occurs when a [run step](/docs/api-reference/run-steps/step-object)\
        \ is cancelled"
      x-oaiMeta:
        dataDescription: "`data` is a [run step](/docs/api-reference/run-steps/step-object)"
    ModelIdsSharedModelIdsSharedAnyOf12:
      type: string
      enum:
      - gpt-4.1
      - gpt-4.1-mini
      - gpt-4.1-nano
      - gpt-4.1-2025-04-14
      - gpt-4.1-mini-2025-04-14
      - gpt-4.1-nano-2025-04-14
      - o4-mini
      - o4-mini-2025-04-16
      - o3
      - o3-2025-04-16
      - o3-mini
      - o3-mini-2025-01-31
      - o1
      - o1-2024-12-17
      - o1-preview
      - o1-preview-2024-09-12
      - o1-mini
      - o1-mini-2024-09-12
      - gpt-4o
      - gpt-4o-2024-11-20
      - gpt-4o-2024-08-06
      - gpt-4o-2024-05-13
      - gpt-4o-audio-preview
      - gpt-4o-audio-preview-2024-10-01
      - gpt-4o-audio-preview-2024-12-17
      - gpt-4o-mini-audio-preview
      - gpt-4o-mini-audio-preview-2024-12-17
      - gpt-4o-search-preview
      - gpt-4o-mini-search-preview
      - gpt-4o-search-preview-2025-03-11
      - gpt-4o-mini-search-preview-2025-03-11
      - chatgpt-4o-latest
      - gpt-4o-mini
      - gpt-4o-mini-2024-07-18
      - gpt-4-turbo
      - gpt-4-turbo-2024-04-09
      - gpt-4-0125-preview
      - gpt-4-turbo-preview
      - gpt-4-1106-preview
      - gpt-4-vision-preview
      - gpt-4
      - gpt-4-0314
      - gpt-4-0613
      - gpt-4-32k
      - gpt-4-32k-0314
      - gpt-4-32k-0613
      - gpt-3.5-turbo
      - gpt-3.5-turbo-16k
      - gpt-3.5-turbo-0301
      - gpt-3.5-turbo-0613
      - gpt-3.5-turbo-1106
      - gpt-3.5-turbo-0125
      - gpt-3.5-turbo-16k-0613
    ResponseCodeInterpreterCallInProgressEvent:
      required:
      - code_interpreter_call
      - output_index
      - response_id
      - type
      type: object
      properties:
        code_interpreter_call:
          allOf:
          - $ref: '#/components/schemas/CodeInterpreterToolCall'
          x-ballerina-name: codeInterpreterCall
        type:
          type: string
          description: |
            The type of the event. Always `response.code_interpreter_call.in_progress`
          enum:
          - response.code_interpreter_call.in_progress
          x-stainless-const: true
        output_index:
          type: integer
          description: |
            The index of the output item that the code interpreter call is in progress
          x-ballerina-name: outputIndex
      description: Emitted when a code interpreter call is in progress
      x-oaiMeta:
        name: response.code_interpreter_call.in_progress
        group: responses
        example: |
          {
            "type": "response.code_interpreter_call.in.progress",
            "response_id": "resp-123",
            "output_index": 0,
            "code_interpreter_call": {}
          }
    Wait:
      title: Wait
      required:
      - type
      type: object
      properties:
        type:
          type: string
          description: "Specifies the event type. For a wait action, this property\
            \ is \nalways set to `wait`\n"
          default: wait
          enum:
          - wait
          x-stainless-const: true
      description: |
        A wait action
    AuditLogOrganizationupdated:
      type: object
      properties:
        changes_requested:
          allOf:
          - $ref: '#/components/schemas/AuditLogOrganizationupdatedChangesRequested'
          x-ballerina-name: changesRequested
        id:
          type: string
          description: The organization ID
      description: The details for events with this `type`
    CreateMessageRequest:
      required:
      - content
      - role
      type: object
      properties:
        metadata:
          $ref: '#/components/schemas/Metadata'
        role:
          type: string
          description: |
            The role of the entity that is creating the message. Allowed values include:
            - `user`: Indicates the message is sent by an actual user and should be used in most cases to represent user-generated messages.
            - `assistant`: Indicates the message is generated by the assistant. Use this value to insert messages from the assistant into the conversation
          enum:
          - user
          - assistant
        attachments:
          required:
          - file_id
          - tools
          type: array
          description: "A list of files attached to the message, and the tools they\
            \ should be added to"
          nullable: true
          items:
            $ref: '#/components/schemas/CreateMessageRequestAttachments'
        content:
          oneOf:
          - title: Text content
            type: string
            description: The text contents of the message.
          - title: Array of content parts
            minItems: 1
            type: array
            description: "An array of content parts with a defined type, each can\
              \ be of type `text` or images can be passed with `image_url` or `image_file`.\
              \ Image types are only supported on [Vision-compatible models](/docs/models)."
            items:
              oneOf:
              - $ref: '#/components/schemas/MessageContentImageFileObject'
              - $ref: '#/components/schemas/MessageContentImageUrlObject'
              - $ref: '#/components/schemas/MessageRequestContentTextObject'
      additionalProperties: false
    CreateAssistantRequestToolResourcesFileSearch:
      type: object
      properties:
        vector_store_ids:
          maxItems: 1
          type: array
          description: |
            The [vector store](/docs/api-reference/vector-stores/object) attached to this assistant. There can be a maximum of 1 vector store attached to the assistant.
          items:
            type: string
        vector_stores:
          maxItems: 1
          type: array
          description: |
            A helper to create a [vector store](/docs/api-reference/vector-stores/object) with file_ids and attach it to this assistant. There can be a maximum of 1 vector store attached to the assistant.
          items:
            type: object
            properties:
              file_ids:
                maxItems: 10000
                type: array
                description: |
                  A list of [file](/docs/api-reference/files) IDs to add to the vector store. There can be a maximum of 10000 files in a vector store.
                items:
                  type: string
              chunking_strategy:
                type: object
                description: "The chunking strategy used to chunk the file(s). If\
                  \ not set, will use the `auto` strategy."
                oneOf:
                - title: Auto Chunking Strategy
                  required:
                  - type
                  type: object
                  properties:
                    type:
                      type: string
                      description: Always `auto`.
                      enum:
                      - auto
                      x-stainless-const: true
                  additionalProperties: false
                  description: The default strategy. This strategy currently uses
                    a `max_chunk_size_tokens` of `800` and `chunk_overlap_tokens`
                    of `400`.
                - title: Static Chunking Strategy
                  required:
                  - static
                  - type
                  type: object
                  properties:
                    type:
                      type: string
                      description: Always `static`.
                      enum:
                      - static
                      x-stainless-const: true
                    static:
                      required:
                      - chunk_overlap_tokens
                      - max_chunk_size_tokens
                      type: object
                      properties:
                        max_chunk_size_tokens:
                          maximum: 4096
                          minimum: 100
                          type: integer
                          description: The maximum number of tokens in each chunk.
                            The default value is `800`. The minimum value is `100`
                            and the maximum value is `4096`.
                        chunk_overlap_tokens:
                          type: integer
                          description: |
                            The number of tokens that overlap between chunks. The default value is `400`.

                            Note that the overlap must not exceed half of `max_chunk_size_tokens`.
                      additionalProperties: false
                  additionalProperties: false
              metadata:
                $ref: '#/components/schemas/Metadata'
      oneOf:
      - required:
        - vector_store_ids
      - required:
        - vector_stores
    ChatCompletionDeleted:
      required:
      - deleted
      - id
      - object
      type: object
      properties:
        deleted:
          type: boolean
          description: Whether the chat completion was deleted
        id:
          type: string
          description: The ID of the chat completion that was deleted
        object:
          type: string
          description: The type of object being deleted
          enum:
          - chat.completion.deleted
          x-stainless-const: true
    AuditLogRateLimitupdated:
      type: object
      properties:
        changes_requested:
          allOf:
          - $ref: '#/components/schemas/AuditLogRateLimitupdatedChangesRequested'
          x-ballerina-name: changesRequested
        id:
          type: string
          description: The rate limit ID
      description: The details for events with this `type`
    RunStepObject:
      title: Run steps
      required:
      - assistant_id
      - cancelled_at
      - completed_at
      - created_at
      - expired_at
      - failed_at
      - id
      - last_error
      - metadata
      - object
      - run_id
      - status
      - step_details
      - thread_id
      - type
      - usage
      type: object
      properties:
        cancelled_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the run step was cancelled
          nullable: true
          x-ballerina-name: cancelledAt
        metadata:
          $ref: '#/components/schemas/Metadata'
        assistant_id:
          type: string
          description: "The ID of the [assistant](/docs/api-reference/assistants)\
            \ associated with the run step"
          x-ballerina-name: assistantId
        run_id:
          type: string
          description: "The ID of the [run](/docs/api-reference/runs) that this run\
            \ step is a part of"
          x-ballerina-name: runId
        usage:
          $ref: '#/components/schemas/RunStepCompletionUsage'
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the run step was created
          x-ballerina-name: createdAt
        expired_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the run step expired.
            A step is considered expired if the parent run is expired
          nullable: true
          x-ballerina-name: expiredAt
        type:
          type: string
          description: "The type of run step, which can be either `message_creation`\
            \ or `tool_calls`"
          enum:
          - message_creation
          - tool_calls
        step_details:
          type: object
          description: The details of the run step
          oneOf:
          - $ref: '#/components/schemas/RunStepDetailsMessageCreationObject'
          - $ref: '#/components/schemas/RunStepDetailsToolCallsObject'
          x-ballerina-name: stepDetails
        completed_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the run step completed
          nullable: true
          x-ballerina-name: completedAt
        thread_id:
          type: string
          description: "The ID of the [thread](/docs/api-reference/threads) that was\
            \ run"
          x-ballerina-name: threadId
        id:
          type: string
          description: "The identifier of the run step, which can be referenced in\
            \ API endpoints"
        last_error:
          allOf:
          - $ref: '#/components/schemas/RunStepObjectLastError'
          x-ballerina-name: lastError
        failed_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the run step failed
          nullable: true
          x-ballerina-name: failedAt
        object:
          type: string
          description: "The object type, which is always `thread.run.step`"
          enum:
          - thread.run.step
          x-stainless-const: true
        status:
          type: string
          description: "The status of the run step, which can be either `in_progress`,\
            \ `cancelled`, `failed`, `completed`, or `expired`"
          enum:
          - in_progress
          - cancelled
          - failed
          - completed
          - expired
      description: |
        Represents a step in execution of a run
      x-oaiMeta:
        name: The run step object
        beta: true
        example: |
          {
            "id": "step_abc123",
            "object": "thread.run.step",
            "created_at": 1699063291,
            "run_id": "run_abc123",
            "assistant_id": "asst_abc123",
            "thread_id": "thread_abc123",
            "type": "message_creation",
            "status": "completed",
            "cancelled_at": null,
            "completed_at": 1699063291,
            "expired_at": null,
            "failed_at": null,
            "last_error": null,
            "step_details": {
              "type": "message_creation",
              "message_creation": {
                "message_id": "msg_abc123"
              }
            },
            "usage": {
              "prompt_tokens": 123,
              "completion_tokens": 456,
              "total_tokens": 579
            }
          }
    ChatCompletionNamedToolChoice:
      required:
      - function
      - type
      type: object
      properties:
        function:
          $ref: '#/components/schemas/AssistantsNamedToolChoiceFunction'
        type:
          type: string
          description: "The type of the tool. Currently, only `function` is supported"
          enum:
          - function
          x-stainless-const: true
      description: Specifies a tool the model should use. Use to force the model to
        call a specific function
    ChatCompletionModalities:
      type: array
      description: |
        Output types that you would like the model to generate for this request.
        Most models are capable of generating text, which is the default:

        `["text"]`

        The `gpt-4o-audio-preview` model can also be used to [generate audio](/docs/guides/audio). To
        request that this model generate both text and audio responses, you can
        use:

        `["text", "audio"]`
      nullable: true
      items:
        type: string
        enum:
        - text
        - audio
    MessageObjectContent:
      oneOf:
      - $ref: '#/components/schemas/MessageContentImageFileObject'
      - $ref: '#/components/schemas/MessageContentImageUrlObject'
      - $ref: '#/components/schemas/MessageContentTextObject'
      - $ref: '#/components/schemas/MessageContentRefusalObject'
    InlineResponse200:
      oneOf:
      - $ref: '#/components/schemas/CreateTranscriptionResponseJson'
      - $ref: '#/components/schemas/CreateTranscriptionResponseVerboseJson'
    RealtimeServerEventResponseOutputItemDone:
      required:
      - event_id
      - item
      - output_index
      - response_id
      - type
      type: object
      properties:
        item:
          $ref: '#/components/schemas/RealtimeConversationItem'
        event_id:
          type: string
          description: The unique ID of the server event
          x-ballerina-name: eventId
        response_id:
          type: string
          description: The ID of the Response to which the item belongs
          x-ballerina-name: responseId
        type:
          type: string
          description: "The event type, must be `response.output_item.done`"
          enum:
          - response.output_item.done
          x-stainless-const: true
        output_index:
          type: integer
          description: The index of the output item in the Response
          x-ballerina-name: outputIndex
      description: "Returned when an Item is done streaming. Also emitted when a Response\
        \ is \ninterrupted, incomplete, or cancelled\n"
      x-oaiMeta:
        name: response.output_item.done
        group: realtime
        example: |
          {
              "event_id": "event_3536",
              "type": "response.output_item.done",
              "response_id": "resp_001",
              "output_index": 0,
              "item": {
                  "id": "msg_007",
                  "object": "realtime.item",
                  "type": "message",
                  "status": "completed",
                  "role": "assistant",
                  "content": [
                      {
                          "type": "text",
                          "text": "Sure, I can help with that."
                      }
                  ]
              }
          }
    RealtimeTranscriptionSessionCreateResponseClientSecret:
      required:
      - expires_at
      - value
      type: object
      properties:
        expires_at:
          type: integer
          description: |
            Timestamp for when the token expires. Currently, all tokens expire
            after one minute
          x-ballerina-name: expiresAt
        value:
          type: string
          description: |
            Ephemeral key usable in client environments to authenticate connections
            to the Realtime API. Use this in client-side environments rather than
            a standard API token, which should only be used server-side
      description: |
        Ephemeral key returned by the API. Only present when the session is
        created on the server via REST API
    RunStepDetailsToolCallsFunctionObjectFunction:
      required:
      - arguments
      - name
      - output
      type: object
      properties:
        output:
          type: string
          description: "The output of the function. This will be `null` if the outputs\
            \ have not been [submitted](/docs/api-reference/runs/submitToolOutputs)\
            \ yet"
          nullable: true
        name:
          type: string
          description: The name of the function
        arguments:
          type: string
          description: The arguments passed to the function
      description: The definition of the function that was called
    FineTunePreferenceRequestInputInput:
      type: object
      properties:
        parallel_tool_calls:
          allOf:
          - $ref: '#/components/schemas/ParallelToolCalls'
          x-ballerina-name: parallelToolCalls
        messages:
          minItems: 1
          type: array
          items:
            $ref: '#/components/schemas/FineTuneChatRequestInputMessages'
        tools:
          type: array
          description: A list of tools the model may generate JSON inputs for
          items:
            $ref: '#/components/schemas/ChatCompletionTool'
    FunctionToolCall:
      title: Function tool call
      required:
      - arguments
      - call_id
      - name
      - type
      type: object
      properties:
        name:
          type: string
          description: |
            The name of the function to run
        arguments:
          type: string
          description: |
            A JSON string of the arguments to pass to the function
        id:
          type: string
          description: |
            The unique ID of the function tool call
        type:
          type: string
          description: |
            The type of the function tool call. Always `function_call`
          enum:
          - function_call
          x-stainless-const: true
        call_id:
          type: string
          description: |
            The unique ID of the function tool call generated by the model
          x-ballerina-name: callId
        status:
          type: string
          description: |
            The status of the item. One of `in_progress`, `completed`, or
            `incomplete`. Populated when items are returned via API
          enum:
          - in_progress
          - completed
          - incomplete
      description: "A tool call to run a function. See the \n[function calling guide](/docs/guides/function-calling)\
        \ for more information\n"
    UsageCompletionsResult:
      required:
      - input_tokens
      - num_model_requests
      - object
      - output_tokens
      type: object
      properties:
        num_model_requests:
          type: integer
          description: The count of requests made to the model
          x-ballerina-name: numModelRequests
        project_id:
          type: string
          description: "When `group_by=project_id`, this field provides the project\
            \ ID of the grouped usage result"
          nullable: true
          x-ballerina-name: projectId
        user_id:
          type: string
          description: "When `group_by=user_id`, this field provides the user ID of\
            \ the grouped usage result"
          nullable: true
          x-ballerina-name: userId
        output_audio_tokens:
          type: integer
          description: The aggregated number of audio output tokens used
          x-ballerina-name: outputAudioTokens
        batch:
          type: boolean
          description: "When `group_by=batch`, this field tells whether the grouped\
            \ usage result is batch or not"
          nullable: true
        output_tokens:
          type: integer
          description: "The aggregated number of text output tokens used. For customers\
            \ subscribe to scale tier, this includes scale tier tokens"
          x-ballerina-name: outputTokens
        model:
          type: string
          description: "When `group_by=model`, this field provides the model name\
            \ of the grouped usage result"
          nullable: true
        input_cached_tokens:
          type: integer
          description: "The aggregated number of text input tokens that has been cached\
            \ from previous requests. For customers subscribe to scale tier, this\
            \ includes scale tier tokens"
          x-ballerina-name: inputCachedTokens
        input_audio_tokens:
          type: integer
          description: "The aggregated number of audio input tokens used, including\
            \ cached tokens"
          x-ballerina-name: inputAudioTokens
        input_tokens:
          type: integer
          description: "The aggregated number of text input tokens used, including\
            \ cached tokens. For customers subscribe to scale tier, this includes\
            \ scale tier tokens"
          x-ballerina-name: inputTokens
        api_key_id:
          type: string
          description: "When `group_by=api_key_id`, this field provides the API key\
            \ ID of the grouped usage result"
          nullable: true
          x-ballerina-name: apiKeyId
        object:
          type: string
          enum:
          - organization.usage.completions.result
          x-stainless-const: true
      description: The aggregated completions usage details of the specific time bucket
      x-oaiMeta:
        name: Completions usage object
        example: |
          {
              "object": "organization.usage.completions.result",
              "input_tokens": 5000,
              "output_tokens": 1000,
              "input_cached_tokens": 4000,
              "input_audio_tokens": 300,
              "output_audio_tokens": 200,
              "num_model_requests": 5,
              "project_id": "proj_abc",
              "user_id": "user-abc",
              "api_key_id": "key_abc",
              "model": "gpt-4o-mini-2024-07-18",
              "batch": false
          }
    ResponseFormatJsonSchema:
      title: JSON schema
      required:
      - json_schema
      - type
      type: object
      properties:
        json_schema:
          allOf:
          - $ref: '#/components/schemas/JSONSchema'
          x-ballerina-name: jsonSchema
        type:
          type: string
          description: The type of response format being defined. Always `json_schema`
          enum:
          - json_schema
          x-stainless-const: true
      description: |
        JSON Schema response format. Used to generate structured JSON responses.
        Learn more about [Structured Outputs](/docs/guides/structured-outputs)
    CreateAssistantRequestToolResources:
      type: object
      properties:
        code_interpreter:
          allOf:
          - $ref: '#/components/schemas/CreateAssistantRequestToolResourcesCodeInterpreter'
          x-ballerina-name: codeInterpreter
        file_search:
          allOf:
          - $ref: '#/components/schemas/CreateAssistantRequestToolResourcesFileSearch'
          x-ballerina-name: fileSearch
      description: |
        A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs
      nullable: true
    RealtimeClientEventTranscriptionSessionUpdate:
      required:
      - session
      - type
      type: object
      properties:
        event_id:
          type: string
          description: Optional client-generated ID used to identify this event
          x-ballerina-name: eventId
        session:
          $ref: '#/components/schemas/RealtimeTranscriptionSessionCreateRequest'
        type:
          type: string
          description: "The event type, must be `transcription_session.update`"
          enum:
          - transcription_session.update
          x-stainless-const: true
      description: |
        Send this event to update a transcription session
      x-oaiMeta:
        name: transcription_session.update
        group: realtime
        example: |
          {
            "type": "transcription_session.update",
            "session": {
              "input_audio_format": "pcm16",
              "input_audio_transcription": {
                "model": "gpt-4o-transcribe",
                "prompt": "",
                "language": ""
              },
              "turn_detection": {
                "type": "server_vad",
                "threshold": 0.5,
                "prefix_padding_ms": 300,
                "silence_duration_ms": 500,
                "create_response": true,
              },
              "input_audio_noise_reduction": {
                "type": "near_field"
              },
              "include": [
                "item.input_audio_transcription.logprobs",
              ]
            }
          }
    RealtimeSessionInputAudioNoiseReduction:
      type: object
      properties:
        type:
          type: string
          description: |
            Type of noise reduction. `near_field` is for close-talking microphones such as headphones, `far_field` is for far-field microphones such as laptop or conference room microphones
          enum:
          - near_field
          - far_field
      description: |
        Configuration for input audio noise reduction. This can be set to `null` to turn off.
        Noise reduction filters audio added to the input audio buffer before it is sent to VAD and the model.
        Filtering the audio can improve VAD and turn detection accuracy (reducing false positives) and model performance by improving perception of the input audio
    AuditLogProjectcreatedData:
      type: object
      properties:
        name:
          type: string
          description: The project name
        title:
          type: string
          description: The title of the project as seen on the dashboard
      description: The payload used to create the project
    ResponseAudioDoneEvent:
      required:
      - response_id
      - type
      type: object
      properties:
        type:
          type: string
          description: |
            The type of the event. Always `response.audio.done`
          enum:
          - response.audio.done
          x-stainless-const: true
      description: Emitted when the audio response is complete
      x-oaiMeta:
        name: response.audio.done
        group: responses
        example: |
          {
            "type": "response.audio.done",
            "response_id": "resp-123"
          }
    AuditLogProjectupdatedChangesRequested:
      type: object
      properties:
        title:
          type: string
          description: The title of the project as seen on the dashboard
      description: The payload used to update the project
    ProjectRateLimitListResponse:
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
      type: object
      properties:
        first_id:
          type: string
          x-ballerina-name: firstId
        data:
          type: array
          items:
            $ref: '#/components/schemas/ProjectRateLimit'
        last_id:
          type: string
          x-ballerina-name: lastId
        has_more:
          type: boolean
          x-ballerina-name: hasMore
        object:
          type: string
          enum:
          - list
          x-stainless-const: true
    ThreadStreamEventOneOf1:
      required:
      - data
      - event
      type: object
      properties:
        data:
          $ref: '#/components/schemas/ThreadObject'
        event:
          type: string
          enum:
          - thread.created
          x-stainless-const: true
        enabled:
          type: boolean
          description: Whether to enable input audio transcription
      description: "Occurs when a new [thread](/docs/api-reference/threads/object)\
        \ is created"
      x-oaiMeta:
        dataDescription: "`data` is a [thread](/docs/api-reference/threads/object)"
    FunctionCallOutputItemParam:
      title: Function tool call output
      required:
      - call_id
      - output
      - type
      type: object
      properties:
        output:
          maxLength: 10485760
          type: string
          description: A JSON string of the output of the function tool call
        id:
          anyOf:
          - type: string
            description: The unique ID of the function tool call output. Populated
              when this item is returned via API.
          - nullable: true
        type:
          type: string
          description: The type of the function tool call output. Always `function_call_output`
          default: function_call_output
          enum:
          - function_call_output
          x-stainless-const: true
        call_id:
          maxLength: 64
          minLength: 1
          type: string
          description: The unique ID of the function tool call generated by the model
          x-ballerina-name: callId
        status:
          anyOf:
          - type: string
            description: "The status of the item. One of `in_progress`, `completed`,\
              \ or `incomplete`. Populated when items are returned via API."
            enum:
            - in_progress
            - completed
            - incomplete
          - nullable: true
      description: The output of a function tool call
    UploadPart:
      title: UploadPart
      required:
      - created_at
      - id
      - object
      - upload_id
      type: object
      properties:
        upload_id:
          type: string
          description: The ID of the Upload object that this Part was added to
          x-ballerina-name: uploadId
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the Part was created
          x-ballerina-name: createdAt
        id:
          type: string
          description: "The upload Part unique identifier, which can be referenced\
            \ in API endpoints"
        object:
          type: string
          description: "The object type, which is always `upload.part`"
          enum:
          - upload.part
          x-stainless-const: true
      description: |
        The upload Part represents a chunk of bytes we can add to an Upload object
      x-oaiMeta:
        name: The upload part object
        example: |
          {
              "id": "part_def456",
              "object": "upload.part",
              "created_at": 1719186911,
              "upload_id": "upload_abc123"
          }
    ToggleCertificatesRequest:
      required:
      - certificate_ids
      type: object
      properties:
        certificate_ids:
          maxItems: 10
          minItems: 1
          type: array
          items:
            type: string
            example: cert_abc
          x-ballerina-name: certificateIds
    Error:
      required:
      - code
      - message
      - param
      - type
      type: object
      properties:
        code:
          type: string
          nullable: true
        param:
          type: string
          nullable: true
        message:
          type: string
          nullable: false
        type:
          type: string
          nullable: false
    ChatCompletionRequestAssistantMessageFunctionCall:
      required:
      - arguments
      - name
      type: object
      properties:
        name:
          type: string
          description: The name of the function to call
        arguments:
          type: string
          description: "The arguments to call the function with, as generated by the\
            \ model in JSON format. Note that the model does not always generate valid\
            \ JSON, and may hallucinate parameters not defined by your function schema.\
            \ Validate the arguments in your code before calling your function"
      description: "Deprecated and replaced by `tool_calls`. The name and arguments\
        \ of a function that should be called, as generated by the model"
      nullable: true
      deprecated: true
    CompletionUsagePromptTokensDetails:
      type: object
      properties:
        audio_tokens:
          type: integer
          description: Audio input tokens present in the prompt
          default: 0
          x-ballerina-name: audioTokens
        cached_tokens:
          type: integer
          description: Cached tokens present in the prompt
          default: 0
          x-ballerina-name: cachedTokens
      description: Breakdown of tokens used in the prompt
    ChatCompletionRequestMessageContentPartImageImageUrl:
      required:
      - url
      type: object
      properties:
        detail:
          type: string
          description: "Specifies the detail level of the image. Learn more in the\
            \ [Vision guide](/docs/guides/vision#low-or-high-fidelity-image-understanding)"
          default: auto
          enum:
          - auto
          - low
          - high
        url:
          type: string
          description: Either a URL of the image or the base64 encoded image data
          format: uri
    RealtimeClientEventResponseCancel:
      required:
      - type
      type: object
      properties:
        event_id:
          type: string
          description: Optional client-generated ID used to identify this event
          x-ballerina-name: eventId
        response_id:
          type: string
          description: "A specific response ID to cancel - if not provided, will cancel\
            \ an \nin-progress response in the default conversation\n"
          x-ballerina-name: responseId
        type:
          type: string
          description: "The event type, must be `response.cancel`"
          enum:
          - response.cancel
          x-stainless-const: true
      description: "Send this event to cancel an in-progress response. The server\
        \ will respond \nwith a `response.cancelled` event or an error if there is\
        \ no response to \ncancel\n"
      x-oaiMeta:
        name: response.cancel
        group: realtime
        example: |
          {
              "event_id": "event_567",
              "type": "response.cancel"
          }
    AuditLogUserdeleted:
      type: object
      properties:
        id:
          type: string
          description: The user ID
      description: The details for events with this `type`
    ResponseTextDeltaEvent:
      required:
      - content_index
      - delta
      - item_id
      - output_index
      - type
      type: object
      properties:
        item_id:
          type: string
          description: |
            The ID of the output item that the text delta was added to
          x-ballerina-name: itemId
        content_index:
          type: integer
          description: |
            The index of the content part that the text delta was added to
          x-ballerina-name: contentIndex
        delta:
          type: string
          description: |
            The text delta that was added
        type:
          type: string
          description: |
            The type of the event. Always `response.output_text.delta`
          enum:
          - response.output_text.delta
          x-stainless-const: true
        output_index:
          type: integer
          description: |
            The index of the output item that the text delta was added to
          x-ballerina-name: outputIndex
      description: Emitted when there is an additional text delta
      x-oaiMeta:
        name: response.output_text.delta
        group: responses
        example: |
          {
            "type": "response.output_text.delta",
            "item_id": "msg_123",
            "output_index": 0,
            "content_index": 0,
            "delta": "In"
          }
    ChatCompletionResponseMessage:
      required:
      - content
      - refusal
      - role
      type: object
      properties:
        role:
          type: string
          description: The role of the author of this message
          enum:
          - assistant
          x-stainless-const: true
        function_call:
          allOf:
          - $ref: '#/components/schemas/ChatCompletionResponseMessageFunctionCall'
          x-ballerina-name: functionCall
        refusal:
          type: string
          description: The refusal message generated by the model
          nullable: true
        annotations:
          type: array
          description: |
            Annotations for the message, when applicable, as when using the
            [web search tool](/docs/guides/tools-web-search?api-mode=chat)
          items:
            $ref: '#/components/schemas/ChatCompletionResponseMessageAnnotations'
        tool_calls:
          allOf:
          - $ref: '#/components/schemas/ChatCompletionMessageToolCalls'
          x-ballerina-name: toolCalls
        audio:
          $ref: '#/components/schemas/ChatCompletionResponseMessageAudio'
        content:
          type: string
          description: The contents of the message
          nullable: true
      description: A chat completion message generated by the model
    BatchRequestOutput:
      type: object
      properties:
        response:
          $ref: '#/components/schemas/BatchRequestOutputResponse'
        custom_id:
          type: string
          description: A developer-provided per-request id that will be used to match
            outputs to inputs
          x-ballerina-name: customId
        id:
          type: string
        error:
          $ref: '#/components/schemas/BatchRequestOutputError'
      description: The per-line object of the batch output and error files
      x-oaiMeta:
        name: The request output object
        example: |
          {"id": "batch_req_wnaDys", "custom_id": "request-2", "response": {"status_code": 200, "request_id": "req_c187b3", "body": {"id": "chatcmpl-9758Iw", "object": "chat.completion", "created": 1711475054, "model": "gpt-4o-mini", "choices": [{"index": 0, "message": {"role": "assistant", "content": "2 + 2 equals 4."}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 24, "completion_tokens": 15, "total_tokens": 39}, "system_fingerprint": null}}, "error": null}
    UsageResponse:
      required:
      - data
      - has_more
      - next_page
      - object
      type: object
      properties:
        next_page:
          type: string
          x-ballerina-name: nextPage
        data:
          type: array
          items:
            $ref: '#/components/schemas/UsageTimeBucket'
        has_more:
          type: boolean
          x-ballerina-name: hasMore
        object:
          type: string
          enum:
          - page
          x-stainless-const: true
    EvalRunResultCounts:
      required:
      - errored
      - failed
      - passed
      - total
      type: object
      properties:
        total:
          type: integer
          description: Total number of executed output items
        failed:
          type: integer
          description: Number of output items that failed to pass the evaluation
        passed:
          type: integer
          description: Number of output items that passed the evaluation
        errored:
          type: integer
          description: Number of output items that resulted in an error
      description: Counters summarizing the outcomes of the evaluation run
    AuditLogActor:
      type: object
      properties:
        api_key:
          allOf:
          - $ref: '#/components/schemas/AuditLogActorApiKey'
          x-ballerina-name: apiKey
        session:
          $ref: '#/components/schemas/AuditLogActorSession'
        type:
          type: string
          description: The type of actor. Is either `session` or `api_key`
          enum:
          - session
          - api_key
      description: The actor who performed the audit logged action
    RealtimeServerEventSessionUpdated:
      required:
      - event_id
      - session
      - type
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event
          x-ballerina-name: eventId
        session:
          $ref: '#/components/schemas/RealtimeSession'
        type:
          type: string
          description: "The event type, must be `session.updated`"
          enum:
          - session.updated
          x-stainless-const: true
      description: "Returned when a session is updated with a `session.update` event,\
        \ unless \nthere is an error\n"
      x-oaiMeta:
        name: session.updated
        group: realtime
        example: |
          {
              "event_id": "event_5678",
              "type": "session.updated",
              "session": {
                  "id": "sess_001",
                  "object": "realtime.session",
                  "model": "gpt-4o-realtime-preview",
                  "modalities": ["text"],
                  "instructions": "New instructions",
                  "voice": "sage",
                  "input_audio_format": "pcm16",
                  "output_audio_format": "pcm16",
                  "input_audio_transcription": {
                      "model": "whisper-1"
                  },
                  "turn_detection": null,
                  "tools": [],
                  "tool_choice": "none",
                  "temperature": 0.7,
                  "max_response_output_tokens": 200
              }
          }
    RunStepDetailsToolCallsCodeOutputLogsObject:
      title: Code Interpreter log output
      required:
      - logs
      - type
      type: object
      properties:
        type:
          type: string
          description: Always `logs`
          enum:
          - logs
          x-stainless-const: true
        logs:
          type: string
          description: The text output from the Code Interpreter tool call
      description: Text output from the Code Interpreter tool call as part of a run
        step
    StaticChunkingStrategyResponseParam:
      title: Static Chunking Strategy
      required:
      - static
      - type
      type: object
      properties:
        static:
          $ref: '#/components/schemas/StaticChunkingStrategy'
        type:
          type: string
          description: Always `static`
          enum:
          - static
          x-stainless-const: true
      additionalProperties: false
    RealtimeConversationItemWithReference:
      type: object
      properties:
        output:
          type: string
          description: |
            The output of the function call (for `function_call_output` items)
        role:
          type: string
          description: "The role of the message sender (`user`, `assistant`, `system`),\
            \ only \napplicable for `message` items\n"
          enum:
          - user
          - assistant
          - system
        name:
          type: string
          description: |
            The name of the function being called (for `function_call` items)
        arguments:
          type: string
          description: |
            The arguments of the function call (for `function_call` items)
        id:
          type: string
          description: |
            For an item of type (`message` | `function_call` | `function_call_output`)
            this field allows the client to assign the unique ID of the item. It is
            not required because the server will generate one if not provided.

            For an item of type `item_reference`, this field is required and is a
            reference to any item that has previously existed in the conversation
        type:
          type: string
          description: |
            The type of the item (`message`, `function_call`, `function_call_output`, `item_reference`)
          enum:
          - message
          - function_call
          - function_call_output
        content:
          type: array
          description: "The content of the message, applicable for `message` items.\
            \ \n- Message items of role `system` support only `input_text` content\n\
            - Message items of role `user` support `input_text` and `input_audio`\
            \ \n  content\n- Message items of role `assistant` support `text` content\n"
          items:
            $ref: '#/components/schemas/RealtimeConversationItemContent'
        object:
          type: string
          description: |
            Identifier for the API object being returned - always `realtime.item`
          enum:
          - realtime.item
          x-stainless-const: true
        status:
          type: string
          description: "The status of the item (`completed`, `incomplete`). These\
            \ have no effect \non the conversation, but are accepted for consistency\
            \ with the \n`conversation.item.created` event\n"
          enum:
          - completed
          - incomplete
        call_id:
          type: string
          description: "The ID of the function call (for `function_call` and \n`function_call_output`\
            \ items). If passed on a `function_call_output` \nitem, the server will\
            \ check that a `function_call` item with the same \nID exists in the conversation\
            \ history\n"
          x-ballerina-name: callId
      description: The item to add to the conversation
    EvalApiError:
      title: EvalApiError
      required:
      - code
      - message
      type: object
      properties:
        code:
          type: string
          description: The error code
        message:
          type: string
          description: The error message
      description: |
        An object representing an error response from the Eval API
      x-oaiMeta:
        name: The API error object
        group: evals
        example: |
          {
            "code": "internal_error",
            "message": "The eval run failed due to an internal error."
          }
    ProjectServiceAccountDeleteResponse:
      required:
      - deleted
      - id
      - object
      type: object
      properties:
        deleted:
          type: boolean
        id:
          type: string
        object:
          type: string
          enum:
          - organization.project.service_account.deleted
          x-stainless-const: true
    Invite:
      required:
      - email
      - expires_at
      - id
      - invited_at
      - object
      - role
      - status
      type: object
      properties:
        role:
          type: string
          description: '`owner` or `reader`'
          enum:
          - owner
          - reader
        expires_at:
          type: integer
          description: The Unix timestamp (in seconds) of when the invite expires
          x-ballerina-name: expiresAt
        projects:
          type: array
          description: The projects that were granted membership upon acceptance of
            the invite
          items:
            $ref: '#/components/schemas/InviteProjects'
        invited_at:
          type: integer
          description: The Unix timestamp (in seconds) of when the invite was sent
          x-ballerina-name: invitedAt
        id:
          type: string
          description: "The identifier, which can be referenced in API endpoints"
        accepted_at:
          type: integer
          description: The Unix timestamp (in seconds) of when the invite was accepted
          x-ballerina-name: acceptedAt
        email:
          type: string
          description: The email address of the individual to whom the invite was
            sent
        object:
          type: string
          description: "The object type, which is always `organization.invite`"
          enum:
          - organization.invite
          x-stainless-const: true
        status:
          type: string
          description: "`accepted`,`expired`, or `pending`"
          enum:
          - accepted
          - expired
          - pending
      description: Represents an individual `invite` to the organization
      x-oaiMeta:
        name: The invite object
        example: |
          {
            "object": "organization.invite",
            "id": "invite-abc",
            "email": "user@example.com",
            "role": "owner",
            "status": "accepted",
            "invited_at": 1711471533,
            "expires_at": 1711471533,
            "accepted_at": 1711471533,
            "projects": [
              {
                "id": "project-xyz",
                "role": "member"
              }
            ]
          }
    RealtimeServerEventConversationItemCreated:
      required:
      - event_id
      - item
      - previous_item_id
      - type
      type: object
      properties:
        item:
          $ref: '#/components/schemas/RealtimeConversationItem'
        event_id:
          type: string
          description: The unique ID of the server event
          x-ballerina-name: eventId
        type:
          type: string
          description: "The event type, must be `conversation.item.created`"
          enum:
          - conversation.item.created
          x-stainless-const: true
        previous_item_id:
          type: string
          description: "The ID of the preceding item in the Conversation context,\
            \ allows the \nclient to understand the order of the conversation\n"
          x-ballerina-name: previousItemId
      description: "Returned when a conversation item is created. There are several\
        \ scenarios that produce this event:\n  - The server is generating a Response,\
        \ which if successful will produce \n    either one or two Items, which will\
        \ be of type `message` \n    (role `assistant`) or type `function_call`.\n\
        \  - The input audio buffer has been committed, either by the client or the\
        \ \n    server (in `server_vad` mode). The server will take the content of\
        \ the \n    input audio buffer and add it to a new user message Item.\n  -\
        \ The client has sent a `conversation.item.create` event to add a new Item\
        \ \n    to the Conversation\n"
      x-oaiMeta:
        name: conversation.item.created
        group: realtime
        example: |
          {
              "event_id": "event_1920",
              "type": "conversation.item.created",
              "previous_item_id": "msg_002",
              "item": {
                  "id": "msg_003",
                  "object": "realtime.item",
                  "type": "message",
                  "status": "completed",
                  "role": "user",
                  "content": []
              }
          }
    AuditLogCheckpointPermissiondeleted:
      type: object
      properties:
        id:
          type: string
          description: The ID of the checkpoint permission
      description: The details for events with this `type`
    MessageContentImageFileObjectImageFile:
      required:
      - file_id
      type: object
      properties:
        file_id:
          type: string
          description: "The [File](/docs/api-reference/files) ID of the image in the\
            \ message content. Set `purpose=\"vision\"` when uploading the File if\
            \ you need to later display the file content"
          x-ballerina-name: fileId
        detail:
          type: string
          description: "Specifies the detail level of the image if specified by the\
            \ user. `low` uses fewer tokens, you can opt in to high resolution using\
            \ `high`"
          default: auto
          enum:
          - auto
          - low
          - high
    BatchRequestCounts:
      required:
      - completed
      - failed
      - total
      type: object
      properties:
        total:
          type: integer
          description: Total number of requests in the batch
        completed:
          type: integer
          description: Number of requests that have been completed successfully
        failed:
          type: integer
          description: Number of requests that have failed
      description: The request counts for different statuses within the batch
    ResponseCompletedEvent:
      required:
      - response
      - type
      type: object
      properties:
        response:
          $ref: '#/components/schemas/Response'
        type:
          type: string
          description: |
            The type of the event. Always `response.completed`
          enum:
          - response.completed
          x-stainless-const: true
      description: Emitted when the model response is complete
      x-oaiMeta:
        name: response.completed
        group: responses
        example: |
          {
            "type": "response.completed",
            "response": {
              "id": "resp_123",
              "object": "response",
              "created_at": 1740855869,
              "status": "completed",
              "error": null,
              "incomplete_details": null,
              "input": [],
              "instructions": null,
              "max_output_tokens": null,
              "model": "gpt-4o-mini-2024-07-18",
              "output": [
                {
                  "id": "msg_123",
                  "type": "message",
                  "role": "assistant",
                  "content": [
                    {
                      "type": "output_text",
                      "text": "In a shimmering forest under a sky full of stars, a lonely unicorn named Lila discovered a hidden pond that glowed with moonlight. Every night, she would leave sparkling, magical flowers by the water's edge, hoping to share her beauty with others. One enchanting evening, she woke to find a group of friendly animals gathered around, eager to be friends and share in her magic.",
                      "annotations": []
                    }
                  ]
                }
              ],
              "previous_response_id": null,
              "reasoning_effort": null,
              "store": false,
              "temperature": 1,
              "text": {
                "format": {
                  "type": "text"
                }
              },
              "tool_choice": "auto",
              "tools": [],
              "top_p": 1,
              "truncation": "disabled",
              "usage": {
                "input_tokens": 0,
                "output_tokens": 0,
                "output_tokens_details": {
                  "reasoning_tokens": 0
                },
                "total_tokens": 0
              },
              "user": null,
              "metadata": {}
            }
          }
    WebSearchContextSize:
      type: string
      description: "High level guidance for the amount of context window space to\
        \ use for the \nsearch. One of `low`, `medium`, or `high`. `medium` is the\
        \ default\n"
      default: medium
      enum:
      - low
      - medium
      - high
    VoiceIdsSharedVoiceIdsSharedAnyOf12:
      type: string
      enum:
      - alloy
      - ash
      - ballad
      - coral
      - echo
      - fable
      - onyx
      - nova
      - sage
      - shimmer
      - verse
    ProjectApiKeyOwner:
      type: object
      properties:
        service_account:
          allOf:
          - $ref: '#/components/schemas/ProjectServiceAccount'
          x-ballerina-name: serviceAccount
        type:
          type: string
          description: '`user` or `service_account`'
          enum:
          - user
          - service_account
        user:
          $ref: '#/components/schemas/ProjectUser'
    ResponseWebSearchCallSearchingEvent:
      required:
      - item_id
      - output_index
      - type
      type: object
      properties:
        item_id:
          type: string
          description: |
            Unique ID for the output item associated with the web search call
          x-ballerina-name: itemId
        type:
          type: string
          description: |
            The type of the event. Always `response.web_search_call.searching`
          enum:
          - response.web_search_call.searching
          x-stainless-const: true
        output_index:
          type: integer
          description: |
            The index of the output item that the web search call is associated with
          x-ballerina-name: outputIndex
      description: Emitted when a web search call is executing
      x-oaiMeta:
        name: response.web_search_call.searching
        group: responses
        example: |
          {
            "type": "response.web_search_call.searching",
            "output_index": 0,
            "item_id": "ws_123",
          }
    RealtimeServerEventResponseAudioTranscriptDelta:
      required:
      - content_index
      - delta
      - event_id
      - item_id
      - output_index
      - response_id
      - type
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event
          x-ballerina-name: eventId
        item_id:
          type: string
          description: The ID of the item
          x-ballerina-name: itemId
        content_index:
          type: integer
          description: The index of the content part in the item's content array
          x-ballerina-name: contentIndex
        response_id:
          type: string
          description: The ID of the response
          x-ballerina-name: responseId
        delta:
          type: string
          description: The transcript delta
        type:
          type: string
          description: "The event type, must be `response.audio_transcript.delta`"
          enum:
          - response.audio_transcript.delta
          x-stainless-const: true
        output_index:
          type: integer
          description: The index of the output item in the response
          x-ballerina-name: outputIndex
      description: |
        Returned when the model-generated transcription of audio output is updated
      x-oaiMeta:
        name: response.audio_transcript.delta
        group: realtime
        example: |
          {
              "event_id": "event_4546",
              "type": "response.audio_transcript.delta",
              "response_id": "resp_001",
              "item_id": "msg_008",
              "output_index": 0,
              "content_index": 0,
              "delta": "Hello, how can I a"
          }
    ResponseFileSearchCallSearchingEvent:
      required:
      - item_id
      - output_index
      - type
      type: object
      properties:
        item_id:
          type: string
          description: |
            The ID of the output item that the file search call is initiated
          x-ballerina-name: itemId
        type:
          type: string
          description: |
            The type of the event. Always `response.file_search_call.searching`
          enum:
          - response.file_search_call.searching
          x-stainless-const: true
        output_index:
          type: integer
          description: |
            The index of the output item that the file search call is searching
          x-ballerina-name: outputIndex
      description: Emitted when a file search is currently searching
      x-oaiMeta:
        name: response.file_search_call.searching
        group: responses
        example: |
          {
            "type": "response.file_search_call.searching",
            "output_index": 0,
            "item_id": "fs_123",
          }
    AssistantsApiToolChoiceOptionOneOf1:
      type: string
      description: |
        `none` means the model will not call any tools and instead generates a message. `auto` means the model can pick between generating a message or calling one or more tools. `required` means the model must call one or more tools before responding to the user
      enum:
      - none
      - auto
      - required
    ListRunsResponse:
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
      type: object
      properties:
        first_id:
          type: string
          example: run_abc123
          x-ballerina-name: firstId
        data:
          type: array
          items:
            $ref: '#/components/schemas/RunObject'
        last_id:
          type: string
          example: run_abc456
          x-ballerina-name: lastId
        has_more:
          type: boolean
          example: false
          x-ballerina-name: hasMore
        object:
          type: string
          example: list
    RunStepDetailsToolCallsFunctionObject:
      title: Function tool call
      required:
      - function
      - id
      - type
      type: object
      properties:
        function:
          $ref: '#/components/schemas/RunStepDetailsToolCallsFunctionObjectFunction'
        id:
          type: string
          description: The ID of the tool call object
        type:
          type: string
          description: The type of tool call. This is always going to be `function`
            for this type of tool call
          enum:
          - function
          x-stainless-const: true
    EvalTextSimilarityGrader:
      title: TextSimilarityGrader
      required:
      - evaluation_metric
      - input
      - pass_threshold
      - reference
      - type
      type: object
      properties:
        reference:
          type: string
          description: The text being graded against
        input:
          type: string
          description: The text being graded
        pass_threshold:
          type: number
          description: A float score where a value greater than or equal indicates
            a passing grade
          x-ballerina-name: passThreshold
        name:
          type: string
          description: The name of the grader
        evaluation_metric:
          type: string
          description: "The evaluation metric to use. One of `fuzzy_match`, `bleu`,\
            \ `gleu`, `meteor`, `rouge_1`, `rouge_2`, `rouge_3`, `rouge_4`, `rouge_5`,\
            \ or `rouge_l`"
          enum:
          - fuzzy_match
          - bleu
          - gleu
          - meteor
          - rouge_1
          - rouge_2
          - rouge_3
          - rouge_4
          - rouge_5
          - rouge_l
          x-ballerina-name: evaluationMetric
        type:
          type: string
          description: The type of grader
          default: text_similarity
          enum:
          - text_similarity
          x-stainless-const: true
      description: |
        A TextSimilarityGrader object which grades text based on similarity metrics
      x-oaiMeta:
        name: The eval text similarity grader object
        group: evals
        example: |
          {
            "type": "text_similarity",
            "name": "example text similarity grader",
            "input": "The graded text",
            "reference": "The reference text",
            "pass_threshold": 0.8,
            "evaluation_metric": "fuzzy_match"
          }
    FileSearchTool:
      title: File search
      required:
      - type
      - vector_store_ids
      type: object
      properties:
        vector_store_ids:
          type: array
          description: The IDs of the vector stores to search
          items:
            type: string
          x-ballerina-name: vectorStoreIds
        max_num_results:
          type: integer
          description: The maximum number of results to return. This number should
            be between 1 and 50 inclusive
          x-ballerina-name: maxNumResults
        ranking_options:
          allOf:
          - $ref: '#/components/schemas/RankingOptions'
          x-ballerina-name: rankingOptions
        filters:
          anyOf:
          - $ref: '#/components/schemas/Filters'
          - nullable: true
        type:
          type: string
          description: The type of the file search tool. Always `file_search`
          default: file_search
          enum:
          - file_search
          x-stainless-const: true
      description: "A tool that searches for relevant content from uploaded files.\
        \ Learn more about the [file search tool](https://platform.openai.com/docs/guides/tools-file-search)"
    EvalList:
      title: EvalList
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
      type: object
      properties:
        first_id:
          type: string
          description: The identifier of the first eval in the data array
          x-ballerina-name: firstId
        data:
          type: array
          description: |
            An array of eval objects
          items:
            $ref: '#/components/schemas/Eval'
        last_id:
          type: string
          description: The identifier of the last eval in the data array
          x-ballerina-name: lastId
        has_more:
          type: boolean
          description: Indicates whether there are more evals available
          x-ballerina-name: hasMore
        object:
          type: string
          description: |
            The type of this object. It is always set to "list"
          default: list
          enum:
          - list
          x-stainless-const: true
      description: |
        An object representing a list of evals
      x-oaiMeta:
        name: The eval list object
        group: evals
        example: |
          {
            "object": "list",
            "data": [
              {
                "object": "eval",
                "id": "eval_67abd54d9b0081909a86353f6fb9317a",
                "data_source_config": {
                  "type": "custom",
                  "schema": {
                    "type": "object",
                    "properties": {
                      "item": {
                        "type": "object",
                        "properties": {
                          "input": {
                            "type": "string"
                          },
                          "ground_truth": {
                            "type": "string"
                          }
                        },
                        "required": [
                          "input",
                          "ground_truth"
                        ]
                      }
                    },
                    "required": [
                      "item"
                    ]
                  }
                },
                "testing_criteria": [
                  {
                    "name": "String check",
                    "id": "String check-2eaf2d8d-d649-4335-8148-9535a7ca73c2",
                    "type": "string_check",
                    "input": "{{item.input}}",
                    "reference": "{{item.ground_truth}}",
                    "operation": "eq"
                  }
                ],
                "name": "External Data Eval",
                "created_at": 1739314509,
                "metadata": {},
              }
            ],
            "first_id": "eval_67abd54d9b0081909a86353f6fb9317a",
            "last_id": "eval_67abd54d9b0081909a86353f6fb9317a",
            "has_more": true
          }
    CreateRunRequest:
      required:
      - assistant_id
      type: object
      properties:
        reasoning_effort:
          allOf:
          - $ref: '#/components/schemas/ReasoningEffort'
          x-ballerina-name: reasoningEffort
        instructions:
          type: string
          description: "Overrides the [instructions](/docs/api-reference/assistants/createAssistant)\
            \ of the assistant. This is useful for modifying the behavior on a per-run\
            \ basis"
          nullable: true
        additional_instructions:
          type: string
          description: Appends additional instructions at the end of the instructions
            for the run. This is useful for modifying the behavior on a per-run basis
            without overriding other instructions
          nullable: true
          x-ballerina-name: additionalInstructions
        metadata:
          $ref: '#/components/schemas/Metadata'
        assistant_id:
          type: string
          description: "The ID of the [assistant](/docs/api-reference/assistants)\
            \ to use to execute this run"
          x-ballerina-name: assistantId
        additional_messages:
          type: array
          description: Adds additional messages to the thread before creating the
            run
          nullable: true
          items:
            $ref: '#/components/schemas/CreateMessageRequest'
          x-ballerina-name: additionalMessages
        tools:
          maxItems: 20
          type: array
          description: Override the tools the assistant can use for this run. This
            is useful for modifying the behavior on a per-run basis
          nullable: true
          items:
            $ref: '#/components/schemas/AssistantObjectTools'
        truncation_strategy:
          allOf:
          - $ref: '#/components/schemas/TruncationObject'
          - nullable: true
          x-ballerina-name: truncationStrategy
        top_p:
          maximum: 1
          minimum: 0
          type: number
          description: |
            An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

            We generally recommend altering this or temperature but not both
          nullable: true
          example: 1
          default: 1
          x-ballerina-name: topP
        max_completion_tokens:
          minimum: 256
          type: integer
          description: |
            The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info
          nullable: true
          x-ballerina-name: maxCompletionTokens
        response_format:
          allOf:
          - $ref: '#/components/schemas/AssistantsApiResponseFormatOption'
          x-ballerina-name: responseFormat
        parallel_tool_calls:
          allOf:
          - $ref: '#/components/schemas/ParallelToolCalls'
          x-ballerina-name: parallelToolCalls
        stream:
          type: boolean
          description: |
            If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message
          nullable: true
        temperature:
          maximum: 2
          minimum: 0
          type: number
          description: |
            What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic
          nullable: true
          example: 1
          default: 1
        tool_choice:
          allOf:
          - $ref: '#/components/schemas/AssistantsApiToolChoiceOption'
          - nullable: true
          x-ballerina-name: toolChoice
        model:
          description: "The ID of the [Model](/docs/api-reference/models) to be used\
            \ to execute this run. If a value is provided here, it will override the\
            \ model associated with the assistant. If not, the model associated with\
            \ the assistant will be used"
          nullable: true
          example: gpt-4o
          anyOf:
          - type: string
          - $ref: '#/components/schemas/AssistantSupportedModels'
          x-oaiTypeLabel: string
        max_prompt_tokens:
          minimum: 256
          type: integer
          description: |
            The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info
          nullable: true
          x-ballerina-name: maxPromptTokens
      additionalProperties: false
    ChatCompletionToolChoiceOption:
      description: |
        Controls which (if any) tool is called by the model.
        `none` means the model will not call any tool and instead generates a message.
        `auto` means the model can pick between generating a message or calling one or more tools.
        `required` means the model must call one or more tools.
        Specifying a particular tool via `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

        `none` is the default when no tools are present. `auto` is the default if tools are present
      oneOf:
      - $ref: '#/components/schemas/ChatCompletionToolChoiceOptionOneOf1'
      - $ref: '#/components/schemas/ChatCompletionNamedToolChoice'
    InviteDeleteResponse:
      required:
      - deleted
      - id
      - object
      type: object
      properties:
        deleted:
          type: boolean
        id:
          type: string
        object:
          type: string
          description: "The object type, which is always `organization.invite.deleted`"
          enum:
          - organization.invite.deleted
          x-stainless-const: true
    RunObjectRequiredAction:
      required:
      - submit_tool_outputs
      - type
      type: object
      properties:
        submit_tool_outputs:
          allOf:
          - $ref: '#/components/schemas/RunObjectRequiredActionSubmitToolOutputs'
          x-ballerina-name: submitToolOutputs
        type:
          type: string
          description: "For now, this is always `submit_tool_outputs`"
          enum:
          - submit_tool_outputs
          x-stainless-const: true
      description: Details on the action required to continue the run. Will be `null`
        if no action is required
      nullable: true
    ResponseOutputItemAddedEvent:
      required:
      - item
      - output_index
      - type
      type: object
      properties:
        item:
          $ref: '#/components/schemas/OutputItem'
        type:
          type: string
          description: |
            The type of the event. Always `response.output_item.added`
          enum:
          - response.output_item.added
          x-stainless-const: true
        output_index:
          type: integer
          description: |
            The index of the output item that was added
          x-ballerina-name: outputIndex
      description: Emitted when a new output item is added
      x-oaiMeta:
        name: response.output_item.added
        group: responses
        example: |
          {
            "type": "response.output_item.added",
            "output_index": 0,
            "item": {
              "id": "msg_123",
              "status": "in_progress",
              "type": "message",
              "role": "assistant",
              "content": []
            }
          }
    FileSearchRankingOptions:
      title: File search tool call ranking options
      required:
      - score_threshold
      type: object
      properties:
        score_threshold:
          maximum: 1
          minimum: 0
          type: number
          description: The score threshold for the file search. All values must be
            a floating point number between 0 and 1
          x-ballerina-name: scoreThreshold
        ranker:
          $ref: '#/components/schemas/FileSearchRanker'
      description: |
        The ranking options for the file search. If not specified, the file search tool will use the `auto` ranker and a score_threshold of 0.

        See the [file search tool documentation](/docs/assistants/tools/file-search#customizing-file-search-settings) for more information
    RunStepDetailsToolCallsFileSearchRankingOptionsObject:
      title: File search tool call ranking options
      required:
      - ranker
      - score_threshold
      type: object
      properties:
        score_threshold:
          maximum: 1
          minimum: 0
          type: number
          description: The score threshold for the file search. All values must be
            a floating point number between 0 and 1
          x-ballerina-name: scoreThreshold
        ranker:
          $ref: '#/components/schemas/FileSearchRanker'
      description: The ranking options for the file search
    AuditLogOrganizationupdatedChangesRequestedSettings:
      type: object
      properties:
        threads_ui_visibility:
          type: string
          description: "Visibility of the threads page which shows messages created\
            \ with the Assistants API and Playground. One of `ANY_ROLE`, `OWNERS`,\
            \ or `NONE`"
          x-ballerina-name: threadsUiVisibility
        usage_dashboard_visibility:
          type: string
          description: Visibility of the usage dashboard which shows activity and
            costs for your organization. One of `ANY_ROLE` or `OWNERS`
          x-ballerina-name: usageDashboardVisibility
    VectorStoreSearchRequestRankingOptions:
      type: object
      properties:
        score_threshold:
          maximum: 1
          minimum: 0
          type: number
          default: 0
          x-ballerina-name: scoreThreshold
        ranker:
          type: string
          default: auto
          enum:
          - auto
          - default-2024-11-15
      additionalProperties: false
      description: Ranking options for search
    RealtimeSessionInputAudioTranscription:
      type: object
      properties:
        model:
          type: string
          description: |
            The model to use for transcription, current options are `gpt-4o-transcribe`, `gpt-4o-mini-transcribe`, and `whisper-1`
        language:
          type: string
          description: |
            The language of the input audio. Supplying the input language in
            [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) (e.g. `en`) format
            will improve accuracy and latency
        prompt:
          type: string
          description: |
            An optional text to guide the model's style or continue a previous audio
            segment.
            For `whisper-1`, the [prompt is a list of keywords](/docs/guides/speech-to-text#prompting).
            For `gpt-4o-transcribe` models, the prompt is a free text string, for example "expect words related to technology"
      description: |
        Configuration for input audio transcription, defaults to off and can be  set to `null` to turn off once on. Input audio transcription is not native to the model, since the model consumes audio directly. Transcription runs  asynchronously through [the /audio/transcriptions endpoint](https://platform.openai.com/docs/api-reference/audio/createTranscription) and should be treated as guidance of input audio content rather than precisely what the model heard. The client can optionally set the language and prompt for transcription, these offer additional guidance to the transcription service
    ChatCompletionMessageToolCalls:
      type: array
      description: "The tool calls generated by the model, such as function calls"
      items:
        $ref: '#/components/schemas/ChatCompletionMessageToolCall'
    ChatCompletionTokenLogprobTopLogprobs:
      required:
      - bytes
      - logprob
      - token
      type: object
      properties:
        logprob:
          type: number
          description: "The log probability of this token, if it is within the top\
            \ 20 most likely tokens. Otherwise, the value `-9999.0` is used to signify\
            \ that the token is very unlikely"
        bytes:
          type: array
          description: A list of integers representing the UTF-8 bytes representation
            of the token. Useful in instances where characters are represented by
            multiple tokens and their byte representations must be combined to generate
            the correct text representation. Can be `null` if there is no bytes representation
            for the token
          nullable: true
          items:
            type: integer
        token:
          type: string
          description: The token
    ParallelToolCalls:
      type: boolean
      description: "Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling)\
        \ during tool use"
      default: true
    ResponseIncompleteEvent:
      required:
      - response
      - type
      type: object
      properties:
        response:
          $ref: '#/components/schemas/Response'
        type:
          type: string
          description: |
            The type of the event. Always `response.incomplete`
          enum:
          - response.incomplete
          x-stainless-const: true
      description: |
        An event that is emitted when a response finishes as incomplete
      x-oaiMeta:
        name: response.incomplete
        group: responses
        example: "{\n  \"type\": \"response.incomplete\",\n  \"response\": {\n   \
          \ \"id\": \"resp_123\",\n    \"object\": \"response\",\n    \"created_at\"\
          : 1740855869,\n    \"status\": \"incomplete\",\n    \"error\": null, \n\
          \    \"incomplete_details\": {\n      \"reason\": \"max_tokens\"\n    },\n\
          \    \"instructions\": null,\n    \"max_output_tokens\": null,\n    \"model\"\
          : \"gpt-4o-mini-2024-07-18\",\n    \"output\": [],\n    \"previous_response_id\"\
          : null,\n    \"reasoning_effort\": null,\n    \"store\": false,\n    \"\
          temperature\": 1,\n    \"text\": {\n      \"format\": {\n        \"type\"\
          : \"text\"\n      }\n    },\n    \"tool_choice\": \"auto\",\n    \"tools\"\
          : [],\n    \"top_p\": 1,\n    \"truncation\": \"disabled\",\n    \"usage\"\
          : null,\n    \"user\": null,\n    \"metadata\": {}\n  }\n}\n"
    Project:
      required:
      - created_at
      - id
      - name
      - object
      - status
      type: object
      properties:
        archived_at:
          type: integer
          description: The Unix timestamp (in seconds) of when the project was archived
            or `null`
          nullable: true
          x-ballerina-name: archivedAt
        name:
          type: string
          description: The name of the project. This appears in reporting
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) of when the project was created
          x-ballerina-name: createdAt
        id:
          type: string
          description: "The identifier, which can be referenced in API endpoints"
        object:
          type: string
          description: "The object type, which is always `organization.project`"
          enum:
          - organization.project
          x-stainless-const: true
        status:
          type: string
          description: '`active` or `archived`'
          enum:
          - active
          - archived
      description: Represents an individual project
      x-oaiMeta:
        name: The project object
        example: |
          {
              "id": "proj_abc",
              "object": "organization.project",
              "name": "Project example",
              "created_at": 1711471533,
              "archived_at": null,
              "status": "active"
          }
    TranscriptionWord:
      required:
      - end
      - start
      - word
      type: object
      properties:
        start:
          type: number
          description: Start time of the word in seconds
          format: float
        end:
          type: number
          description: End time of the word in seconds
          format: float
        word:
          type: string
          description: The text content of the word
    RealtimeSessionCreateResponseInputAudioTranscription:
      type: object
      properties:
        model:
          type: string
          description: "The model to use for transcription, `whisper-1` is the only\
            \ currently \nsupported model\n"
      description: "Configuration for input audio transcription, defaults to off and\
        \ can be \nset to `null` to turn off once on. Input audio transcription is\
        \ not native \nto the model, since the model consumes audio directly. Transcription\
        \ runs \nasynchronously through Whisper and should be treated as rough guidance\
        \ \nrather than the representation understood by the model\n"
    AssistantObjectToolResources:
      type: object
      properties:
        code_interpreter:
          allOf:
          - $ref: '#/components/schemas/AssistantObjectToolResourcesCodeInterpreter'
          x-ballerina-name: codeInterpreter
        file_search:
          allOf:
          - $ref: '#/components/schemas/AssistantObjectToolResourcesFileSearch'
          x-ballerina-name: fileSearch
      description: |
        A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs
      nullable: true
    EvalTestingCriteria:
      oneOf:
      - $ref: '#/components/schemas/EvalLabelModelGrader'
      - $ref: '#/components/schemas/EvalStringCheckGrader'
      - $ref: '#/components/schemas/EvalTextSimilarityGrader'
      - $ref: '#/components/schemas/EvalPythonGrader'
      - $ref: '#/components/schemas/EvalScoreModelGrader'
    RunStreamEventRunStreamEventOneOf12:
      required:
      - data
      - event
      type: object
      properties:
        data:
          $ref: '#/components/schemas/RunObject'
        event:
          type: string
          enum:
          - thread.run.queued
          x-stainless-const: true
      description: "Occurs when a [run](/docs/api-reference/runs/object) moves to\
        \ a `queued` status"
      x-oaiMeta:
        dataDescription: "`data` is a [run](/docs/api-reference/runs/object)"
    CreateVectorStoreFileRequest:
      required:
      - file_id
      type: object
      properties:
        chunking_strategy:
          allOf:
          - $ref: '#/components/schemas/ChunkingStrategyRequestParam'
          x-ballerina-name: chunkingStrategy
        file_id:
          type: string
          description: "A [File](/docs/api-reference/files) ID that the vector store\
            \ should use. Useful for tools like `file_search` that can access files"
          x-ballerina-name: fileId
        attributes:
          $ref: '#/components/schemas/VectorStoreFileAttributes'
      additionalProperties: false
    RealtimeTranscriptionSessionCreateRequestInputAudioTranscription:
      type: object
      properties:
        model:
          type: string
          description: |
            The model to use for transcription, current options are `gpt-4o-transcribe`, `gpt-4o-mini-transcribe`, and `whisper-1`
          enum:
          - gpt-4o-transcribe
          - gpt-4o-mini-transcribe
          - whisper-1
        language:
          type: string
          description: |
            The language of the input audio. Supplying the input language in
            [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) (e.g. `en`) format
            will improve accuracy and latency
        prompt:
          type: string
          description: |
            An optional text to guide the model's style or continue a previous audio
            segment.
            For `whisper-1`, the [prompt is a list of keywords](/docs/guides/speech-to-text#prompting).
            For `gpt-4o-transcribe` models, the prompt is a free text string, for example "expect words related to technology"
      description: |
        Configuration for input audio transcription. The client can optionally set the language and prompt for transcription, these offer additional guidance to the transcription service
    ProjectUserCreateRequest:
      required:
      - role
      - user_id
      type: object
      properties:
        role:
          type: string
          description: '`owner` or `member`'
          enum:
          - owner
          - member
        user_id:
          type: string
          description: The ID of the user
          x-ballerina-name: userId
    RealtimeSessionCreateResponse:
      required:
      - client_secret
      type: object
      properties:
        voice:
          $ref: '#/components/schemas/VoiceIdsShared'
        instructions:
          type: string
          description: "The default system instructions (i.e. system message) prepended\
            \ to model \ncalls. This field allows the client to guide the model on\
            \ desired \nresponses. The model can be instructed on response content\
            \ and format, \n(e.g. \"be extremely succinct\", \"act friendly\", \"\
            here are examples of good \nresponses\") and on audio behavior (e.g. \"\
            talk quickly\", \"inject emotion \ninto your voice\", \"laugh frequently\"\
            ). The instructions are not guaranteed \nto be followed by the model,\
            \ but they provide guidance to the model on the \ndesired behavior.\n\n\
            Note that the server sets default instructions which will be used if this\
            \ \nfield is not set and are visible in the `session.created` event at\
            \ the \nstart of the session\n"
        input_audio_format:
          type: string
          description: |
            The format of input audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`
          x-ballerina-name: inputAudioFormat
        modalities:
          type: array
          description: |
            The set of modalities the model can respond with. To disable audio,
            set this to ["text"]
          items:
            type: string
            enum:
            - text
            - audio
        max_response_output_tokens:
          description: |
            Maximum number of output tokens for a single assistant response,
            inclusive of tool calls. Provide an integer between 1 and 4096 to
            limit output tokens, or `inf` for the maximum available tokens for a
            given model. Defaults to `inf`
          oneOf:
          - type: integer
          - type: string
            enum:
            - inf
            x-stainless-const: true
          x-ballerina-name: maxResponseOutputTokens
        output_audio_format:
          type: string
          description: |
            The format of output audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`
          x-ballerina-name: outputAudioFormat
        input_audio_transcription:
          allOf:
          - $ref: '#/components/schemas/RealtimeSessionCreateResponseInputAudioTranscription'
          x-ballerina-name: inputAudioTranscription
        temperature:
          type: number
          description: |
            Sampling temperature for the model, limited to [0.6, 1.2]. Defaults to 0.8
        turn_detection:
          allOf:
          - $ref: '#/components/schemas/RealtimeSessionCreateResponseTurnDetection'
          x-ballerina-name: turnDetection
        tool_choice:
          type: string
          description: "How the model chooses tools. Options are `auto`, `none`, `required`,\
            \ or \nspecify a function\n"
          x-ballerina-name: toolChoice
        client_secret:
          allOf:
          - $ref: '#/components/schemas/RealtimeSessionCreateResponseClientSecret'
          x-ballerina-name: clientSecret
        tools:
          type: array
          description: Tools (functions) available to the model
          items:
            $ref: '#/components/schemas/RealtimeResponseCreateParamsTools'
      description: |
        A new Realtime session configuration, with an ephermeral key. Default TTL
        for keys is one minute
      x-oaiMeta:
        name: The session object
        group: realtime
        example: "{\n  \"id\": \"sess_001\",\n  \"object\": \"realtime.session\",\n\
          \  \"model\": \"gpt-4o-realtime-preview\",\n  \"modalities\": [\"audio\"\
          , \"text\"],\n  \"instructions\": \"You are a friendly assistant.\",\n \
          \ \"voice\": \"alloy\",\n  \"input_audio_format\": \"pcm16\",\n  \"output_audio_format\"\
          : \"pcm16\",\n  \"input_audio_transcription\": {\n      \"model\": \"whisper-1\"\
          \n  },\n  \"turn_detection\": null,\n  \"tools\": [],\n  \"tool_choice\"\
          : \"none\",\n  \"temperature\": 0.7,\n  \"max_response_output_tokens\":\
          \ 200,\n  \"client_secret\": {\n    \"value\": \"ek_abc123\", \n    \"expires_at\"\
          : 1234567890\n  }\n}\n"
    Metadata:
      type: object
      additionalProperties:
        type: string
      description: "Set of 16 key-value pairs that can be attached to an object. This\
        \ can be\nuseful for storing additional information about the object in a\
        \ structured\nformat, and querying for objects via API or the dashboard. \n\
        \nKeys are strings with a maximum length of 64 characters. Values are strings\n\
        with a maximum length of 512 characters\n"
      nullable: true
      x-oaiTypeLabel: map
    AuditLogRateLimitdeleted:
      type: object
      properties:
        id:
          type: string
          description: The rate limit ID
      description: The details for events with this `type`
    ChatCompletionMessageToolCallChunkFunction:
      type: object
      properties:
        name:
          type: string
          description: The name of the function to call
        arguments:
          type: string
          description: "The arguments to call the function with, as generated by the\
            \ model in JSON format. Note that the model does not always generate valid\
            \ JSON, and may hallucinate parameters not defined by your function schema.\
            \ Validate the arguments in your code before calling your function"
    FileSearchToolCall:
      title: File search tool call
      required:
      - id
      - queries
      - status
      - type
      type: object
      properties:
        id:
          type: string
          description: |
            The unique ID of the file search tool call
        type:
          type: string
          description: |
            The type of the file search tool call. Always `file_search_call`
          enum:
          - file_search_call
          x-stainless-const: true
        queries:
          type: array
          description: |
            The queries used to search for files
          items:
            type: string
        results:
          type: array
          description: |
            The results of the file search tool call
          nullable: true
          items:
            $ref: '#/components/schemas/FileSearchToolCallResults'
        status:
          type: string
          description: "The status of the file search tool call. One of `in_progress`,\
            \ \n`searching`, `incomplete` or `failed`,\n"
          enum:
          - in_progress
          - searching
          - completed
          - incomplete
          - failed
      description: "The results of a file search tool call. See the \n[file search\
        \ guide](/docs/guides/tools-file-search) for more information\n"
    RunStepDetailsToolCallsFileSearchResultObjectContent:
      type: object
      properties:
        text:
          type: string
          description: The text content of the file
        type:
          type: string
          description: The type of the content
          enum:
          - text
          x-stainless-const: true
    EvalsevalIdBody:
      type: object
      properties:
        metadata:
          $ref: '#/components/schemas/Metadata'
        name:
          type: string
          description: Rename the evaluation
    RealtimeResponse:
      type: object
      properties:
        voice:
          $ref: '#/components/schemas/VoiceIdsShared'
        metadata:
          $ref: '#/components/schemas/Metadata'
        usage:
          $ref: '#/components/schemas/RealtimeResponseUsage'
        output:
          type: array
          description: The list of output items generated by the response
          items:
            $ref: '#/components/schemas/RealtimeConversationItem'
        modalities:
          type: array
          description: |
            The set of modalities the model used to respond. If there are multiple modalities,
            the model will pick one, for example if `modalities` is `["text", "audio"]`, the model
            could be responding in either text or audio
          items:
            type: string
            enum:
            - text
            - audio
        conversation_id:
          type: string
          description: |
            Which conversation the response is added to, determined by the `conversation`
            field in the `response.create` event. If `auto`, the response will be added to
            the default conversation and the value of `conversation_id` will be an id like
            `conv_1234`. If `none`, the response will not be added to any conversation and
            the value of `conversation_id` will be `null`. If responses are being triggered
            by server VAD, the response will be added to the default conversation, thus
            the `conversation_id` will be an id like `conv_1234`
          x-ballerina-name: conversationId
        output_audio_format:
          type: string
          description: |
            The format of output audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`
          enum:
          - pcm16
          - g711_ulaw
          - g711_alaw
          x-ballerina-name: outputAudioFormat
        temperature:
          type: number
          description: |
            Sampling temperature for the model, limited to [0.6, 1.2]. Defaults to 0.8
        id:
          type: string
          description: The unique ID of the response
        status_details:
          allOf:
          - $ref: '#/components/schemas/RealtimeResponseStatusDetails'
          x-ballerina-name: statusDetails
        object:
          type: string
          description: "The object type, must be `realtime.response`"
          enum:
          - realtime.response
          x-stainless-const: true
        status:
          type: string
          description: "The final status of the response (`completed`, `cancelled`,\
            \ `failed`, or \n`incomplete`)\n"
          enum:
          - completed
          - cancelled
          - failed
          - incomplete
        max_output_tokens:
          description: |
            Maximum number of output tokens for a single assistant response,
            inclusive of tool calls, that was used in this response
          oneOf:
          - type: integer
          - type: string
            enum:
            - inf
            x-stainless-const: true
          x-ballerina-name: maxOutputTokens
      description: The response resource
    ResponseTextAnnotationDeltaEvent:
      required:
      - annotation
      - annotation_index
      - content_index
      - item_id
      - output_index
      - type
      type: object
      properties:
        annotation:
          $ref: '#/components/schemas/Annotation'
        annotation_index:
          type: integer
          description: |
            The index of the annotation that was added
          x-ballerina-name: annotationIndex
        item_id:
          type: string
          description: |
            The ID of the output item that the text annotation was added to
          x-ballerina-name: itemId
        content_index:
          type: integer
          description: |
            The index of the content part that the text annotation was added to
          x-ballerina-name: contentIndex
        type:
          type: string
          description: |
            The type of the event. Always `response.output_text.annotation.added`
          enum:
          - response.output_text.annotation.added
          x-stainless-const: true
        output_index:
          type: integer
          description: |
            The index of the output item that the text annotation was added to
          x-ballerina-name: outputIndex
      description: Emitted when a text annotation is added
      x-oaiMeta:
        name: response.output_text.annotation.added
        group: responses
        example: |
          {
            "type": "response.output_text.annotation.added",
            "item_id": "msg_abc123",
            "output_index": 1,
            "content_index": 0,
            "annotation_index": 0,
            "annotation": {
              "type": "file_citation",
              "index": 390,
              "file_id": "file-4wDz5b167pAf72nx1h9eiN",
              "filename": "dragons.pdf"
            }
          }
    OutputTextContent:
      title: Output text
      required:
      - annotations
      - text
      - type
      type: object
      properties:
        annotations:
          type: array
          description: The annotations of the text output
          items:
            $ref: '#/components/schemas/Annotation'
        text:
          type: string
          description: The text output from the model
        type:
          type: string
          description: The type of the output text. Always `output_text`
          default: output_text
          enum:
          - output_text
          x-stainless-const: true
      description: A text output from the model
    RunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventOneOf12345:
      required:
      - data
      - event
      type: object
      properties:
        data:
          $ref: '#/components/schemas/RunObject'
        event:
          type: string
          enum:
          - thread.run.completed
          x-stainless-const: true
      description: "Occurs when a [run](/docs/api-reference/runs/object) is completed"
      x-oaiMeta:
        dataDescription: "`data` is a [run](/docs/api-reference/runs/object)"
    AuditLogRateLimitupdatedChangesRequested:
      type: object
      properties:
        batch_1_day_max_input_tokens:
          type: integer
          description: The maximum batch input tokens per day. Only relevant for certain
            models
          x-ballerina-name: batch1DayMaxInputTokens
        max_tokens_per_1_minute:
          type: integer
          description: The maximum tokens per minute
          x-ballerina-name: maxTokensPer1Minute
        max_images_per_1_minute:
          type: integer
          description: The maximum images per minute. Only relevant for certain models
          x-ballerina-name: maxImagesPer1Minute
        max_audio_megabytes_per_1_minute:
          type: integer
          description: The maximum audio megabytes per minute. Only relevant for certain
            models
          x-ballerina-name: maxAudioMegabytesPer1Minute
        max_requests_per_1_minute:
          type: integer
          description: The maximum requests per minute
          x-ballerina-name: maxRequestsPer1Minute
        max_requests_per_1_day:
          type: integer
          description: The maximum requests per day. Only relevant for certain models
          x-ballerina-name: maxRequestsPer1Day
      description: The payload used to update the rate limits
    DeleteCertificateResponse:
      required:
      - id
      - object
      type: object
      properties:
        id:
          type: string
          description: The ID of the certificate that was deleted
        object:
          type: string
          description: "The object type, must be `certificate.deleted`"
          enum:
          - certificate.deleted
          x-stainless-const: true
    MessageDeltaContentTextObjectTextAnnotations:
      oneOf:
      - $ref: '#/components/schemas/MessageDeltaContentTextAnnotationsFileCitationObject'
      - $ref: '#/components/schemas/MessageDeltaContentTextAnnotationsFilePathObject'
    RunStepDeltaStepDetailsToolCallsCodeOutputImageObject:
      title: Code interpreter image output
      required:
      - index
      - type
      type: object
      properties:
        image:
          $ref: '#/components/schemas/RunStepDeltaStepDetailsToolCallsCodeOutputImageObjectImage'
        index:
          type: integer
          description: The index of the output in the outputs array
        type:
          type: string
          description: Always `image`
          enum:
          - image
          x-stainless-const: true
    MessageDeltaObjectDelta:
      type: object
      properties:
        role:
          type: string
          description: The entity that produced the message. One of `user` or `assistant`
          enum:
          - user
          - assistant
        content:
          type: array
          description: The content of the message in array of text and/or images
          items:
            $ref: '#/components/schemas/MessageDeltaObjectDeltaContent'
      description: The delta containing the fields that have changed on the Message
    RealtimeClientEventConversationItemTruncate:
      required:
      - audio_end_ms
      - content_index
      - item_id
      - type
      type: object
      properties:
        event_id:
          type: string
          description: Optional client-generated ID used to identify this event
          x-ballerina-name: eventId
        item_id:
          type: string
          description: "The ID of the assistant message item to truncate. Only assistant\
            \ message \nitems can be truncated\n"
          x-ballerina-name: itemId
        content_index:
          type: integer
          description: The index of the content part to truncate. Set this to 0
          x-ballerina-name: contentIndex
        type:
          type: string
          description: "The event type, must be `conversation.item.truncate`"
          enum:
          - conversation.item.truncate
          x-stainless-const: true
        audio_end_ms:
          type: integer
          description: "Inclusive duration up to which audio is truncated, in milliseconds.\
            \ If \nthe audio_end_ms is greater than the actual audio duration, the\
            \ server \nwill respond with an error\n"
          x-ballerina-name: audioEndMs
      description: "Send this event to truncate a previous assistant messages audio.\
        \ The server \nwill produce audio faster than realtime, so this event is useful\
        \ when the user \ninterrupts to truncate audio that has already been sent\
        \ to the client but not \nyet played. This will synchronize the server's understanding\
        \ of the audio with \nthe client's playback.\n\nTruncating audio will delete\
        \ the server-side text transcript to ensure there \nis not text in the context\
        \ that hasn't been heard by the user.\n\nIf successful, the server will respond\
        \ with a `conversation.item.truncated` \nevent. \n"
      x-oaiMeta:
        name: conversation.item.truncate
        group: realtime
        example: |
          {
              "event_id": "event_678",
              "type": "conversation.item.truncate",
              "item_id": "msg_002",
              "content_index": 0,
              "audio_end_ms": 1500
          }
    RealtimeServerEventConversationItemTruncated:
      required:
      - audio_end_ms
      - content_index
      - event_id
      - item_id
      - type
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event
          x-ballerina-name: eventId
        item_id:
          type: string
          description: The ID of the assistant message item that was truncated
          x-ballerina-name: itemId
        content_index:
          type: integer
          description: The index of the content part that was truncated
          x-ballerina-name: contentIndex
        type:
          type: string
          description: "The event type, must be `conversation.item.truncated`"
          enum:
          - conversation.item.truncated
          x-stainless-const: true
        audio_end_ms:
          type: integer
          description: |
            The duration up to which the audio was truncated, in milliseconds
          x-ballerina-name: audioEndMs
      description: "Returned when an earlier assistant audio message item is truncated\
        \ by the \nclient with a `conversation.item.truncate` event. This event is\
        \ used to \nsynchronize the server's understanding of the audio with the client's\
        \ playback.\n\nThis action will truncate the audio and remove the server-side\
        \ text transcript \nto ensure there is no text in the context that hasn't\
        \ been heard by the user\n"
      x-oaiMeta:
        name: conversation.item.truncated
        group: realtime
        example: |
          {
              "event_id": "event_2526",
              "type": "conversation.item.truncated",
              "item_id": "msg_004",
              "content_index": 0,
              "audio_end_ms": 1500
          }
    AuditLogApiKeycreatedData:
      type: object
      properties:
        scopes:
          type: array
          description: "A list of scopes allowed for the API key, e.g. `[\"api.model.request\"\
            ]`"
          items:
            type: string
      description: The payload used to create the API key
    WebSearchToolCall:
      title: Web search tool call
      required:
      - id
      - status
      - type
      type: object
      properties:
        id:
          type: string
          description: |
            The unique ID of the web search tool call
        type:
          type: string
          description: |
            The type of the web search tool call. Always `web_search_call`
          enum:
          - web_search_call
          x-stainless-const: true
        status:
          type: string
          description: |
            The status of the web search tool call
          enum:
          - in_progress
          - searching
          - completed
          - failed
      description: "The results of a web search tool call. See the \n[web search guide](/docs/guides/tools-web-search)\
        \ for more information\n"
    UsageAudioTranscriptionsResult:
      required:
      - num_model_requests
      - object
      - seconds
      type: object
      properties:
        seconds:
          type: integer
          description: The number of seconds processed
        num_model_requests:
          type: integer
          description: The count of requests made to the model
          x-ballerina-name: numModelRequests
        project_id:
          type: string
          description: "When `group_by=project_id`, this field provides the project\
            \ ID of the grouped usage result"
          nullable: true
          x-ballerina-name: projectId
        user_id:
          type: string
          description: "When `group_by=user_id`, this field provides the user ID of\
            \ the grouped usage result"
          nullable: true
          x-ballerina-name: userId
        model:
          type: string
          description: "When `group_by=model`, this field provides the model name\
            \ of the grouped usage result"
          nullable: true
        api_key_id:
          type: string
          description: "When `group_by=api_key_id`, this field provides the API key\
            \ ID of the grouped usage result"
          nullable: true
          x-ballerina-name: apiKeyId
        object:
          type: string
          enum:
          - organization.usage.audio_transcriptions.result
          x-stainless-const: true
      description: The aggregated audio transcriptions usage details of the specific
        time bucket
      x-oaiMeta:
        name: Audio transcriptions usage object
        example: |
          {
              "object": "organization.usage.audio_transcriptions.result",
              "seconds": 10,
              "num_model_requests": 1,
              "project_id": "proj_abc",
              "user_id": "user-abc",
              "api_key_id": "key_abc",
              "model": "tts-1"
          }
    RunStepDetailsToolCallsObject:
      title: Tool calls
      required:
      - tool_calls
      - type
      type: object
      properties:
        tool_calls:
          type: array
          description: |
            An array of tool calls the run step was involved in. These can be associated with one of three types of tools: `code_interpreter`, `file_search`, or `function`
          items:
            $ref: '#/components/schemas/RunStepDetailsToolCallsObjectToolCalls'
          x-ballerina-name: toolCalls
        type:
          type: string
          description: Always `tool_calls`
          enum:
          - tool_calls
          x-stainless-const: true
      description: Details of the tool call
    LogProbProperties:
      required:
      - bytes
      - logprob
      - token
      type: object
      properties:
        logprob:
          type: number
          description: |
            The log probability of the token
        bytes:
          type: array
          description: |
            The bytes that were used to generate the log probability
          items:
            type: integer
        token:
          type: string
          description: |
            The token that was used to generate the log probability
      description: |
        A log probability object
    RunToolCallObjectFunction:
      required:
      - arguments
      - name
      type: object
      properties:
        name:
          type: string
          description: The name of the function
        arguments:
          type: string
          description: The arguments that the model expects you to pass to the function
      description: The function definition
    ResponseUsageInputTokensDetails:
      required:
      - cached_tokens
      type: object
      properties:
        cached_tokens:
          type: integer
          description: "The number of tokens that were retrieved from the cache. \n\
            [More on prompt caching](/docs/guides/prompt-caching)\n"
          x-ballerina-name: cachedTokens
      description: A detailed breakdown of the input tokens
    ChatCompletionMessageList:
      title: ChatCompletionMessageList
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
      type: object
      properties:
        first_id:
          type: string
          description: The identifier of the first chat message in the data array
          x-ballerina-name: firstId
        data:
          type: array
          description: |
            An array of chat completion message objects
          items:
            $ref: '#/components/schemas/ChatCompletionMessageListData'
        last_id:
          type: string
          description: The identifier of the last chat message in the data array
          x-ballerina-name: lastId
        has_more:
          type: boolean
          description: Indicates whether there are more chat messages available
          x-ballerina-name: hasMore
        object:
          type: string
          description: |
            The type of this object. It is always set to "list"
          default: list
          enum:
          - list
          x-stainless-const: true
      description: |
        An object representing a list of chat completion messages
      x-oaiMeta:
        name: The chat completion message list object
        group: chat
        example: |
          {
            "object": "list",
            "data": [
              {
                "id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2-0",
                "role": "user",
                "content": "write a haiku about ai",
                "name": null,
                "content_parts": null
              }
            ],
            "first_id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2-0",
            "last_id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2-0",
            "has_more": false
          }
    CreateCompletionRequest:
      required:
      - model
      - prompt
      type: object
      properties:
        logit_bias:
          type: object
          additionalProperties:
            type: integer
          description: |
            Modify the likelihood of specified tokens appearing in the completion.

            Accepts a JSON object that maps tokens (specified by their token ID in the GPT tokenizer) to an associated bias value from -100 to 100. You can use this [tokenizer tool](/tokenizer?view=bpe) to convert text to token IDs. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.

            As an example, you can pass `{"50256": -100}` to prevent the <|endoftext|> token from being generated
          nullable: true
          x-oaiTypeLabel: map
          x-ballerina-name: logitBias
        seed:
          type: integer
          description: |
            If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same `seed` and parameters should return the same result.

            Determinism is not guaranteed, and you should refer to the `system_fingerprint` response parameter to monitor changes in the backend
          format: int64
          nullable: true
        max_tokens:
          minimum: 0
          type: integer
          description: |
            The maximum number of [tokens](/tokenizer) that can be generated in the completion.

            The token count of your prompt plus `max_tokens` cannot exceed the model's context length. [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken) for counting tokens
          nullable: true
          example: 16
          default: 16
          x-ballerina-name: maxTokens
        presence_penalty:
          maximum: 2
          minimum: -2
          type: number
          description: |
            Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.

            [See more information about frequency and presence penalties.](/docs/guides/text-generation)
          nullable: true
          default: 0
          x-ballerina-name: presencePenalty
        echo:
          type: boolean
          description: |
            Echo back the prompt in addition to the completion
          nullable: true
          default: false
        suffix:
          type: string
          description: |
            The suffix that comes after a completion of inserted text.

            This parameter is only supported for `gpt-3.5-turbo-instruct`
          nullable: true
          example: test.
        "n":
          maximum: 128
          minimum: 1
          type: integer
          description: |
            How many completions to generate for each prompt.

            **Note:** Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`
          nullable: true
          example: 1
          default: 1
        logprobs:
          maximum: 5
          minimum: 0
          type: integer
          description: |
            Include the log probabilities on the `logprobs` most likely output tokens, as well the chosen tokens. For example, if `logprobs` is 5, the API will return a list of the 5 most likely tokens. The API will always return the `logprob` of the sampled token, so there may be up to `logprobs+1` elements in the response.

            The maximum value for `logprobs` is 5
          nullable: true
        top_p:
          maximum: 1
          minimum: 0
          type: number
          description: |
            An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

            We generally recommend altering this or `temperature` but not both
          nullable: true
          example: 1
          default: 1
          x-ballerina-name: topP
        frequency_penalty:
          maximum: 2
          minimum: -2
          type: number
          description: |
            Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.

            [See more information about frequency and presence penalties.](/docs/guides/text-generation)
          nullable: true
          default: 0
          x-ballerina-name: frequencyPenalty
        best_of:
          maximum: 20
          minimum: 0
          type: integer
          description: |
            Generates `best_of` completions server-side and returns the "best" (the one with the highest log probability per token). Results cannot be streamed.

            When used with `n`, `best_of` controls the number of candidate completions and `n` specifies how many to return  `best_of` must be greater than `n`.

            **Note:** Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`
          nullable: true
          default: 1
          x-ballerina-name: bestOf
        stop:
          $ref: '#/components/schemas/StopConfiguration'
        stream:
          type: boolean
          description: |
            Whether to stream back partial progress. If set, tokens will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format) as they become available, with the stream terminated by a `data: [DONE]` message. [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions)
          nullable: true
          default: false
        temperature:
          maximum: 2
          minimum: 0
          type: number
          description: |
            What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

            We generally recommend altering this or `top_p` but not both
          nullable: true
          example: 1
          default: 1
        model:
          description: |
            ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them
          anyOf:
          - type: string
          - type: string
            enum:
            - gpt-3.5-turbo-instruct
            - davinci-002
            - babbage-002
          x-oaiTypeLabel: string
        stream_options:
          allOf:
          - $ref: '#/components/schemas/ChatCompletionStreamOptions'
          x-ballerina-name: streamOptions
        prompt:
          description: |
            The prompt(s) to generate completions for, encoded as a string, array of strings, array of tokens, or array of token arrays.

            Note that <|endoftext|> is the document separator that the model sees during training, so if a prompt is not specified the model will generate as if from the beginning of a new document
          nullable: true
          oneOf:
          - type: string
            example: This is a test.
            default: ""
          - type: array
            items:
              type: string
              example: This is a test.
              default: ""
          - minItems: 1
            type: array
            example: "[1212, 318, 257, 1332, 13]"
            items:
              type: integer
          - minItems: 1
            type: array
            example: "[[1212, 318, 257, 1332, 13]]"
            items:
              minItems: 1
              type: array
              items:
                type: integer
          default: <|endoftext|>
        user:
          type: string
          description: |
            A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids)
          example: user-1234
    RealtimeConversationItem:
      type: object
      properties:
        output:
          type: string
          description: |
            The output of the function call (for `function_call_output` items)
        role:
          type: string
          description: "The role of the message sender (`user`, `assistant`, `system`),\
            \ only \napplicable for `message` items\n"
          enum:
          - user
          - assistant
          - system
        name:
          type: string
          description: |
            The name of the function being called (for `function_call` items)
        arguments:
          type: string
          description: |
            The arguments of the function call (for `function_call` items)
        id:
          type: string
          description: "The unique ID of the item, this can be generated by the client\
            \ to help \nmanage server-side context, but is not required because the\
            \ server will \ngenerate one if not provided\n"
        type:
          type: string
          description: |
            The type of the item (`message`, `function_call`, `function_call_output`)
          enum:
          - message
          - function_call
          - function_call_output
        content:
          type: array
          description: "The content of the message, applicable for `message` items.\
            \ \n- Message items of role `system` support only `input_text` content\n\
            - Message items of role `user` support `input_text` and `input_audio`\
            \ \n  content\n- Message items of role `assistant` support `text` content\n"
          items:
            $ref: '#/components/schemas/RealtimeConversationItemContent'
        object:
          type: string
          description: |
            Identifier for the API object being returned - always `realtime.item`
          enum:
          - realtime.item
          x-stainless-const: true
        status:
          type: string
          description: "The status of the item (`completed`, `incomplete`). These\
            \ have no effect \non the conversation, but are accepted for consistency\
            \ with the \n`conversation.item.created` event\n"
          enum:
          - completed
          - incomplete
        call_id:
          type: string
          description: "The ID of the function call (for `function_call` and \n`function_call_output`\
            \ items). If passed on a `function_call_output` \nitem, the server will\
            \ check that a `function_call` item with the same \nID exists in the conversation\
            \ history\n"
          x-ballerina-name: callId
      description: The item to add to the conversation
    InputImageContent:
      title: Input image
      required:
      - detail
      - type
      type: object
      properties:
        image_url:
          anyOf:
          - type: string
            description: The URL of the image to be sent to the model. A fully qualified
              URL or base64 encoded image in a data URL.
          - nullable: true
          x-ballerina-name: imageUrl
        file_id:
          anyOf:
          - type: string
            description: The ID of the file to be sent to the model.
          - nullable: true
          x-ballerina-name: fileId
        detail:
          type: string
          description: "The detail level of the image to be sent to the model. One\
            \ of `high`, `low`, or `auto`. Defaults to `auto`"
          enum:
          - low
          - high
          - auto
        type:
          type: string
          description: The type of the input item. Always `input_image`
          default: input_image
          enum:
          - input_image
          x-stainless-const: true
      description: "An image input to the model. Learn about [image inputs](/docs/guides/vision)"
    CreateChatCompletionResponseLogprobs:
      required:
      - content
      - refusal
      type: object
      properties:
        refusal:
          type: array
          description: A list of message refusal tokens with log probability information
          nullable: true
          items:
            $ref: '#/components/schemas/ChatCompletionTokenLogprob'
        content:
          type: array
          description: A list of message content tokens with log probability information
          nullable: true
          items:
            $ref: '#/components/schemas/ChatCompletionTokenLogprob'
      description: Log probability information for the choice
      nullable: true
    UrlCitationBody:
      title: URL citation
      required:
      - end_index
      - start_index
      - title
      - type
      - url
      type: object
      properties:
        start_index:
          type: integer
          description: The index of the first character of the URL citation in the
            message
          x-ballerina-name: startIndex
        end_index:
          type: integer
          description: The index of the last character of the URL citation in the
            message
          x-ballerina-name: endIndex
        type:
          type: string
          description: The type of the URL citation. Always `url_citation`
          default: url_citation
          enum:
          - url_citation
          x-stainless-const: true
        title:
          type: string
          description: The title of the web resource
        url:
          type: string
          description: The URL of the web resource
      description: A citation for a web resource used to generate a model response
    ServiceTier:
      type: string
      description: |
        Specifies the latency tier to use for processing the request. This parameter is relevant for customers subscribed to the scale tier service:
          - If set to 'auto', and the Project is Scale tier enabled, the system
            will utilize scale tier credits until they are exhausted.
          - If set to 'auto', and the Project is not Scale tier enabled, the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.
          - If set to 'default', the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.
          - If set to 'flex', the request will be processed with the Flex Processing service tier. [Learn more](/docs/guides/flex-processing).
          - When not set, the default behavior is 'auto'.

          When this parameter is set, the response body will include the `service_tier` utilized
      nullable: true
      default: auto
      enum:
      - auto
      - default
      - flex
    RunStepDetailsToolCallsObjectToolCalls:
      oneOf:
      - $ref: '#/components/schemas/RunStepDetailsToolCallsCodeObject'
      - $ref: '#/components/schemas/RunStepDetailsToolCallsFileSearchObject'
      - $ref: '#/components/schemas/RunStepDetailsToolCallsFunctionObject'
    UpdateVectorStoreFileAttributesRequest:
      required:
      - attributes
      type: object
      properties:
        attributes:
          $ref: '#/components/schemas/VectorStoreFileAttributes'
      additionalProperties: false
      x-oaiMeta:
        name: Update vector store file attributes request
    RealtimeServerEventResponseOutputItemAdded:
      required:
      - event_id
      - item
      - output_index
      - response_id
      - type
      type: object
      properties:
        item:
          $ref: '#/components/schemas/RealtimeConversationItem'
        event_id:
          type: string
          description: The unique ID of the server event
          x-ballerina-name: eventId
        response_id:
          type: string
          description: The ID of the Response to which the item belongs
          x-ballerina-name: responseId
        type:
          type: string
          description: "The event type, must be `response.output_item.added`"
          enum:
          - response.output_item.added
          x-stainless-const: true
        output_index:
          type: integer
          description: The index of the output item in the Response
          x-ballerina-name: outputIndex
      description: Returned when a new Item is created during Response generation
      x-oaiMeta:
        name: response.output_item.added
        group: realtime
        example: |
          {
              "event_id": "event_3334",
              "type": "response.output_item.added",
              "response_id": "resp_001",
              "output_index": 0,
              "item": {
                  "id": "msg_007",
                  "object": "realtime.item",
                  "type": "message",
                  "status": "in_progress",
                  "role": "assistant",
                  "content": []
              }
          }
    ProjectApiKey:
      required:
      - created_at
      - id
      - last_used_at
      - name
      - object
      - owner
      - redacted_value
      type: object
      properties:
        owner:
          $ref: '#/components/schemas/ProjectApiKeyOwner'
        last_used_at:
          type: integer
          description: The Unix timestamp (in seconds) of when the API key was last
            used
          x-ballerina-name: lastUsedAt
        name:
          type: string
          description: The name of the API key
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) of when the API key was created
          x-ballerina-name: createdAt
        redacted_value:
          type: string
          description: The redacted value of the API key
          x-ballerina-name: redactedValue
        id:
          type: string
          description: "The identifier, which can be referenced in API endpoints"
        object:
          type: string
          description: "The object type, which is always `organization.project.api_key`"
          enum:
          - organization.project.api_key
          x-stainless-const: true
      description: Represents an individual API key in a project
      x-oaiMeta:
        name: The project API key object
        example: |
          {
              "object": "organization.project.api_key",
              "redacted_value": "sk-abc...def",
              "name": "My API Key",
              "created_at": 1711471533,
              "last_used_at": 1711471534,
              "id": "key_abc",
              "owner": {
                  "type": "user",
                  "user": {
                      "object": "organization.project.user",
                      "id": "user_abc",
                      "name": "First Last",
                      "email": "user@example.com",
                      "role": "owner",
                      "created_at": 1711471533
                  }
              }
          }
    ListAssistantsResponse:
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
      type: object
      properties:
        first_id:
          type: string
          example: asst_abc123
          x-ballerina-name: firstId
        data:
          type: array
          items:
            $ref: '#/components/schemas/AssistantObject'
        last_id:
          type: string
          example: asst_abc456
          x-ballerina-name: lastId
        has_more:
          type: boolean
          example: false
          x-ballerina-name: hasMore
        object:
          type: string
          example: list
      x-oaiMeta:
        name: List assistants response object
        group: chat
        example: |
          {
            "object": "list",
            "data": [
              {
                "id": "asst_abc123",
                "object": "assistant",
                "created_at": 1698982736,
                "name": "Coding Tutor",
                "description": null,
                "model": "gpt-4o",
                "instructions": "You are a helpful assistant designed to make me better at coding!",
                "tools": [],
                "tool_resources": {},
                "metadata": {},
                "top_p": 1.0,
                "temperature": 1.0,
                "response_format": "auto"
              },
              {
                "id": "asst_abc456",
                "object": "assistant",
                "created_at": 1698982718,
                "name": "My Assistant",
                "description": null,
                "model": "gpt-4o",
                "instructions": "You are a helpful assistant designed to make me better at coding!",
                "tools": [],
                "tool_resources": {},
                "metadata": {},
                "top_p": 1.0,
                "temperature": 1.0,
                "response_format": "auto"
              },
              {
                "id": "asst_abc789",
                "object": "assistant",
                "created_at": 1698982643,
                "name": null,
                "description": null,
                "model": "gpt-4o",
                "instructions": null,
                "tools": [],
                "tool_resources": {},
                "metadata": {},
                "top_p": 1.0,
                "temperature": 1.0,
                "response_format": "auto"
              }
            ],
            "first_id": "asst_abc123",
            "last_id": "asst_abc789",
            "has_more": false
          }
    TranscriptTextDeltaEvent:
      required:
      - delta
      - type
      type: object
      properties:
        delta:
          type: string
          description: |
            The text delta that was additionally transcribed
        type:
          type: string
          description: |
            The type of the event. Always `transcript.text.delta`
          enum:
          - transcript.text.delta
          x-stainless-const: true
        logprobs:
          type: array
          description: |
            The log probabilities of the delta. Only included if you [create a transcription](/docs/api-reference/audio/create-transcription) with the `include[]` parameter set to `logprobs`
          items:
            $ref: '#/components/schemas/TranscriptTextDeltaEventLogprobs'
      description: "Emitted when there is an additional text delta. This is also the\
        \ first event emitted when the transcription starts. Only emitted when you\
        \ [create a transcription](/docs/api-reference/audio/create-transcription)\
        \ with the `Stream` parameter set to `true`"
      x-oaiMeta:
        name: Stream Event (transcript.text.delta)
        group: transcript
        example: |
          {
            "type": "transcript.text.delta",
            "delta": " wonderful"
          }
    AuditLogApiKeydeleted:
      type: object
      properties:
        id:
          type: string
          description: The tracking ID of the API key
      description: The details for events with this `type`
    RealtimeClientEventConversationItemRetrieve:
      required:
      - item_id
      - type
      type: object
      properties:
        event_id:
          type: string
          description: Optional client-generated ID used to identify this event
          x-ballerina-name: eventId
        item_id:
          type: string
          description: The ID of the item to retrieve
          x-ballerina-name: itemId
        type:
          type: string
          description: "The event type, must be `conversation.item.retrieve`"
          enum:
          - conversation.item.retrieve
          x-stainless-const: true
      description: "Send this event when you want to retrieve the server's representation\
        \ of a specific item in the conversation history. This is useful, for example,\
        \ to inspect user audio after noise cancellation and VAD.\nThe server will\
        \ respond with a `conversation.item.retrieved` event, \nunless the item does\
        \ not exist in the conversation history, in which case the \nserver will respond\
        \ with an error\n"
      x-oaiMeta:
        name: conversation.item.retrieve
        group: realtime
        example: |
          {
              "event_id": "event_901",
              "type": "conversation.item.retrieve",
              "item_id": "msg_003"
          }
    MessageRequestContentTextObject:
      title: Text
      required:
      - text
      - type
      type: object
      properties:
        text:
          type: string
          description: Text content to be sent to the model
        type:
          type: string
          description: Always `text`
          enum:
          - text
          x-stainless-const: true
      description: The text content that is part of a message
    FunctionToolCallResource:
      allOf:
      - $ref: '#/components/schemas/FunctionToolCall'
      - $ref: '#/components/schemas/FunctionToolCallResourceAllOf2'
    ResponseReasoningSummaryPartDoneEvent:
      required:
      - item_id
      - output_index
      - part
      - summary_index
      - type
      type: object
      properties:
        item_id:
          type: string
          description: |
            The ID of the item this summary part is associated with
          x-ballerina-name: itemId
        summary_index:
          type: integer
          description: |
            The index of the summary part within the reasoning summary
          x-ballerina-name: summaryIndex
        part:
          $ref: '#/components/schemas/ResponseReasoningSummaryPartDoneEventPart'
        type:
          type: string
          description: |
            The type of the event. Always `response.reasoning_summary_part.done`
          enum:
          - response.reasoning_summary_part.done
          x-stainless-const: true
        output_index:
          type: integer
          description: |
            The index of the output item this summary part is associated with
          x-ballerina-name: outputIndex
      description: Emitted when a reasoning summary part is completed
      x-oaiMeta:
        name: response.reasoning_summary_part.done
        group: responses
        example: |
          {
            "type": "response.reasoning_summary_part.done",
            "item_id": "rs_6806bfca0b2481918a5748308061a2600d3ce51bdffd5476",
            "output_index": 0,
            "summary_index": 0,
            "part": {
              "type": "summary_text",
              "text": "**Responding to a greeting**\n\nThe user just said, \"Hello!\" So, it seems I need to engage. I'll greet them back and offer help since they're looking to chat. I could say something like, \"Hello! How can I assist you today?\" That feels friendly and open. They didn't ask a specific question, so this approach will work well for starting a conversation. Let's see where it goes from there!"
            }
          }
    TranscriptionSegment:
      required:
      - avg_logprob
      - compression_ratio
      - end
      - id
      - no_speech_prob
      - seek
      - start
      - temperature
      - text
      - tokens
      type: object
      properties:
        start:
          type: number
          description: Start time of the segment in seconds
          format: float
        temperature:
          type: number
          description: Temperature parameter used for generating the segment
          format: float
        avg_logprob:
          type: number
          description: "Average logprob of the segment. If the value is lower than\
            \ -1, consider the logprobs failed"
          format: float
          x-ballerina-name: avgLogprob
        no_speech_prob:
          type: number
          description: "Probability of no speech in the segment. If the value is higher\
            \ than 1.0 and the `avg_logprob` is below -1, consider this segment silent"
          format: float
          x-ballerina-name: noSpeechProb
        end:
          type: number
          description: End time of the segment in seconds
          format: float
        tokens:
          type: array
          description: Array of token IDs for the text content
          items:
            type: integer
        id:
          type: integer
          description: Unique identifier of the segment
        text:
          type: string
          description: Text content of the segment
        seek:
          type: integer
          description: Seek offset of the segment
        compression_ratio:
          type: number
          description: "Compression ratio of the segment. If the value is greater\
            \ than 2.4, consider the compression failed"
          format: float
          x-ballerina-name: compressionRatio
    CreateImageRequest:
      required:
      - prompt
      type: object
      properties:
        response_format:
          type: string
          description: The format in which generated images with `dall-e-2` and `dall-e-3`
            are returned. Must be one of `url` or `b64_json`. URLs are only valid
            for 60 minutes after the image has been generated. This parameter isn't
            supported for `gpt-image-1` which will always return base64-encoded images
          nullable: true
          example: url
          default: url
          enum:
          - url
          - b64_json
          x-ballerina-name: responseFormat
        output_format:
          type: string
          description: "The format in which the generated images are returned. This\
            \ parameter is only supported for `gpt-image-1`. Must be one of `png`,\
            \ `jpeg`, or `webp`"
          nullable: true
          example: png
          default: png
          enum:
          - png
          - jpeg
          - webp
          x-ballerina-name: outputFormat
        size:
          type: string
          description: "The size of the generated images. Must be one of `1024x1024`,\
            \ `1536x1024` (landscape), `1024x1536` (portrait), or `auto` (default\
            \ value) for `gpt-image-1`, one of `256x256`, `512x512`, or `1024x1024`\
            \ for `dall-e-2`, and one of `1024x1024`, `1792x1024`, or `1024x1792`\
            \ for `dall-e-3`"
          nullable: true
          example: 1024x1024
          default: auto
          enum:
          - auto
          - 1024x1024
          - 1536x1024
          - 1024x1536
          - 256x256
          - 512x512
          - 1792x1024
          - 1024x1792
        output_compression:
          type: integer
          description: "The compression level (0-100%) for the generated images. This\
            \ parameter is only supported for `gpt-image-1` with the `webp` or `jpeg`\
            \ output formats, and defaults to 100"
          nullable: true
          example: 100
          default: 100
          x-ballerina-name: outputCompression
        background:
          type: string
          description: "Allows to set transparency for the background of the generated\
            \ image(s). \nThis parameter is only supported for `gpt-image-1`. Must\
            \ be one of \n`transparent`, `opaque` or `auto` (default value). When\
            \ `auto` is used, the \nmodel will automatically determine the best background\
            \ for the image.\n\nIf `transparent`, the output format needs to support\
            \ transparency, so it \nshould be set to either `png` (default value)\
            \ or `webp`\n"
          nullable: true
          example: transparent
          default: auto
          enum:
          - transparent
          - opaque
          - auto
        moderation:
          type: string
          description: Control the content-moderation level for images generated by
            `gpt-image-1`. Must be either `low` for less restrictive filtering or
            `auto` (default value)
          nullable: true
          example: low
          default: auto
          enum:
          - low
          - auto
        model:
          description: "The model to use for image generation. One of `dall-e-2`,\
            \ `dall-e-3`, or `gpt-image-1`. Defaults to `dall-e-2` unless a parameter\
            \ specific to `gpt-image-1` is used"
          nullable: true
          example: gpt-image-1
          anyOf:
          - type: string
          - type: string
            enum:
            - dall-e-2
            - dall-e-3
            - gpt-image-1
          default: dall-e-2
          x-oaiTypeLabel: string
        style:
          type: string
          description: "The style of the generated images. This parameter is only\
            \ supported for `dall-e-3`. Must be one of `vivid` or `natural`. Vivid\
            \ causes the model to lean towards generating hyper-real and dramatic\
            \ images. Natural causes the model to produce more natural, less hyper-real\
            \ looking images"
          nullable: true
          example: vivid
          default: vivid
          enum:
          - vivid
          - natural
        prompt:
          type: string
          description: "A text description of the desired image(s). The maximum length\
            \ is 32000 characters for `gpt-image-1`, 1000 characters for `dall-e-2`\
            \ and 4000 characters for `dall-e-3`"
          example: A cute baby sea otter
        user:
          type: string
          description: |
            A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids)
          example: user-1234
        "n":
          maximum: 10
          minimum: 1
          type: integer
          description: "The number of images to generate. Must be between 1 and 10.\
            \ For `dall-e-3`, only `n=1` is supported"
          nullable: true
          example: 1
          default: 1
        quality:
          type: string
          description: "The quality of the image that will be generated. \n\n- `auto`\
            \ (default value) will automatically select the best quality for the given\
            \ model.\n- `high`, `medium` and `low` are supported for `gpt-image-1`.\n\
            - `hd` and `standard` are supported for `dall-e-3`.\n- `standard` is the\
            \ only option for `dall-e-2`\n"
          nullable: true
          example: medium
          default: auto
          enum:
          - standard
          - hd
          - low
          - medium
          - high
          - auto
    AdminApiKey:
      required:
      - created_at
      - id
      - last_used_at
      - name
      - object
      - owner
      - redacted_value
      type: object
      properties:
        owner:
          $ref: '#/components/schemas/AdminApiKeyOwner'
        last_used_at:
          type: integer
          description: The Unix timestamp (in seconds) of when the API key was last
            used
          format: int64
          nullable: true
          example: 1711471534
          x-ballerina-name: lastUsedAt
        name:
          type: string
          description: The name of the API key
          example: Administration Key
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) of when the API key was created
          format: int64
          example: 1711471533
          x-ballerina-name: createdAt
        id:
          type: string
          description: "The identifier, which can be referenced in API endpoints"
          example: key_abc
        redacted_value:
          type: string
          description: The redacted value of the API key
          example: sk-admin...def
          x-ballerina-name: redactedValue
        value:
          type: string
          description: The value of the API key. Only shown on create
          example: sk-admin-1234abcd
        object:
          type: string
          description: "The object type, which is always `organization.admin_api_key`"
          example: organization.admin_api_key
          x-stainless-const: true
      description: Represents an individual Admin API key in an org
      x-oaiMeta:
        name: The admin API key object
        example: |
          {
            "object": "organization.admin_api_key",
            "id": "key_abc",
            "name": "Main Admin Key",
            "redacted_value": "sk-admin...xyz",
            "created_at": 1711471533,
            "last_used_at": 1711471534,
            "owner": {
              "type": "user",
              "object": "organization.user",
              "id": "user_123",
              "name": "John Doe",
              "created_at": 1711471533,
              "role": "owner"
            }
          }
    CompoundFilterFilters:
      oneOf:
      - $ref: '#/components/schemas/ComparisonFilter'
    Click:
      title: Click
      required:
      - button
      - type
      - x
      - "y"
      type: object
      properties:
        button:
          type: string
          description: |
            Indicates which mouse button was pressed during the click. One of `left`, `right`, `wheel`, `back`, or `forward`
          enum:
          - left
          - right
          - wheel
          - back
          - forward
        x:
          type: integer
          description: |
            The x-coordinate where the click occurred
        "y":
          type: integer
          description: |
            The y-coordinate where the click occurred
        type:
          type: string
          description: "Specifies the event type. For a click action, this property\
            \ is \nalways set to `click`\n"
          default: click
          enum:
          - click
          x-stainless-const: true
      description: |
        A click action
    FineTuningCheckpointPermission:
      title: FineTuningCheckpointPermission
      required:
      - created_at
      - id
      - object
      - project_id
      type: object
      properties:
        project_id:
          type: string
          description: The project identifier that the permission is for
          x-ballerina-name: projectId
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the permission was
            created
          x-ballerina-name: createdAt
        id:
          type: string
          description: "The permission identifier, which can be referenced in the\
            \ API endpoints"
        object:
          type: string
          description: "The object type, which is always \"checkpoint.permission\""
          enum:
          - checkpoint.permission
          x-stainless-const: true
      description: |
        The `checkpoint.permission` object represents a permission for a fine-tuned model checkpoint
      x-oaiMeta:
        name: The fine-tuned model checkpoint permission object
        example: |
          {
            "object": "checkpoint.permission",
            "id": "cp_zc4Q7MP6XxulcVzj4MZdwsAB",
            "created_at": 1712211699,
            "project_id": "proj_abGMw1llN8IrBb6SvvY5A1iH"
          }
    ItemResource:
      description: |
        Content item used to generate a response
      discriminator:
        propertyName: type
      oneOf:
      - $ref: '#/components/schemas/InputMessageResource'
      - $ref: '#/components/schemas/OutputMessage'
      - $ref: '#/components/schemas/FileSearchToolCall'
      - $ref: '#/components/schemas/ComputerToolCall'
      - $ref: '#/components/schemas/ComputerToolCallOutputResource'
      - $ref: '#/components/schemas/WebSearchToolCall'
      - $ref: '#/components/schemas/FunctionToolCallResource'
      - $ref: '#/components/schemas/FunctionToolCallOutputResource'
    ChatCompletionToolChoiceOptionOneOf1:
      type: string
      description: |
        `none` means the model will not call any tool and instead generates a message. `auto` means the model can pick between generating a message or calling one or more tools. `required` means the model must call one or more tools
      enum:
      - none
      - auto
      - required
    UsageImagesResult:
      required:
      - images
      - num_model_requests
      - object
      type: object
      properties:
        images:
          type: integer
          description: The number of images processed
        num_model_requests:
          type: integer
          description: The count of requests made to the model
          x-ballerina-name: numModelRequests
        size:
          type: string
          description: "When `group_by=size`, this field provides the image size of\
            \ the grouped usage result"
          nullable: true
        project_id:
          type: string
          description: "When `group_by=project_id`, this field provides the project\
            \ ID of the grouped usage result"
          nullable: true
          x-ballerina-name: projectId
        user_id:
          type: string
          description: "When `group_by=user_id`, this field provides the user ID of\
            \ the grouped usage result"
          nullable: true
          x-ballerina-name: userId
        model:
          type: string
          description: "When `group_by=model`, this field provides the model name\
            \ of the grouped usage result"
          nullable: true
        source:
          type: string
          description: "When `group_by=source`, this field provides the source of\
            \ the grouped usage result, possible values are `image.generation`, `image.edit`,\
            \ `image.variation`"
          nullable: true
        api_key_id:
          type: string
          description: "When `group_by=api_key_id`, this field provides the API key\
            \ ID of the grouped usage result"
          nullable: true
          x-ballerina-name: apiKeyId
        object:
          type: string
          enum:
          - organization.usage.images.result
          x-stainless-const: true
      description: The aggregated images usage details of the specific time bucket
      x-oaiMeta:
        name: Images usage object
        example: |
          {
              "object": "organization.usage.images.result",
              "images": 2,
              "num_model_requests": 2,
              "size": "1024x1024",
              "source": "image.generation",
              "project_id": "proj_abc",
              "user_id": "user-abc",
              "api_key_id": "key_abc",
              "model": "dall-e-3"
          }
    RealtimeServerEventConversationItemInputAudioTranscriptionCompleted:
      required:
      - content_index
      - event_id
      - item_id
      - transcript
      - type
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event
          x-ballerina-name: eventId
        transcript:
          type: string
          description: The transcribed text
        item_id:
          type: string
          description: The ID of the user message item containing the audio
          x-ballerina-name: itemId
        content_index:
          type: integer
          description: The index of the content part containing the audio
          x-ballerina-name: contentIndex
        type:
          type: string
          description: |
            The event type, must be
            `conversation.item.input_audio_transcription.completed`
          enum:
          - conversation.item.input_audio_transcription.completed
          x-stainless-const: true
        logprobs:
          type: array
          description: The log probabilities of the transcription
          nullable: true
          items:
            $ref: '#/components/schemas/LogProbProperties'
      description: "This event is the output of audio transcription for user audio\
        \ written to the \nuser audio buffer. Transcription begins when the input\
        \ audio buffer is \ncommitted by the client or server (in `server_vad` mode).\
        \ Transcription runs \nasynchronously with Response creation, so this event\
        \ may come before or after \nthe Response events.\n\nRealtime API models accept\
        \ audio natively, and thus input transcription is a \nseparate process run\
        \ on a separate ASR (Automatic Speech Recognition) model, \ncurrently always\
        \ `whisper-1`. Thus the transcript may diverge somewhat from \nthe model's\
        \ interpretation, and should be treated as a rough guide\n"
      x-oaiMeta:
        name: conversation.item.input_audio_transcription.completed
        group: realtime
        example: |
          {
              "event_id": "event_2122",
              "type": "conversation.item.input_audio_transcription.completed",
              "item_id": "msg_003",
              "content_index": 0,
              "transcript": "Hello, how are you?"
          }
    ModifyThreadRequestToolResourcesFileSearch:
      type: object
      properties:
        vector_store_ids:
          maxItems: 1
          type: array
          description: |
            The [vector store](/docs/api-reference/vector-stores/object) attached to this thread. There can be a maximum of 1 vector store attached to the thread
          items:
            type: string
          x-ballerina-name: vectorStoreIds
    AuditLogServiceAccountupdatedChangesRequested:
      type: object
      properties:
        role:
          type: string
          description: The role of the service account. Is either `owner` or `member`
      description: The payload used to updated the service account
    MessageStreamEventMessageStreamEventOneOf12:
      required:
      - data
      - event
      type: object
      properties:
        data:
          $ref: '#/components/schemas/MessageObject'
        event:
          type: string
          enum:
          - thread.message.in_progress
          x-stainless-const: true
      description: "Occurs when a [message](/docs/api-reference/messages/object) moves\
        \ to an `in_progress` state"
      x-oaiMeta:
        dataDescription: "`data` is a [message](/docs/api-reference/messages/object)"
    ResponseInProgressEvent:
      required:
      - response
      - type
      type: object
      properties:
        response:
          $ref: '#/components/schemas/Response'
        type:
          type: string
          description: |
            The type of the event. Always `response.in_progress`
          enum:
          - response.in_progress
          x-stainless-const: true
      description: Emitted when the response is in progress
      x-oaiMeta:
        name: response.in_progress
        group: responses
        example: |
          {
            "type": "response.in_progress",
            "response": {
              "id": "resp_67ccfcdd16748190a91872c75d38539e09e4d4aac714747c",
              "object": "response",
              "created_at": 1741487325,
              "status": "in_progress",
              "error": null,
              "incomplete_details": null,
              "instructions": null,
              "max_output_tokens": null,
              "model": "gpt-4o-2024-08-06",
              "output": [],
              "parallel_tool_calls": true,
              "previous_response_id": null,
              "reasoning": {
                "effort": null,
                "summary": null
              },
              "store": true,
              "temperature": 1,
              "text": {
                "format": {
                  "type": "text"
                }
              },
              "tool_choice": "auto",
              "tools": [],
              "top_p": 1,
              "truncation": "disabled",
              "usage": null,
              "user": null,
              "metadata": {}
            }
          }
    RunObjectIncompleteDetails:
      type: object
      properties:
        reason:
          type: string
          description: The reason why the run is incomplete. This will point to which
            specific token limit was reached over the course of the run
          enum:
          - max_completion_tokens
          - max_prompt_tokens
      description: Details on why the run is incomplete. Will be `null` if the run
        is not incomplete
      nullable: true
    RunStepStreamEventOneOf1:
      required:
      - data
      - event
      type: object
      properties:
        data:
          $ref: '#/components/schemas/RunStepObject'
        event:
          type: string
          enum:
          - thread.run.step.created
          x-stainless-const: true
      description: "Occurs when a [run step](/docs/api-reference/run-steps/step-object)\
        \ is created"
      x-oaiMeta:
        dataDescription: "`data` is a [run step](/docs/api-reference/run-steps/step-object)"
    ResponseCodeInterpreterCallCodeDoneEvent:
      required:
      - code
      - output_index
      - response_id
      - type
      type: object
      properties:
        code:
          type: string
          description: |
            The final code snippet output by the code interpreter
        type:
          type: string
          description: |
            The type of the event. Always `response.code_interpreter_call.code.done`
          enum:
          - response.code_interpreter_call.code.done
          x-stainless-const: true
        output_index:
          type: integer
          description: |
            The index of the output item that the code interpreter call is in progress
          x-ballerina-name: outputIndex
      description: Emitted when code snippet output is finalized by the code interpreter
      x-oaiMeta:
        name: response.code_interpreter_call.code.done
        group: responses
        example: |
          {
            "type": "response.code_interpreter_call.code.done",
            "response_id": "resp-123",
            "output_index": 3,
            "code": "console.log('done');"
          }
    EasyInputMessage:
      title: Input message
      required:
      - content
      - role
      type: object
      properties:
        role:
          type: string
          description: |
            The role of the message input. One of `user`, `assistant`, `system`, or
            `developer`
          enum:
          - user
          - assistant
          - system
          - developer
        type:
          type: string
          description: |
            The type of the message input. Always `message`
          enum:
          - message
          x-stainless-const: true
        content:
          description: |
            Text, image, or audio input to the model, used to generate a response.
            Can also contain previous assistant responses
          oneOf:
          - title: Text input
            type: string
            description: |
              A text input to the model.
          - $ref: '#/components/schemas/InputMessageContentList'
      description: |
        A message input to the model with a role indicating instruction following
        hierarchy. Instructions given with the `developer` or `system` role take
        precedence over instructions given with the `user` role. Messages with the
        `assistant` role are presumed to have been generated by the model in previous
        interactions
    VectorStoreSearchResultContentObject:
      required:
      - text
      - type
      type: object
      properties:
        text:
          type: string
          description: The text content returned from search
        type:
          type: string
          description: The type of content
          enum:
          - text
      additionalProperties: false
      x-oaiMeta:
        name: Vector store search result content object
    BatchErrorsData:
      type: object
      properties:
        code:
          type: string
          description: An error code identifying the error type
        param:
          type: string
          description: "The name of the parameter that caused the error, if applicable"
          nullable: true
        line:
          type: integer
          description: "The line number of the input file where the error occurred,\
            \ if applicable"
          nullable: true
        message:
          type: string
          description: A human-readable message providing more details about the error
    CreateChatCompletionRequestAudio:
      required:
      - format
      - voice
      type: object
      properties:
        voice:
          $ref: '#/components/schemas/VoiceIdsShared'
        format:
          type: string
          description: |
            Specifies the output audio format. Must be one of `wav`, `mp3`, `flac`,
            `opus`, or `pcm16`
          enum:
          - wav
          - aac
          - mp3
          - flac
          - opus
          - pcm16
      description: |
        Parameters for audio output. Required when audio output is requested with
        `modalities: ["audio"]`. [Learn more](/docs/guides/audio)
      nullable: true
    StopConfigurationOneOf1:
      type: string
      nullable: true
      example: |2+

      default: <|endoftext|>
    ComputerCallOutputItemParam:
      title: Computer tool call output
      required:
      - call_id
      - output
      - type
      type: object
      properties:
        output:
          $ref: '#/components/schemas/ComputerScreenshotImage'
        acknowledged_safety_checks:
          anyOf:
          - type: array
            description: The safety checks reported by the API that have been acknowledged
              by the developer.
            items:
              $ref: '#/components/schemas/ComputerCallSafetyCheckParam'
          - nullable: true
          x-ballerina-name: acknowledgedSafetyChecks
        id:
          anyOf:
          - type: string
            description: The ID of the computer tool call output.
          - nullable: true
        type:
          type: string
          description: The type of the computer tool call output. Always `computer_call_output`
          default: computer_call_output
          enum:
          - computer_call_output
          x-stainless-const: true
        call_id:
          maxLength: 64
          minLength: 1
          type: string
          description: The ID of the computer tool call that produced the output
          x-ballerina-name: callId
        status:
          anyOf:
          - type: string
            description: "The status of the message input. One of `in_progress`, `completed`,\
              \ or `incomplete`. Populated when input items are returned via API."
            enum:
            - in_progress
            - completed
            - incomplete
          - nullable: true
      description: The output of a computer tool call
    BatchRequestOutputError:
      type: object
      properties:
        code:
          type: string
          description: A machine-readable error code
        message:
          type: string
          description: A human-readable error message
      description: "For requests that failed with a non-HTTP error, this will contain\
        \ more information on the cause of the failure"
      nullable: true
    CreateThreadRequestToolResources:
      type: object
      properties:
        code_interpreter:
          allOf:
          - $ref: '#/components/schemas/CreateAssistantRequestToolResourcesCodeInterpreter'
          x-ballerina-name: codeInterpreter
        file_search:
          allOf:
          - $ref: '#/components/schemas/CreateThreadRequestToolResourcesFileSearch'
          x-ballerina-name: fileSearch
      description: |
        A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs
      nullable: true
    ResponseFunctionCallArgumentsDeltaEvent:
      required:
      - delta
      - item_id
      - output_index
      - type
      type: object
      properties:
        item_id:
          type: string
          description: |
            The ID of the output item that the function-call arguments delta is added to
          x-ballerina-name: itemId
        delta:
          type: string
          description: |
            The function-call arguments delta that is added
        type:
          type: string
          description: |
            The type of the event. Always `response.function_call_arguments.delta`
          enum:
          - response.function_call_arguments.delta
          x-stainless-const: true
        output_index:
          type: integer
          description: |
            The index of the output item that the function-call arguments delta is added to
          x-ballerina-name: outputIndex
      description: Emitted when there is a partial function-call arguments delta
      x-oaiMeta:
        name: response.function_call_arguments.delta
        group: responses
        example: |
          {
            "type": "response.function_call_arguments.delta",
            "item_id": "item-abc",
            "output_index": 0,
            "delta": "{ \"arg\":"
          }
    RunObject:
      title: A run on a thread
      required:
      - assistant_id
      - cancelled_at
      - completed_at
      - created_at
      - expires_at
      - failed_at
      - id
      - incomplete_details
      - instructions
      - last_error
      - max_completion_tokens
      - max_prompt_tokens
      - metadata
      - model
      - object
      - parallel_tool_calls
      - required_action
      - response_format
      - started_at
      - status
      - thread_id
      - tool_choice
      - tools
      - truncation_strategy
      - usage
      type: object
      properties:
        cancelled_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the run was cancelled
          nullable: true
          x-ballerina-name: cancelledAt
        instructions:
          type: string
          description: "The instructions that the [assistant](/docs/api-reference/assistants)\
            \ used for this run"
        metadata:
          $ref: '#/components/schemas/Metadata'
        assistant_id:
          type: string
          description: "The ID of the [assistant](/docs/api-reference/assistants)\
            \ used for execution of this run"
          x-ballerina-name: assistantId
        required_action:
          allOf:
          - $ref: '#/components/schemas/RunObjectRequiredAction'
          x-ballerina-name: requiredAction
        usage:
          $ref: '#/components/schemas/RunCompletionUsage'
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the run was created
          x-ballerina-name: createdAt
        tools:
          maxItems: 20
          type: array
          description: "The list of tools that the [assistant](/docs/api-reference/assistants)\
            \ used for this run"
          items:
            $ref: '#/components/schemas/AssistantObjectTools'
          default: []
        top_p:
          type: number
          description: "The nucleus sampling value used for this run. If not set,\
            \ defaults to 1"
          nullable: true
          x-ballerina-name: topP
        max_completion_tokens:
          minimum: 256
          type: integer
          description: |
            The maximum number of completion tokens specified to have been used over the course of the run
          nullable: true
          x-ballerina-name: maxCompletionTokens
        thread_id:
          type: string
          description: "The ID of the [thread](/docs/api-reference/threads) that was\
            \ executed on as a part of this run"
          x-ballerina-name: threadId
        expires_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the run will expire
          nullable: true
          x-ballerina-name: expiresAt
        response_format:
          allOf:
          - $ref: '#/components/schemas/AssistantsApiResponseFormatOption'
          x-ballerina-name: responseFormat
        temperature:
          type: number
          description: "The sampling temperature used for this run. If not set, defaults\
            \ to 1"
          nullable: true
        tool_choice:
          allOf:
          - $ref: '#/components/schemas/AssistantsApiToolChoiceOption'
          - nullable: true
          x-ballerina-name: toolChoice
        model:
          type: string
          description: "The model that the [assistant](/docs/api-reference/assistants)\
            \ used for this run"
        id:
          type: string
          description: "The identifier, which can be referenced in API endpoints"
        last_error:
          allOf:
          - $ref: '#/components/schemas/RunObjectLastError'
          x-ballerina-name: lastError
        incomplete_details:
          allOf:
          - $ref: '#/components/schemas/RunObjectIncompleteDetails'
          x-ballerina-name: incompleteDetails
        truncation_strategy:
          allOf:
          - $ref: '#/components/schemas/TruncationObject'
          - nullable: true
          x-ballerina-name: truncationStrategy
        completed_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the run was completed
          nullable: true
          x-ballerina-name: completedAt
        parallel_tool_calls:
          allOf:
          - $ref: '#/components/schemas/ParallelToolCalls'
          x-ballerina-name: parallelToolCalls
        started_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the run was started
          nullable: true
          x-ballerina-name: startedAt
        failed_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the run failed
          nullable: true
          x-ballerina-name: failedAt
        max_prompt_tokens:
          minimum: 256
          type: integer
          description: |
            The maximum number of prompt tokens specified to have been used over the course of the run
          nullable: true
          x-ballerina-name: maxPromptTokens
        object:
          type: string
          description: "The object type, which is always `thread.run`"
          enum:
          - thread.run
          x-stainless-const: true
        status:
          type: string
          description: "The status of the run, which can be either `queued`, `in_progress`,\
            \ `requires_action`, `cancelling`, `cancelled`, `failed`, `completed`,\
            \ `incomplete`, or `expired`"
          enum:
          - queued
          - in_progress
          - requires_action
          - cancelling
          - cancelled
          - failed
          - completed
          - incomplete
          - expired
      description: "Represents an execution run on a [thread](/docs/api-reference/threads)"
      x-oaiMeta:
        name: The run object
        beta: true
        example: |
          {
            "id": "run_abc123",
            "object": "thread.run",
            "created_at": 1698107661,
            "assistant_id": "asst_abc123",
            "thread_id": "thread_abc123",
            "status": "completed",
            "started_at": 1699073476,
            "expires_at": null,
            "cancelled_at": null,
            "failed_at": null,
            "completed_at": 1699073498,
            "last_error": null,
            "model": "gpt-4o",
            "instructions": null,
            "tools": [{"type": "file_search"}, {"type": "code_interpreter"}],
            "metadata": {},
            "incomplete_details": null,
            "usage": {
              "prompt_tokens": 123,
              "completion_tokens": 456,
              "total_tokens": 579
            },
            "temperature": 1.0,
            "top_p": 1.0,
            "max_prompt_tokens": 1000,
            "max_completion_tokens": 1000,
            "truncation_strategy": {
              "type": "auto",
              "last_messages": null
            },
            "response_format": "auto",
            "tool_choice": "auto",
            "parallel_tool_calls": true
          }
    RealtimeServerEventResponseAudioDelta:
      required:
      - content_index
      - delta
      - event_id
      - item_id
      - output_index
      - response_id
      - type
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event
          x-ballerina-name: eventId
        item_id:
          type: string
          description: The ID of the item
          x-ballerina-name: itemId
        content_index:
          type: integer
          description: The index of the content part in the item's content array
          x-ballerina-name: contentIndex
        response_id:
          type: string
          description: The ID of the response
          x-ballerina-name: responseId
        delta:
          type: string
          description: Base64-encoded audio data delta
        type:
          type: string
          description: "The event type, must be `response.audio.delta`"
          enum:
          - response.audio.delta
          x-stainless-const: true
        output_index:
          type: integer
          description: The index of the output item in the response
          x-ballerina-name: outputIndex
      description: Returned when the model-generated audio is updated
      x-oaiMeta:
        name: response.audio.delta
        group: realtime
        example: |
          {
              "event_id": "event_4950",
              "type": "response.audio.delta",
              "response_id": "resp_001",
              "item_id": "msg_008",
              "output_index": 0,
              "content_index": 0,
              "delta": "Base64EncodedAudioDelta"
          }
    RunStepDetailsToolCallsFileSearchResultObject:
      title: File search tool call result
      required:
      - file_id
      - file_name
      - score
      type: object
      properties:
        score:
          maximum: 1
          minimum: 0
          type: number
          description: The score of the result. All values must be a floating point
            number between 0 and 1
        file_name:
          type: string
          description: The name of the file that result was found in
          x-ballerina-name: fileName
        file_id:
          type: string
          description: The ID of the file that result was found in
          x-ballerina-name: fileId
        content:
          type: array
          description: The content of the result that was found. The content is only
            included if requested via the include query parameter
          items:
            $ref: '#/components/schemas/RunStepDetailsToolCallsFileSearchResultObjectContent'
      description: A result instance of the file search
      x-oaiTypeLabel: map
    MessageDeltaContentRefusalObject:
      title: Refusal
      required:
      - index
      - type
      type: object
      properties:
        refusal:
          type: string
        index:
          type: integer
          description: The index of the refusal part in the message
        type:
          type: string
          description: Always `refusal`
          enum:
          - refusal
          x-stainless-const: true
      description: The refusal content that is part of a message
    AssistantMessage:
      title: Assistant message
      type: object
      properties:
        weight:
          type: integer
          description: Controls whether the assistant message is trained against (0
            or 1)
          enum:
          - 0
          - 1
      deprecated: false
    EvalRunOutputItemSampleOutput:
      type: object
      properties:
        role:
          type: string
          description: "The role of the message (e.g. \"system\", \"assistant\", \"\
            user\")"
        content:
          type: string
          description: The content of the message
    ChatCompletionTool:
      required:
      - function
      - type
      type: object
      properties:
        function:
          $ref: '#/components/schemas/FunctionObject'
        type:
          type: string
          description: "The type of the tool. Currently, only `function` is supported"
          enum:
          - function
          x-stainless-const: true
    EvalResponsesSource:
      title: EvalResponsesSource
      required:
      - type
      type: object
      properties:
        reasoning_effort:
          allOf:
          - $ref: '#/components/schemas/ReasoningEffort'
          x-ballerina-name: reasoningEffort
        top_p:
          type: number
          description: Nucleus sampling parameter. This is a query parameter used
            to select responses
          nullable: true
          x-ballerina-name: topP
        metadata:
          type: object
          description: Metadata filter for the responses. This is a query parameter
            used to select responses
          nullable: true
        created_after:
          minimum: 0
          type: integer
          description: Only include items created after this timestamp (inclusive).
            This is a query parameter used to select responses
          nullable: true
          x-ballerina-name: createdAfter
        created_before:
          minimum: 0
          type: integer
          description: Only include items created before this timestamp (inclusive).
            This is a query parameter used to select responses
          nullable: true
          x-ballerina-name: createdBefore
        instructions_search:
          type: string
          description: Optional search string for instructions. This is a query parameter
            used to select responses
          nullable: true
          x-ballerina-name: instructionsSearch
        temperature:
          type: number
          description: Sampling temperature. This is a query parameter used to select
            responses
          nullable: true
        allow_parallel_tool_calls:
          type: boolean
          description: Whether to allow parallel tool calls. This is a query parameter
            used to select responses
          nullable: true
          x-ballerina-name: allowParallelToolCalls
        model:
          type: string
          description: The name of the model to find responses for. This is a query
            parameter used to select responses
          nullable: true
        type:
          type: string
          description: The type of run data source. Always `responses`
          enum:
          - responses
        has_tool_calls:
          type: boolean
          description: Whether the response has tool calls. This is a query parameter
            used to select responses
          nullable: true
          x-ballerina-name: hasToolCalls
        users:
          type: array
          description: List of user identifiers. This is a query parameter used to
            select responses
          nullable: true
          items:
            type: string
      description: |
        A EvalResponsesSource object describing a run data source configuration
      x-oaiMeta:
        name: The run data source object used to configure an individual run
        group: eval runs
        example: |
          {
            "type": "responses",
            "model": "gpt-4o-mini-2024-07-18",
            "temperature": 0.7,
            "top_p": 1.0,
            "users": ["user1", "user2"],
            "allow_parallel_tool_calls": true
          }
    ResponseAudioDeltaEvent:
      required:
      - delta
      - type
      type: object
      properties:
        delta:
          type: string
          description: |
            A chunk of Base64 encoded response audio bytes
        type:
          type: string
          description: |
            The type of the event. Always `response.audio.delta`
          enum:
          - response.audio.delta
          x-stainless-const: true
      description: Emitted when there is a partial audio response
      x-oaiMeta:
        name: response.audio.delta
        group: responses
        example: |
          {
            "type": "response.audio.delta",
            "response_id": "resp_123",
            "delta": "base64encoded..."
          }
    ResponseRefusalDoneEvent:
      required:
      - content_index
      - item_id
      - output_index
      - refusal
      - type
      type: object
      properties:
        item_id:
          type: string
          description: |
            The ID of the output item that the refusal text is finalized
          x-ballerina-name: itemId
        content_index:
          type: integer
          description: |
            The index of the content part that the refusal text is finalized
          x-ballerina-name: contentIndex
        refusal:
          type: string
          description: |
            The refusal text that is finalized
        type:
          type: string
          description: |
            The type of the event. Always `response.refusal.done`
          enum:
          - response.refusal.done
          x-stainless-const: true
        output_index:
          type: integer
          description: |
            The index of the output item that the refusal text is finalized
          x-ballerina-name: outputIndex
      description: Emitted when refusal text is finalized
      x-oaiMeta:
        name: response.refusal.done
        group: responses
        example: |
          {
            "type": "response.refusal.done",
            "item_id": "item-abc",
            "output_index": 1,
            "content_index": 2,
            "refusal": "final refusal text"
          }
    Includable:
      type: string
      description: |
        Specify additional output data to include in the model response. Currently
        supported values are:
        - `file_search_call.results`: Include the search results of
          the file search tool call.
        - `message.input_image.image_url`: Include image urls from the input message.
        - `computer_call_output.output.image_url`: Include image urls from the computer call output
      enum:
      - file_search_call.results
      - message.input_image.image_url
      - computer_call_output.output.image_url
    VectorStoreExpirationAfter:
      title: Vector store expiration policy
      required:
      - anchor
      - days
      type: object
      properties:
        anchor:
          type: string
          description: "Anchor timestamp after which the expiration policy applies.\
            \ Supported anchors: `last_active_at`"
          enum:
          - last_active_at
          x-stainless-const: true
        days:
          maximum: 365
          minimum: 1
          type: integer
          description: The number of days after the anchor time that the vector store
            will expire
      description: The expiration policy for a vector store
    RealtimeServerEventResponseAudioTranscriptDone:
      required:
      - content_index
      - event_id
      - item_id
      - output_index
      - response_id
      - transcript
      - type
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event
          x-ballerina-name: eventId
        transcript:
          type: string
          description: The final transcript of the audio
        item_id:
          type: string
          description: The ID of the item
          x-ballerina-name: itemId
        content_index:
          type: integer
          description: The index of the content part in the item's content array
          x-ballerina-name: contentIndex
        response_id:
          type: string
          description: The ID of the response
          x-ballerina-name: responseId
        type:
          type: string
          description: "The event type, must be `response.audio_transcript.done`"
          enum:
          - response.audio_transcript.done
          x-stainless-const: true
        output_index:
          type: integer
          description: The index of the output item in the response
          x-ballerina-name: outputIndex
      description: |
        Returned when the model-generated transcription of audio output is done
        streaming. Also emitted when a Response is interrupted, incomplete, or
        cancelled
      x-oaiMeta:
        name: response.audio_transcript.done
        group: realtime
        example: |
          {
              "event_id": "event_4748",
              "type": "response.audio_transcript.done",
              "response_id": "resp_001",
              "item_id": "msg_008",
              "output_index": 0,
              "content_index": 0,
              "transcript": "Hello, how can I assist you today?"
          }
    AuditLogProjectcreated:
      type: object
      properties:
        data:
          $ref: '#/components/schemas/AuditLogProjectcreatedData'
        id:
          type: string
          description: The project ID
      description: The details for events with this `type`
    AssistantsApiToolChoiceOption:
      description: |
        Controls which (if any) tool is called by the model.
        `none` means the model will not call any tools and instead generates a message.
        `auto` is the default value and means the model can pick between generating a message or calling one or more tools.
        `required` means the model must call one or more tools before responding to the user.
        Specifying a particular tool like `{"type": "file_search"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool
      oneOf:
      - $ref: '#/components/schemas/AssistantsApiToolChoiceOptionOneOf1'
      - $ref: '#/components/schemas/AssistantsNamedToolChoice'
    ChatCompletionStreamResponseDelta:
      type: object
      properties:
        role:
          type: string
          description: The role of the author of this message
          enum:
          - developer
          - system
          - user
          - assistant
          - tool
        function_call:
          allOf:
          - $ref: '#/components/schemas/ChatCompletionStreamResponseDeltaFunctionCall'
          x-ballerina-name: functionCall
        refusal:
          type: string
          description: The refusal message generated by the model
          nullable: true
        tool_calls:
          type: array
          items:
            $ref: '#/components/schemas/ChatCompletionMessageToolCallChunk'
          x-ballerina-name: toolCalls
        content:
          type: string
          description: The contents of the chunk message
          nullable: true
      description: A chat completion delta generated by streamed model responses
    AssistantSupportedModels:
      type: string
      enum:
      - gpt-4.1
      - gpt-4.1-mini
      - gpt-4.1-nano
      - gpt-4.1-2025-04-14
      - gpt-4.1-mini-2025-04-14
      - gpt-4.1-nano-2025-04-14
      - o3-mini
      - o3-mini-2025-01-31
      - o1
      - o1-2024-12-17
      - gpt-4o
      - gpt-4o-2024-11-20
      - gpt-4o-2024-08-06
      - gpt-4o-2024-05-13
      - gpt-4o-mini
      - gpt-4o-mini-2024-07-18
      - gpt-4.5-preview
      - gpt-4.5-preview-2025-02-27
      - gpt-4-turbo
      - gpt-4-turbo-2024-04-09
      - gpt-4-0125-preview
      - gpt-4-turbo-preview
      - gpt-4-1106-preview
      - gpt-4-vision-preview
      - gpt-4
      - gpt-4-0314
      - gpt-4-0613
      - gpt-4-32k
      - gpt-4-32k-0314
      - gpt-4-32k-0613
      - gpt-3.5-turbo
      - gpt-3.5-turbo-16k
      - gpt-3.5-turbo-0613
      - gpt-3.5-turbo-1106
      - gpt-3.5-turbo-0125
      - gpt-3.5-turbo-16k-0613
    RunStepDetailsToolCallsCodeOutputImageObject:
      title: Code Interpreter image output
      required:
      - image
      - type
      type: object
      properties:
        image:
          $ref: '#/components/schemas/RunStepDetailsToolCallsCodeOutputImageObjectImage'
        type:
          type: string
          description: Always `image`
          enum:
          - image
          x-stainless-const: true
    CreateTranscriptionResponseJsonLogprobs:
      type: object
      properties:
        logprob:
          type: number
          description: The log probability of the token
        bytes:
          type: array
          description: The bytes of the token
          items:
            type: number
        token:
          type: string
          description: The token in the transcription
    RunStepDeltaStepDetailsToolCallsCodeObjectCodeInterpreterOutputs:
      type: object
      oneOf:
      - $ref: '#/components/schemas/RunStepDeltaStepDetailsToolCallsCodeOutputLogsObject'
      - $ref: '#/components/schemas/RunStepDeltaStepDetailsToolCallsCodeOutputImageObject'
    Certificate:
      required:
      - certificate_details
      - created_at
      - id
      - name
      - object
      type: object
      properties:
        name:
          type: string
          description: The name of the certificate
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) of when the certificate was
            uploaded
          x-ballerina-name: createdAt
        active:
          type: boolean
          description: Whether the certificate is currently active at the specified
            scope. Not returned when getting details for a specific certificate
        id:
          type: string
          description: "The identifier, which can be referenced in API endpoints"
        certificate_details:
          allOf:
          - $ref: '#/components/schemas/CertificateCertificateDetails'
          x-ballerina-name: certificateDetails
        object:
          type: string
          description: |
            The object type.

            - If creating, updating, or getting a specific certificate, the object type is `certificate`.
            - If listing, activating, or deactivating certificates for the organization, the object type is `organization.certificate`.
            - If listing, activating, or deactivating certificates for a project, the object type is `organization.project.certificate`
          enum:
          - certificate
          - organization.certificate
          - organization.project.certificate
          x-stainless-const: true
      description: Represents an individual `certificate` uploaded to the organization
      x-oaiMeta:
        name: The certificate object
        example: |
          {
            "object": "certificate",
            "id": "cert_abc",
            "name": "My Certificate",
            "created_at": 1234567,
            "certificate_details": {
              "valid_at": 1234567,
              "expires_at": 12345678,
              "content": "-----BEGIN CERTIFICATE----- MIIGAjCCA...6znFlOW+ -----END CERTIFICATE-----"
            }
          }
    ResponseCodeInterpreterCallCodeDeltaEvent:
      required:
      - delta
      - output_index
      - response_id
      - type
      type: object
      properties:
        delta:
          type: string
          description: |
            The partial code snippet added by the code interpreter
        type:
          type: string
          description: |
            The type of the event. Always `response.code_interpreter_call.code.delta`
          enum:
          - response.code_interpreter_call.code.delta
          x-stainless-const: true
        output_index:
          type: integer
          description: |
            The index of the output item that the code interpreter call is in progress
          x-ballerina-name: outputIndex
      description: Emitted when a partial code snippet is added by the code interpreter
      x-oaiMeta:
        name: response.code_interpreter_call.code.delta
        group: responses
        example: |
          {
            "type": "response.code_interpreter_call.code.delta",
            "response_id": "resp-123",
            "output_index": 0,
            "delta": "partial code"
          }
    OpenAIFile:
      title: OpenAIFile
      required:
      - bytes
      - created_at
      - filename
      - id
      - object
      - purpose
      - status
      properties:
        id:
          type: string
          description: "The file identifier, which can be referenced in the API endpoints."
        bytes:
          type: integer
          description: "The size of the file, in bytes."
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the file was created.
        expires_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the file will expire.
        filename:
          type: string
          description: The name of the file.
        object:
          type: string
          description: "The object type, which is always `file`."
          enum:
          - file
          x-stainless-const: true
        purpose:
          type: string
          description: "The intended purpose of the file. Supported values are `assistants`,\
            \ `assistants_output`, `batch`, `batch_output`, `fine-tune`, `fine-tune-results`\
            \ and `vision`."
          enum:
          - assistants
          - assistants_output
          - batch
          - batch_output
          - fine-tune
          - fine-tune-results
          - vision
        status:
          type: string
          description: "Deprecated. The current status of the file, which can be either\
            \ `uploaded`, `processed`, or `error`."
          deprecated: true
          enum:
          - uploaded
          - processed
          - error
        status_details:
          type: string
          description: "Deprecated. For details on why a fine-tuning training file\
            \ failed validation, see the `error` field on `fine_tuning.job`."
          deprecated: true
      description: The `File` object represents a document that has been uploaded
        to OpenAI
      x-oaiMeta:
        name: The file object
        example: |
          {
            "id": "file-abc123",
            "object": "file",
            "bytes": 120000,
            "created_at": 1677610602,
            "expires_at": 1680202602,
            "filename": "salesOverview.pdf",
            "purpose": "assistants",
          }
    ResponseUsage:
      required:
      - input_tokens
      - input_tokens_details
      - output_tokens
      - output_tokens_details
      - total_tokens
      type: object
      properties:
        input_tokens_details:
          allOf:
          - $ref: '#/components/schemas/ResponseUsageInputTokensDetails'
          x-ballerina-name: inputTokensDetails
        total_tokens:
          type: integer
          description: The total number of tokens used
          x-ballerina-name: totalTokens
        output_tokens:
          type: integer
          description: The number of output tokens
          x-ballerina-name: outputTokens
        input_tokens:
          type: integer
          description: The number of input tokens
          x-ballerina-name: inputTokens
        output_tokens_details:
          allOf:
          - $ref: '#/components/schemas/ResponseUsageOutputTokensDetails'
          x-ballerina-name: outputTokensDetails
      description: |
        Represents token usage details including input tokens, output tokens,
        a breakdown of output tokens, and the total tokens used
    VectorStoreFileAttributes:
      maxProperties: 16
      type: object
      additionalProperties:
        oneOf:
        - maxLength: 512
          type: string
        - type: number
        - type: boolean
      description: "Set of 16 key-value pairs that can be attached to an object. This\
        \ can be \nuseful for storing additional information about the object in a\
        \ structured \nformat, and querying for objects via API or the dashboard.\
        \ Keys are strings \nwith a maximum length of 64 characters. Values are strings\
        \ with a maximum \nlength of 512 characters, booleans, or numbers\n"
      nullable: true
      x-oaiTypeLabel: map
    InputFileContent:
      title: Input file
      required:
      - type
      type: object
      properties:
        filename:
          type: string
          description: The name of the file to be sent to the model
        file_id:
          anyOf:
          - type: string
            description: The ID of the file to be sent to the model.
          - nullable: true
          x-ballerina-name: fileId
        type:
          type: string
          description: The type of the input item. Always `input_file`
          default: input_file
          enum:
          - input_file
          x-stainless-const: true
        file_data:
          type: string
          description: |
            The content of the file to be sent to the model
          x-ballerina-name: fileData
      description: A file input to the model
    AssistantStreamEvent:
      description: |
        Represents an event emitted when streaming a Run.

        Each event in a server-sent events stream has an `event` and `data` property:

        ```
        event: thread.created
        data: {"id": "thread_123", "object": "thread", ...}
        ```

        We emit events whenever a new object is created, transitions to a new state, or is being
        streamed in parts (deltas). For example, we emit `thread.run.created` when a new run
        is created, `thread.run.completed` when a run completes, and so on. When an Assistant chooses
        to create a message during a run, we emit a `thread.message.created event`, a
        `thread.message.in_progress` event, many `thread.message.delta` events, and finally a
        `thread.message.completed` event.

        We may add additional events over time, so we recommend handling unknown events gracefully
        in your code. See the [Assistants API quickstart](/docs/assistants/overview) to learn how to
        integrate the Assistants API with streaming
      oneOf:
      - $ref: '#/components/schemas/ThreadStreamEvent'
      - $ref: '#/components/schemas/RunStreamEvent'
      - $ref: '#/components/schemas/RunStepStreamEvent'
      - $ref: '#/components/schemas/MessageStreamEvent'
      - $ref: '#/components/schemas/ErrorEvent'
      - $ref: '#/components/schemas/DoneEvent'
      x-oaiMeta:
        name: Assistant stream events
        beta: true
    ApiKeyList:
      type: object
      properties:
        first_id:
          type: string
          example: key_abc
          x-ballerina-name: firstId
        data:
          type: array
          items:
            $ref: '#/components/schemas/AdminApiKey'
        last_id:
          type: string
          example: key_xyz
          x-ballerina-name: lastId
        has_more:
          type: boolean
          example: false
          x-ballerina-name: hasMore
        object:
          type: string
          example: list
    StopConfigurationStopConfigurationOneOf12:
      maxItems: 4
      minItems: 1
      type: array
      items:
        type: string
        example: "[\"\\n\"]"
    RealtimeSessionCreateResponseTurnDetection:
      type: object
      properties:
        silence_duration_ms:
          type: integer
          description: "Duration of silence to detect speech stop (in milliseconds).\
            \ Defaults \nto 500ms. With shorter values the model will respond more\
            \ quickly, \nbut may jump in on short pauses from the user\n"
          x-ballerina-name: silenceDurationMs
        prefix_padding_ms:
          type: integer
          description: "Amount of audio to include before the VAD detected speech\
            \ (in \nmilliseconds). Defaults to 300ms\n"
          x-ballerina-name: prefixPaddingMs
        threshold:
          type: number
          description: "Activation threshold for VAD (0.0 to 1.0), this defaults to\
            \ 0.5. A \nhigher threshold will require louder audio to activate the\
            \ model, and \nthus might perform better in noisy environments\n"
        type:
          type: string
          description: |
            Type of turn detection, only `server_vad` is currently supported
      description: "Configuration for turn detection. Can be set to `null` to turn\
        \ off. Server \nVAD means that the model will detect the start and end of\
        \ speech based on \naudio volume and respond at the end of user speech\n"
    ListVectorStoreFilesResponse:
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
      properties:
        object:
          type: string
          example: list
        data:
          type: array
          items:
            $ref: '#/components/schemas/VectorStoreFileObject'
        first_id:
          type: string
          example: file-abc123
        last_id:
          type: string
          example: file-abc456
        has_more:
          type: boolean
          example: false
    RunStepDetailsToolCallsCodeOutputImageObjectImage:
      required:
      - file_id
      type: object
      properties:
        file_id:
          type: string
          description: "The [file](/docs/api-reference/files) ID of the image"
          x-ballerina-name: fileId
    AuditLogInvitesent:
      type: object
      properties:
        data:
          $ref: '#/components/schemas/AuditLogInvitesentData'
        id:
          type: string
          description: The ID of the invite
      description: The details for events with this `type`
    StaticChunkingStrategy:
      required:
      - chunk_overlap_tokens
      - max_chunk_size_tokens
      type: object
      properties:
        max_chunk_size_tokens:
          maximum: 4096
          minimum: 100
          type: integer
          description: The maximum number of tokens in each chunk. The default value
            is `800`. The minimum value is `100` and the maximum value is `4096`
          x-ballerina-name: maxChunkSizeTokens
        chunk_overlap_tokens:
          type: integer
          description: |
            The number of tokens that overlap between chunks. The default value is `400`.

            Note that the overlap must not exceed half of `max_chunk_size_tokens`
          x-ballerina-name: chunkOverlapTokens
      additionalProperties: false
    VectorStoreFileContentResponseData:
      type: object
      properties:
        text:
          type: string
          description: The text content
        type:
          type: string
          description: The content type (currently only `"text"`)
    RealtimeServerEventRateLimitsUpdatedRateLimits:
      type: object
      properties:
        name:
          type: string
          description: |
            The name of the rate limit (`requests`, `tokens`)
          enum:
          - requests
          - tokens
        limit:
          type: integer
          description: The maximum allowed value for the rate limit
        reset_seconds:
          type: number
          description: Seconds until the rate limit resets
          x-ballerina-name: resetSeconds
        remaining:
          type: integer
          description: The remaining value before the limit is reached
    CreateEvalRequestTestingCriteria:
      oneOf:
      - $ref: '#/components/schemas/CreateEvalLabelModelGrader'
      - $ref: '#/components/schemas/EvalStringCheckGrader'
      - $ref: '#/components/schemas/EvalTextSimilarityGrader'
      - $ref: '#/components/schemas/EvalPythonGrader'
      - $ref: '#/components/schemas/EvalScoreModelGrader'
    MessageContentImageFileObject:
      title: Image file
      required:
      - image_file
      - type
      type: object
      properties:
        image_file:
          allOf:
          - $ref: '#/components/schemas/MessageContentImageFileObjectImageFile'
          x-ballerina-name: imageFile
        type:
          type: string
          description: Always `image_file`
          enum:
          - image_file
          x-stainless-const: true
      description: "References an image [File](/docs/api-reference/files) in the content\
        \ of a message"
    RealtimeServerEventInputAudioBufferSpeechStopped:
      required:
      - audio_end_ms
      - event_id
      - item_id
      - type
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event
          x-ballerina-name: eventId
        item_id:
          type: string
          description: The ID of the user message item that will be created
          x-ballerina-name: itemId
        type:
          type: string
          description: "The event type, must be `input_audio_buffer.speech_stopped`"
          enum:
          - input_audio_buffer.speech_stopped
          x-stainless-const: true
        audio_end_ms:
          type: integer
          description: "Milliseconds since the session started when speech stopped.\
            \ This will \ncorrespond to the end of audio sent to the model, and thus\
            \ includes the \n`min_silence_duration_ms` configured in the Session\n"
          x-ballerina-name: audioEndMs
      description: "Returned in `server_vad` mode when the server detects the end\
        \ of speech in \nthe audio buffer. The server will also send an `conversation.item.created`\
        \ \nevent with the user message item that is created from the audio buffer\n"
      x-oaiMeta:
        name: input_audio_buffer.speech_stopped
        group: realtime
        example: |
          {
              "event_id": "event_1718",
              "type": "input_audio_buffer.speech_stopped",
              "audio_end_ms": 2000,
              "item_id": "msg_003"
          }
    RealtimeServerEventConversationCreatedConversation:
      type: object
      properties:
        id:
          type: string
          description: The unique ID of the conversation
        object:
          type: string
          description: "The object type, must be `realtime.conversation`"
      description: The conversation resource
    AssistantObject:
      title: Assistant
      required:
      - created_at
      - description
      - id
      - instructions
      - metadata
      - model
      - name
      - object
      - tools
      type: object
      properties:
        instructions:
          maxLength: 256000
          type: string
          description: |
            The system instructions that the assistant uses. The maximum length is 256,000 characters
          nullable: true
        tool_resources:
          allOf:
          - $ref: '#/components/schemas/AssistantObjectToolResources'
          x-ballerina-name: toolResources
        metadata:
          $ref: '#/components/schemas/Metadata'
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the assistant was
            created
          x-ballerina-name: createdAt
        description:
          maxLength: 512
          type: string
          description: |
            The description of the assistant. The maximum length is 512 characters
          nullable: true
        tools:
          maxItems: 128
          type: array
          description: |
            A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`
          items:
            $ref: '#/components/schemas/AssistantObjectTools'
          default: []
        top_p:
          maximum: 1
          minimum: 0
          type: number
          description: |
            An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

            We generally recommend altering this or temperature but not both
          nullable: true
          example: 1
          default: 1
          x-ballerina-name: topP
        response_format:
          allOf:
          - $ref: '#/components/schemas/AssistantsApiResponseFormatOption'
          x-ballerina-name: responseFormat
        name:
          maxLength: 256
          type: string
          description: |
            The name of the assistant. The maximum length is 256 characters
          nullable: true
        temperature:
          maximum: 2
          minimum: 0
          type: number
          description: |
            What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic
          nullable: true
          example: 1
          default: 1
        model:
          type: string
          description: |
            ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them
        id:
          type: string
          description: "The identifier, which can be referenced in API endpoints"
        object:
          type: string
          description: "The object type, which is always `assistant`"
          enum:
          - assistant
          x-stainless-const: true
      description: Represents an `assistant` that can call the model and use tools
      x-oaiMeta:
        name: The assistant object
        beta: true
        example: |
          {
            "id": "asst_abc123",
            "object": "assistant",
            "created_at": 1698984975,
            "name": "Math Tutor",
            "description": null,
            "model": "gpt-4o",
            "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
            "tools": [
              {
                "type": "code_interpreter"
              }
            ],
            "metadata": {},
            "top_p": 1.0,
            "temperature": 1.0,
            "response_format": "auto"
          }
    EffectiveAt:
      type: object
      properties:
        lt:
          type: integer
          description: Return only events whose `effective_at` (Unix seconds) is less
            than this value
        gte:
          type: integer
          description: Return only events whose `effective_at` (Unix seconds) is greater
            than or equal to this value
        lte:
          type: integer
          description: Return only events whose `effective_at` (Unix seconds) is less
            than or equal to this value
        gt:
          type: integer
          description: Return only events whose `effective_at` (Unix seconds) is greater
            than this value
    TextResponseFormatConfiguration:
      description: "An object specifying the format that the model must output.\n\n\
        Configuring `{ \"type\": \"json_schema\" }` enables Structured Outputs, \n\
        which ensures the model will match your supplied JSON schema. Learn more in\
        \ the \n[Structured Outputs guide](/docs/guides/structured-outputs).\n\nThe\
        \ default format is `{ \"type\": \"text\" }` with no additional options.\n\
        \n**Not recommended for gpt-4o and newer models:**\n\nSetting to `{ \"type\"\
        : \"json_object\" }` enables the older JSON mode, which\nensures the message\
        \ the model generates is valid JSON. Using `json_schema`\nis preferred for\
        \ models that support it\n"
      oneOf:
      - $ref: '#/components/schemas/ResponseFormatText'
      - $ref: '#/components/schemas/TextResponseFormatJsonSchema'
      - $ref: '#/components/schemas/ResponseFormatJsonObject'
    ChatCompletionRequestFunctionMessage:
      title: Function message
      required:
      - content
      - name
      - role
      type: object
      properties:
        role:
          type: string
          description: "The role of the messages author, in this case `function`"
          enum:
          - function
          x-stainless-const: true
        name:
          type: string
          description: The name of the function to call
        content:
          type: string
          description: The contents of the function message
          nullable: true
      deprecated: true
    CompoundFilter:
      title: Compound Filter
      required:
      - filters
      - type
      type: object
      properties:
        filters:
          type: array
          description: Array of filters to combine. Items can be `ComparisonFilter`
            or `CompoundFilter`
          items:
            $ref: '#/components/schemas/CompoundFilterFilters'
        type:
          type: string
          description: "Type of operation: `and` or `or`"
          enum:
          - and
          - or
      additionalProperties: false
      description: Combine multiple filters using `and` or `or`
      x-oaiMeta:
        name: CompoundFilter
    RealtimeClientEvent:
      description: |
        A realtime client event
      discriminator:
        propertyName: type
      anyOf:
      - $ref: '#/components/schemas/RealtimeClientEventConversationItemCreate'
      - $ref: '#/components/schemas/RealtimeClientEventConversationItemDelete'
      - $ref: '#/components/schemas/RealtimeClientEventConversationItemRetrieve'
      - $ref: '#/components/schemas/RealtimeClientEventConversationItemTruncate'
      - $ref: '#/components/schemas/RealtimeClientEventInputAudioBufferAppend'
      - $ref: '#/components/schemas/RealtimeClientEventInputAudioBufferClear'
      - $ref: '#/components/schemas/RealtimeClientEventOutputAudioBufferClear'
      - $ref: '#/components/schemas/RealtimeClientEventInputAudioBufferCommit'
      - $ref: '#/components/schemas/RealtimeClientEventResponseCancel'
      - $ref: '#/components/schemas/RealtimeClientEventResponseCreate'
      - $ref: '#/components/schemas/RealtimeClientEventSessionUpdate'
      - $ref: '#/components/schemas/RealtimeClientEventTranscriptionSessionUpdate'
    ComputerCallSafetyCheckParam:
      required:
      - id
      type: object
      properties:
        code:
          anyOf:
          - type: string
            description: The type of the pending safety check.
          - nullable: true
        id:
          type: string
          description: The ID of the pending safety check
        message:
          anyOf:
          - type: string
            description: Details about the pending safety check.
          - nullable: true
      description: A pending safety check for the computer call
    ChatCompletionMessageToolCallFunction:
      required:
      - arguments
      - name
      type: object
      properties:
        name:
          type: string
          description: The name of the function to call
        arguments:
          type: string
          description: "The arguments to call the function with, as generated by the\
            \ model in JSON format. Note that the model does not always generate valid\
            \ JSON, and may hallucinate parameters not defined by your function schema.\
            \ Validate the arguments in your code before calling your function"
      description: The function that the model called
    MessageDeltaContentTextAnnotationsFilePathObject:
      title: File path
      required:
      - index
      - type
      type: object
      properties:
        file_path:
          allOf:
          - $ref: '#/components/schemas/MessageDeltaContentTextAnnotationsFilePathObjectFilePath'
          x-ballerina-name: filePath
        start_index:
          minimum: 0
          type: integer
          x-ballerina-name: startIndex
        index:
          type: integer
          description: The index of the annotation in the text content part
        end_index:
          minimum: 0
          type: integer
          x-ballerina-name: endIndex
        text:
          type: string
          description: The text in the message content that needs to be replaced
        type:
          type: string
          description: Always `file_path`
          enum:
          - file_path
          x-stainless-const: true
      description: A URL for the file that's generated when the assistant used the
        `code_interpreter` tool to generate a file
    MessageContentTextAnnotationsFilePathObject:
      title: File path
      required:
      - end_index
      - file_path
      - start_index
      - text
      - type
      type: object
      properties:
        file_path:
          allOf:
          - $ref: '#/components/schemas/MessageContentTextAnnotationsFilePathObjectFilePath'
          x-ballerina-name: filePath
        start_index:
          minimum: 0
          type: integer
          x-ballerina-name: startIndex
        end_index:
          minimum: 0
          type: integer
          x-ballerina-name: endIndex
        text:
          type: string
          description: The text in the message content that needs to be replaced
        type:
          type: string
          description: Always `file_path`
          enum:
          - file_path
          x-stainless-const: true
      description: A URL for the file that's generated when the assistant used the
        `code_interpreter` tool to generate a file
    ResponseFileSearchCallInProgressEvent:
      required:
      - item_id
      - output_index
      - type
      type: object
      properties:
        item_id:
          type: string
          description: |
            The ID of the output item that the file search call is initiated
          x-ballerina-name: itemId
        type:
          type: string
          description: |
            The type of the event. Always `response.file_search_call.in_progress`
          enum:
          - response.file_search_call.in_progress
          x-stainless-const: true
        output_index:
          type: integer
          description: |
            The index of the output item that the file search call is initiated
          x-ballerina-name: outputIndex
      description: Emitted when a file search call is initiated
      x-oaiMeta:
        name: response.file_search_call.in_progress
        group: responses
        example: |
          {
            "type": "response.file_search_call.in_progress",
            "output_index": 0,
            "item_id": "fs_123",
          }
    ResponseTextDoneEvent:
      required:
      - content_index
      - item_id
      - output_index
      - text
      - type
      type: object
      properties:
        item_id:
          type: string
          description: |
            The ID of the output item that the text content is finalized
          x-ballerina-name: itemId
        content_index:
          type: integer
          description: |
            The index of the content part that the text content is finalized
          x-ballerina-name: contentIndex
        text:
          type: string
          description: |
            The text content that is finalized
        type:
          type: string
          description: |
            The type of the event. Always `response.output_text.done`
          enum:
          - response.output_text.done
          x-stainless-const: true
        output_index:
          type: integer
          description: |
            The index of the output item that the text content is finalized
          x-ballerina-name: outputIndex
      description: Emitted when text content is finalized
      x-oaiMeta:
        name: response.output_text.done
        group: responses
        example: |
          {
            "type": "response.output_text.done",
            "item_id": "msg_123",
            "output_index": 0,
            "content_index": 0,
            "text": "In a shimmering forest under a sky full of stars, a lonely unicorn named Lila discovered a hidden pond that glowed with moonlight. Every night, she would leave sparkling, magical flowers by the water's edge, hoping to share her beauty with others. One enchanting evening, she woke to find a group of friendly animals gathered around, eager to be friends and share in her magic."
          }
    RunStepDetailsToolCallsFileSearchObjectFileSearch:
      type: object
      properties:
        ranking_options:
          allOf:
          - $ref: '#/components/schemas/RunStepDetailsToolCallsFileSearchRankingOptionsObject'
          x-ballerina-name: rankingOptions
        results:
          type: array
          description: The results of the file search
          items:
            $ref: '#/components/schemas/RunStepDetailsToolCallsFileSearchResultObject'
      description: "For now, this is always going to be an empty object"
    CreateThreadAndRunRequest:
      required:
      - assistant_id
      type: object
      properties:
        instructions:
          type: string
          description: Override the default system message of the assistant. This
            is useful for modifying the behavior on a per-run basis
          nullable: true
        tool_resources:
          allOf:
          - $ref: '#/components/schemas/CreateThreadAndRunRequestToolResources'
          x-ballerina-name: toolResources
        metadata:
          $ref: '#/components/schemas/Metadata'
        assistant_id:
          type: string
          description: "The ID of the [assistant](/docs/api-reference/assistants)\
            \ to use to execute this run"
          x-ballerina-name: assistantId
        thread:
          $ref: '#/components/schemas/CreateThreadRequest'
        tools:
          maxItems: 20
          type: array
          description: Override the tools the assistant can use for this run. This
            is useful for modifying the behavior on a per-run basis
          nullable: true
          items:
            $ref: '#/components/schemas/AssistantObjectTools'
        truncation_strategy:
          allOf:
          - $ref: '#/components/schemas/TruncationObject'
          - nullable: true
          x-ballerina-name: truncationStrategy
        top_p:
          maximum: 1
          minimum: 0
          type: number
          description: |
            An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

            We generally recommend altering this or temperature but not both
          nullable: true
          example: 1
          default: 1
          x-ballerina-name: topP
        max_completion_tokens:
          minimum: 256
          type: integer
          description: |
            The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info
          nullable: true
          x-ballerina-name: maxCompletionTokens
        response_format:
          allOf:
          - $ref: '#/components/schemas/AssistantsApiResponseFormatOption'
          x-ballerina-name: responseFormat
        parallel_tool_calls:
          allOf:
          - $ref: '#/components/schemas/ParallelToolCalls'
          x-ballerina-name: parallelToolCalls
        stream:
          type: boolean
          description: |
            If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message
          nullable: true
        temperature:
          maximum: 2
          minimum: 0
          type: number
          description: |
            What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic
          nullable: true
          example: 1
          default: 1
        tool_choice:
          allOf:
          - $ref: '#/components/schemas/AssistantsApiToolChoiceOption'
          - nullable: true
          x-ballerina-name: toolChoice
        model:
          description: "The ID of the [Model](/docs/api-reference/models) to be used\
            \ to execute this run. If a value is provided here, it will override the\
            \ model associated with the assistant. If not, the model associated with\
            \ the assistant will be used"
          nullable: true
          example: gpt-4o
          anyOf:
          - type: string
          - type: string
            enum:
            - gpt-4.1
            - gpt-4.1-mini
            - gpt-4.1-nano
            - gpt-4.1-2025-04-14
            - gpt-4.1-mini-2025-04-14
            - gpt-4.1-nano-2025-04-14
            - gpt-4o
            - gpt-4o-2024-11-20
            - gpt-4o-2024-08-06
            - gpt-4o-2024-05-13
            - gpt-4o-mini
            - gpt-4o-mini-2024-07-18
            - gpt-4.5-preview
            - gpt-4.5-preview-2025-02-27
            - gpt-4-turbo
            - gpt-4-turbo-2024-04-09
            - gpt-4-0125-preview
            - gpt-4-turbo-preview
            - gpt-4-1106-preview
            - gpt-4-vision-preview
            - gpt-4
            - gpt-4-0314
            - gpt-4-0613
            - gpt-4-32k
            - gpt-4-32k-0314
            - gpt-4-32k-0613
            - gpt-3.5-turbo
            - gpt-3.5-turbo-16k
            - gpt-3.5-turbo-0613
            - gpt-3.5-turbo-1106
            - gpt-3.5-turbo-0125
            - gpt-3.5-turbo-16k-0613
          x-oaiTypeLabel: string
        max_prompt_tokens:
          minimum: 256
          type: integer
          description: |
            The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info
          nullable: true
          x-ballerina-name: maxPromptTokens
      additionalProperties: false
    RunStepDeltaStepDetailsToolCallsObjectToolCalls:
      oneOf:
      - $ref: '#/components/schemas/RunStepDeltaStepDetailsToolCallsCodeObject'
      - $ref: '#/components/schemas/RunStepDeltaStepDetailsToolCallsFileSearchObject'
      - $ref: '#/components/schemas/RunStepDeltaStepDetailsToolCallsFunctionObject'
    ReasoningItemSummary:
      required:
      - text
      - type
      type: object
      properties:
        text:
          type: string
          description: |
            A short summary of the reasoning used by the model when generating
            the response
        type:
          type: string
          description: |
            The type of the object. Always `summary_text`
          enum:
          - summary_text
          x-stainless-const: true
    FineTuningJobEvent:
      required:
      - created_at
      - id
      - level
      - message
      - object
      type: object
      properties:
        data:
          type: object
          description: The data associated with the event
        level:
          type: string
          description: The log level of the event
          enum:
          - info
          - warn
          - error
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the fine-tuning job
            was created
          x-ballerina-name: createdAt
        id:
          type: string
          description: The object identifier
        message:
          type: string
          description: The message of the event
        type:
          type: string
          description: The type of event
          enum:
          - message
          - metrics
        object:
          type: string
          description: "The object type, which is always \"fine_tuning.job.event\""
          enum:
          - fine_tuning.job.event
          x-stainless-const: true
      description: Fine-tuning job event object
      x-oaiMeta:
        name: The fine-tuning job event object
        example: |
          {
            "object": "fine_tuning.job.event",
            "id": "ftevent-abc123"
            "created_at": 1677610602,
            "level": "info",
            "message": "Created fine-tuning job",
            "data": {},
            "type": "message"
          }
    FunctionToolCallOutputResource:
      allOf:
      - $ref: '#/components/schemas/FunctionToolCallOutput'
      - $ref: '#/components/schemas/FunctionToolCallOutputResourceAllOf2'
    AssistantsNamedToolChoice:
      required:
      - type
      type: object
      properties:
        function:
          $ref: '#/components/schemas/AssistantsNamedToolChoiceFunction'
        type:
          type: string
          description: "The type of the tool. If type is `function`, the function\
            \ name must be set"
          enum:
          - function
          - code_interpreter
          - file_search
      description: Specifies a tool the model should use. Use to force the model to
        call a specific tool
    RealtimeServerEventResponseTextDelta:
      required:
      - content_index
      - delta
      - event_id
      - item_id
      - output_index
      - response_id
      - type
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event
          x-ballerina-name: eventId
        item_id:
          type: string
          description: The ID of the item
          x-ballerina-name: itemId
        content_index:
          type: integer
          description: The index of the content part in the item's content array
          x-ballerina-name: contentIndex
        response_id:
          type: string
          description: The ID of the response
          x-ballerina-name: responseId
        delta:
          type: string
          description: The text delta
        type:
          type: string
          description: "The event type, must be `response.text.delta`"
          enum:
          - response.text.delta
          x-stainless-const: true
        output_index:
          type: integer
          description: The index of the output item in the response
          x-ballerina-name: outputIndex
      description: Returned when the text value of a "text" content part is updated
      x-oaiMeta:
        name: response.text.delta
        group: realtime
        example: |
          {
              "event_id": "event_4142",
              "type": "response.text.delta",
              "response_id": "resp_001",
              "item_id": "msg_007",
              "output_index": 0,
              "content_index": 0,
              "delta": "Sure, I can h"
          }
    ListRunStepsResponse:
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
      properties:
        object:
          type: string
          example: list
        data:
          type: array
          items:
            $ref: '#/components/schemas/RunStepObject'
        first_id:
          type: string
          example: step_abc123
        last_id:
          type: string
          example: step_abc456
        has_more:
          type: boolean
          example: false
    CreateEvalRequest:
      title: CreateEvalRequest
      required:
      - data_source_config
      - testing_criteria
      type: object
      properties:
        metadata:
          $ref: '#/components/schemas/Metadata'
        name:
          type: string
          description: The name of the evaluation
        testing_criteria:
          type: array
          description: A list of graders for all eval runs in this group
          items:
            $ref: '#/components/schemas/CreateEvalRequestTestingCriteria'
          x-ballerina-name: testingCriteria
        data_source_config:
          type: object
          description: The configuration for the data source used for the evaluation
            runs
          oneOf:
          - $ref: '#/components/schemas/CreateEvalCustomDataSourceConfig'
          - $ref: '#/components/schemas/CreateEvalLogsDataSourceConfig'
          x-ballerina-name: dataSourceConfig
    AuditLogActorServiceAccount:
      type: object
      properties:
        id:
          type: string
          description: The service account id
      description: The service account that performed the audit logged action
    ProjectUserDeleteResponse:
      required:
      - deleted
      - id
      - object
      type: object
      properties:
        deleted:
          type: boolean
        id:
          type: string
        object:
          type: string
          enum:
          - organization.project.user.deleted
          x-stainless-const: true
    VoiceIdsSharedAnyOf1:
      type: string
    ChatCompletionRequestMessageContentPartAudioInputAudio:
      required:
      - data
      - format
      type: object
      properties:
        data:
          type: string
          description: Base64 encoded audio data
        format:
          type: string
          description: |
            The format of the encoded audio data. Currently supports "wav" and "mp3"
          enum:
          - wav
          - mp3
    CreateFineTuningJobRequest:
      required:
      - model
      - training_file
      type: object
      properties:
        training_file:
          type: string
          description: |
            The ID of an uploaded file that contains training data.

            See [upload file](/docs/api-reference/files/create) for how to upload a file.

            Your dataset must be formatted as a JSONL file. Additionally, you must upload your file with the purpose `fine-tune`.

            The contents of the file should differ depending on if the model uses the [chat](/docs/api-reference/fine-tuning/chat-input), [completions](/docs/api-reference/fine-tuning/completions-input) format, or if the fine-tuning method uses the [preference](/docs/api-reference/fine-tuning/preference-input) format.

            See the [fine-tuning guide](/docs/guides/fine-tuning) for more details
          example: file-abc123
          x-ballerina-name: trainingFile
        metadata:
          $ref: '#/components/schemas/Metadata'
        seed:
          maximum: 2147483647
          minimum: 0
          type: integer
          description: |
            The seed controls the reproducibility of the job. Passing in the same seed and job parameters should produce the same results, but may differ in rare cases.
            If a seed is not specified, one will be generated for you
          nullable: true
          example: 42
        method:
          $ref: '#/components/schemas/FineTuneMethod'
        validation_file:
          type: string
          description: |
            The ID of an uploaded file that contains validation data.

            If you provide this file, the data is used to generate validation
            metrics periodically during fine-tuning. These metrics can be viewed in
            the fine-tuning results file.
            The same data should not be present in both train and validation files.

            Your dataset must be formatted as a JSONL file. You must upload your file with the purpose `fine-tune`.

            See the [fine-tuning guide](/docs/guides/fine-tuning) for more details
          nullable: true
          example: file-abc123
          x-ballerina-name: validationFile
        hyperparameters:
          $ref: '#/components/schemas/CreateFineTuningJobRequestHyperparameters'
        model:
          description: |
            The name of the model to fine-tune. You can select one of the
            [supported models](/docs/guides/fine-tuning#which-models-can-be-fine-tuned)
          example: gpt-4o-mini
          anyOf:
          - type: string
          - type: string
            enum:
            - babbage-002
            - davinci-002
            - gpt-3.5-turbo
            - gpt-4o-mini
          x-oaiTypeLabel: string
        suffix:
          maxLength: 64
          minLength: 1
          type: string
          description: |
            A string of up to 64 characters that will be added to your fine-tuned model name.

            For example, a `suffix` of "custom-model-name" would produce a model name like `ft:gpt-4o-mini:openai:custom-model-name:7p4lURel`
          nullable: true
        integrations:
          type: array
          description: A list of integrations to enable for your fine-tuning job
          nullable: true
          items:
            $ref: '#/components/schemas/CreateFineTuningJobRequestIntegrations'
    MessageContentImageUrlObjectImageUrl:
      required:
      - url
      type: object
      properties:
        detail:
          type: string
          description: "Specifies the detail level of the image. `low` uses fewer\
            \ tokens, you can opt in to high resolution using `high`. Default value\
            \ is `auto`"
          default: auto
          enum:
          - auto
          - low
          - high
        url:
          type: string
          description: "The external URL of the image, must be a supported image types:\
            \ jpeg, jpg, png, gif, webp"
          format: uri
    UsageModerationsResult:
      required:
      - input_tokens
      - num_model_requests
      - object
      type: object
      properties:
        num_model_requests:
          type: integer
          description: The count of requests made to the model
          x-ballerina-name: numModelRequests
        project_id:
          type: string
          description: "When `group_by=project_id`, this field provides the project\
            \ ID of the grouped usage result"
          nullable: true
          x-ballerina-name: projectId
        user_id:
          type: string
          description: "When `group_by=user_id`, this field provides the user ID of\
            \ the grouped usage result"
          nullable: true
          x-ballerina-name: userId
        model:
          type: string
          description: "When `group_by=model`, this field provides the model name\
            \ of the grouped usage result"
          nullable: true
        input_tokens:
          type: integer
          description: The aggregated number of input tokens used
          x-ballerina-name: inputTokens
        api_key_id:
          type: string
          description: "When `group_by=api_key_id`, this field provides the API key\
            \ ID of the grouped usage result"
          nullable: true
          x-ballerina-name: apiKeyId
        object:
          type: string
          enum:
          - organization.usage.moderations.result
          x-stainless-const: true
      description: The aggregated moderations usage details of the specific time bucket
      x-oaiMeta:
        name: Moderations usage object
        example: |
          {
              "object": "organization.usage.moderations.result",
              "input_tokens": 20,
              "num_model_requests": 2,
              "project_id": "proj_abc",
              "user_id": "user-abc",
              "api_key_id": "key_abc",
              "model": "text-moderation"
          }
    RealtimeSessionTurnDetection:
      type: object
      properties:
        silence_duration_ms:
          type: integer
          description: "Used only for `server_vad` mode. Duration of silence to detect\
            \ speech stop (in milliseconds). Defaults \nto 500ms. With shorter values\
            \ the model will respond more quickly, \nbut may jump in on short pauses\
            \ from the user\n"
          x-ballerina-name: silenceDurationMs
        create_response:
          type: boolean
          description: |
            Whether or not to automatically generate a response when a VAD stop event occurs
          default: true
          x-ballerina-name: createResponse
        interrupt_response:
          type: boolean
          description: |
            Whether or not to automatically interrupt any ongoing response with output to the default
            conversation (i.e. `conversation` of `auto`) when a VAD start event occurs
          default: true
          x-ballerina-name: interruptResponse
        prefix_padding_ms:
          type: integer
          description: "Used only for `server_vad` mode. Amount of audio to include\
            \ before the VAD detected speech (in \nmilliseconds). Defaults to 300ms\n"
          x-ballerina-name: prefixPaddingMs
        eagerness:
          type: string
          description: |
            Used only for `semantic_vad` mode. The eagerness of the model to respond. `low` will wait longer for the user to continue speaking, `high` will respond more quickly. `auto` is the default and is equivalent to `medium`
          default: auto
          enum:
          - low
          - medium
          - high
          - auto
        threshold:
          type: number
          description: "Used only for `server_vad` mode. Activation threshold for\
            \ VAD (0.0 to 1.0), this defaults to 0.5. A \nhigher threshold will require\
            \ louder audio to activate the model, and \nthus might perform better\
            \ in noisy environments\n"
        type:
          type: string
          description: |
            Type of turn detection
          default: server_vad
          enum:
          - server_vad
          - semantic_vad
      description: |
        Configuration for turn detection, ether Server VAD or Semantic VAD. This can be set to `null` to turn off, in which case the client must manually trigger model response.
        Server VAD means that the model will detect the start and end of speech based on audio volume and respond at the end of user speech.
        Semantic VAD is more advanced and uses a turn detection model (in conjuction with VAD) to semantically estimate whether the user has finished speaking, then dynamically sets a timeout based on this probability. For example, if user audio trails off with "uhhm", the model will score a low probability of turn end and wait longer for the user to continue speaking. This can be useful for more natural conversations, but may have a higher latency
    FileSearchRanker:
      type: string
      description: The ranker to use for the file search. If not specified will use
        the `auto` ranker
      enum:
      - auto
      - default_2024_08_21
    CreateFineTuningJobRequestIntegrations:
      required:
      - type
      - wandb
      type: object
      properties:
        wandb:
          $ref: '#/components/schemas/CreateFineTuningJobRequestWandb'
        type:
          description: |
            The type of integration to enable. Currently, only "wandb" (Weights and Biases) is supported
          oneOf:
          - type: string
            enum:
            - wandb
            x-stainless-const: true
    DeleteFineTuningCheckpointPermissionResponse:
      required:
      - deleted
      - id
      - object
      type: object
      properties:
        deleted:
          type: boolean
          description: Whether the fine-tuned model checkpoint permission was successfully
            deleted
        id:
          type: string
          description: The ID of the fine-tuned model checkpoint permission that was
            deleted
        object:
          type: string
          description: "The object type, which is always \"checkpoint.permission\""
          enum:
          - checkpoint.permission
          x-stainless-const: true
    AssistantsApiResponseFormatOptionOneOf1:
      type: string
      description: |
        `auto` is the default value
      enum:
      - auto
      x-stainless-const: true
    ProjectRateLimit:
      required:
      - id
      - max_requests_per_1_minute
      - max_tokens_per_1_minute
      - model
      - object
      type: object
      properties:
        batch_1_day_max_input_tokens:
          type: integer
          description: The maximum batch input tokens per day. Only present for relevant
            models
          x-ballerina-name: batch1DayMaxInputTokens
        max_tokens_per_1_minute:
          type: integer
          description: The maximum tokens per minute
          x-ballerina-name: maxTokensPer1Minute
        model:
          type: string
          description: The model this rate limit applies to
        id:
          type: string
          description: "The identifier, which can be referenced in API endpoints"
        max_images_per_1_minute:
          type: integer
          description: The maximum images per minute. Only present for relevant models
          x-ballerina-name: maxImagesPer1Minute
        max_audio_megabytes_per_1_minute:
          type: integer
          description: The maximum audio megabytes per minute. Only present for relevant
            models
          x-ballerina-name: maxAudioMegabytesPer1Minute
        max_requests_per_1_minute:
          type: integer
          description: The maximum requests per minute
          x-ballerina-name: maxRequestsPer1Minute
        object:
          type: string
          description: "The object type, which is always `project.rate_limit`"
          enum:
          - project.rate_limit
          x-stainless-const: true
        max_requests_per_1_day:
          type: integer
          description: The maximum requests per day. Only present for relevant models
          x-ballerina-name: maxRequestsPer1Day
      description: Represents a project rate limit config
      x-oaiMeta:
        name: The project rate limit object
        example: |
          {
              "object": "project.rate_limit",
              "id": "rl_ada",
              "model": "ada",
              "max_requests_per_1_minute": 600,
              "max_tokens_per_1_minute": 150000,
              "max_images_per_1_minute": 10
          }
    RunStepDeltaStepDetailsToolCallsObject:
      title: Tool calls
      required:
      - type
      type: object
      properties:
        tool_calls:
          type: array
          description: |
            An array of tool calls the run step was involved in. These can be associated with one of three types of tools: `code_interpreter`, `file_search`, or `function`
          items:
            $ref: '#/components/schemas/RunStepDeltaStepDetailsToolCallsObjectToolCalls'
          x-ballerina-name: toolCalls
        type:
          type: string
          description: Always `tool_calls`
          enum:
          - tool_calls
          x-stainless-const: true
      description: Details of the tool call
    RunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventOneOf123456:
      required:
      - data
      - event
      type: object
      properties:
        data:
          $ref: '#/components/schemas/RunObject'
        event:
          type: string
          enum:
          - thread.run.incomplete
          x-stainless-const: true
      description: "Occurs when a [run](/docs/api-reference/runs/object) ends with\
        \ status `incomplete`"
      x-oaiMeta:
        dataDescription: "`data` is a [run](/docs/api-reference/runs/object)"
    AuditLogInviteaccepted:
      type: object
      properties:
        id:
          type: string
          description: The ID of the invite
      description: The details for events with this `type`
    Item:
      type: object
      description: |
        Content item used to generate a response
      discriminator:
        propertyName: type
      oneOf:
      - $ref: '#/components/schemas/InputMessage'
      - $ref: '#/components/schemas/OutputMessage'
      - $ref: '#/components/schemas/FileSearchToolCall'
      - $ref: '#/components/schemas/ComputerToolCall'
      - $ref: '#/components/schemas/ComputerCallOutputItemParam'
      - $ref: '#/components/schemas/WebSearchToolCall'
      - $ref: '#/components/schemas/FunctionToolCall'
      - $ref: '#/components/schemas/FunctionCallOutputItemParam'
      - $ref: '#/components/schemas/ReasoningItem'
    CreateEvalCustomDataSourceConfig:
      title: CustomDataSourceConfig
      required:
      - item_schema
      - type
      type: object
      properties:
        item_schema:
          type: object
          additionalProperties: true
          description: The json schema for each row in the data source
          example: |
            {
              "type": "object",
              "properties": {
                "name": {"type": "string"},
                "age": {"type": "integer"}
              },
              "required": ["name", "age"]
            }
          x-ballerina-name: itemSchema
        include_sample_schema:
          type: boolean
          description: "Whether the eval should expect you to populate the sample\
            \ namespace (ie, by generating responses off of your data source)"
          default: false
          x-ballerina-name: includeSampleSchema
        type:
          type: string
          description: The type of data source. Always `custom`
          default: custom
          enum:
          - custom
          x-stainless-const: true
      description: |
        A CustomDataSourceConfig object that defines the schema for the data source used for the evaluation runs.
        This schema is used to define the shape of the data that will be:
        - Used to define your testing criteria and
        - What data is required when creating a run
      x-oaiMeta:
        name: The eval file data source config object
        group: evals
        example: |
          {
            "type": "custom",
            "item_schema": {
              "type": "object",
              "properties": {
                "name": {"type": "string"},
                "age": {"type": "integer"}
              },
              "required": ["name", "age"]
            },
            "include_sample_schema": true
          }
    WebSearchUserLocation:
      required:
      - approximate
      - type
      type: object
      properties:
        approximate:
          $ref: '#/components/schemas/WebSearchLocation'
        type:
          type: string
          description: |
            The type of location approximation. Always `approximate`
          enum:
          - approximate
          x-stainless-const: true
      description: |
        Approximate location parameters for the search
      nullable: true
    RunObjectLastError:
      required:
      - code
      - message
      type: object
      properties:
        code:
          type: string
          description: "One of `server_error`, `rate_limit_exceeded`, or `invalid_prompt`"
          enum:
          - server_error
          - rate_limit_exceeded
          - invalid_prompt
        message:
          type: string
          description: A human-readable description of the error
      description: The last error associated with this run. Will be `null` if there
        are no errors
      nullable: true
    RealtimeServerEventConversationItemInputAudioTranscriptionDelta:
      required:
      - event_id
      - item_id
      - type
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event
          x-ballerina-name: eventId
        item_id:
          type: string
          description: The ID of the item
          x-ballerina-name: itemId
        content_index:
          type: integer
          description: The index of the content part in the item's content array
          x-ballerina-name: contentIndex
        delta:
          type: string
          description: The text delta
        type:
          type: string
          description: "The event type, must be `conversation.item.input_audio_transcription.delta`"
          enum:
          - conversation.item.input_audio_transcription.delta
          x-stainless-const: true
        logprobs:
          type: array
          description: The log probabilities of the transcription
          nullable: true
          items:
            $ref: '#/components/schemas/LogProbProperties'
      description: |
        Returned when the text value of an input audio transcription content part is updated
      x-oaiMeta:
        name: conversation.item.input_audio_transcription.delta
        group: realtime
        example: |
          {
            "type": "conversation.item.input_audio_transcription.delta",
            "event_id": "event_001",
            "item_id": "item_001",
            "content_index": 0,
            "delta": "Hello"
          }
    ResponseCreatedEvent:
      required:
      - response
      - type
      type: object
      properties:
        response:
          $ref: '#/components/schemas/Response'
        type:
          type: string
          description: |
            The type of the event. Always `response.created`
          enum:
          - response.created
          x-stainless-const: true
      description: |
        An event that is emitted when a response is created
      x-oaiMeta:
        name: response.created
        group: responses
        example: |
          {
            "type": "response.created",
            "response": {
              "id": "resp_67ccfcdd16748190a91872c75d38539e09e4d4aac714747c",
              "object": "response",
              "created_at": 1741487325,
              "status": "in_progress",
              "error": null,
              "incomplete_details": null,
              "instructions": null,
              "max_output_tokens": null,
              "model": "gpt-4o-2024-08-06",
              "output": [],
              "parallel_tool_calls": true,
              "previous_response_id": null,
              "reasoning": {
                "effort": null,
                "summary": null
              },
              "store": true,
              "temperature": 1,
              "text": {
                "format": {
                  "type": "text"
                }
              },
              "tool_choice": "auto",
              "tools": [],
              "top_p": 1,
              "truncation": "disabled",
              "usage": null,
              "user": null,
              "metadata": {}
            }
          }
    ComputerToolCallOutputResource:
      allOf:
      - $ref: '#/components/schemas/ComputerToolCallOutput'
      - $ref: '#/components/schemas/ComputerToolCallOutputResourceAllOf2'
    CreateTranscriptionResponseVerboseJson:
      required:
      - duration
      - language
      - text
      type: object
      properties:
        duration:
          type: number
          description: The duration of the input audio
        words:
          type: array
          description: Extracted words and their corresponding timestamps
          items:
            $ref: '#/components/schemas/TranscriptionWord'
        language:
          type: string
          description: The language of the input audio
        text:
          type: string
          description: The transcribed text
        segments:
          type: array
          description: Segments of the transcribed text and their corresponding details
          items:
            $ref: '#/components/schemas/TranscriptionSegment'
      description: "Represents a verbose json transcription response returned by model,\
        \ based on the provided input"
      x-oaiMeta:
        name: The transcription object (Verbose JSON)
        group: audio
        example: |
          {
            "task": "transcribe",
            "language": "english",
            "duration": 8.470000267028809,
            "text": "The beach was a popular spot on a hot summer day. People were swimming in the ocean, building sandcastles, and playing beach volleyball.",
            "segments": [
              {
                "id": 0,
                "seek": 0,
                "start": 0.0,
                "end": 3.319999933242798,
                "text": " The beach was a popular spot on a hot summer day.",
                "tokens": [
                  50364, 440, 7534, 390, 257, 3743, 4008, 322, 257, 2368, 4266, 786, 13, 50530
                ],
                "temperature": 0.0,
                "avg_logprob": -0.2860786020755768,
                "compression_ratio": 1.2363636493682861,
                "no_speech_prob": 0.00985979475080967
              },
              ...
            ]
          }
    RealtimeServerEventResponseContentPartAdded:
      required:
      - content_index
      - event_id
      - item_id
      - output_index
      - part
      - response_id
      - type
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event
          x-ballerina-name: eventId
        item_id:
          type: string
          description: The ID of the item to which the content part was added
          x-ballerina-name: itemId
        content_index:
          type: integer
          description: The index of the content part in the item's content array
          x-ballerina-name: contentIndex
        response_id:
          type: string
          description: The ID of the response
          x-ballerina-name: responseId
        part:
          $ref: '#/components/schemas/RealtimeServerEventResponseContentPartAddedPart'
        type:
          type: string
          description: "The event type, must be `response.content_part.added`"
          enum:
          - response.content_part.added
          x-stainless-const: true
        output_index:
          type: integer
          description: The index of the output item in the response
          x-ballerina-name: outputIndex
      description: |
        Returned when a new content part is added to an assistant message item during
        response generation
      x-oaiMeta:
        name: response.content_part.added
        group: realtime
        example: |
          {
              "event_id": "event_3738",
              "type": "response.content_part.added",
              "response_id": "resp_001",
              "item_id": "msg_007",
              "output_index": 0,
              "content_index": 0,
              "part": {
                  "type": "text",
                  "text": ""
              }
          }
    ProjectServiceAccountApiKey:
      required:
      - created_at
      - id
      - name
      - object
      - value
      type: object
      properties:
        name:
          type: string
        created_at:
          type: integer
          x-ballerina-name: createdAt
        id:
          type: string
        value:
          type: string
        object:
          type: string
          description: "The object type, which is always `organization.project.service_account.api_key`"
          enum:
          - organization.project.service_account.api_key
          x-stainless-const: true
    SimpleInputMessage:
      title: SimpleInputMessage
      required:
      - content
      - role
      type: object
      properties:
        role:
          type: string
          description: "The role of the message (e.g. \"system\", \"assistant\", \"\
            user\")"
        content:
          type: string
          description: The content of the message
    MessageDeltaContentImageUrlObjectImageUrl:
      type: object
      properties:
        detail:
          type: string
          description: "Specifies the detail level of the image. `low` uses fewer\
            \ tokens, you can opt in to high resolution using `high`"
          default: auto
          enum:
          - auto
          - low
          - high
        url:
          type: string
          description: "The URL of the image, must be a supported image types: jpeg,\
            \ jpg, png, gif, webp"
    CreateTranslationRequest:
      required:
      - file
      - model
      type: object
      properties:
        file:
          type: string
          description: |
            The audio file object (not file name) translate, in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm
          format: binary
          x-oaiTypeLabel: file
        response_format:
          type: string
          description: |
            The format of the output, in one of these options: `json`, `text`, `srt`, `verbose_json`, or `vtt`
          default: json
          enum:
          - json
          - text
          - srt
          - verbose_json
          - vtt
          x-ballerina-name: responseFormat
        temperature:
          type: number
          description: |
            The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit
          default: 0
        model:
          description: |
            ID of the model to use. Only `whisper-1` (which is powered by our open source Whisper V2 model) is currently available
          example: whisper-1
          anyOf:
          - type: string
          - type: string
            enum:
            - whisper-1
            x-stainless-const: true
          x-oaiTypeLabel: string
        prompt:
          type: string
          description: |
            An optional text to guide the model's style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text#prompting) should be in English
      additionalProperties: false
    MessageDeltaContentTextAnnotationsFileCitationObjectFileCitation:
      type: object
      properties:
        quote:
          type: string
          description: The specific quote in the file
        file_id:
          type: string
          description: The ID of the specific File the citation is from
          x-ballerina-name: fileId
    ResponseErrorEvent:
      required:
      - code
      - message
      - param
      - type
      type: object
      properties:
        code:
          type: string
          description: |
            The error code
          nullable: true
        param:
          type: string
          description: |
            The error parameter
          nullable: true
        type:
          type: string
          description: |
            The type of the event. Always `error`
          enum:
          - error
          x-stainless-const: true
        message:
          type: string
          description: |
            The error message
      description: Emitted when an error occurs
      x-oaiMeta:
        name: error
        group: responses
        example: |
          {
            "type": "error",
            "code": "ERR_SOMETHING",
            "message": "Something went wrong",
            "param": null
          }
    ComputerUsePreviewTool:
      title: Computer use preview
      required:
      - display_height
      - display_width
      - environment
      - type
      type: object
      properties:
        environment:
          type: string
          description: The type of computer environment to control
          enum:
          - windows
          - mac
          - linux
          - ubuntu
          - browser
        display_height:
          type: integer
          description: The height of the computer display
          x-ballerina-name: displayHeight
        type:
          type: string
          description: The type of the computer use tool. Always `computer_use_preview`
          default: computer_use_preview
          enum:
          - computer_use_preview
          x-stainless-const: true
        display_width:
          type: integer
          description: The width of the computer display
          x-ballerina-name: displayWidth
      description: "A tool that controls a virtual computer. Learn more about the\
        \ [computer tool](https://platform.openai.com/docs/guides/tools-computer-use)"
    AuditLogCertificatecreated:
      type: object
      properties:
        name:
          type: string
          description: The name of the certificate
        id:
          type: string
          description: The certificate ID
      description: The details for events with this `type`
    UpdateVectorStoreRequest:
      type: object
      properties:
        metadata:
          $ref: '#/components/schemas/Metadata'
        expires_after:
          allOf:
          - $ref: '#/components/schemas/VectorStoreExpirationAfter'
          - nullable: true
          x-ballerina-name: expiresAfter
        name:
          type: string
          description: The name of the vector store
          nullable: true
      additionalProperties: false
    ApproximateLocation:
      required:
      - type
      type: object
      properties:
        country:
          anyOf:
          - type: string
            description: "The two-letter [ISO country code](https://en.wikipedia.org/wiki/ISO_3166-1)\
              \ of the user, e.g. `US`."
          - nullable: true
        city:
          anyOf:
          - type: string
            description: "Free text input for the city of the user, e.g. `San Francisco`."
          - nullable: true
        timezone:
          anyOf:
          - type: string
            description: "The [IANA timezone](https://timeapi.io/documentation/iana-timezones)\
              \ of the user, e.g. `America/Los_Angeles`."
          - nullable: true
        type:
          type: string
          description: The type of location approximation. Always `approximate`
          default: approximate
          enum:
          - approximate
          x-stainless-const: true
        region:
          anyOf:
          - type: string
            description: "Free text input for the region of the user, e.g. `California`."
          - nullable: true
    ResponseOutputItemDoneEvent:
      required:
      - item
      - output_index
      - type
      type: object
      properties:
        item:
          $ref: '#/components/schemas/OutputItem'
        type:
          type: string
          description: |
            The type of the event. Always `response.output_item.done`
          enum:
          - response.output_item.done
          x-stainless-const: true
        output_index:
          type: integer
          description: |
            The index of the output item that was marked done
          x-ballerina-name: outputIndex
      description: Emitted when an output item is marked done
      x-oaiMeta:
        name: response.output_item.done
        group: responses
        example: |
          {
            "type": "response.output_item.done",
            "output_index": 0,
            "item": {
              "id": "msg_123",
              "status": "completed",
              "type": "message",
              "role": "assistant",
              "content": [
                {
                  "type": "output_text",
                  "text": "In a shimmering forest under a sky full of stars, a lonely unicorn named Lila discovered a hidden pond that glowed with moonlight. Every night, she would leave sparkling, magical flowers by the water's edge, hoping to share her beauty with others. One enchanting evening, she woke to find a group of friendly animals gathered around, eager to be friends and share in her magic.",
                  "annotations": []
                }
              ]
            }
          }
    CompletionUsageCompletionTokensDetails:
      type: object
      properties:
        accepted_prediction_tokens:
          type: integer
          description: |
            When using Predicted Outputs, the number of tokens in the
            prediction that appeared in the completion
          default: 0
          x-ballerina-name: acceptedPredictionTokens
        audio_tokens:
          type: integer
          description: Audio input tokens generated by the model
          default: 0
          x-ballerina-name: audioTokens
        reasoning_tokens:
          type: integer
          description: Tokens generated by the model for reasoning
          default: 0
          x-ballerina-name: reasoningTokens
        rejected_prediction_tokens:
          type: integer
          description: |
            When using Predicted Outputs, the number of tokens in the
            prediction that did not appear in the completion. However, like
            reasoning tokens, these tokens are still counted in the total
            completion tokens for purposes of billing, output, and context window
            limits
          default: 0
          x-ballerina-name: rejectedPredictionTokens
      description: Breakdown of tokens used in a completion
    CreateFineTuningJobRequestWandb:
      required:
      - project
      type: object
      properties:
        name:
          type: string
          description: |
            A display name to set for the run. If not set, we will use the Job ID as the name
          nullable: true
        project:
          type: string
          description: |
            The name of the project that the new run will be created under
          example: my-wandb-project
        entity:
          type: string
          description: |
            The entity to use for the run. This allows you to set the team or username of the WandB user that you would
            like associated with the run. If not set, the default entity for the registered WandB API key is used
          nullable: true
        tags:
          type: array
          description: |
            A list of tags to be attached to the newly created run. These tags are passed through directly to WandB. Some
            default tags are generated by OpenAI: "openai/finetune", "openai/{base-model}", "openai/{ftjob-abcdef}"
          items:
            type: string
            example: custom-tag
      description: |
        The settings for your integration with Weights and Biases. This payload specifies the project that
        metrics will be sent to. Optionally, you can set an explicit display name for your run, add tags
        to your run, and set a default entity (team, username, etc) to be associated with your run
    UserRoleUpdateRequest:
      required:
      - role
      type: object
      properties:
        role:
          type: string
          description: '`owner` or `reader`'
          enum:
          - owner
          - reader
    AuditLogCheckpointPermissioncreatedData:
      type: object
      properties:
        project_id:
          type: string
          description: The ID of the project that the checkpoint permission was created
            for
          x-ballerina-name: projectId
        fine_tuned_model_checkpoint:
          type: string
          description: The ID of the fine-tuned model checkpoint
          x-ballerina-name: fineTunedModelCheckpoint
      description: The payload used to create the checkpoint permission
    AddUploadPartRequest:
      required:
      - data
      type: object
      properties:
        data:
          type: string
          description: |
            The chunk of bytes for this Part
          format: binary
      additionalProperties: false
    CreateEmbeddingResponseUsage:
      required:
      - prompt_tokens
      - total_tokens
      type: object
      properties:
        prompt_tokens:
          type: integer
          description: The number of tokens used by the prompt
          x-ballerina-name: promptTokens
        total_tokens:
          type: integer
          description: The total number of tokens used by the request
          x-ballerina-name: totalTokens
      description: The usage information for the request
    RunStreamEventRunStreamEventRunStreamEventOneOf123:
      required:
      - data
      - event
      type: object
      properties:
        data:
          $ref: '#/components/schemas/RunObject'
        event:
          type: string
          enum:
          - thread.run.in_progress
          x-stainless-const: true
      description: "Occurs when a [run](/docs/api-reference/runs/object) moves to\
        \ an `in_progress` status"
      x-oaiMeta:
        dataDescription: "`data` is a [run](/docs/api-reference/runs/object)"
    Coordinate:
      title: Coordinate
      required:
      - x
      - "y"
      type: object
      properties:
        x:
          type: integer
          description: |
            The x-coordinate
        "y":
          type: integer
          description: |
            The y-coordinate
      description: |
        An x/y coordinate pair, e.g. `{ x: 100, y: 200 }`
    VectorStoreSearchResultItem:
      required:
      - attributes
      - content
      - file_id
      - filename
      - score
      type: object
      properties:
        score:
          maximum: 1
          minimum: 0
          type: number
          description: The similarity score for the result
        filename:
          type: string
          description: The name of the vector store file
        file_id:
          type: string
          description: The ID of the vector store file
          x-ballerina-name: fileId
        attributes:
          $ref: '#/components/schemas/VectorStoreFileAttributes'
        content:
          type: array
          description: Content chunks from the file
          items:
            $ref: '#/components/schemas/VectorStoreSearchResultContentObject'
      additionalProperties: false
      x-oaiMeta:
        name: Vector store search result item
    AudioResponseFormat:
      type: string
      description: |
        The format of the output, in one of these options: `json`, `text`, `srt`, `verbose_json`, or `vtt`. For `gpt-4o-transcribe` and `gpt-4o-mini-transcribe`, the only supported format is `json`
      default: json
      enum:
      - json
      - text
      - srt
      - verbose_json
      - vtt
    ResponseFunctionCallArgumentsDoneEvent:
      required:
      - arguments
      - item_id
      - output_index
      - type
      type: object
      properties:
        item_id:
          type: string
          description: The ID of the item
          x-ballerina-name: itemId
        arguments:
          type: string
          description: The function-call arguments
        type:
          type: string
          enum:
          - response.function_call_arguments.done
          x-stainless-const: true
        output_index:
          type: integer
          description: The index of the output item
          x-ballerina-name: outputIndex
      description: Emitted when function-call arguments are finalized
      x-oaiMeta:
        name: response.function_call_arguments.done
        group: responses
        example: |
          {
            "type": "response.function_call_arguments.done",
            "item_id": "item-abc",
            "output_index": 1,
            "arguments": "{ \"arg\": 123 }"
          }
    AssistantObjectToolResourcesFileSearch:
      type: object
      properties:
        vector_store_ids:
          maxItems: 1
          type: array
          description: |
            The ID of the [vector store](/docs/api-reference/vector-stores/object) attached to this assistant. There can be a maximum of 1 vector store attached to the assistant
          items:
            type: string
          x-ballerina-name: vectorStoreIds
    ModifyThreadRequestToolResources:
      type: object
      properties:
        code_interpreter:
          allOf:
          - $ref: '#/components/schemas/CreateAssistantRequestToolResourcesCodeInterpreter'
          x-ballerina-name: codeInterpreter
        file_search:
          allOf:
          - $ref: '#/components/schemas/ModifyThreadRequestToolResourcesFileSearch'
          x-ballerina-name: fileSearch
      description: |
        A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs
      nullable: true
    ResponseUsageOutputTokensDetails:
      required:
      - reasoning_tokens
      type: object
      properties:
        reasoning_tokens:
          type: integer
          description: The number of reasoning tokens
          x-ballerina-name: reasoningTokens
      description: A detailed breakdown of the output tokens
    ComputerAction:
      oneOf:
      - $ref: '#/components/schemas/Click'
      - $ref: '#/components/schemas/DoubleClick'
      - $ref: '#/components/schemas/Drag'
      - $ref: '#/components/schemas/KeyPress'
      - $ref: '#/components/schemas/Move'
      - $ref: '#/components/schemas/Screenshot'
      - $ref: '#/components/schemas/Scroll'
      - $ref: '#/components/schemas/Type'
      - $ref: '#/components/schemas/Wait'
    EvalJsonlFileIdSource:
      title: EvalJsonlFileIdSource
      required:
      - id
      - type
      type: object
      properties:
        id:
          type: string
          description: The identifier of the file
        type:
          type: string
          description: The type of jsonl source. Always `file_id`
          default: file_id
          enum:
          - file_id
          x-stainless-const: true
    RunStepDetailsToolCallsCodeObjectCodeInterpreter:
      required:
      - input
      - outputs
      type: object
      properties:
        outputs:
          type: array
          description: "The outputs from the Code Interpreter tool call. Code Interpreter\
            \ can output one or more items, including text (`logs`) or images (`image`).\
            \ Each of these are represented by a different object type"
          items:
            $ref: '#/components/schemas/RunStepDetailsToolCallsCodeObjectCodeInterpreterOutputs'
        input:
          type: string
          description: The input to the Code Interpreter tool call
      description: The Code Interpreter tool call definition
    RealtimeResponseCreateParams:
      type: object
      properties:
        voice:
          $ref: '#/components/schemas/VoiceIdsShared'
        instructions:
          type: string
          description: "The default system instructions (i.e. system message) prepended\
            \ to model \ncalls. This field allows the client to guide the model on\
            \ desired \nresponses. The model can be instructed on response content\
            \ and format, \n(e.g. \"be extremely succinct\", \"act friendly\", \"\
            here are examples of good \nresponses\") and on audio behavior (e.g. \"\
            talk quickly\", \"inject emotion \ninto your voice\", \"laugh frequently\"\
            ). The instructions are not guaranteed \nto be followed by the model,\
            \ but they provide guidance to the model on the \ndesired behavior.\n\n\
            Note that the server sets default instructions which will be used if this\
            \ \nfield is not set and are visible in the `session.created` event at\
            \ the \nstart of the session\n"
        input:
          type: array
          description: |
            Input items to include in the prompt for the model. Using this field
            creates a new context for this Response instead of using the default
            conversation. An empty array `[]` will clear the context for this Response.
            Note that this can include references to items from the default conversation
          items:
            $ref: '#/components/schemas/RealtimeConversationItemWithReference'
        metadata:
          $ref: '#/components/schemas/Metadata'
        modalities:
          type: array
          description: |
            The set of modalities the model can respond with. To disable audio,
            set this to ["text"]
          items:
            type: string
            enum:
            - text
            - audio
        max_response_output_tokens:
          description: |
            Maximum number of output tokens for a single assistant response,
            inclusive of tool calls. Provide an integer between 1 and 4096 to
            limit output tokens, or `inf` for the maximum available tokens for a
            given model. Defaults to `inf`
          oneOf:
          - type: integer
          - type: string
            enum:
            - inf
            x-stainless-const: true
          x-ballerina-name: maxResponseOutputTokens
        output_audio_format:
          type: string
          description: |
            The format of output audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`
          enum:
          - pcm16
          - g711_ulaw
          - g711_alaw
          x-ballerina-name: outputAudioFormat
        temperature:
          type: number
          description: |
            Sampling temperature for the model, limited to [0.6, 1.2]. Defaults to 0.8
        tool_choice:
          type: string
          description: "How the model chooses tools. Options are `auto`, `none`, `required`,\
            \ or \nspecify a function, like `{\"type\": \"function\", \"function\"\
            : {\"name\": \"my_function\"}}`\n"
          x-ballerina-name: toolChoice
        tools:
          type: array
          description: Tools (functions) available to the model
          items:
            $ref: '#/components/schemas/RealtimeResponseCreateParamsTools'
        conversation:
          description: "Controls which conversation the response is added to. Currently\
            \ supports\n`auto` and `none`, with `auto` as the default value. The `auto`\
            \ value\nmeans that the contents of the response will be added to the\
            \ default\nconversation. Set this to `none` to create an out-of-band response\
            \ which \nwill not add items to default conversation\n"
          oneOf:
          - type: string
          - type: string
            default: auto
            enum:
            - auto
            - none
      description: Create a new Realtime response with these parameters
    CertificateCertificateDetails:
      type: object
      properties:
        expires_at:
          type: integer
          description: The Unix timestamp (in seconds) of when the certificate expires
          x-ballerina-name: expiresAt
        content:
          type: string
          description: The content of the certificate in PEM format
        valid_at:
          type: integer
          description: The Unix timestamp (in seconds) of when the certificate becomes
            valid
          x-ballerina-name: validAt
    EvalRunOutputItemList:
      title: EvalRunOutputItemList
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
      type: object
      properties:
        first_id:
          type: string
          description: The identifier of the first eval run output item in the data
            array
          x-ballerina-name: firstId
        data:
          type: array
          description: |
            An array of eval run output item objects
          items:
            $ref: '#/components/schemas/EvalRunOutputItem'
        last_id:
          type: string
          description: The identifier of the last eval run output item in the data
            array
          x-ballerina-name: lastId
        has_more:
          type: boolean
          description: Indicates whether there are more eval run output items available
          x-ballerina-name: hasMore
        object:
          type: string
          description: |
            The type of this object. It is always set to "list"
          default: list
          enum:
          - list
          x-stainless-const: true
      description: |
        An object representing a list of output items for an evaluation run
      x-oaiMeta:
        name: The eval run output item list object
        group: evals
        example: |
          {
            "object": "list",
            "data": [
              {
                "object": "eval.run.output_item",
                "id": "outputitem_67abd55eb6548190bb580745d5644a33",
                "run_id": "evalrun_67abd54d60ec8190832b46859da808f7",
                "eval_id": "eval_67abd54d9b0081909a86353f6fb9317a",
                "created_at": 1739314509,
                "status": "pass",
                "datasource_item_id": 137,
                "datasource_item": {
                    "teacher": "To grade essays, I only check for style, content, and grammar.",
                    "student": "I am a student who is trying to write the best essay."
                },
                "results": [
                  {
                    "name": "String Check Grader",
                    "type": "string-check-grader",
                    "score": 1.0,
                    "passed": true,
                  }
                ],
                "sample": {
                  "input": [
                    {
                      "role": "system",
                      "content": "You are an evaluator bot..."
                    },
                    {
                      "role": "user",
                      "content": "You are assessing..."
                    }
                  ],
                  "output": [
                    {
                      "role": "assistant",
                      "content": "The rubric is not clear nor concise."
                    }
                  ],
                  "finish_reason": "stop",
                  "model": "gpt-4o-2024-08-06",
                  "usage": {
                    "total_tokens": 521,
                    "completion_tokens": 2,
                    "prompt_tokens": 519,
                    "cached_tokens": 0
                  },
                  "error": null,
                  "temperature": 1.0,
                  "max_completion_tokens": 2048,
                  "top_p": 1.0,
                  "seed": 42
                }
              },
            ],
            "first_id": "outputitem_67abd55eb6548190bb580745d5644a33",
            "last_id": "outputitem_67abd55eb6548190bb580745d5644a33",
            "has_more": false
          }
    VoiceIdsShared:
      example: ash
      anyOf:
      - $ref: '#/components/schemas/VoiceIdsSharedAnyOf1'
      - $ref: '#/components/schemas/VoiceIdsSharedVoiceIdsSharedAnyOf12'
    AuditLogCertificatesactivatedCertificates:
      type: object
      properties:
        name:
          type: string
          description: The name of the certificate
        id:
          type: string
          description: The certificate ID
    StaticChunkingStrategyRequestParam:
      title: Static Chunking Strategy
      required:
      - static
      - type
      type: object
      properties:
        static:
          $ref: '#/components/schemas/StaticChunkingStrategy'
        type:
          type: string
          description: Always `static`
          enum:
          - static
          x-stainless-const: true
      additionalProperties: false
      description: Customize your own chunking strategy by setting chunk size and
        chunk overlap
    MessageObjectIncompleteDetails:
      required:
      - reason
      type: object
      properties:
        reason:
          type: string
          description: The reason the message is incomplete
          enum:
          - content_filter
          - max_tokens
          - run_cancelled
          - run_expired
          - run_failed
      description: "On an incomplete message, details about why the message is incomplete"
      nullable: true
    VectorStoreFileObject:
      title: Vector store files
      required:
      - created_at
      - id
      - last_error
      - object
      - status
      - usage_bytes
      - vector_store_id
      type: object
      properties:
        chunking_strategy:
          type: object
          description: The strategy used to chunk the file
          oneOf:
          - $ref: '#/components/schemas/StaticChunkingStrategyResponseParam'
          - $ref: '#/components/schemas/OtherChunkingStrategyResponseParam'
          x-ballerina-name: chunkingStrategy
        usage_bytes:
          type: integer
          description: The total vector store usage in bytes. Note that this may be
            different from the original file size
          x-ballerina-name: usageBytes
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the vector store file
            was created
          x-ballerina-name: createdAt
        attributes:
          $ref: '#/components/schemas/VectorStoreFileAttributes'
        id:
          type: string
          description: "The identifier, which can be referenced in API endpoints"
        last_error:
          allOf:
          - $ref: '#/components/schemas/VectorStoreFileObjectLastError'
          x-ballerina-name: lastError
        object:
          type: string
          description: "The object type, which is always `vector_store.file`"
          enum:
          - vector_store.file
          x-stainless-const: true
        vector_store_id:
          type: string
          description: "The ID of the [vector store](/docs/api-reference/vector-stores/object)\
            \ that the [File](/docs/api-reference/files) is attached to"
          x-ballerina-name: vectorStoreId
        status:
          type: string
          description: "The status of the vector store file, which can be either `in_progress`,\
            \ `completed`, `cancelled`, or `failed`. The status `completed` indicates\
            \ that the vector store file is ready for use"
          enum:
          - in_progress
          - completed
          - cancelled
          - failed
      description: A list of files attached to a vector store
      x-oaiMeta:
        name: The vector store file object
        beta: true
        example: |
          {
            "id": "file-abc123",
            "object": "vector_store.file",
            "usage_bytes": 1234,
            "created_at": 1698107661,
            "vector_store_id": "vs_abc123",
            "status": "completed",
            "last_error": null,
            "chunking_strategy": {
              "type": "static",
              "static": {
                "max_chunk_size_tokens": 800,
                "chunk_overlap_tokens": 400
              }
            }
          }
    ChatCompletionResponseMessageAudio:
      required:
      - data
      - expires_at
      - id
      - transcript
      type: object
      properties:
        expires_at:
          type: integer
          description: |
            The Unix timestamp (in seconds) for when this audio response will
            no longer be accessible on the server for use in multi-turn
            conversations
          x-ballerina-name: expiresAt
        transcript:
          type: string
          description: Transcript of the audio generated by the model
        data:
          type: string
          description: |
            Base64 encoded audio bytes generated by the model, in the format
            specified in the request
        id:
          type: string
          description: Unique identifier for this audio response
      description: |
        If the audio output modality is requested, this object contains data
        about the audio response from the model. [Learn more](/docs/guides/audio)
      nullable: true
    ResponseRefusalDeltaEvent:
      required:
      - content_index
      - delta
      - item_id
      - output_index
      - type
      type: object
      properties:
        item_id:
          type: string
          description: |
            The ID of the output item that the refusal text is added to
          x-ballerina-name: itemId
        content_index:
          type: integer
          description: |
            The index of the content part that the refusal text is added to
          x-ballerina-name: contentIndex
        delta:
          type: string
          description: |
            The refusal text that is added
        type:
          type: string
          description: |
            The type of the event. Always `response.refusal.delta`
          enum:
          - response.refusal.delta
          x-stainless-const: true
        output_index:
          type: integer
          description: |
            The index of the output item that the refusal text is added to
          x-ballerina-name: outputIndex
      description: Emitted when there is a partial refusal text
      x-oaiMeta:
        name: response.refusal.delta
        group: responses
        example: |
          {
            "type": "response.refusal.delta",
            "item_id": "msg_123",
            "output_index": 0,
            "content_index": 0,
            "delta": "refusal text so far"
          }
    FineTuningJobError:
      required:
      - code
      - message
      - param
      type: object
      properties:
        code:
          type: string
          description: A machine-readable error code
        param:
          type: string
          description: "The parameter that was invalid, usually `training_file` or\
            \ `validation_file`. This field will be null if the failure was not parameter-specific"
          nullable: true
        message:
          type: string
          description: A human-readable error message
      description: "For fine-tuning jobs that have `failed`, this will contain more\
        \ information on the cause of the failure"
      nullable: true
    ModelIdsResponses:
      example: gpt-4o
      anyOf:
      - $ref: '#/components/schemas/ModelIdsShared'
      - $ref: '#/components/schemas/ResponsesOnlyModel'
    ChatCompletionList:
      title: ChatCompletionList
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
      type: object
      properties:
        first_id:
          type: string
          description: The identifier of the first chat completion in the data array
          x-ballerina-name: firstId
        data:
          type: array
          description: |
            An array of chat completion objects
          items:
            $ref: '#/components/schemas/CreateChatCompletionResponse'
        last_id:
          type: string
          description: The identifier of the last chat completion in the data array
          x-ballerina-name: lastId
        has_more:
          type: boolean
          description: Indicates whether there are more Chat Completions available
          x-ballerina-name: hasMore
        object:
          type: string
          description: |
            The type of this object. It is always set to "list"
          default: list
          enum:
          - list
          x-stainless-const: true
      description: |
        An object representing a list of Chat Completions
      x-oaiMeta:
        name: The chat completion list object
        group: chat
        example: |
          {
            "object": "list",
            "data": [
              {
                "object": "chat.completion",
                "id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2",
                "model": "gpt-4o-2024-08-06",
                "created": 1738960610,
                "request_id": "req_ded8ab984ec4bf840f37566c1011c417",
                "tool_choice": null,
                "usage": {
                  "total_tokens": 31,
                  "completion_tokens": 18,
                  "prompt_tokens": 13
                },
                "seed": 4944116822809979520,
                "top_p": 1.0,
                "temperature": 1.0,
                "presence_penalty": 0.0,
                "frequency_penalty": 0.0,
                "system_fingerprint": "fp_50cad350e4",
                "input_user": null,
                "service_tier": "default",
                "tools": null,
                "metadata": {},
                "choices": [
                  {
                    "index": 0,
                    "message": {
                      "content": "Mind of circuits hum,  \nLearning patterns in silence  \nFuture's quiet spark.",
                      "role": "assistant",
                      "tool_calls": null,
                      "function_call": null
                    },
                    "finish_reason": "stop",
                    "logprobs": null
                  }
                ],
                "response_format": null
              }
            ],
            "first_id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2",
            "last_id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2",
            "has_more": false
          }
    ChunkingStrategyRequestParam:
      type: object
      description: "The chunking strategy used to chunk the file(s). If not set, will\
        \ use the `auto` strategy"
      oneOf:
      - $ref: '#/components/schemas/AutoChunkingStrategyRequestParam'
      - $ref: '#/components/schemas/StaticChunkingStrategyRequestParam'
    CreateModerationResponseCategoryScores:
      required:
      - harassment
      - harassment/threatening
      - hate
      - hate/threatening
      - illicit
      - illicit/violent
      - self-harm
      - self-harm/instructions
      - self-harm/intent
      - sexual
      - sexual/minors
      - violence
      - violence/graphic
      type: object
      properties:
        illicit/violent:
          type: number
          description: The score for the category 'illicit/violent'
          x-ballerina-name: illicitViolent
        self-harm/instructions:
          type: number
          description: The score for the category 'self-harm/instructions'
          x-ballerina-name: selfHarmInstructions
        harassment:
          type: number
          description: The score for the category 'harassment'
        violence/graphic:
          type: number
          description: The score for the category 'violence/graphic'
          x-ballerina-name: violenceGraphic
        illicit:
          type: number
          description: The score for the category 'illicit'
        self-harm/intent:
          type: number
          description: The score for the category 'self-harm/intent'
          x-ballerina-name: selfHarmIntent
        hate/threatening:
          type: number
          description: The score for the category 'hate/threatening'
          x-ballerina-name: hateThreatening
        sexual/minors:
          type: number
          description: The score for the category 'sexual/minors'
          x-ballerina-name: sexualMinors
        harassment/threatening:
          type: number
          description: The score for the category 'harassment/threatening'
          x-ballerina-name: harassmentThreatening
        hate:
          type: number
          description: The score for the category 'hate'
        self-harm:
          type: number
          description: The score for the category 'self-harm'
          x-ballerina-name: selfHarm
        sexual:
          type: number
          description: The score for the category 'sexual'
        violence:
          type: number
          description: The score for the category 'violence'
      description: A list of the categories along with their scores as predicted by
        model
    RealtimeServerEventSessionCreated:
      required:
      - event_id
      - session
      - type
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event
          x-ballerina-name: eventId
        session:
          $ref: '#/components/schemas/RealtimeSession'
        type:
          type: string
          description: "The event type, must be `session.created`"
          enum:
          - session.created
          x-stainless-const: true
      description: "Returned when a Session is created. Emitted automatically when\
        \ a new \nconnection is established as the first server event. This event\
        \ will contain \nthe default Session configuration\n"
      x-oaiMeta:
        name: session.created
        group: realtime
        example: |
          {
              "event_id": "event_1234",
              "type": "session.created",
              "session": {
                  "id": "sess_001",
                  "object": "realtime.session",
                  "model": "gpt-4o-realtime-preview",
                  "modalities": ["text", "audio"],
                  "instructions": "...model instructions here...",
                  "voice": "sage",
                  "input_audio_format": "pcm16",
                  "output_audio_format": "pcm16",
                  "input_audio_transcription": null,
                  "turn_detection": {
                      "type": "server_vad",
                      "threshold": 0.5,
                      "prefix_padding_ms": 300,
                      "silence_duration_ms": 200
                  },
                  "tools": [],
                  "tool_choice": "auto",
                  "temperature": 0.8,
                  "max_response_output_tokens": "inf"
              }
          }
    RealtimeServerEventResponseFunctionCallArgumentsDelta:
      required:
      - call_id
      - delta
      - event_id
      - item_id
      - output_index
      - response_id
      - type
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event
          x-ballerina-name: eventId
        item_id:
          type: string
          description: The ID of the function call item
          x-ballerina-name: itemId
        response_id:
          type: string
          description: The ID of the response
          x-ballerina-name: responseId
        delta:
          type: string
          description: The arguments delta as a JSON string
        type:
          type: string
          description: |
            The event type, must be `response.function_call_arguments.delta`
          enum:
          - response.function_call_arguments.delta
          x-stainless-const: true
        output_index:
          type: integer
          description: The index of the output item in the response
          x-ballerina-name: outputIndex
        call_id:
          type: string
          description: The ID of the function call
          x-ballerina-name: callId
      description: |
        Returned when the model-generated function call arguments are updated
      x-oaiMeta:
        name: response.function_call_arguments.delta
        group: realtime
        example: |
          {
              "event_id": "event_5354",
              "type": "response.function_call_arguments.delta",
              "response_id": "resp_002",
              "item_id": "fc_001",
              "output_index": 0,
              "call_id": "call_001",
              "delta": "{\"location\": \"San\""
          }
    ResponseReasoningSummaryTextDeltaEvent:
      required:
      - delta
      - item_id
      - output_index
      - summary_index
      - type
      type: object
      properties:
        item_id:
          type: string
          description: |
            The ID of the item this summary text delta is associated with
          x-ballerina-name: itemId
        summary_index:
          type: integer
          description: |
            The index of the summary part within the reasoning summary
          x-ballerina-name: summaryIndex
        delta:
          type: string
          description: |
            The text delta that was added to the summary
        type:
          type: string
          description: |
            The type of the event. Always `response.reasoning_summary_text.delta`
          enum:
          - response.reasoning_summary_text.delta
          x-stainless-const: true
        output_index:
          type: integer
          description: |
            The index of the output item this summary text delta is associated with
          x-ballerina-name: outputIndex
      description: Emitted when a delta is added to a reasoning summary text
      x-oaiMeta:
        name: response.reasoning_summary_text.delta
        group: responses
        example: |
          {
            "type": "response.reasoning_summary_text.delta",
            "item_id": "rs_6806bfca0b2481918a5748308061a2600d3ce51bdffd5476",
            "output_index": 0,
            "summary_index": 0,
            "delta": "**Respond"
          }
    UsageTimeBucketResult:
      oneOf:
      - $ref: '#/components/schemas/UsageCompletionsResult'
      - $ref: '#/components/schemas/UsageEmbeddingsResult'
      - $ref: '#/components/schemas/UsageModerationsResult'
      - $ref: '#/components/schemas/UsageImagesResult'
      - $ref: '#/components/schemas/UsageAudioSpeechesResult'
      - $ref: '#/components/schemas/UsageAudioTranscriptionsResult'
      - $ref: '#/components/schemas/UsageVectorStoresResult'
      - $ref: '#/components/schemas/UsageCodeInterpreterSessionsResult'
      - $ref: '#/components/schemas/CostsResult'
    MessageContentImageUrlObject:
      title: Image URL
      required:
      - image_url
      - type
      type: object
      properties:
        image_url:
          allOf:
          - $ref: '#/components/schemas/MessageContentImageUrlObjectImageUrl'
          x-ballerina-name: imageUrl
        type:
          type: string
          description: The type of the content part
          enum:
          - image_url
          x-stainless-const: true
      description: References an image URL in the content of a message
    AuditLogServiceAccountcreatedData:
      type: object
      properties:
        role:
          type: string
          description: The role of the service account. Is either `owner` or `member`
      description: The payload used to create the service account
    ToolChoiceTypes:
      title: Hosted tool
      required:
      - type
      type: object
      properties:
        type:
          type: string
          description: |
            The type of hosted tool the model should to use. Learn more about
            [built-in tools](/docs/guides/tools).

            Allowed values are:
            - `file_search`
            - `web_search_preview`
            - `computer_use_preview`
          enum:
          - file_search
          - web_search_preview
          - computer_use_preview
          - web_search_preview_2025_03_11
      description: |
        Indicates that the model should use a built-in tool to generate a response.
        [Learn more about built-in tools](/docs/guides/tools)
    CodeInterpreterTextOutput:
      title: Code interpreter text output
      required:
      - logs
      - type
      type: object
      properties:
        type:
          type: string
          description: |
            The type of the code interpreter text output. Always `logs`
          enum:
          - logs
          x-stainless-const: true
        logs:
          type: string
          description: |
            The logs of the code interpreter tool call
      description: |
        The output of a code interpreter tool call that is text
    EvalStringCheckGrader:
      title: StringCheckGrader
      required:
      - input
      - name
      - operation
      - reference
      - type
      type: object
      properties:
        reference:
          type: string
          description: The reference text. This may include template strings
        input:
          type: string
          description: The input text. This may include template strings
        name:
          type: string
          description: The name of the grader
        type:
          type: string
          description: "The object type, which is always `string_check`"
          enum:
          - string_check
          x-stainless-const: true
        operation:
          type: string
          description: "The string check operation to perform. One of `eq`, `ne`,\
            \ `like`, or `ilike`"
          enum:
          - eq
          - ne
          - like
          - ilike
      description: |
        A StringCheckGrader object that performs a string comparison between input and reference using a specified operation
      x-oaiMeta:
        name: The eval string check grader object
        group: evals
        example: |
          {
            "type": "string_check",
            "name": "Example string check grader",
            "input": "{{sample.output_text}}",
            "reference": "{{item.label}}",
            "operation": "eq"
          }
    ResponseItemList:
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
      type: object
      properties:
        first_id:
          type: string
          description: The ID of the first item in the list
          x-ballerina-name: firstId
        data:
          type: array
          description: A list of items used to generate this response
          items:
            $ref: '#/components/schemas/ItemResource'
        last_id:
          type: string
          description: The ID of the last item in the list
          x-ballerina-name: lastId
        has_more:
          type: boolean
          description: Whether there are more items available
          x-ballerina-name: hasMore
        object:
          type: string
          description: "The type of object returned, must be `list`"
          enum:
          - list
          x-stainless-const: true
      description: A list of Response items
      x-oaiMeta:
        name: The input item list
        group: responses
        example: |
          {
            "object": "list",
            "data": [
              {
                "id": "msg_abc123",
                "type": "message",
                "role": "user",
                "content": [
                  {
                    "type": "input_text",
                    "text": "Tell me a three sentence bedtime story about a unicorn."
                  }
                ]
              }
            ],
            "first_id": "msg_abc123",
            "last_id": "msg_abc123",
            "has_more": false
          }
    VectorStoreSearchRequest:
      required:
      - query
      type: object
      properties:
        max_num_results:
          maximum: 50
          minimum: 1
          type: integer
          description: The maximum number of results to return. This number should
            be between 1 and 50 inclusive
          default: 10
          x-ballerina-name: maxNumResults
        ranking_options:
          allOf:
          - $ref: '#/components/schemas/VectorStoreSearchRequestRankingOptions'
          x-ballerina-name: rankingOptions
        query:
          description: A query string for a search
          oneOf:
          - type: string
          - type: array
            items:
              minItems: 1
              type: string
              description: A list of queries to search for.
        rewrite_query:
          type: boolean
          description: Whether to rewrite the natural language query for vector search
          default: false
          x-ballerina-name: rewriteQuery
        filters:
          description: A filter to apply based on file attributes
          oneOf:
          - $ref: '#/components/schemas/ComparisonFilter'
          - $ref: '#/components/schemas/CompoundFilter'
      additionalProperties: false
      x-oaiMeta:
        name: Vector store search request
    ChatCompletionMessageListData:
      allOf:
      - $ref: '#/components/schemas/ChatCompletionResponseMessage'
      - $ref: '#/components/schemas/DataAllOf2'
    RunStepStreamEventRunStepStreamEventRunStepStreamEventRunStepStreamEventOneOf1234:
      required:
      - data
      - event
      type: object
      properties:
        data:
          $ref: '#/components/schemas/RunStepObject'
        event:
          type: string
          enum:
          - thread.run.step.completed
          x-stainless-const: true
      description: "Occurs when a [run step](/docs/api-reference/run-steps/step-object)\
        \ is completed"
      x-oaiMeta:
        dataDescription: "`data` is a [run step](/docs/api-reference/run-steps/step-object)"
    WebSearch:
      title: Web search
      type: object
      properties:
        search_context_size:
          allOf:
          - $ref: '#/components/schemas/WebSearchContextSize'
          x-ballerina-name: searchContextSize
        user_location:
          allOf:
          - $ref: '#/components/schemas/WebSearchUserLocation'
          x-ballerina-name: userLocation
      description: |
        This tool searches the web for relevant results to use in a response.
        Learn more about the [web search tool](/docs/guides/tools-web-search?api-mode=chat)
    ProjectServiceAccountCreateRequest:
      required:
      - name
      type: object
      properties:
        name:
          type: string
          description: The name of the service account being created
    ResponsesOnlyModel:
      title: ResponsesOnlyModel
      type: string
      enum:
      - o1-pro
      - o1-pro-2025-03-19
      - computer-use-preview
      - computer-use-preview-2025-03-11
    CreateChatCompletionStreamResponse:
      required:
      - choices
      - created
      - id
      - model
      - object
      type: object
      properties:
        created:
          type: integer
          description: The Unix timestamp (in seconds) of when the chat completion
            was created. Each chunk has the same timestamp
        usage:
          $ref: '#/components/schemas/CompletionUsage'
        model:
          type: string
          description: The model to generate the completion
        service_tier:
          allOf:
          - $ref: '#/components/schemas/ServiceTier'
          x-ballerina-name: serviceTier
        id:
          type: string
          description: A unique identifier for the chat completion. Each chunk has
            the same ID
        choices:
          type: array
          description: |
            A list of chat completion choices. Can contain more than one elements if `n` is greater than 1. Can also be empty for the
            last chunk if you set `stream_options: {"include_usage": true}`
          items:
            $ref: '#/components/schemas/CreateChatCompletionStreamResponseChoices'
        system_fingerprint:
          type: string
          description: |
            This fingerprint represents the backend configuration that the model runs with.
            Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism
          x-ballerina-name: systemFingerprint
        object:
          type: string
          description: "The object type, which is always `chat.completion.chunk`"
          enum:
          - chat.completion.chunk
          x-stainless-const: true
      description: "Represents a streamed chunk of a chat completion response returned\n\
        by the model, based on the provided input. \n[Learn more](/docs/guides/streaming-responses)\n"
      x-oaiMeta:
        name: The chat completion chunk object
        group: chat
        example: |
          {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"role":"assistant","content":""},"logprobs":null,"finish_reason":null}]}

          {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"content":"Hello"},"logprobs":null,"finish_reason":null}]}

          ....

          {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}]}
    ? RunStepStreamEventRunStepStreamEventRunStepStreamEventRunStepStreamEventRunStepStreamEventRunStepStreamEventRunStepStreamEventOneOf1234567
    : required:
      - data
      - event
      type: object
      properties:
        data:
          $ref: '#/components/schemas/RunStepObject'
        event:
          type: string
          enum:
          - thread.run.step.expired
          x-stainless-const: true
      description: "Occurs when a [run step](/docs/api-reference/run-steps/step-object)\
        \ expires"
      x-oaiMeta:
        dataDescription: "`data` is a [run step](/docs/api-reference/run-steps/step-object)"
    CreateEvalCompletionsRunDataSource:
      title: CompletionsRunDataSource
      required:
      - source
      - type
      type: object
      properties:
        input_messages:
          oneOf:
          - title: TemplateInputMessages
            required:
            - template
            - type
            type: object
            properties:
              type:
                type: string
                description: The type of input messages. Always `template`.
                enum:
                - template
              template:
                type: array
                description: "A list of chat messages forming the prompt or context.\
                  \ May include variable references to the \"item\" namespace, ie\
                  \ {{item.name}}."
                items:
                  oneOf:
                  - $ref: '#/components/schemas/EasyInputMessage'
                  - $ref: '#/components/schemas/EvalItem'
          - title: ItemReferenceInputMessages
            required:
            - item_reference
            - type
            type: object
            properties:
              type:
                type: string
                description: The type of input messages. Always `item_reference`.
                enum:
                - item_reference
              item_reference:
                type: string
                description: "A reference to a variable in the \"item\" namespace.\
                  \ Ie, \"item.name\""
          x-ballerina-name: inputMessages
        model:
          type: string
          description: The name of the model to use for generating completions (e.g.
            "o3-mini")
        source:
          oneOf:
          - $ref: '#/components/schemas/EvalJsonlFileContentSource'
          - $ref: '#/components/schemas/EvalJsonlFileIdSource'
          - $ref: '#/components/schemas/EvalStoredCompletionsSource'
        type:
          type: string
          description: The type of run data source. Always `completions`
          default: completions
          enum:
          - completions
        sampling_params:
          allOf:
          - $ref: '#/components/schemas/CreateEvalCompletionsRunDataSourceSamplingParams'
          x-ballerina-name: samplingParams
      description: |
        A CompletionsRunDataSource object describing a model sampling configuration
      x-oaiMeta:
        name: The completions data source object used to configure an individual run
        group: eval runs
        example: |
          {
            "name": "gpt-4o-mini-2024-07-18",
            "data_source": {
              "type": "completions",
              "input_messages": {
                "type": "item_reference",
                "item_reference": "item.input"
              },
              "model": "gpt-4o-mini-2024-07-18",
              "source": {
                "type": "stored_completions",
                "model": "gpt-4o-mini-2024-07-18"
              }
            }
          }
    CostsResultAmount:
      type: object
      properties:
        currency:
          type: string
          description: Lowercase ISO-4217 currency e.g. "usd"
        value:
          type: number
          description: The numeric value of the cost
      description: The monetary value in its associated currency
    ChatCompletionMessageToolCall:
      required:
      - function
      - id
      - type
      type: object
      properties:
        function:
          $ref: '#/components/schemas/ChatCompletionMessageToolCallFunction'
        id:
          type: string
          description: The ID of the tool call
        type:
          type: string
          description: "The type of the tool. Currently, only `function` is supported"
          enum:
          - function
          x-stainless-const: true
    RealtimeServerEventResponseFunctionCallArgumentsDone:
      required:
      - arguments
      - call_id
      - event_id
      - item_id
      - output_index
      - response_id
      - type
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event
          x-ballerina-name: eventId
        item_id:
          type: string
          description: The ID of the function call item
          x-ballerina-name: itemId
        response_id:
          type: string
          description: The ID of the response
          x-ballerina-name: responseId
        arguments:
          type: string
          description: The final arguments as a JSON string
        type:
          type: string
          description: |
            The event type, must be `response.function_call_arguments.done`
          enum:
          - response.function_call_arguments.done
          x-stainless-const: true
        output_index:
          type: integer
          description: The index of the output item in the response
          x-ballerina-name: outputIndex
        call_id:
          type: string
          description: The ID of the function call
          x-ballerina-name: callId
      description: |
        Returned when the model-generated function call arguments are done streaming.
        Also emitted when a Response is interrupted, incomplete, or cancelled
      x-oaiMeta:
        name: response.function_call_arguments.done
        group: realtime
        example: |
          {
              "event_id": "event_5556",
              "type": "response.function_call_arguments.done",
              "response_id": "resp_002",
              "item_id": "fc_001",
              "output_index": 0,
              "call_id": "call_001",
              "arguments": "{\"location\": \"San Francisco\"}"
          }
    CodeInterpreterFileOutputFiles:
      required:
      - file_id
      - mime_type
      type: object
      properties:
        mime_type:
          type: string
          description: |
            The MIME type of the file
          x-ballerina-name: mimeType
        file_id:
          type: string
          description: |
            The ID of the file
          x-ballerina-name: fileId
    CreateImageEditRequest:
      required:
      - image
      - prompt
      type: object
      properties:
        image:
          description: "The image(s) to edit. Must be a supported image file or an\
            \ array of images.\n\nFor `gpt-image-1`, each image should be a `png`,\
            \ `webp`, or `jpg` file less \nthan 25MB. You can provide up to 16 images.\n\
            \nFor `dall-e-2`, you can only provide one image, and it should be a square\
            \ \n`png` file less than 4MB\n"
          anyOf:
          - type: string
            format: binary
          - maxItems: 16
            type: array
            items:
              type: string
              format: binary
        response_format:
          type: string
          description: "The format in which the generated images are returned. Must\
            \ be one of `url` or `b64_json`. URLs are only valid for 60 minutes after\
            \ the image has been generated. This parameter is only supported for `dall-e-2`,\
            \ as `gpt-image-1` will always return base64-encoded images"
          nullable: true
          example: url
          default: url
          enum:
          - url
          - b64_json
          x-ballerina-name: responseFormat
        size:
          type: string
          description: "The size of the generated images. Must be one of `1024x1024`,\
            \ `1536x1024` (landscape), `1024x1536` (portrait), or `auto` (default\
            \ value) for `gpt-image-1`, and one of `256x256`, `512x512`, or `1024x1024`\
            \ for `dall-e-2`"
          nullable: true
          example: 1024x1024
          default: 1024x1024
          enum:
          - 256x256
          - 512x512
          - 1024x1024
          - 1536x1024
          - 1024x1536
          - auto
        model:
          description: The model to use for image generation. Only `dall-e-2` and
            `gpt-image-1` are supported. Defaults to `dall-e-2` unless a parameter
            specific to `gpt-image-1` is used
          nullable: true
          example: gpt-image-1
          anyOf:
          - type: string
          - type: string
            enum:
            - dall-e-2
            - gpt-image-1
            x-stainless-const: true
          default: dall-e-2
          x-oaiTypeLabel: string
        prompt:
          type: string
          description: "A text description of the desired image(s). The maximum length\
            \ is 1000 characters for `dall-e-2`, and 32000 characters for `gpt-image-1`"
          example: A cute baby sea otter wearing a beret
        user:
          type: string
          description: |
            A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids)
          example: user-1234
        "n":
          maximum: 10
          minimum: 1
          type: integer
          description: The number of images to generate. Must be between 1 and 10
          nullable: true
          example: 1
          default: 1
        mask:
          type: string
          description: "An additional image whose fully transparent areas (e.g. where\
            \ alpha is zero) indicate where `image` should be edited. If there are\
            \ multiple images provided, the mask will be applied on the first image.\
            \ Must be a valid PNG file, less than 4MB, and have the same dimensions\
            \ as `image`"
          format: binary
        quality:
          type: string
          description: |
            The quality of the image that will be generated. `high`, `medium` and `low` are only supported for `gpt-image-1`. `dall-e-2` only supports `standard` quality. Defaults to `auto`
          nullable: true
          example: high
          default: auto
          enum:
          - standard
          - low
          - medium
          - high
          - auto
    Type:
      title: Type
      required:
      - text
      - type
      type: object
      properties:
        text:
          type: string
          description: |
            The text to type
        type:
          type: string
          description: "Specifies the event type. For a type action, this property\
            \ is \nalways set to `type`\n"
          default: type
          enum:
          - type
          x-stainless-const: true
      description: |
        An action to type in text
    AssistantToolsFileSearchFileSearch:
      type: object
      properties:
        max_num_results:
          maximum: 50
          minimum: 1
          type: integer
          description: |
            The maximum number of results the file search tool should output. The default is 20 for `gpt-4*` models and 5 for `gpt-3.5-turbo`. This number should be between 1 and 50 inclusive.

            Note that the file search tool may output fewer than `max_num_results` results. See the [file search tool documentation](/docs/assistants/tools/file-search#customizing-file-search-settings) for more information
          x-ballerina-name: maxNumResults
        ranking_options:
          allOf:
          - $ref: '#/components/schemas/FileSearchRankingOptions'
          x-ballerina-name: rankingOptions
      description: Overrides for the file search tool
    ChatCompletionRole:
      type: string
      description: The role of the author of a message
      enum:
      - developer
      - system
      - user
      - assistant
      - tool
      - function
    EvalJsonlFileContentSource:
      title: EvalJsonlFileContentSource
      required:
      - content
      - type
      type: object
      properties:
        type:
          type: string
          description: The type of jsonl source. Always `file_content`
          default: file_content
          enum:
          - file_content
          x-stainless-const: true
        content:
          type: array
          description: The content of the jsonl file
          items:
            $ref: '#/components/schemas/EvalJsonlFileContentSourceContent'
    UserDeleteResponse:
      required:
      - deleted
      - id
      - object
      type: object
      properties:
        deleted:
          type: boolean
        id:
          type: string
        object:
          type: string
          enum:
          - organization.user.deleted
          x-stainless-const: true
    AssistantObjectTools:
      oneOf:
      - $ref: '#/components/schemas/AssistantToolsCode'
      - $ref: '#/components/schemas/AssistantToolsFileSearch'
      - $ref: '#/components/schemas/AssistantToolsFunction'
    ImagesResponseUsageInputTokensDetails:
      required:
      - image_tokens
      - text_tokens
      type: object
      properties:
        text_tokens:
          type: integer
          description: The number of text tokens in the input prompt
          x-ballerina-name: textTokens
        image_tokens:
          type: integer
          description: The number of image tokens in the input prompt
          x-ballerina-name: imageTokens
      description: The input tokens detailed information for the image generation
    ErrorEvent:
      required:
      - data
      - event
      type: object
      properties:
        data:
          $ref: '#/components/schemas/Error'
        event:
          type: string
          enum:
          - error
          x-stainless-const: true
      description: "Occurs when an [error](/docs/guides/error-codes#api-errors) occurs.\
        \ This can happen due to an internal server error or a timeout"
      x-oaiMeta:
        dataDescription: "`data` is an [error](/docs/guides/error-codes#api-errors)"
    Model:
      title: Model
      required:
      - created
      - id
      - object
      - owned_by
      properties:
        id:
          type: string
          description: "The model identifier, which can be referenced in the API endpoints."
        created:
          type: integer
          description: The Unix timestamp (in seconds) when the model was created.
        object:
          type: string
          description: "The object type, which is always \"model\"."
          enum:
          - model
          x-stainless-const: true
        owned_by:
          type: string
          description: The organization that owns the model.
      description: Describes an OpenAI model offering that can be used with the API
      x-oaiMeta:
        name: The model object
        example: |
          {
            "id": "VAR_chat_model_id",
            "object": "model",
            "created": 1686935002,
            "owned_by": "openai"
          }
    RealtimeServerEventResponseAudioDone:
      required:
      - content_index
      - event_id
      - item_id
      - output_index
      - response_id
      - type
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event
          x-ballerina-name: eventId
        item_id:
          type: string
          description: The ID of the item
          x-ballerina-name: itemId
        content_index:
          type: integer
          description: The index of the content part in the item's content array
          x-ballerina-name: contentIndex
        response_id:
          type: string
          description: The ID of the response
          x-ballerina-name: responseId
        type:
          type: string
          description: "The event type, must be `response.audio.done`"
          enum:
          - response.audio.done
          x-stainless-const: true
        output_index:
          type: integer
          description: The index of the output item in the response
          x-ballerina-name: outputIndex
      description: |
        Returned when the model-generated audio is done. Also emitted when a Response
        is interrupted, incomplete, or cancelled
      x-oaiMeta:
        name: response.audio.done
        group: realtime
        example: |
          {
              "event_id": "event_5152",
              "type": "response.audio.done",
              "response_id": "resp_001",
              "item_id": "msg_008",
              "output_index": 0,
              "content_index": 0
          }
    ReasoningEffort:
      type: string
      description: "**o-series models only** \n\nConstrains effort on reasoning for\
        \ \n[reasoning models](https://platform.openai.com/docs/guides/reasoning).\n\
        Currently supported values are `low`, `medium`, and `high`. Reducing\nreasoning\
        \ effort can result in faster responses and fewer tokens used\non reasoning\
        \ in a response\n"
      nullable: true
      default: medium
      enum:
      - low
      - medium
      - high
    RefusalContent:
      title: Refusal
      required:
      - refusal
      - type
      type: object
      properties:
        refusal:
          type: string
          description: The refusal explanationfrom the model
        type:
          type: string
          description: The type of the refusal. Always `refusal`
          default: refusal
          enum:
          - refusal
          x-stainless-const: true
      description: A refusal from the model
    ListFilesResponse:
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
      type: object
      properties:
        first_id:
          type: string
          example: file-abc123
          x-ballerina-name: firstId
        data:
          type: array
          items:
            $ref: '#/components/schemas/OpenAIFile'
        last_id:
          type: string
          example: file-abc456
          x-ballerina-name: lastId
        has_more:
          type: boolean
          example: false
          x-ballerina-name: hasMore
        object:
          type: string
          example: list
    DataAllOf2:
      required:
      - id
      type: object
      properties:
        id:
          type: string
          description: The identifier of the chat message
    CreateVectorStoreRequest:
      type: object
      properties:
        chunking_strategy:
          type: object
          description: "The chunking strategy used to chunk the file(s). If not set,\
            \ will use the `auto` strategy. Only applicable if `file_ids` is non-empty"
          oneOf:
          - $ref: '#/components/schemas/AutoChunkingStrategyRequestParam'
          - $ref: '#/components/schemas/StaticChunkingStrategyRequestParam'
          x-ballerina-name: chunkingStrategy
        metadata:
          $ref: '#/components/schemas/Metadata'
        expires_after:
          allOf:
          - $ref: '#/components/schemas/VectorStoreExpirationAfter'
          x-ballerina-name: expiresAfter
        file_ids:
          maxItems: 500
          type: array
          description: "A list of [File](/docs/api-reference/files) IDs that the vector\
            \ store should use. Useful for tools like `file_search` that can access\
            \ files"
          items:
            type: string
          x-ballerina-name: fileIds
        name:
          type: string
          description: The name of the vector store
      additionalProperties: false
    FineTuneChatCompletionRequestAssistantMessage:
      required:
      - role
      allOf:
      - $ref: '#/components/schemas/AssistantMessage'
      - $ref: '#/components/schemas/ChatCompletionRequestAssistantMessage'
    ProjectApiKeyDeleteResponse:
      required:
      - deleted
      - id
      - object
      type: object
      properties:
        deleted:
          type: boolean
        id:
          type: string
        object:
          type: string
          enum:
          - organization.project.api_key.deleted
          x-stainless-const: true
    ResponseCodeInterpreterCallInterpretingEvent:
      required:
      - code_interpreter_call
      - output_index
      - response_id
      - type
      type: object
      properties:
        code_interpreter_call:
          allOf:
          - $ref: '#/components/schemas/CodeInterpreterToolCall'
          x-ballerina-name: codeInterpreterCall
        type:
          type: string
          description: |
            The type of the event. Always `response.code_interpreter_call.interpreting`
          enum:
          - response.code_interpreter_call.interpreting
          x-stainless-const: true
        output_index:
          type: integer
          description: |
            The index of the output item that the code interpreter call is in progress
          x-ballerina-name: outputIndex
      description: Emitted when the code interpreter is actively interpreting the
        code snippet
      x-oaiMeta:
        name: response.code_interpreter_call.interpreting
        group: responses
        example: |
          {
            "type": "response.code_interpreter_call.interpreting",
            "response_id": "resp-123",
            "output_index": 4,
            "code_interpreter_call": {}
          }
    ResponseFileSearchCallCompletedEvent:
      required:
      - item_id
      - output_index
      - type
      type: object
      properties:
        item_id:
          type: string
          description: |
            The ID of the output item that the file search call is initiated
          x-ballerina-name: itemId
        type:
          type: string
          description: |
            The type of the event. Always `response.file_search_call.completed`
          enum:
          - response.file_search_call.completed
          x-stainless-const: true
        output_index:
          type: integer
          description: |
            The index of the output item that the file search call is initiated
          x-ballerina-name: outputIndex
      description: Emitted when a file search call is completed (results found)
      x-oaiMeta:
        name: response.file_search_call.completed
        group: responses
        example: |
          {
            "type": "response.file_search_call.completed",
            "output_index": 0,
            "item_id": "fs_123",
          }
    ThreadObject:
      title: Thread
      required:
      - created_at
      - id
      - metadata
      - object
      - tool_resources
      type: object
      properties:
        tool_resources:
          allOf:
          - $ref: '#/components/schemas/ModifyThreadRequestToolResources'
          x-ballerina-name: toolResources
        metadata:
          $ref: '#/components/schemas/Metadata'
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the thread was created
          x-ballerina-name: createdAt
        id:
          type: string
          description: "The identifier, which can be referenced in API endpoints"
        object:
          type: string
          description: "The object type, which is always `thread`"
          enum:
          - thread
          x-stainless-const: true
      description: "Represents a thread that contains [messages](/docs/api-reference/messages)"
      x-oaiMeta:
        name: The thread object
        beta: true
        example: |
          {
            "id": "thread_abc123",
            "object": "thread",
            "created_at": 1698107661,
            "metadata": {}
          }
    AuditLogServiceAccountcreated:
      type: object
      properties:
        data:
          $ref: '#/components/schemas/AuditLogServiceAccountcreatedData'
        id:
          type: string
          description: The service account ID
      description: The details for events with this `type`
    ChatCompletionStreamOptions:
      type: object
      properties:
        include_usage:
          type: boolean
          description: "If set, an additional chunk will be streamed before the `data:\
            \ [DONE]`\nmessage. The `usage` field on this chunk shows the token usage\
            \ statistics\nfor the entire request, and the `choices` field will always\
            \ be an empty\narray. \n\nAll other chunks will also include a `usage`\
            \ field, but with a null\nvalue. **NOTE:** If the stream is interrupted,\
            \ you may not receive the\nfinal usage chunk which contains the total\
            \ token usage for the request\n"
          x-ballerina-name: includeUsage
      description: |
        Options for streaming response. Only set this when you set `stream: true`
      nullable: true
    CreateResponse:
      allOf:
      - $ref: '#/components/schemas/CreateModelResponseProperties'
      - $ref: '#/components/schemas/ResponseProperties'
      - $ref: '#/components/schemas/CreateResponseAllOf3'
    ListPaginatedFineTuningJobsResponse:
      required:
      - data
      - has_more
      - object
      type: object
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/FineTuningJob'
        has_more:
          type: boolean
          x-ballerina-name: hasMore
        object:
          type: string
          enum:
          - list
          x-stainless-const: true
    ListFineTuningCheckpointPermissionResponse:
      required:
      - data
      - has_more
      - object
      type: object
      properties:
        first_id:
          type: string
          nullable: true
          x-ballerina-name: firstId
        data:
          type: array
          items:
            $ref: '#/components/schemas/FineTuningCheckpointPermission'
        last_id:
          type: string
          nullable: true
          x-ballerina-name: lastId
        has_more:
          type: boolean
          x-ballerina-name: hasMore
        object:
          type: string
          enum:
          - list
          x-stainless-const: true
    AuditLog:
      required:
      - actor
      - effective_at
      - id
      - type
      type: object
      properties:
        rate_limit.updated:
          allOf:
          - $ref: '#/components/schemas/AuditLogRateLimitupdated'
          x-ballerina-name: rateLimitUpdated
        user.updated:
          allOf:
          - $ref: '#/components/schemas/AuditLogUserupdated'
          x-ballerina-name: userUpdated
        project:
          $ref: '#/components/schemas/AuditLogProject'
        certificate.deleted:
          allOf:
          - $ref: '#/components/schemas/AuditLogCertificatedeleted'
          x-ballerina-name: certificateDeleted
        service_account.deleted:
          allOf:
          - $ref: '#/components/schemas/AuditLogServiceAccountdeleted'
          x-ballerina-name: serviceAccountDeleted
        type:
          $ref: '#/components/schemas/AuditLogEventType'
        logout.failed:
          allOf:
          - $ref: '#/components/schemas/AuditLogLoginfailed'
          x-ballerina-name: logoutFailed
        certificate.updated:
          allOf:
          - $ref: '#/components/schemas/AuditLogCertificatecreated'
          x-ballerina-name: certificateUpdated
        login.failed:
          allOf:
          - $ref: '#/components/schemas/AuditLogLoginfailed'
          x-ballerina-name: loginFailed
        service_account.updated:
          allOf:
          - $ref: '#/components/schemas/AuditLogServiceAccountupdated'
          x-ballerina-name: serviceAccountUpdated
        rate_limit.deleted:
          allOf:
          - $ref: '#/components/schemas/AuditLogRateLimitdeleted'
          x-ballerina-name: rateLimitDeleted
        id:
          type: string
          description: The ID of this log
        project.created:
          allOf:
          - $ref: '#/components/schemas/AuditLogProjectcreated'
          x-ballerina-name: projectCreated
        certificate.created:
          allOf:
          - $ref: '#/components/schemas/AuditLogCertificatecreated'
          x-ballerina-name: certificateCreated
        checkpoint_permission.created:
          allOf:
          - $ref: '#/components/schemas/AuditLogCheckpointPermissioncreated'
          x-ballerina-name: checkpointPermissionCreated
        organization.updated:
          allOf:
          - $ref: '#/components/schemas/AuditLogOrganizationupdated'
          x-ballerina-name: organizationUpdated
        project.updated:
          allOf:
          - $ref: '#/components/schemas/AuditLogProjectupdated'
          x-ballerina-name: projectUpdated
        project.archived:
          allOf:
          - $ref: '#/components/schemas/AuditLogProjectarchived'
          x-ballerina-name: projectArchived
        user.added:
          allOf:
          - $ref: '#/components/schemas/AuditLogUseradded'
          x-ballerina-name: userAdded
        invite.accepted:
          allOf:
          - $ref: '#/components/schemas/AuditLogInviteaccepted'
          x-ballerina-name: inviteAccepted
        invite.deleted:
          allOf:
          - $ref: '#/components/schemas/AuditLogInviteaccepted'
          x-ballerina-name: inviteDeleted
        actor:
          $ref: '#/components/schemas/AuditLogActor'
        effective_at:
          type: integer
          description: The Unix timestamp (in seconds) of the event
          x-ballerina-name: effectiveAt
        checkpoint_permission.deleted:
          allOf:
          - $ref: '#/components/schemas/AuditLogCheckpointPermissiondeleted'
          x-ballerina-name: checkpointPermissionDeleted
        invite.sent:
          allOf:
          - $ref: '#/components/schemas/AuditLogInvitesent'
          x-ballerina-name: inviteSent
        certificates.deactivated:
          allOf:
          - $ref: '#/components/schemas/AuditLogCertificatesactivated'
          x-ballerina-name: certificatesDeactivated
        service_account.created:
          allOf:
          - $ref: '#/components/schemas/AuditLogServiceAccountcreated'
          x-ballerina-name: serviceAccountCreated
        api_key.created:
          allOf:
          - $ref: '#/components/schemas/AuditLogApiKeycreated'
          x-ballerina-name: apiKeyCreated
        user.deleted:
          allOf:
          - $ref: '#/components/schemas/AuditLogUserdeleted'
          x-ballerina-name: userDeleted
        api_key.deleted:
          allOf:
          - $ref: '#/components/schemas/AuditLogApiKeydeleted'
          x-ballerina-name: apiKeyDeleted
        certificates.activated:
          allOf:
          - $ref: '#/components/schemas/AuditLogCertificatesactivated'
          x-ballerina-name: certificatesActivated
        api_key.updated:
          allOf:
          - $ref: '#/components/schemas/AuditLogApiKeyupdated'
          x-ballerina-name: apiKeyUpdated
      description: A log of a user action or configuration change within this organization
      x-oaiMeta:
        name: The audit log object
        example: |
          {
              "id": "req_xxx_20240101",
              "type": "api_key.created",
              "effective_at": 1720804090,
              "actor": {
                  "type": "session",
                  "session": {
                      "user": {
                          "id": "user-xxx",
                          "email": "user@example.com"
                      },
                      "ip_address": "127.0.0.1",
                      "user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
                  }
              },
              "api_key.created": {
                  "id": "key_xxxx",
                  "data": {
                      "scopes": ["resource.operation"]
                  }
              }
          }
    FineTuningJobCheckpointMetrics:
      type: object
      properties:
        full_valid_mean_token_accuracy:
          type: number
          x-ballerina-name: fullValidMeanTokenAccuracy
        valid_loss:
          type: number
          x-ballerina-name: validLoss
        full_valid_loss:
          type: number
          x-ballerina-name: fullValidLoss
        train_mean_token_accuracy:
          type: number
          x-ballerina-name: trainMeanTokenAccuracy
        valid_mean_token_accuracy:
          type: number
          x-ballerina-name: validMeanTokenAccuracy
        train_loss:
          type: number
          x-ballerina-name: trainLoss
        step:
          type: number
      description: Metrics at the step number during the fine-tuning job
    RealtimeServerEventResponseCreated:
      required:
      - event_id
      - response
      - type
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event
          x-ballerina-name: eventId
        response:
          $ref: '#/components/schemas/RealtimeResponse'
        type:
          type: string
          description: "The event type, must be `response.created`"
          enum:
          - response.created
          x-stainless-const: true
      description: |
        Returned when a new Response is created. The first event of response creation,
        where the response is in an initial state of `in_progress`
      x-oaiMeta:
        name: response.created
        group: realtime
        example: |
          {
              "event_id": "event_2930",
              "type": "response.created",
              "response": {
                  "id": "resp_001",
                  "object": "realtime.response",
                  "status": "in_progress",
                  "status_details": null,
                  "output": [],
                  "usage": null
              }
          }
    Filters:
      anyOf:
      - $ref: '#/components/schemas/ComparisonFilter'
      - $ref: '#/components/schemas/CompoundFilter'
    ChatCompletionRequestSystemMessageContentPart:
      oneOf:
      - $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartText'
    ChatCompletionRequestAssistantMessage:
      title: Assistant message
      required:
      - role
      type: object
      properties:
        role:
          type: string
          description: "The role of the messages author, in this case `assistant`"
          enum:
          - assistant
          x-stainless-const: true
        function_call:
          allOf:
          - $ref: '#/components/schemas/ChatCompletionRequestAssistantMessageFunctionCall'
          x-ballerina-name: functionCall
        refusal:
          type: string
          description: The refusal message by the assistant
          nullable: true
        name:
          type: string
          description: An optional name for the participant. Provides the model information
            to differentiate between participants of the same role
        tool_calls:
          allOf:
          - $ref: '#/components/schemas/ChatCompletionMessageToolCalls'
          x-ballerina-name: toolCalls
        audio:
          $ref: '#/components/schemas/ChatCompletionRequestAssistantMessageAudio'
        content:
          description: |
            The contents of the assistant message. Required unless `tool_calls` or `function_call` is specified
          nullable: true
          oneOf:
          - title: Text content
            type: string
            description: The contents of the assistant message.
          - title: Array of content parts
            minItems: 1
            type: array
            description: "An array of content parts with a defined type. Can be one\
              \ or more of type `text`, or exactly one of type `refusal`."
            items:
              $ref: '#/components/schemas/ChatCompletionRequestAssistantMessageContentPart'
      description: |
        Messages sent by the model in response to user messages
    ListVectorStoresResponse:
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
      properties:
        object:
          type: string
          example: list
        data:
          type: array
          items:
            $ref: '#/components/schemas/VectorStoreObject'
        first_id:
          type: string
          example: vs_abc123
        last_id:
          type: string
          example: vs_abc456
        has_more:
          type: boolean
          example: false
    RunStepDeltaObject:
      title: Run step delta object
      required:
      - delta
      - id
      - object
      type: object
      properties:
        delta:
          $ref: '#/components/schemas/RunStepDeltaObjectDelta'
        id:
          type: string
          description: "The identifier of the run step, which can be referenced in\
            \ API endpoints"
        object:
          type: string
          description: "The object type, which is always `thread.run.step.delta`"
          enum:
          - thread.run.step.delta
          x-stainless-const: true
      description: |
        Represents a run step delta i.e. any changed fields on a run step during streaming
      x-oaiMeta:
        name: The run step delta object
        beta: true
        example: |
          {
            "id": "step_123",
            "object": "thread.run.step.delta",
            "delta": {
              "step_details": {
                "type": "tool_calls",
                "tool_calls": [
                  {
                    "index": 0,
                    "id": "call_123",
                    "type": "code_interpreter",
                    "code_interpreter": { "input": "", "outputs": [] }
                  }
                ]
              }
            }
          }
    RunStepObjectLastError:
      required:
      - code
      - message
      type: object
      properties:
        code:
          type: string
          description: One of `server_error` or `rate_limit_exceeded`
          enum:
          - server_error
          - rate_limit_exceeded
        message:
          type: string
          description: A human-readable description of the error
      description: The last error associated with this run step. Will be `null` if
        there are no errors
      nullable: true
    RunStepDetailsToolCallsCodeObject:
      title: Code Interpreter tool call
      required:
      - code_interpreter
      - id
      - type
      type: object
      properties:
        code_interpreter:
          allOf:
          - $ref: '#/components/schemas/RunStepDetailsToolCallsCodeObjectCodeInterpreter'
          x-ballerina-name: codeInterpreter
        id:
          type: string
          description: The ID of the tool call
        type:
          type: string
          description: The type of tool call. This is always going to be `code_interpreter`
            for this type of tool call
          enum:
          - code_interpreter
          x-stainless-const: true
      description: Details of the Code Interpreter tool call the run step was involved
        in
    ChatCompletionRequestToolMessageContentPart:
      oneOf:
      - $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartText'
    CreateModerationResponse:
      required:
      - id
      - model
      - results
      type: object
      properties:
        model:
          type: string
          description: The model used to generate the moderation results
        id:
          type: string
          description: The unique identifier for the moderation request
        results:
          type: array
          description: A list of moderation objects
          items:
            $ref: '#/components/schemas/CreateModerationResponseResults'
      description: Represents if a given text input is potentially harmful
      x-oaiMeta:
        name: The moderation object
        example: |
          {
            "id": "modr-0d9740456c391e43c445bf0f010940c7",
            "model": "omni-moderation-latest",
            "results": [
              {
                "flagged": true,
                "categories": {
                  "harassment": true,
                  "harassment/threatening": true,
                  "sexual": false,
                  "hate": false,
                  "hate/threatening": false,
                  "illicit": false,
                  "illicit/violent": false,
                  "self-harm/intent": false,
                  "self-harm/instructions": false,
                  "self-harm": false,
                  "sexual/minors": false,
                  "violence": true,
                  "violence/graphic": true
                },
                "category_scores": {
                  "harassment": 0.8189693396524255,
                  "harassment/threatening": 0.804985420696006,
                  "sexual": 1.573112165348997e-6,
                  "hate": 0.007562942636942845,
                  "hate/threatening": 0.004208854591835476,
                  "illicit": 0.030535955153511665,
                  "illicit/violent": 0.008925306722380033,
                  "self-harm/intent": 0.00023023930975076432,
                  "self-harm/instructions": 0.0002293869201073356,
                  "self-harm": 0.012598046106750154,
                  "sexual/minors": 2.212566909570261e-8,
                  "violence": 0.9999992735124786,
                  "violence/graphic": 0.843064871157054
                },
                "category_applied_input_types": {
                  "harassment": [
                    "text"
                  ],
                  "harassment/threatening": [
                    "text"
                  ],
                  "sexual": [
                    "text",
                    "image"
                  ],
                  "hate": [
                    "text"
                  ],
                  "hate/threatening": [
                    "text"
                  ],
                  "illicit": [
                    "text"
                  ],
                  "illicit/violent": [
                    "text"
                  ],
                  "self-harm/intent": [
                    "text",
                    "image"
                  ],
                  "self-harm/instructions": [
                    "text",
                    "image"
                  ],
                  "self-harm": [
                    "text",
                    "image"
                  ],
                  "sexual/minors": [
                    "text"
                  ],
                  "violence": [
                    "text",
                    "image"
                  ],
                  "violence/graphic": [
                    "text",
                    "image"
                  ]
                }
              }
            ]
          }
    AuditLogApiKeyupdatedChangesRequested:
      type: object
      properties:
        scopes:
          type: array
          description: "A list of scopes allowed for the API key, e.g. `[\"api.model.request\"\
            ]`"
          items:
            type: string
      description: The payload used to update the API key
    AuditLogUserupdated:
      type: object
      properties:
        changes_requested:
          allOf:
          - $ref: '#/components/schemas/AuditLogUserupdatedChangesRequested'
          x-ballerina-name: changesRequested
        id:
          type: string
          description: The project ID
      description: The details for events with this `type`
    ItemReferenceParam:
      title: Item reference
      required:
      - id
      type: object
      properties:
        id:
          type: string
          description: The ID of the item to reference
        type:
          anyOf:
          - type: string
            description: The type of item to reference. Always `item_reference`.
            default: item_reference
            enum:
            - item_reference
            x-stainless-const: true
          - nullable: true
      description: An internal identifier for an item to reference
    MessageContentTextAnnotationsFilePathObjectFilePath:
      required:
      - file_id
      type: object
      properties:
        file_id:
          type: string
          description: The ID of the file that was generated
          x-ballerina-name: fileId
    ResponseReasoningSummaryPartDoneEventPart:
      required:
      - text
      - type
      type: object
      properties:
        text:
          type: string
          description: The text of the summary part
        type:
          type: string
          description: The type of the summary part. Always `summary_text`
          enum:
          - summary_text
          x-stainless-const: true
      description: |
        The completed summary part
    CreateThreadAndRunRequestToolResources:
      type: object
      properties:
        code_interpreter:
          allOf:
          - $ref: '#/components/schemas/CreateAssistantRequestToolResourcesCodeInterpreter'
          x-ballerina-name: codeInterpreter
        file_search:
          allOf:
          - $ref: '#/components/schemas/AssistantObjectToolResourcesFileSearch'
          x-ballerina-name: fileSearch
      description: |
        A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs
      nullable: true
    InviteRequestProjects:
      required:
      - id
      - role
      type: object
      properties:
        role:
          type: string
          description: Project membership role
          enum:
          - member
          - owner
        id:
          type: string
          description: Project's public ID
    ChatCompletionFunctionCallOption:
      required:
      - name
      type: object
      properties:
        name:
          type: string
          description: The name of the function to call
      description: |
        Specifying a particular function via `{"name": "my_function"}` forces the model to call that function
    OutputAudio:
      title: Output audio
      required:
      - data
      - transcript
      - type
      type: object
      properties:
        transcript:
          type: string
          description: |
            The transcript of the audio data from the model
        data:
          type: string
          description: |
            Base64-encoded audio data from the model
        type:
          type: string
          description: |
            The type of the output audio. Always `output_audio`
          enum:
          - output_audio
          x-stainless-const: true
      description: |
        An audio output from the model
    EvalRunOutputItemSample:
      required:
      - error
      - finish_reason
      - input
      - max_completion_tokens
      - model
      - output
      - seed
      - temperature
      - top_p
      - usage
      type: object
      properties:
        output:
          type: array
          description: An array of output messages
          items:
            $ref: '#/components/schemas/EvalRunOutputItemSampleOutput'
        top_p:
          type: number
          description: The top_p value used for sampling
          x-ballerina-name: topP
        input:
          type: array
          description: An array of input messages
          items:
            $ref: '#/components/schemas/EvalRunOutputItemSampleInput'
        max_completion_tokens:
          type: integer
          description: The maximum number of tokens allowed for completion
          x-ballerina-name: maxCompletionTokens
        finish_reason:
          type: string
          description: The reason why the sample generation was finished
          x-ballerina-name: finishReason
        seed:
          type: integer
          description: The seed used for generating the sample
        usage:
          $ref: '#/components/schemas/EvalRunOutputItemSampleUsage'
        temperature:
          type: number
          description: The sampling temperature used
        model:
          type: string
          description: The model used for generating the sample
        error:
          $ref: '#/components/schemas/EvalApiError'
      description: A sample containing the input and output of the evaluation run
    FineTuningJob:
      title: FineTuningJob
      required:
      - created_at
      - error
      - fine_tuned_model
      - finished_at
      - hyperparameters
      - id
      - model
      - object
      - organization_id
      - result_files
      - seed
      - status
      - trained_tokens
      - training_file
      - validation_file
      type: object
      properties:
        training_file:
          type: string
          description: "The file ID used for training. You can retrieve the training\
            \ data with the [Files API](/docs/api-reference/files/retrieve-contents)"
          x-ballerina-name: trainingFile
        result_files:
          type: array
          description: "The compiled results file ID(s) for the fine-tuning job. You\
            \ can retrieve the results with the [Files API](/docs/api-reference/files/retrieve-contents)"
          items:
            type: string
            example: file-abc123
          x-ballerina-name: resultFiles
        metadata:
          $ref: '#/components/schemas/Metadata'
        finished_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the fine-tuning job
            was finished. The value will be null if the fine-tuning job is still running
          nullable: true
          x-ballerina-name: finishedAt
        seed:
          type: integer
          description: The seed used for the fine-tuning job
        method:
          $ref: '#/components/schemas/FineTuneMethod'
        fine_tuned_model:
          type: string
          description: The name of the fine-tuned model that is being created. The
            value will be null if the fine-tuning job is still running
          nullable: true
          x-ballerina-name: fineTunedModel
        validation_file:
          type: string
          description: "The file ID used for validation. You can retrieve the validation\
            \ results with the [Files API](/docs/api-reference/files/retrieve-contents)"
          nullable: true
          x-ballerina-name: validationFile
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the fine-tuning job
            was created
          x-ballerina-name: createdAt
        error:
          $ref: '#/components/schemas/FineTuningJobError'
        estimated_finish:
          type: integer
          description: The Unix timestamp (in seconds) for when the fine-tuning job
            is estimated to finish. The value will be null if the fine-tuning job
            is not running
          nullable: true
          x-ballerina-name: estimatedFinish
        organization_id:
          type: string
          description: The organization that owns the fine-tuning job
          x-ballerina-name: organizationId
        hyperparameters:
          $ref: '#/components/schemas/FineTuningJobHyperparameters'
        model:
          type: string
          description: The base model that is being fine-tuned
        id:
          type: string
          description: "The object identifier, which can be referenced in the API\
            \ endpoints"
        trained_tokens:
          type: integer
          description: The total number of billable tokens processed by this fine-tuning
            job. The value will be null if the fine-tuning job is still running
          nullable: true
          x-ballerina-name: trainedTokens
        integrations:
          maxItems: 5
          type: array
          description: A list of integrations to enable for this fine-tuning job
          nullable: true
          items:
            $ref: '#/components/schemas/FineTuningJobIntegrations'
        object:
          type: string
          description: "The object type, which is always \"fine_tuning.job\""
          enum:
          - fine_tuning.job
          x-stainless-const: true
        status:
          type: string
          description: "The current status of the fine-tuning job, which can be either\
            \ `validating_files`, `queued`, `running`, `succeeded`, `failed`, or `cancelled`"
          enum:
          - validating_files
          - queued
          - running
          - succeeded
          - failed
          - cancelled
      description: |
        The `fine_tuning.job` object represents a fine-tuning job that has been created through the API
      x-oaiMeta:
        name: The fine-tuning job object
        example: |
          {
            "object": "fine_tuning.job",
            "id": "ftjob-abc123",
            "model": "davinci-002",
            "created_at": 1692661014,
            "finished_at": 1692661190,
            "fine_tuned_model": "ft:davinci-002:my-org:custom_suffix:7q8mpxmy",
            "organization_id": "org-123",
            "result_files": [
                "file-abc123"
            ],
            "status": "succeeded",
            "validation_file": null,
            "training_file": "file-abc123",
            "hyperparameters": {
                "n_epochs": 4,
                "batch_size": 1,
                "learning_rate_multiplier": 1.0
            },
            "trained_tokens": 5768,
            "integrations": [],
            "seed": 0,
            "estimated_finish": 0,
            "method": {
              "type": "supervised",
              "supervised": {
                "hyperparameters": {
                  "n_epochs": 4,
                  "batch_size": 1,
                  "learning_rate_multiplier": 1.0
                }
              }
            },
            "metadata": {
              "key": "value"
            }
          }
    RunStepDeltaStepDetailsToolCallsFunctionObjectFunction:
      type: object
      properties:
        output:
          type: string
          description: "The output of the function. This will be `null` if the outputs\
            \ have not been [submitted](/docs/api-reference/runs/submitToolOutputs)\
            \ yet"
          nullable: true
        name:
          type: string
          description: The name of the function
        arguments:
          type: string
          description: The arguments passed to the function
      description: The definition of the function that was called
    ChatCompletionRequestSystemMessage:
      title: System message
      required:
      - content
      - role
      type: object
      properties:
        role:
          type: string
          description: "The role of the messages author, in this case `system`"
          enum:
          - system
          x-stainless-const: true
        name:
          type: string
          description: An optional name for the participant. Provides the model information
            to differentiate between participants of the same role
        content:
          description: The contents of the system message
          oneOf:
          - title: Text content
            type: string
            description: The contents of the system message.
          - title: Array of content parts
            minItems: 1
            type: array
            description: "An array of content parts with a defined type. For system\
              \ messages, only type `text` is supported."
            items:
              $ref: '#/components/schemas/ChatCompletionRequestSystemMessageContentPart'
      description: |
        Developer-provided instructions that the model should follow, regardless of
        messages sent by the user. With o1 models and newer, use `developer` messages
        for this purpose instead
    CreateEvalJsonlRunDataSource:
      title: JsonlRunDataSource
      required:
      - source
      - type
      type: object
      properties:
        source:
          oneOf:
          - $ref: '#/components/schemas/EvalJsonlFileContentSource'
          - $ref: '#/components/schemas/EvalJsonlFileIdSource'
        type:
          type: string
          description: The type of data source. Always `jsonl`
          default: jsonl
          enum:
          - jsonl
          x-stainless-const: true
      description: "A JsonlRunDataSource object with that specifies a JSONL file that\
        \ matches the eval \n"
      x-oaiMeta:
        name: The file data source object for the eval run configuration
        group: evals
        example: |
          {
           "type": "jsonl",
           "source": {
             "type": "file_id",
             "id": "file-9GYS6xbkWgWhmE7VoLUWFg"
           }
          }
    MessageContentTextObjectText:
      required:
      - annotations
      - value
      type: object
      properties:
        annotations:
          type: array
          items:
            $ref: '#/components/schemas/MessageContentTextObjectTextAnnotations'
        value:
          type: string
          description: The data that makes up the text
    RunStreamEvent:
      oneOf:
      - $ref: '#/components/schemas/RunStreamEventOneOf1'
      - $ref: '#/components/schemas/RunStreamEventRunStreamEventOneOf12'
      - $ref: '#/components/schemas/RunStreamEventRunStreamEventRunStreamEventOneOf123'
      - $ref: '#/components/schemas/RunStreamEventRunStreamEventRunStreamEventRunStreamEventOneOf1234'
      - $ref: '#/components/schemas/RunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventOneOf12345'
      - $ref: '#/components/schemas/RunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventOneOf123456'
      - $ref: '#/components/schemas/RunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventOneOf1234567'
      - $ref: '#/components/schemas/RunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventOneOf12345678'
      - $ref: '#/components/schemas/RunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventOneOf123456789'
      - $ref: '#/components/schemas/RunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventOneOf12345678910'
    ResponseFailedEvent:
      required:
      - response
      - type
      type: object
      properties:
        response:
          $ref: '#/components/schemas/Response'
        type:
          type: string
          description: |
            The type of the event. Always `response.failed`
          enum:
          - response.failed
          x-stainless-const: true
      description: |
        An event that is emitted when a response fails
      x-oaiMeta:
        name: response.failed
        group: responses
        example: |
          {
            "type": "response.failed",
            "response": {
              "id": "resp_123",
              "object": "response",
              "created_at": 1740855869,
              "status": "failed",
              "error": {
                "code": "server_error",
                "message": "The model failed to generate a response."
              },
              "incomplete_details": null,
              "instructions": null,
              "max_output_tokens": null,
              "model": "gpt-4o-mini-2024-07-18",
              "output": [],
              "previous_response_id": null,
              "reasoning_effort": null,
              "store": false,
              "temperature": 1,
              "text": {
                "format": {
                  "type": "text"
                }
              },
              "tool_choice": "auto",
              "tools": [],
              "top_p": 1,
              "truncation": "disabled",
              "usage": null,
              "user": null,
              "metadata": {}
            }
          }
    TranscriptTextDoneEvent:
      required:
      - text
      - type
      type: object
      properties:
        text:
          type: string
          description: |
            The text that was transcribed
        type:
          type: string
          description: |
            The type of the event. Always `transcript.text.done`
          enum:
          - transcript.text.done
          x-stainless-const: true
        logprobs:
          type: array
          description: |
            The log probabilities of the individual tokens in the transcription. Only included if you [create a transcription](/docs/api-reference/audio/create-transcription) with the `include[]` parameter set to `logprobs`
          items:
            $ref: '#/components/schemas/TranscriptTextDeltaEventLogprobs'
      description: "Emitted when the transcription is complete. Contains the complete\
        \ transcription text. Only emitted when you [create a transcription](/docs/api-reference/audio/create-transcription)\
        \ with the `Stream` parameter set to `true`"
      x-oaiMeta:
        name: Stream Event (transcript.text.done)
        group: transcript
        example: |
          {
            "type": "transcript.text.done",
            "text": "I see skies of blue and clouds of white, the bright blessed days, the dark sacred nights, and I think to myself, what a wonderful world."
          }
    RealtimeServerEventResponseDone:
      required:
      - event_id
      - response
      - type
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event
          x-ballerina-name: eventId
        response:
          $ref: '#/components/schemas/RealtimeResponse'
        type:
          type: string
          description: "The event type, must be `response.done`"
          enum:
          - response.done
          x-stainless-const: true
      description: "Returned when a Response is done streaming. Always emitted, no\
        \ matter the \nfinal state. The Response object included in the `response.done`\
        \ event will \ninclude all output Items in the Response but will omit the\
        \ raw audio data\n"
      x-oaiMeta:
        name: response.done
        group: realtime
        example: |
          {
              "event_id": "event_3132",
              "type": "response.done",
              "response": {
                  "id": "resp_001",
                  "object": "realtime.response",
                  "status": "completed",
                  "status_details": null,
                  "output": [
                      {
                          "id": "msg_006",
                          "object": "realtime.item",
                          "type": "message",
                          "status": "completed",
                          "role": "assistant",
                          "content": [
                              {
                                  "type": "text",
                                  "text": "Sure, how can I assist you today?"
                              }
                          ]
                      }
                  ],
                  "usage": {
                      "total_tokens":275,
                      "input_tokens":127,
                      "output_tokens":148,
                      "input_token_details": {
                          "cached_tokens":384,
                          "text_tokens":119,
                          "audio_tokens":8,
                          "cached_tokens_details": {
                              "text_tokens": 128,
                              "audio_tokens": 256
                          }
                      },
                      "output_token_details": {
                        "text_tokens":36,
                        "audio_tokens":112
                      }
                  }
              }
          }
    EvalRunOutputItemSampleUsage:
      required:
      - cached_tokens
      - completion_tokens
      - prompt_tokens
      - total_tokens
      type: object
      properties:
        completion_tokens:
          type: integer
          description: The number of completion tokens generated
          x-ballerina-name: completionTokens
        prompt_tokens:
          type: integer
          description: The number of prompt tokens used
          x-ballerina-name: promptTokens
        total_tokens:
          type: integer
          description: The total number of tokens used
          x-ballerina-name: totalTokens
        cached_tokens:
          type: integer
          description: The number of tokens retrieved from cache
          x-ballerina-name: cachedTokens
      description: Token usage details for the sample
    FineTuningJobIntegrations:
      oneOf:
      - $ref: '#/components/schemas/FineTuningIntegration'
    ResponseWebSearchCallCompletedEvent:
      required:
      - item_id
      - output_index
      - type
      type: object
      properties:
        item_id:
          type: string
          description: |
            Unique ID for the output item associated with the web search call
          x-ballerina-name: itemId
        type:
          type: string
          description: |
            The type of the event. Always `response.web_search_call.completed`
          enum:
          - response.web_search_call.completed
          x-stainless-const: true
        output_index:
          type: integer
          description: |
            The index of the output item that the web search call is associated with
          x-ballerina-name: outputIndex
      description: Emitted when a web search call is completed
      x-oaiMeta:
        name: response.web_search_call.completed
        group: responses
        example: |
          {
            "type": "response.web_search_call.completed",
            "output_index": 0,
            "item_id": "ws_123",
          }
    Content:
      description: |
        Multi-modal input and output contents
      oneOf:
      - $ref: '#/components/schemas/InputContent'
      - $ref: '#/components/schemas/OutputContent'
    AuditLogApiKeyupdated:
      type: object
      properties:
        changes_requested:
          allOf:
          - $ref: '#/components/schemas/AuditLogApiKeyupdatedChangesRequested'
          x-ballerina-name: changesRequested
        id:
          type: string
          description: The tracking ID of the API key
      description: The details for events with this `type`
    OutputContent:
      oneOf:
      - $ref: '#/components/schemas/OutputTextContent'
      - $ref: '#/components/schemas/RefusalContent'
    InviteRequest:
      required:
      - email
      - role
      type: object
      properties:
        role:
          type: string
          description: '`owner` or `reader`'
          enum:
          - reader
          - owner
        projects:
          type: array
          description: "An array of projects to which membership is granted at the\
            \ same time the org invite is accepted. If omitted, the user will be invited\
            \ to the default project for compatibility with legacy behavior"
          items:
            $ref: '#/components/schemas/InviteRequestProjects'
        email:
          type: string
          description: Send an email to this address
    ListFineTuningJobEventsResponse:
      required:
      - data
      - has_more
      - object
      type: object
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/FineTuningJobEvent'
        has_more:
          type: boolean
          x-ballerina-name: hasMore
        object:
          type: string
          enum:
          - list
          x-stainless-const: true
    ModelIdsShared:
      example: gpt-4o
      anyOf:
      - $ref: '#/components/schemas/ModelIdsSharedAnyOf1'
      - $ref: '#/components/schemas/ModelIdsSharedModelIdsSharedAnyOf12'
    ProjectUpdateRequest:
      required:
      - name
      type: object
      properties:
        name:
          type: string
          description: "The updated name of the project, this name appears in reports"
    InputMessageContentList:
      title: Input item content list
      type: array
      description: "A list of one or many input items to the model, containing different\
        \ content \ntypes\n"
      items:
        $ref: '#/components/schemas/InputContent'
    User:
      required:
      - added_at
      - email
      - id
      - name
      - object
      - role
      type: object
      properties:
        added_at:
          type: integer
          description: The Unix timestamp (in seconds) of when the user was added
          x-ballerina-name: addedAt
        role:
          type: string
          description: '`owner` or `reader`'
          enum:
          - owner
          - reader
        name:
          type: string
          description: The name of the user
        id:
          type: string
          description: "The identifier, which can be referenced in API endpoints"
        email:
          type: string
          description: The email address of the user
        object:
          type: string
          description: "The object type, which is always `organization.user`"
          enum:
          - organization.user
          x-stainless-const: true
      description: Represents an individual `user` within an organization
      x-oaiMeta:
        name: The user object
        example: |
          {
              "object": "organization.user",
              "id": "user_abc",
              "name": "First Last",
              "email": "user@example.com",
              "role": "owner",
              "added_at": 1711471533
          }
    CreateModerationResponseResults:
      required:
      - categories
      - category_applied_input_types
      - category_scores
      - flagged
      type: object
      properties:
        category_scores:
          allOf:
          - $ref: '#/components/schemas/CreateModerationResponseCategoryScores'
          x-ballerina-name: categoryScores
        flagged:
          type: boolean
          description: Whether any of the below categories are flagged
        category_applied_input_types:
          allOf:
          - $ref: '#/components/schemas/CreateModerationResponseCategoryAppliedInputTypes'
          x-ballerina-name: categoryAppliedInputTypes
        categories:
          $ref: '#/components/schemas/CreateModerationResponseCategories'
    MessageDeltaContentImageFileObject:
      title: Image file
      required:
      - index
      - type
      type: object
      properties:
        index:
          type: integer
          description: The index of the content part in the message
        image_file:
          allOf:
          - $ref: '#/components/schemas/MessageDeltaContentImageFileObjectImageFile'
          x-ballerina-name: imageFile
        type:
          type: string
          description: Always `image_file`
          enum:
          - image_file
          x-stainless-const: true
      description: "References an image [File](/docs/api-reference/files) in the content\
        \ of a message"
    RunStepDeltaStepDetailsToolCallsCodeObject:
      title: Code interpreter tool call
      required:
      - index
      - type
      type: object
      properties:
        code_interpreter:
          allOf:
          - $ref: '#/components/schemas/RunStepDeltaStepDetailsToolCallsCodeObjectCodeInterpreter'
          x-ballerina-name: codeInterpreter
        index:
          type: integer
          description: The index of the tool call in the tool calls array
        id:
          type: string
          description: The ID of the tool call
        type:
          type: string
          description: The type of tool call. This is always going to be `code_interpreter`
            for this type of tool call
          enum:
          - code_interpreter
          x-stainless-const: true
      description: Details of the Code Interpreter tool call the run step was involved
        in
    ComputerToolCallOutputResourceAllOf2:
      required:
      - id
      type: object
    FunctionObject:
      required:
      - name
      type: object
      properties:
        name:
          type: string
          description: "The name of the function to be called. Must be a-z, A-Z, 0-9,\
            \ or contain underscores and dashes, with a maximum length of 64"
        description:
          type: string
          description: "A description of what the function does, used by the model\
            \ to choose when and how to call the function"
        strict:
          type: boolean
          description: "Whether to enable strict schema adherence when generating\
            \ the function call. If set to true, the model will follow the exact schema\
            \ defined in the `parameters` field. Only a subset of JSON Schema is supported\
            \ when `strict` is `true`. Learn more about Structured Outputs in the\
            \ [function calling guide](docs/guides/function-calling)"
          nullable: true
          default: false
        parameters:
          $ref: '#/components/schemas/FunctionParameters'
    ResponseErrorCode:
      type: string
      description: |
        The error code for the response
      enum:
      - server_error
      - rate_limit_exceeded
      - invalid_prompt
      - vector_store_timeout
      - invalid_image
      - invalid_image_format
      - invalid_base64_image
      - invalid_image_url
      - image_too_large
      - image_too_small
      - image_parse_error
      - image_content_policy_violation
      - invalid_image_mode
      - image_file_too_large
      - unsupported_image_media_type
      - empty_image_file
      - failed_to_download_image
      - image_file_not_found
    EvalRunPerTestingCriteriaResults:
      required:
      - failed
      - passed
      - testing_criteria
      type: object
      properties:
        testing_criteria:
          type: string
          description: A description of the testing criteria
          x-ballerina-name: testingCriteria
        passed:
          type: integer
          description: Number of tests passed for this criteria
        failed:
          type: integer
          description: Number of tests failed for this criteria
    RealtimeServerEventOutputAudioBufferStopped:
      required:
      - event_id
      - response_id
      - type
      type: object
      properties:
        event_id:
          type: string
          description: The unique ID of the server event
          x-ballerina-name: eventId
        response_id:
          type: string
          description: The unique ID of the response that produced the audio
          x-ballerina-name: responseId
        type:
          type: string
          description: "The event type, must be `output_audio_buffer.stopped`"
          enum:
          - output_audio_buffer.stopped
          x-stainless-const: true
      description: |
        **WebRTC Only:** Emitted when the output audio buffer has been completely drained on the server,
        and no more audio is forthcoming. This event is emitted after the full response
        data has been sent to the client (`response.done`).
        [Learn more](/docs/guides/realtime-model-capabilities#client-and-server-events-for-audio-in-webrtc)
      x-oaiMeta:
        name: output_audio_buffer.stopped
        group: realtime
        example: |
          {
              "event_id": "event_abc123",
              "type": "output_audio_buffer.stopped",
              "response_id": "resp_abc123"
          }
    RankingOptions:
      type: object
      properties:
        score_threshold:
          type: number
          description: "The score threshold for the file search, a number between\
            \ 0 and 1. Numbers closer to 1 will attempt to return only the most relevant\
            \ results, but may return fewer results"
          x-ballerina-name: scoreThreshold
        ranker:
          type: string
          description: The ranker to use for the file search
          enum:
          - auto
          - default-2024-11-15
    CompletionscompletionIdBody:
      required:
      - metadata
      type: object
      properties:
        metadata:
          $ref: '#/components/schemas/Metadata'
    Move:
      title: Move
      required:
      - type
      - x
      - "y"
      type: object
      properties:
        x:
          type: integer
          description: |
            The x-coordinate to move to
        "y":
          type: integer
          description: |
            The y-coordinate to move to
        type:
          type: string
          description: "Specifies the event type. For a move action, this property\
            \ is \nalways set to `move`\n"
          default: move
          enum:
          - move
          x-stainless-const: true
      description: |
        A mouse move action
    InviteListResponse:
      required:
      - data
      - object
      type: object
      properties:
        first_id:
          type: string
          description: The first `invite_id` in the retrieved `list`
          x-ballerina-name: firstId
        data:
          type: array
          items:
            $ref: '#/components/schemas/Invite'
        last_id:
          type: string
          description: The last `invite_id` in the retrieved `list`
          x-ballerina-name: lastId
        has_more:
          type: boolean
          description: The `has_more` property is used for pagination to indicate
            there are additional results
          x-ballerina-name: hasMore
        object:
          type: string
          description: "The object type, which is always `list`"
          enum:
          - list
          x-stainless-const: true
    FineTuneSupervisedMethod:
      type: object
      properties:
        hyperparameters:
          $ref: '#/components/schemas/FineTuneSupervisedMethodHyperparameters'
      description: Configuration for the supervised fine-tuning method
    CreateAssistantRequest:
      required:
      - model
      type: object
      properties:
        reasoning_effort:
          allOf:
          - $ref: '#/components/schemas/ReasoningEffort'
          x-ballerina-name: reasoningEffort
        top_p:
          maximum: 1
          minimum: 0
          type: number
          description: |
            An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

            We generally recommend altering this or temperature but not both
          nullable: true
          example: 1
          default: 1
          x-ballerina-name: topP
        instructions:
          maxLength: 256000
          type: string
          description: |
            The system instructions that the assistant uses. The maximum length is 256,000 characters
          nullable: true
        tool_resources:
          allOf:
          - $ref: '#/components/schemas/CreateAssistantRequestToolResources'
          x-ballerina-name: toolResources
        metadata:
          $ref: '#/components/schemas/Metadata'
        response_format:
          allOf:
          - $ref: '#/components/schemas/AssistantsApiResponseFormatOption'
          x-ballerina-name: responseFormat
        name:
          maxLength: 256
          type: string
          description: |
            The name of the assistant. The maximum length is 256 characters
          nullable: true
        temperature:
          maximum: 2
          minimum: 0
          type: number
          description: |
            What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic
          nullable: true
          example: 1
          default: 1
        description:
          maxLength: 512
          type: string
          description: |
            The description of the assistant. The maximum length is 512 characters
          nullable: true
        model:
          description: |
            ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them
          example: gpt-4o
          anyOf:
          - type: string
          - $ref: '#/components/schemas/AssistantSupportedModels'
          x-oaiTypeLabel: string
        tools:
          maxItems: 128
          type: array
          description: |
            A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`
          items:
            $ref: '#/components/schemas/AssistantObjectTools'
          default: []
      additionalProperties: false
    DeleteVectorStoreResponse:
      required:
      - deleted
      - id
      - object
      type: object
      properties:
        deleted:
          type: boolean
        id:
          type: string
        object:
          type: string
          enum:
          - vector_store.deleted
          x-stainless-const: true
    DeleteAssistantResponse:
      required:
      - deleted
      - id
      - object
      type: object
      properties:
        deleted:
          type: boolean
        id:
          type: string
        object:
          type: string
          enum:
          - assistant.deleted
          x-stainless-const: true
    CreateAssistantRequestToolResourcesCodeInterpreter:
      type: object
      properties:
        file_ids:
          maxItems: 20
          type: array
          description: |
            A list of [file](/docs/api-reference/files) IDs made available to the `code_interpreter` tool. There can be a maximum of 20 files associated with the tool
          items:
            type: string
          default: []
          x-ballerina-name: fileIds
    CreateEvalItem:
      title: CreateEvalItem
      type: object
      description: "A chat message that makes up the prompt or context. May include\
        \ variable references to the \"item\" namespace, ie {{item.name}}"
      oneOf:
      - $ref: '#/components/schemas/SimpleInputMessage'
      - $ref: '#/components/schemas/EvalItem'
      x-oaiMeta:
        name: The chat message object used to configure an individual run
    FilePath:
      title: File path
      required:
      - file_id
      - index
      - type
      type: object
      properties:
        file_id:
          type: string
          description: |
            The ID of the file
          x-ballerina-name: fileId
        index:
          type: integer
          description: |
            The index of the file in the list of files
        type:
          type: string
          description: |
            The type of the file path. Always `file_path`
          enum:
          - file_path
          x-stainless-const: true
      description: |
        A path to a file
    RealtimeTranscriptionSessionCreateResponse:
      required:
      - client_secret
      type: object
      properties:
        input_audio_format:
          type: string
          description: |
            The format of input audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`
          x-ballerina-name: inputAudioFormat
        modalities:
          type: array
          description: |
            The set of modalities the model can respond with. To disable audio,
            set this to ["text"]
          items:
            type: string
            enum:
            - text
            - audio
        input_audio_transcription:
          allOf:
          - $ref: '#/components/schemas/RealtimeTranscriptionSessionCreateResponseInputAudioTranscription'
          x-ballerina-name: inputAudioTranscription
        turn_detection:
          allOf:
          - $ref: '#/components/schemas/RealtimeSessionCreateResponseTurnDetection'
          x-ballerina-name: turnDetection
        client_secret:
          allOf:
          - $ref: '#/components/schemas/RealtimeTranscriptionSessionCreateResponseClientSecret'
          x-ballerina-name: clientSecret
      description: "A new Realtime transcription session configuration.\n\nWhen a\
        \ session is created on the server via REST API, the session object\nalso\
        \ contains an ephemeral key. Default TTL for keys is one minute. This \nproperty\
        \ is not present when a session is updated via the WebSocket API\n"
      x-oaiMeta:
        name: The transcription session object
        group: realtime
        example: |
          {
            "id": "sess_BBwZc7cFV3XizEyKGDCGL",
            "object": "realtime.transcription_session",
            "expires_at": 1742188264,
            "modalities": ["audio", "text"],
            "turn_detection": {
              "type": "server_vad",
              "threshold": 0.5,
              "prefix_padding_ms": 300,
              "silence_duration_ms": 200
            },
            "input_audio_format": "pcm16",
            "input_audio_transcription": {
              "model": "gpt-4o-transcribe",
              "language": null,
              "prompt": ""
            },
            "client_secret": null
          }
    RunStepDetailsToolCallsFileSearchObject:
      title: File search tool call
      required:
      - file_search
      - id
      - type
      type: object
      properties:
        file_search:
          allOf:
          - $ref: '#/components/schemas/RunStepDetailsToolCallsFileSearchObjectFileSearch'
          x-ballerina-name: fileSearch
        id:
          type: string
          description: The ID of the tool call object
        type:
          type: string
          description: The type of tool call. This is always going to be `file_search`
            for this type of tool call
          enum:
          - file_search
          x-stainless-const: true
    ResponseFormatText:
      title: Text
      required:
      - type
      type: object
      properties:
        type:
          type: string
          description: The type of response format being defined. Always `text`
          enum:
          - text
          x-stainless-const: true
      description: |
        Default response format. Used to generate text responses
    RunStreamEventRunStreamEventRunStreamEventRunStreamEventOneOf1234:
      required:
      - data
      - event
      type: object
      properties:
        data:
          $ref: '#/components/schemas/RunObject'
        event:
          type: string
          enum:
          - thread.run.requires_action
          x-stainless-const: true
      description: "Occurs when a [run](/docs/api-reference/runs/object) moves to\
        \ a `requires_action` status"
      x-oaiMeta:
        dataDescription: "`data` is a [run](/docs/api-reference/runs/object)"
    InputMessageResource:
      allOf:
      - $ref: '#/components/schemas/InputMessage'
      - $ref: '#/components/schemas/InputMessageResourceAllOf2'
    AuditLogServiceAccountdeleted:
      type: object
      properties:
        id:
          type: string
          description: The service account ID
      description: The details for events with this `type`
    ChatCompletionRequestDeveloperMessage:
      title: Developer message
      required:
      - content
      - role
      type: object
      properties:
        role:
          type: string
          description: "The role of the messages author, in this case `developer`"
          enum:
          - developer
          x-stainless-const: true
        name:
          type: string
          description: An optional name for the participant. Provides the model information
            to differentiate between participants of the same role
        content:
          description: The contents of the developer message
          oneOf:
          - title: Text content
            type: string
            description: The contents of the developer message.
          - title: Array of content parts
            minItems: 1
            type: array
            description: "An array of content parts with a defined type. For developer\
              \ messages, only type `text` is supported."
            items:
              $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartText'
      description: |
        Developer-provided instructions that the model should follow, regardless of
        messages sent by the user. With o1 models and newer, `developer` messages
        replace the previous `system` messages
    CreateChatCompletionResponse:
      required:
      - choices
      - created
      - id
      - model
      - object
      type: object
      properties:
        created:
          type: integer
          description: The Unix timestamp (in seconds) of when the chat completion
            was created
        usage:
          $ref: '#/components/schemas/CompletionUsage'
        model:
          type: string
          description: The model used for the chat completion
        service_tier:
          allOf:
          - $ref: '#/components/schemas/ServiceTier'
          x-ballerina-name: serviceTier
        id:
          type: string
          description: A unique identifier for the chat completion
        choices:
          type: array
          description: A list of chat completion choices. Can be more than one if
            `n` is greater than 1
          items:
            $ref: '#/components/schemas/CreateChatCompletionResponseChoices'
        system_fingerprint:
          type: string
          description: |
            This fingerprint represents the backend configuration that the model runs with.

            Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism
          x-ballerina-name: systemFingerprint
        object:
          type: string
          description: "The object type, which is always `chat.completion`"
          enum:
          - chat.completion
          x-stainless-const: true
      description: "Represents a chat completion response returned by model, based\
        \ on the provided input"
      x-oaiMeta:
        name: The chat completion object
        group: chat
        example: |
          {
            "id": "chatcmpl-B9MHDbslfkBeAs8l4bebGdFOJ6PeG",
            "object": "chat.completion",
            "created": 1741570283,
            "model": "gpt-4o-2024-08-06",
            "choices": [
              {
                "index": 0,
                "message": {
                  "role": "assistant",
                  "content": "The image shows a wooden boardwalk path running through a lush green field or meadow. The sky is bright blue with some scattered clouds, giving the scene a serene and peaceful atmosphere. Trees and shrubs are visible in the background.",
                  "refusal": null,
                  "annotations": []
                },
                "logprobs": null,
                "finish_reason": "stop"
              }
            ],
            "usage": {
              "prompt_tokens": 1117,
              "completion_tokens": 46,
              "total_tokens": 1163,
              "prompt_tokens_details": {
                "cached_tokens": 0,
                "audio_tokens": 0
              },
              "completion_tokens_details": {
                "reasoning_tokens": 0,
                "audio_tokens": 0,
                "accepted_prediction_tokens": 0,
                "rejected_prediction_tokens": 0
              }
            },
            "service_tier": "default",
            "system_fingerprint": "fp_fc9f1d7035"
          }
    ChatCompletionRequestToolMessage:
      title: Tool message
      required:
      - content
      - role
      - tool_call_id
      type: object
      properties:
        role:
          type: string
          description: "The role of the messages author, in this case `tool`"
          enum:
          - tool
          x-stainless-const: true
        tool_call_id:
          type: string
          description: Tool call that this message is responding to
          x-ballerina-name: toolCallId
        content:
          description: The contents of the tool message
          oneOf:
          - title: Text content
            type: string
            description: The contents of the tool message.
          - title: Array of content parts
            minItems: 1
            type: array
            description: "An array of content parts with a defined type. For tool\
              \ messages, only type `text` is supported."
            items:
              $ref: '#/components/schemas/ChatCompletionRequestToolMessageContentPart'
    CreateTranslationResponseJson:
      required:
      - text
      type: object
      properties:
        text:
          type: string
    RealtimeResponseUsageOutputTokenDetails:
      type: object
      properties:
        audio_tokens:
          type: integer
          description: The number of audio tokens used in the Response
          x-ballerina-name: audioTokens
        text_tokens:
          type: integer
          description: The number of text tokens used in the Response
          x-ballerina-name: textTokens
      description: Details about the output tokens used in the Response
    CreateImageVariationRequest:
      required:
      - image
      type: object
      properties:
        image:
          type: string
          description: "The image to use as the basis for the variation(s). Must be\
            \ a valid PNG file, less than 4MB, and square"
          format: binary
        response_format:
          type: string
          description: The format in which the generated images are returned. Must
            be one of `url` or `b64_json`. URLs are only valid for 60 minutes after
            the image has been generated
          nullable: true
          example: url
          default: url
          enum:
          - url
          - b64_json
          x-ballerina-name: responseFormat
        size:
          type: string
          description: "The size of the generated images. Must be one of `256x256`,\
            \ `512x512`, or `1024x1024`"
          nullable: true
          example: 1024x1024
          default: 1024x1024
          enum:
          - 256x256
          - 512x512
          - 1024x1024
        model:
          description: The model to use for image generation. Only `dall-e-2` is supported
            at this time
          nullable: true
          example: dall-e-2
          anyOf:
          - type: string
          - type: string
            enum:
            - dall-e-2
            x-stainless-const: true
          default: dall-e-2
          x-oaiTypeLabel: string
        user:
          type: string
          description: |
            A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids)
          example: user-1234
        "n":
          maximum: 10
          minimum: 1
          type: integer
          description: The number of images to generate. Must be between 1 and 10
          nullable: true
          example: 1
          default: 1
    UploadCertificateRequest:
      required:
      - content
      type: object
      properties:
        name:
          type: string
          description: An optional name for the certificate
        content:
          type: string
          description: The certificate content in PEM format
    MessageStreamEventOneOf1:
      required:
      - data
      - event
      type: object
      properties:
        data:
          $ref: '#/components/schemas/MessageObject'
        event:
          type: string
          enum:
          - thread.message.created
          x-stainless-const: true
      description: "Occurs when a [message](/docs/api-reference/messages/object) is\
        \ created"
      x-oaiMeta:
        dataDescription: "`data` is a [message](/docs/api-reference/messages/object)"
    DeleteThreadResponse:
      required:
      - deleted
      - id
      - object
      type: object
      properties:
        deleted:
          type: boolean
        id:
          type: string
        object:
          type: string
          enum:
          - thread.deleted
          x-stainless-const: true
    Response:
      allOf:
      - $ref: '#/components/schemas/ModelResponseProperties'
      - $ref: '#/components/schemas/ResponseProperties'
      - $ref: '#/components/schemas/ResponseAllOf3'
    FineTunePreferenceRequestInputPreferredCompletion:
      oneOf:
      - $ref: '#/components/schemas/ChatCompletionRequestAssistantMessage'
    EvalPythonGrader:
      title: PythonGrader
      required:
      - name
      - source
      - type
      type: object
      properties:
        pass_threshold:
          type: number
          description: The threshold for the score
          x-ballerina-name: passThreshold
        name:
          type: string
          description: The name of the grader
        source:
          type: string
          description: The source code of the python script
        image_tag:
          type: string
          description: The image tag to use for the python script
          x-ballerina-name: imageTag
        type:
          type: string
          description: "The object type, which is always `python`"
          enum:
          - python
          x-stainless-const: true
      description: |
        A PythonGrader object that runs a python script on the input
      x-oaiMeta:
        name: The eval python grader object
        group: evals
        example: |
          {
            "type": "string_check",
            "name": "Example string check grader",
            "input": "{{sample.output_text}}",
            "reference": "{{item.label}}",
            "operation": "eq"
          }
    AuditLogEventType:
      type: string
      description: The event type
      enum:
      - api_key.created
      - api_key.updated
      - api_key.deleted
      - checkpoint_permission.created
      - checkpoint_permission.deleted
      - invite.sent
      - invite.accepted
      - invite.deleted
      - login.succeeded
      - login.failed
      - logout.succeeded
      - logout.failed
      - organization.updated
      - project.created
      - project.updated
      - project.archived
      - service_account.created
      - service_account.updated
      - service_account.deleted
      - rate_limit.updated
      - rate_limit.deleted
      - user.added
      - user.updated
      - user.deleted
    ChatCompletionRequestMessageContentPartRefusal:
      title: Refusal content part
      required:
      - refusal
      - type
      type: object
      properties:
        refusal:
          type: string
          description: The refusal message generated by the model
        type:
          type: string
          description: The type of the content part
          enum:
          - refusal
          x-stainless-const: true
    RunStepDetailsMessageCreationObject:
      title: Message creation
      required:
      - message_creation
      - type
      type: object
      properties:
        message_creation:
          allOf:
          - $ref: '#/components/schemas/RunStepDetailsMessageCreationObjectMessageCreation'
          x-ballerina-name: messageCreation
        type:
          type: string
          description: Always `message_creation`
          enum:
          - message_creation
          x-stainless-const: true
      description: Details of the message creation by the run step
    JSONSchema:
      title: JSON schema
      required:
      - name
      type: object
      properties:
        schema:
          $ref: '#/components/schemas/ResponseFormatJsonSchemaSchema'
        name:
          type: string
          description: |
            The name of the response format. Must be a-z, A-Z, 0-9, or contain
            underscores and dashes, with a maximum length of 64
        description:
          type: string
          description: |
            A description of what the response format is for, used by the model to
            determine how to respond in the format
        strict:
          type: boolean
          description: |
            Whether to enable strict schema adherence when generating the output.
            If set to true, the model will always follow the exact schema defined
            in the `schema` field. Only a subset of JSON Schema is supported when
            `strict` is `true`. To learn more, read the [Structured Outputs
            guide](/docs/guides/structured-outputs)
          nullable: true
          default: false
      description: |
        Structured Outputs configuration options, including a JSON Schema
    ResponsePropertiesText:
      type: object
      properties:
        format:
          $ref: '#/components/schemas/TextResponseFormatConfiguration'
      description: |
        Configuration options for a text response from the model. Can be plain
        text or structured JSON data. Learn more:
        - [Text inputs and outputs](/docs/guides/text)
        - [Structured Outputs](/docs/guides/structured-outputs)
  securitySchemes:
    ApiKeyAuth:
      type: http
      scheme: bearer
x-oaiMeta:
  navigationGroups:
  - id: responses
    title: Responses
  - id: chat
    title: Chat Completions
  - id: realtime
    title: Realtime
    beta: true
  - id: endpoints
    title: Platform APIs
  - id: vector_stores
    title: Vector stores
  - id: assistants
    title: Assistants
    beta: true
  - id: administration
    title: Administration
  - id: legacy
    title: Legacy
  groups:
  - id: responses
    title: Responses
    description: |
      OpenAI's most advanced interface for generating model responses. Supports
      text and image inputs, and text outputs. Create stateful interactions
      with the model, using the output of previous responses as input. Extend
      the model's capabilities with built-in tools for file search, web search,
      computer use, and more. Allow the model access to external systems and data
      using function calling.

      Related guides:
      - [Quickstart](/docs/quickstart?api-mode=responses)
      - [Text inputs and outputs](/docs/guides/text?api-mode=responses)
      - [Image inputs](/docs/guides/images?api-mode=responses)
      - [Structured Outputs](/docs/guides/structured-outputs?api-mode=responses)
      - [Function calling](/docs/guides/function-calling?api-mode=responses)
      - [Conversation state](/docs/guides/conversation-state?api-mode=responses)
      - [Extend the models with tools](/docs/guides/tools?api-mode=responses)
    navigationGroup: responses
    sections:
    - type: endpoint
      key: createResponse
      path: create
    - type: endpoint
      key: getResponse
      path: get
    - type: endpoint
      key: deleteResponse
      path: delete
    - type: endpoint
      key: listInputItems
      path: input-items
    - type: object
      key: Response
      path: object
    - type: object
      key: ResponseItemList
      path: list
  - id: responses-streaming
    title: Streaming
    description: |
      When you [create a Response](/docs/api-reference/responses/create) with
      `stream` set to `true`, the server will emit server-sent events to the
      client as the Response is generated. This section contains the events that
      are emitted by the server.

      [Learn more about streaming responses](/docs/guides/streaming-responses?api-mode=responses).
    navigationGroup: responses
    sections:
    - type: object
      key: ResponseCreatedEvent
      path: <auto>
    - type: object
      key: ResponseInProgressEvent
      path: <auto>
    - type: object
      key: ResponseCompletedEvent
      path: <auto>
    - type: object
      key: ResponseFailedEvent
      path: <auto>
    - type: object
      key: ResponseIncompleteEvent
      path: <auto>
    - type: object
      key: ResponseOutputItemAddedEvent
      path: <auto>
    - type: object
      key: ResponseOutputItemDoneEvent
      path: <auto>
    - type: object
      key: ResponseContentPartAddedEvent
      path: <auto>
    - type: object
      key: ResponseContentPartDoneEvent
      path: <auto>
    - type: object
      key: ResponseTextDeltaEvent
      path: <auto>
    - type: object
      key: ResponseTextAnnotationDeltaEvent
      path: <auto>
    - type: object
      key: ResponseTextDoneEvent
      path: <auto>
    - type: object
      key: ResponseRefusalDeltaEvent
      path: <auto>
    - type: object
      key: ResponseRefusalDoneEvent
      path: <auto>
    - type: object
      key: ResponseFunctionCallArgumentsDeltaEvent
      path: <auto>
    - type: object
      key: ResponseFunctionCallArgumentsDoneEvent
      path: <auto>
    - type: object
      key: ResponseFileSearchCallInProgressEvent
      path: <auto>
    - type: object
      key: ResponseFileSearchCallSearchingEvent
      path: <auto>
    - type: object
      key: ResponseFileSearchCallCompletedEvent
      path: <auto>
    - type: object
      key: ResponseWebSearchCallInProgressEvent
      path: <auto>
    - type: object
      key: ResponseWebSearchCallSearchingEvent
      path: <auto>
    - type: object
      key: ResponseWebSearchCallCompletedEvent
      path: <auto>
    - type: object
      key: ResponseReasoningSummaryPartAddedEvent
      path: <auto>
    - type: object
      key: ResponseReasoningSummaryPartDoneEvent
      path: <auto>
    - type: object
      key: ResponseReasoningSummaryTextDeltaEvent
      path: <auto>
    - type: object
      key: ResponseReasoningSummaryTextDoneEvent
      path: <auto>
    - type: object
      key: ResponseErrorEvent
      path: <auto>
  - id: chat
    title: Chat Completions
    description: |
      The Chat Completions API endpoint will generate a model response from a
      list of messages comprising a conversation.

      Related guides:
      - [Quickstart](/docs/quickstart?api-mode=chat)
      - [Text inputs and outputs](/docs/guides/text?api-mode=chat)
      - [Image inputs](/docs/guides/images?api-mode=chat)
      - [Audio inputs and outputs](/docs/guides/audio?api-mode=chat)
      - [Structured Outputs](/docs/guides/structured-outputs?api-mode=chat)
      - [Function calling](/docs/guides/function-calling?api-mode=chat)
      - [Conversation state](/docs/guides/conversation-state?api-mode=chat)

      **Starting a new project?** We recommend trying [Responses](/docs/api-reference/responses)
      to take advantage of the latest OpenAI platform features. Compare
      [Chat Completions with Responses](/docs/guides/responses-vs-chat-completions?api-mode=responses).
    navigationGroup: chat
    sections:
    - type: endpoint
      key: createChatCompletion
      path: create
    - type: endpoint
      key: getChatCompletion
      path: get
    - type: endpoint
      key: getChatCompletionMessages
      path: getMessages
    - type: endpoint
      key: listChatCompletions
      path: list
    - type: endpoint
      key: updateChatCompletion
      path: update
    - type: endpoint
      key: deleteChatCompletion
      path: delete
    - type: object
      key: CreateChatCompletionResponse
      path: object
    - type: object
      key: ChatCompletionList
      path: list-object
    - type: object
      key: ChatCompletionMessageList
      path: message-list
  - id: chat-streaming
    title: Streaming
    description: |
      Stream Chat Completions in real time. Receive chunks of completions
      returned from the model using server-sent events.
      [Learn more](/docs/guides/streaming-responses?api-mode=chat).
    navigationGroup: chat
    sections:
    - type: object
      key: CreateChatCompletionStreamResponse
      path: streaming
  - id: realtime
    title: Realtime
    beta: true
    description: |
      Communicate with a GPT-4o class model in real time using WebRTC or
      WebSockets. Supports text and audio inputs and ouputs, along with audio
      transcriptions.
      [Learn more about the Realtime API](/docs/guides/realtime).
    navigationGroup: realtime
  - id: realtime-sessions
    title: Session tokens
    description: |
      REST API endpoint to generate ephemeral session tokens for use in client-side
      applications.
    navigationGroup: realtime
    sections:
    - type: endpoint
      key: create-realtime-session
      path: create
    - type: endpoint
      key: create-realtime-transcription-session
      path: create-transcription
    - type: object
      key: RealtimeSessionCreateResponse
      path: session_object
    - type: object
      key: RealtimeTranscriptionSessionCreateResponse
      path: transcription_session_object
  - id: realtime-client-events
    title: Client events
    description: |
      These are events that the OpenAI Realtime WebSocket server will accept from the client.
    navigationGroup: realtime
    sections:
    - type: object
      key: RealtimeClientEventSessionUpdate
      path: <auto>
    - type: object
      key: RealtimeClientEventInputAudioBufferAppend
      path: <auto>
    - type: object
      key: RealtimeClientEventInputAudioBufferCommit
      path: <auto>
    - type: object
      key: RealtimeClientEventInputAudioBufferClear
      path: <auto>
    - type: object
      key: RealtimeClientEventConversationItemCreate
      path: <auto>
    - type: object
      key: RealtimeClientEventConversationItemRetrieve
      path: <auto>
    - type: object
      key: RealtimeClientEventConversationItemTruncate
      path: <auto>
    - type: object
      key: RealtimeClientEventConversationItemDelete
      path: <auto>
    - type: object
      key: RealtimeClientEventResponseCreate
      path: <auto>
    - type: object
      key: RealtimeClientEventResponseCancel
      path: <auto>
    - type: object
      key: RealtimeClientEventTranscriptionSessionUpdate
      path: <auto>
    - type: object
      key: RealtimeClientEventOutputAudioBufferClear
      path: <auto>
  - id: realtime-server-events
    title: Server events
    description: |
      These are events emitted from the OpenAI Realtime WebSocket server to the client.
    navigationGroup: realtime
    sections:
    - type: object
      key: RealtimeServerEventError
      path: <auto>
    - type: object
      key: RealtimeServerEventSessionCreated
      path: <auto>
    - type: object
      key: RealtimeServerEventSessionUpdated
      path: <auto>
    - type: object
      key: RealtimeServerEventConversationCreated
      path: <auto>
    - type: object
      key: RealtimeServerEventConversationItemCreated
      path: <auto>
    - type: object
      key: RealtimeServerEventConversationItemRetrieved
      path: <auto>
    - type: object
      key: RealtimeServerEventConversationItemInputAudioTranscriptionCompleted
      path: <auto>
    - type: object
      key: RealtimeServerEventConversationItemInputAudioTranscriptionDelta
      path: <auto>
    - type: object
      key: RealtimeServerEventConversationItemInputAudioTranscriptionFailed
      path: <auto>
    - type: object
      key: RealtimeServerEventConversationItemTruncated
      path: <auto>
    - type: object
      key: RealtimeServerEventConversationItemDeleted
      path: <auto>
    - type: object
      key: RealtimeServerEventInputAudioBufferCommitted
      path: <auto>
    - type: object
      key: RealtimeServerEventInputAudioBufferCleared
      path: <auto>
    - type: object
      key: RealtimeServerEventInputAudioBufferSpeechStarted
      path: <auto>
    - type: object
      key: RealtimeServerEventInputAudioBufferSpeechStopped
      path: <auto>
    - type: object
      key: RealtimeServerEventResponseCreated
      path: <auto>
    - type: object
      key: RealtimeServerEventResponseDone
      path: <auto>
    - type: object
      key: RealtimeServerEventResponseOutputItemAdded
      path: <auto>
    - type: object
      key: RealtimeServerEventResponseOutputItemDone
      path: <auto>
    - type: object
      key: RealtimeServerEventResponseContentPartAdded
      path: <auto>
    - type: object
      key: RealtimeServerEventResponseContentPartDone
      path: <auto>
    - type: object
      key: RealtimeServerEventResponseTextDelta
      path: <auto>
    - type: object
      key: RealtimeServerEventResponseTextDone
      path: <auto>
    - type: object
      key: RealtimeServerEventResponseAudioTranscriptDelta
      path: <auto>
    - type: object
      key: RealtimeServerEventResponseAudioTranscriptDone
      path: <auto>
    - type: object
      key: RealtimeServerEventResponseAudioDelta
      path: <auto>
    - type: object
      key: RealtimeServerEventResponseAudioDone
      path: <auto>
    - type: object
      key: RealtimeServerEventResponseFunctionCallArgumentsDelta
      path: <auto>
    - type: object
      key: RealtimeServerEventResponseFunctionCallArgumentsDone
      path: <auto>
    - type: object
      key: RealtimeServerEventTranscriptionSessionUpdated
      path: <auto>
    - type: object
      key: RealtimeServerEventRateLimitsUpdated
      path: <auto>
    - type: object
      key: RealtimeServerEventOutputAudioBufferStarted
      path: <auto>
    - type: object
      key: RealtimeServerEventOutputAudioBufferStopped
      path: <auto>
    - type: object
      key: RealtimeServerEventOutputAudioBufferCleared
      path: <auto>
  - id: audio
    title: Audio
    description: |
      Learn how to turn audio into text or text into audio.

      Related guide: [Speech to text](/docs/guides/speech-to-text)
    navigationGroup: endpoints
    sections:
    - type: endpoint
      key: createSpeech
      path: createSpeech
    - type: endpoint
      key: createTranscription
      path: createTranscription
    - type: endpoint
      key: createTranslation
      path: createTranslation
    - type: object
      key: CreateTranscriptionResponseJson
      path: json-object
    - type: object
      key: CreateTranscriptionResponseVerboseJson
      path: verbose-json-object
    - type: object
      key: TranscriptTextDeltaEvent
      path: transcript-text-delta-event
    - type: object
      key: TranscriptTextDoneEvent
      path: transcript-text-done-event
  - id: images
    title: Images
    description: |
      Given a prompt and/or an input image, the model will generate a new image.
      Related guide: [Image generation](/docs/guides/images)
    navigationGroup: endpoints
    sections:
    - type: endpoint
      key: createImage
      path: create
    - type: endpoint
      key: createImageEdit
      path: createEdit
    - type: endpoint
      key: createImageVariation
      path: createVariation
    - type: object
      key: ImagesResponse
      path: object
  - id: embeddings
    title: Embeddings
    description: |
      Get a vector representation of a given input that can be easily consumed by machine learning models and algorithms.
      Related guide: [Embeddings](/docs/guides/embeddings)
    navigationGroup: endpoints
    sections:
    - type: endpoint
      key: createEmbedding
      path: create
    - type: object
      key: Embedding
      path: object
  - id: evals
    title: Evals
    description: |
      Create, manage, and run evals in the OpenAI platform.
      Related guide: [Evals](/docs/guides/evals)
    navigationGroup: endpoints
    sections:
    - type: endpoint
      key: createEval
      path: create
    - type: endpoint
      key: getEval
      path: get
    - type: endpoint
      key: updateEval
      path: update
    - type: endpoint
      key: deleteEval
      path: delete
    - type: endpoint
      key: listEvals
      path: list
    - type: endpoint
      key: getEvalRuns
      path: getRuns
    - type: endpoint
      key: getEvalRun
      path: getRun
    - type: endpoint
      key: createEvalRun
      path: createRun
    - type: endpoint
      key: cancelEvalRun
      path: cancelRun
    - type: endpoint
      key: deleteEvalRun
      path: deleteRun
    - type: endpoint
      key: getEvalRunOutputItem
      path: getRunOutputItem
    - type: endpoint
      key: getEvalRunOutputItems
      path: getRunOutputItems
    - type: object
      key: Eval
      path: object
    - type: object
      key: EvalRun
      path: run-object
    - type: object
      key: EvalRunOutputItem
      path: run-output-item-object
  - id: fine-tuning
    title: Fine-tuning
    description: |
      Manage fine-tuning jobs to tailor a model to your specific training data.
      Related guide: [Fine-tune models](/docs/guides/fine-tuning)
    navigationGroup: endpoints
    sections:
    - type: endpoint
      key: createFineTuningJob
      path: create
    - type: endpoint
      key: listPaginatedFineTuningJobs
      path: list
    - type: endpoint
      key: listFineTuningEvents
      path: list-events
    - type: endpoint
      key: listFineTuningJobCheckpoints
      path: list-checkpoints
    - type: endpoint
      key: listFineTuningCheckpointPermissions
      path: list-permissions
    - type: endpoint
      key: createFineTuningCheckpointPermission
      path: create-permission
    - type: endpoint
      key: deleteFineTuningCheckpointPermission
      path: delete-permission
    - type: endpoint
      key: retrieveFineTuningJob
      path: retrieve
    - type: endpoint
      key: cancelFineTuningJob
      path: cancel
    - type: object
      key: FineTuneChatRequestInput
      path: chat-input
    - type: object
      key: FineTunePreferenceRequestInput
      path: preference-input
    - type: object
      key: FineTuneCompletionRequestInput
      path: completions-input
    - type: object
      key: FineTuningJob
      path: object
    - type: object
      key: FineTuningJobEvent
      path: event-object
    - type: object
      key: FineTuningJobCheckpoint
      path: checkpoint-object
    - type: object
      key: FineTuningCheckpointPermission
      path: permission-object
  - id: batch
    title: Batch
    description: |
      Create large batches of API requests for asynchronous processing. The Batch API returns completions within 24 hours for a 50% discount.
      Related guide: [Batch](/docs/guides/batch)
    navigationGroup: endpoints
    sections:
    - type: endpoint
      key: createBatch
      path: create
    - type: endpoint
      key: retrieveBatch
      path: retrieve
    - type: endpoint
      key: cancelBatch
      path: cancel
    - type: endpoint
      key: listBatches
      path: list
    - type: object
      key: Batch
      path: object
    - type: object
      key: BatchRequestInput
      path: request-input
    - type: object
      key: BatchRequestOutput
      path: request-output
  - id: files
    title: Files
    description: |
      Files are used to upload documents that can be used with features like [Assistants](/docs/api-reference/assistants), [Fine-tuning](/docs/api-reference/fine-tuning), and [Batch API](/docs/guides/batch).
    navigationGroup: endpoints
    sections:
    - type: endpoint
      key: createFile
      path: create
    - type: endpoint
      key: listFiles
      path: list
    - type: endpoint
      key: retrieveFile
      path: retrieve
    - type: endpoint
      key: deleteFile
      path: delete
    - type: endpoint
      key: downloadFile
      path: retrieve-contents
    - type: object
      key: OpenAIFile
      path: object
  - id: uploads
    title: Uploads
    description: |
      Allows you to upload large files in multiple parts.
    navigationGroup: endpoints
    sections:
    - type: endpoint
      key: createUpload
      path: create
    - type: endpoint
      key: addUploadPart
      path: add-part
    - type: endpoint
      key: completeUpload
      path: complete
    - type: endpoint
      key: cancelUpload
      path: cancel
    - type: object
      key: Upload
      path: object
    - type: object
      key: UploadPart
      path: part-object
  - id: models
    title: Models
    description: |
      List and describe the various models available in the API. You can refer to the [Models](/docs/models) documentation to understand what models are available and the differences between them.
    navigationGroup: endpoints
    sections:
    - type: endpoint
      key: listModels
      path: list
    - type: endpoint
      key: retrieveModel
      path: retrieve
    - type: endpoint
      key: deleteModel
      path: delete
    - type: object
      key: Model
      path: object
  - id: moderations
    title: Moderations
    description: |
      Given text and/or image inputs, classifies if those inputs are potentially harmful across several categories.
      Related guide: [Moderations](/docs/guides/moderation)
    navigationGroup: endpoints
    sections:
    - type: endpoint
      key: createModeration
      path: create
    - type: object
      key: CreateModerationResponse
      path: object
  - id: vector-stores
    title: Vector stores
    description: |
      Vector stores power semantic search for the Retrieval API and the `file_search` tool in the Responses and Assistants APIs.

      Related guide: [File Search](/docs/assistants/tools/file-search)
    navigationGroup: vector_stores
    sections:
    - type: endpoint
      key: createVectorStore
      path: create
    - type: endpoint
      key: listVectorStores
      path: list
    - type: endpoint
      key: getVectorStore
      path: retrieve
    - type: endpoint
      key: modifyVectorStore
      path: modify
    - type: endpoint
      key: deleteVectorStore
      path: delete
    - type: endpoint
      key: searchVectorStore
      path: search
    - type: object
      key: VectorStoreObject
      path: object
  - id: vector-stores-files
    title: Vector store files
    description: |
      Vector store files represent files inside a vector store.

      Related guide: [File Search](/docs/assistants/tools/file-search)
    navigationGroup: vector_stores
    sections:
    - type: endpoint
      key: createVectorStoreFile
      path: createFile
    - type: endpoint
      key: listVectorStoreFiles
      path: listFiles
    - type: endpoint
      key: getVectorStoreFile
      path: getFile
    - type: endpoint
      key: retrieveVectorStoreFileContent
      path: getContent
    - type: endpoint
      key: updateVectorStoreFileAttributes
      path: updateAttributes
    - type: endpoint
      key: deleteVectorStoreFile
      path: deleteFile
    - type: object
      key: VectorStoreFileObject
      path: file-object
  - id: vector-stores-file-batches
    title: Vector store file batches
    description: |
      Vector store file batches represent operations to add multiple files to a vector store.
      Related guide: [File Search](/docs/assistants/tools/file-search)
    navigationGroup: vector_stores
    sections:
    - type: endpoint
      key: createVectorStoreFileBatch
      path: createBatch
    - type: endpoint
      key: getVectorStoreFileBatch
      path: getBatch
    - type: endpoint
      key: cancelVectorStoreFileBatch
      path: cancelBatch
    - type: endpoint
      key: listFilesInVectorStoreBatch
      path: listBatchFiles
    - type: object
      key: VectorStoreFileBatchObject
      path: batch-object
  - id: assistants
    title: Assistants
    beta: true
    description: |
      Build assistants that can call models and use tools to perform tasks.

      [Get started with the Assistants API](/docs/assistants)
    navigationGroup: assistants
    sections:
    - type: endpoint
      key: createAssistant
      path: createAssistant
    - type: endpoint
      key: listAssistants
      path: listAssistants
    - type: endpoint
      key: getAssistant
      path: getAssistant
    - type: endpoint
      key: modifyAssistant
      path: modifyAssistant
    - type: endpoint
      key: deleteAssistant
      path: deleteAssistant
    - type: object
      key: AssistantObject
      path: object
  - id: threads
    title: Threads
    beta: true
    description: |
      Create threads that assistants can interact with.

      Related guide: [Assistants](/docs/assistants/overview)
    navigationGroup: assistants
    sections:
    - type: endpoint
      key: createThread
      path: createThread
    - type: endpoint
      key: getThread
      path: getThread
    - type: endpoint
      key: modifyThread
      path: modifyThread
    - type: endpoint
      key: deleteThread
      path: deleteThread
    - type: object
      key: ThreadObject
      path: object
  - id: messages
    title: Messages
    beta: true
    description: |
      Create messages within threads

      Related guide: [Assistants](/docs/assistants/overview)
    navigationGroup: assistants
    sections:
    - type: endpoint
      key: createMessage
      path: createMessage
    - type: endpoint
      key: listMessages
      path: listMessages
    - type: endpoint
      key: getMessage
      path: getMessage
    - type: endpoint
      key: modifyMessage
      path: modifyMessage
    - type: endpoint
      key: deleteMessage
      path: deleteMessage
    - type: object
      key: MessageObject
      path: object
  - id: runs
    title: Runs
    beta: true
    description: |
      Represents an execution run on a thread.

      Related guide: [Assistants](/docs/assistants/overview)
    navigationGroup: assistants
    sections:
    - type: endpoint
      key: createRun
      path: createRun
    - type: endpoint
      key: createThreadAndRun
      path: createThreadAndRun
    - type: endpoint
      key: listRuns
      path: listRuns
    - type: endpoint
      key: getRun
      path: getRun
    - type: endpoint
      key: modifyRun
      path: modifyRun
    - type: endpoint
      key: submitToolOuputsToRun
      path: submitToolOutputs
    - type: endpoint
      key: cancelRun
      path: cancelRun
    - type: object
      key: RunObject
      path: object
  - id: run-steps
    title: Run steps
    beta: true
    description: |
      Represents the steps (model and tool calls) taken during the run.

      Related guide: [Assistants](/docs/assistants/overview)
    navigationGroup: assistants
    sections:
    - type: endpoint
      key: listRunSteps
      path: listRunSteps
    - type: endpoint
      key: getRunStep
      path: getRunStep
    - type: object
      key: RunStepObject
      path: step-object
  - id: assistants-streaming
    title: Streaming
    beta: true
    description: |
      Stream the result of executing a Run or resuming a Run after submitting tool outputs.
      You can stream events from the [Create Thread and Run](/docs/api-reference/runs/createThreadAndRun),
      [Create Run](/docs/api-reference/runs/createRun), and [Submit Tool Outputs](/docs/api-reference/runs/submitToolOutputs)
      endpoints by passing `"stream": true`. The response will be a [Server-Sent events](https://html.spec.whatwg.org/multipage/server-sent-events.html#server-sent-events) stream.
      Our Node and Python SDKs provide helpful utilities to make streaming easy. Reference the
      [Assistants API quickstart](/docs/assistants/overview) to learn more.
    navigationGroup: assistants
    sections:
    - type: object
      key: MessageDeltaObject
      path: message-delta-object
    - type: object
      key: RunStepDeltaObject
      path: run-step-delta-object
    - type: object
      key: AssistantStreamEvent
      path: events
  - id: administration
    title: Administration
    description: |
      Programmatically manage your organization.
      The Audit Logs endpoint provides a log of all actions taken in the organization for security and monitoring purposes.
      To access these endpoints please generate an Admin API Key through the [API Platform Organization overview](/organization/admin-keys). Admin API keys cannot be used for non-administration endpoints.
      For best practices on setting up your organization, please refer to this [guide](/docs/guides/production-best-practices#setting-up-your-organization)
    navigationGroup: administration
  - id: admin-api-keys
    title: Admin API Keys
    description: |
      Admin API keys enable Organization Owners to programmatically manage various aspects of their organization, including users, projects, and API keys. These keys provide administrative capabilities, such as creating, updating, and deleting users; managing projects; and overseeing API key lifecycles.

      Key Features of Admin API Keys:

      - User Management: Invite new users, update roles, and remove users from the organization.

      - Project Management: Create, update, archive projects, and manage user assignments within projects.

      - API Key Oversight: List, retrieve, and delete API keys associated with projects.

      Only Organization Owners have the authority to create and utilize Admin API keys. To manage these keys, Organization Owners can navigate to the Admin Keys section of their API Platform dashboard.

      For direct access to the Admin Keys management page, Organization Owners can use the following link:

      [https://platform.openai.com/settings/organization/admin-keys](https://platform.openai.com/settings/organization/admin-keys)

      It's crucial to handle Admin API keys with care due to their elevated permissions. Adhering to best practices, such as regular key rotation and assigning appropriate permissions, enhances security and ensures proper governance within the organization.
    navigationGroup: administration
    sections:
    - type: endpoint
      key: admin-api-keys-list
      path: list
    - type: endpoint
      key: admin-api-keys-create
      path: create
    - type: endpoint
      key: admin-api-keys-get
      path: listget
    - type: endpoint
      key: admin-api-keys-delete
      path: delete
    - type: object
      key: AdminApiKey
      path: object
  - id: invite
    title: Invites
    description: Invite and manage invitations for an organization.
    navigationGroup: administration
    sections:
    - type: endpoint
      key: list-invites
      path: list
    - type: endpoint
      key: inviteUser
      path: create
    - type: endpoint
      key: retrieve-invite
      path: retrieve
    - type: endpoint
      key: delete-invite
      path: delete
    - type: object
      key: Invite
      path: object
  - id: users
    title: Users
    description: |
      Manage users and their role in an organization.
    navigationGroup: administration
    sections:
    - type: endpoint
      key: list-users
      path: list
    - type: endpoint
      key: modify-user
      path: modify
    - type: endpoint
      key: retrieve-user
      path: retrieve
    - type: endpoint
      key: delete-user
      path: delete
    - type: object
      key: User
      path: object
  - id: projects
    title: Projects
    description: |
      Manage the projects within an orgnanization includes creation, updating, and archiving or projects.
      The Default project cannot be archived.
    navigationGroup: administration
    sections:
    - type: endpoint
      key: list-projects
      path: list
    - type: endpoint
      key: create-project
      path: create
    - type: endpoint
      key: retrieve-project
      path: retrieve
    - type: endpoint
      key: modify-project
      path: modify
    - type: endpoint
      key: archive-project
      path: archive
    - type: object
      key: Project
      path: object
  - id: project-users
    title: Project users
    description: |
      Manage users within a project, including adding, updating roles, and removing users.
    navigationGroup: administration
    sections:
    - type: endpoint
      key: list-project-users
      path: list
    - type: endpoint
      key: create-project-user
      path: creeate
    - type: endpoint
      key: retrieve-project-user
      path: retrieve
    - type: endpoint
      key: modify-project-user
      path: modify
    - type: endpoint
      key: delete-project-user
      path: delete
    - type: object
      key: ProjectUser
      path: object
  - id: project-service-accounts
    title: Project service accounts
    description: |
      Manage service accounts within a project. A service account is a bot user that is not associated with a user.
      If a user leaves an organization, their keys and membership in projects will no longer work. Service accounts
      do not have this limitation. However, service accounts can also be deleted from a project.
    navigationGroup: administration
    sections:
    - type: endpoint
      key: list-project-service-accounts
      path: list
    - type: endpoint
      key: create-project-service-account
      path: create
    - type: endpoint
      key: retrieve-project-service-account
      path: retrieve
    - type: endpoint
      key: delete-project-service-account
      path: delete
    - type: object
      key: ProjectServiceAccount
      path: object
  - id: project-api-keys
    title: Project API keys
    description: |
      Manage API keys for a given project. Supports listing and deleting keys for users.
      This API does not allow issuing keys for users, as users need to authorize themselves to generate keys.
    navigationGroup: administration
    sections:
    - type: endpoint
      key: list-project-api-keys
      path: list
    - type: endpoint
      key: retrieve-project-api-key
      path: retrieve
    - type: endpoint
      key: delete-project-api-key
      path: delete
    - type: object
      key: ProjectApiKey
      path: object
  - id: project-rate-limits
    title: Project rate limits
    description: |
      Manage rate limits per model for projects. Rate limits may be configured to be equal to or lower than the organization's rate limits.
    navigationGroup: administration
    sections:
    - type: endpoint
      key: list-project-rate-limits
      path: list
    - type: endpoint
      key: update-project-rate-limits
      path: update
    - type: object
      key: ProjectRateLimit
      path: object
  - id: audit-logs
    title: Audit logs
    description: |
      Logs of user actions and configuration changes within this organization.
      To log events, you must activate logging in the [Organization Settings](/settings/organization/general).
      Once activated, for security reasons, logging cannot be deactivated.
    navigationGroup: administration
    sections:
    - type: endpoint
      key: list-audit-logs
      path: list
    - type: object
      key: AuditLog
      path: object
  - id: usage
    title: Usage
    description: |
      The **Usage API** provides detailed insights into your activity across the OpenAI API. It also includes a separate [Costs endpoint](/docs/api-reference/usage/costs), which offers visibility into your spend, breaking down consumption by invoice line items and project IDs.

      While the Usage API delivers granular usage data, it may not always reconcile perfectly with the Costs due to minor differences in how usage and spend are recorded. For financial purposes, we recommend using the [Costs endpoint](/docs/api-reference/usage/costs) or the [Costs tab](/settings/organization/usage) in the Usage Dashboard, which will reconcile back to your billing invoice.
    navigationGroup: administration
    sections:
    - type: endpoint
      key: usage-completions
      path: completions
    - type: object
      key: UsageCompletionsResult
      path: completions_object
    - type: endpoint
      key: usage-embeddings
      path: embeddings
    - type: object
      key: UsageEmbeddingsResult
      path: embeddings_object
    - type: endpoint
      key: usage-moderations
      path: moderations
    - type: object
      key: UsageModerationsResult
      path: moderations_object
    - type: endpoint
      key: usage-images
      path: images
    - type: object
      key: UsageImagesResult
      path: images_object
    - type: endpoint
      key: usage-audio-speeches
      path: audio_speeches
    - type: object
      key: UsageAudioSpeechesResult
      path: audio_speeches_object
    - type: endpoint
      key: usage-audio-transcriptions
      path: audio_transcriptions
    - type: object
      key: UsageAudioTranscriptionsResult
      path: audio_transcriptions_object
    - type: endpoint
      key: usage-vector-stores
      path: vector_stores
    - type: object
      key: UsageVectorStoresResult
      path: vector_stores_object
    - type: endpoint
      key: usage-code-interpreter-sessions
      path: code_interpreter_sessions
    - type: object
      key: UsageCodeInterpreterSessionsResult
      path: code_interpreter_sessions_object
    - type: endpoint
      key: usage-costs
      path: costs
    - type: object
      key: CostsResult
      path: costs_object
  - id: certificates
    beta: true
    title: Certificates
    description: |
      Manage Mutual TLS certificates across your organization and projects.

      [Learn more about Mutual TLS.](https://help.openai.com/en/articles/10876024-openai-mutual-tls-beta-program)
    navigationGroup: administration
    sections:
    - type: endpoint
      key: uploadCertificate
      path: uploadCertificate
    - type: endpoint
      key: getCertificate
      path: getCertificate
    - type: endpoint
      key: modifyCertificate
      path: modifyCertificate
    - type: endpoint
      key: deleteCertificate
      path: deleteCertificate
    - type: endpoint
      key: listOrganizationCertificates
      path: listOrganizationCertificates
    - type: endpoint
      key: listProjectCertificates
      path: listProjectCertificates
    - type: endpoint
      key: activateOrganizationCertificates
      path: activateOrganizationCertificates
    - type: endpoint
      key: deactivateOrganizationCertificates
      path: deactivateOrganizationCertificates
    - type: endpoint
      key: activateProjectCertificates
      path: activateProjectCertificates
    - type: endpoint
      key: deactivateProjectCertificates
      path: deactivateProjectCertificates
    - type: object
      key: Certificate
      path: object
  - id: completions
    title: Completions
    legacy: true
    navigationGroup: legacy
    description: |
      Given a prompt, the model will return one or more predicted completions along with the probabilities of alternative tokens at each position. Most developer should use our [Chat Completions API](/docs/guides/text-generation#text-generation-models) to leverage our best and newest models.
    sections:
    - type: endpoint
      key: createCompletion
      path: create
    - type: object
      key: CreateCompletionResponse
      path: object
